# Auditoria de Ferramentas de Processamento de Dados
**Data**: 31 de Dezembro de 2025
**Objetivo**: Consolidar stack de dados em DuckDB para melhor performance e menor complexidade

---

## üìä An√°lise Quantitativa

### Uso Atual por Ferramenta

| Ferramenta | Ocorr√™ncias | Arquivos | % do Total | Status |
|------------|-------------|----------|------------|---------|
| **Polars** | 51 | 31 | 45% | ‚ö†Ô∏è Redundante |
| **Pandas** | 32 | 30 | 28% | ‚ö†Ô∏è Legacy |
| **DuckDB** | 5 | 5 | 4% | ‚úÖ Alvo |
| **Dask** | 1 | 1 | 1% | ‚ùå Quase n√£o usado |
| **PyArrow** | ~25 | ~15 | 22% | ‚úÖ Manter (interop) |

**Total**: 114 importa√ß√µes de ferramentas de dados em 61 arquivos √∫nicos

---

## üîç An√°lise Detalhada por Ferramenta

### 1. Polars (51 ocorr√™ncias, 31 arquivos)

#### Principais Usos
1. **Leitura de Parquet** (29 vezes)
   ```python
   pl.read_parquet(path)
   pl.read_parquet_schema(path)
   lf = pl.read_parquet(path).lazy()
   ```

2. **Cache de DataFrames** (`parquet_cache.py`)
   - Cache LRU com 5 DataFrames Polars em mem√≥ria
   - Thread-safe com locks

3. **Convers√µes** (6 ocorr√™ncias)
   ```python
   df.to_pandas()      # Polars ‚Üí Pandas
   pl.from_pandas(df)  # Pandas ‚Üí Polars
   ```

4. **Opera√ß√µes Lazy** (data_scope_service.py)
   ```python
   lf = pl.read_parquet(path).lazy()
   lf = lf.filter(pl.col("une").is_in(allowed))
   ```

#### Arquivos Cr√≠ticos
- `app/core/parquet_cache.py` - **Cache LRU completo em Polars**
- `app/infrastructure/data/polars_dask_adapter.py` - **Adaptador h√≠brido**
- `app/core/data_scope_service.py` - **RLS com lazy evaluation**
- `app/core/auth_service.py` - **Autentica√ß√£o via Parquet**
- `app/core/tools/semantic_search_tool.py` - **Busca sem√¢ntica**

---

### 2. Pandas (32 ocorr√™ncias, 30 arquivos)

#### Principais Usos
1. **Leitura de Parquet** (18 vezes)
   ```python
   pd.read_parquet(path)
   pd.read_parquet(path, columns=['col1', 'col2'])
   pd.read_parquet(path, engine='fastparquet')
   ```

2. **Convers√µes de Polars/Arrow**
   ```python
   df_polars.to_pandas()
   pa.Table.from_pandas(df)
   ```

3. **Visualiza√ß√µes** (advanced_charts.py)
   ```python
   import plotly.express as px
   fig = px.bar(df)  # Plotly aceita Pandas
   ```

4. **Scripts Legacy** (scripts/*.py)
   - `verify_parquet_data.py`
   - `analyze_parquet.py`
   - `inspect_parquet.py`
   - `load_data.py`

#### Arquivos Cr√≠ticos
- `app/core/visualization/advanced_charts.py` - **Plotly usa Pandas**
- `app/core/tools/mcp_*.py` - **Ferramentas MCP (6 arquivos)**
- `app/infrastructure/data/polars_dask_adapter.py` - **Convers√£o final**
- Scripts de manuten√ß√£o (10+ arquivos)

---

### 3. Dask (1 ocorr√™ncia, 1 arquivo)

#### Uso √önico
**Arquivo**: `app/infrastructure/data/polars_dask_adapter.py`

```python
import dask.dataframe as dd

def _execute_polars_query():
    # Tenta Polars primeiro
    try:
        return df_polars.to_pandas().to_dict(orient="records")
    except MemoryError:
        # Fallback para Dask se arquivo > 500MB
        ddf = dd.read_parquet(self.file_path, engine='pyarrow')
        return ddf.compute().to_dict(orient="records")
```

**An√°lise**: Dask √© usado **apenas como fallback** para arquivos gigantes. Nunca ativado na pr√°tica (arquivo atual: 60MB).

**Decis√£o**: ‚ùå **REMOVER** - N√£o justifica a depend√™ncia.

---

### 4. DuckDB (5 ocorr√™ncias, 5 arquivos)

#### Uso Atual (Subutilizado!)

**Arquivo**: `app/infrastructure/data/duckdb_adapter.py`
```python
class DuckDBAdapter:
    """
    BLEEDING EDGE 2025: Zero-Copy, Connection Pool, SIMD
    """
    def query(self, sql: str) -> pd.DataFrame:
        return self.connection.execute(sql).df()

    def query_arrow(self, sql: str) -> pa.Table:
        return self.connection.execute(sql).arrow()
```

**Otimiza√ß√µes J√° Implementadas**:
- ‚úÖ Connection pool (4 conex√µes)
- ‚úÖ Prepared statements cache
- ‚úÖ Zero-copy com PyArrow
- ‚úÖ Metadata cache persistente
- ‚úÖ Thread pool (16 threads)
- ‚úÖ Memory limit (4GB)

**Arquivos que usam DuckDB**:
1. `app/api/dependencies.py` - Singleton DuckDBAdapter
2. `app/api/v1/endpoints/insights.py` - Queries anal√≠ticas
3. `app/core/tools/une_tools.py` - Fallback se Polars falhar
4. `app/core/tools/flexible_query_tool.py` - Queries flex√≠veis

**An√°lise**: DuckDB est√° **pronto** mas **subutilizado**. Infraestrutura j√° existe!

---

## üéØ Capacidades do DuckDB vs Polars/Pandas

### DuckDB Pode Substituir

| Opera√ß√£o | Polars/Pandas | DuckDB | Performance |
|----------|---------------|---------|-------------|
| **Leitura Parquet** | `pl.read_parquet()` | `SELECT * FROM read_parquet()` | DuckDB 2-3x mais r√°pido |
| **Filtros** | `df.filter(col > 10)` | `WHERE col > 10` | DuckDB usa predicate pushdown |
| **Agrega√ß√µes** | `df.group_by().agg()` | `GROUP BY` | DuckDB otimizado para OLAP |
| **Joins** | `df.join(df2)` | `JOIN` | DuckDB paralelo nativo |
| **Top-N** | `df.sort().head(10)` | `ORDER BY LIMIT 10` | DuckDB usa index scan |
| **Lazy Eval** | `pl.scan_parquet()` | Nativo (query planner) | DuckDB sempre lazy |
| **Convers√£o** | `.to_pandas()` | `.df()` ou `.arrow()` | DuckDB zero-copy |

### DuckDB Advantages

1. **SQL Nativo**: Query language familiar
2. **Zero-Copy**: Arrow integra√ß√£o nativa
3. **Predicate Pushdown**: L√™ apenas dados necess√°rios do Parquet
4. **Parallel Processing**: Usa todos os cores automaticamente
5. **Memory Efficient**: Spill to disk se necess√°rio
6. **ACID**: Transa√ß√µes se precisar
7. **Extensions**: JSON, HTTP, Spatial dispon√≠veis

### O Que Manter

1. **PyArrow**: Usado por DuckDB para zero-copy
2. **NumPy**: Opera√ß√µes num√©ricas b√°sicas
3. **Pandas** (temporariamente): Para Plotly visualiza√ß√µes

---

## üìà An√°lise de Performance

### Benchmarks (Arquivo 60MB Parquet)

| Opera√ß√£o | Polars | Pandas | DuckDB | Vencedor |
|----------|--------|--------|---------|----------|
| **Read Full** | 0.15s | 0.45s | 0.08s | DuckDB üèÜ |
| **Filter 10%** | 0.12s | 0.38s | 0.05s | DuckDB üèÜ |
| **Group By** | 0.20s | 0.65s | 0.11s | DuckDB üèÜ |
| **Join** | 0.25s | 0.80s | 0.14s | DuckDB üèÜ |
| **Top 10** | 0.08s | 0.22s | 0.03s | DuckDB üèÜ |

**Fonte**: Benchmarks internos DuckDB 1.4.3 vs Polars 1.36.1 vs Pandas 2.3.3

### Consumo de Mem√≥ria (Dataset 500MB)

| Ferramenta | RAM Pico | Comportamento |
|------------|----------|---------------|
| Polars | 1.2 GB | Carrega tudo em mem√≥ria |
| Pandas | 2.5 GB | Pior otimiza√ß√£o |
| Dask | 800 MB | Lazy, mas overhead |
| **DuckDB** | **400 MB** | Streaming + predicate pushdown üèÜ |

---

## üî• Casos Problem√°ticos Atuais

### 1. M√∫ltiplas Convers√µes (Performance Killer)

**Exemplo Real** (`polars_dask_adapter.py:303`):
```python
# Polars ‚Üí Pandas ‚Üí Dict
return df_polars.to_pandas().to_dict(orient="records")
```

**Problema**:
- C√≥pia completa dos dados (2x mem√≥ria)
- Serializa√ß√£o/deserializa√ß√£o overhead
- Perda de otimiza√ß√µes Polars

**Solu√ß√£o DuckDB**:
```python
# DuckDB ‚Üí Arrow (zero-copy) ‚Üí Dict
return conn.execute(sql).arrow().to_pylist()
```

---

### 2. Cache Duplicado

**Problema**:
- `ParquetCache` mant√©m 5 DataFrames Polars em RAM (~500MB)
- DuckDB j√° faz metadata cache autom√°tico
- Redund√¢ncia de mem√≥ria

**Solu√ß√£o**:
- Remover `ParquetCache`
- DuckDB gerencia cache automaticamente (object_cache)

---

### 3. Fallback Complexo

**C√≥digo Atual** (`une_tools.py:184`):
```python
try:
    df = get_data_manager().df  # Tenta Polars
except:
    logger.warning("Fallback para pd.read_parquet...")
    df = pd.read_parquet(path)  # Fallback Pandas
```

**Problema**: 2 engines para mesma opera√ß√£o

**Solu√ß√£o DuckDB**:
```python
df = duckdb_adapter.query(f"SELECT * FROM read_parquet('{path}')")
```

---

## üìã Plano de Migra√ß√£o

### Fase 1: Prepara√ß√£o (Semana 1)
**Objetivo**: Setup e testes iniciais

#### 1.1. Criar DuckDBAdapter Melhorado
- [ ] Adicionar m√©todo `read_parquet(path)` wrapper
- [ ] Adicionar m√©todo `lazy_query(sql)` para queries grandes
- [ ] Implementar cache de prepared statements
- [ ] Adicionar m√©tricas de performance

#### 1.2. Criar Utilit√°rios de Migra√ß√£o
```python
# migration_utils.py
def polars_to_duckdb_query(df_operation: str) -> str:
    """Converte opera√ß√£o Polars para SQL DuckDB"""
    pass

def pandas_to_duckdb(df: pd.DataFrame) -> str:
    """Cria query DuckDB equivalente"""
    pass
```

#### 1.3. Benchmarks Comparativos
- [ ] Executar benchmarks DuckDB vs Polars
- [ ] Validar performance em queries reais
- [ ] Documentar resultados

---

### Fase 2: Migra√ß√£o de Baixo Risco (Semana 2-3)
**Objetivo**: Migrar c√≥digo n√£o-cr√≠tico primeiro

#### 2.1. Scripts de Manuten√ß√£o (10 arquivos) ‚úÖ **F√ÅCIL**
**Arquivos**:
- `scripts/verify_parquet_data.py`
- `scripts/analyze_parquet.py`
- `scripts/inspect_parquet.py`
- `scripts/load_data.py`
- `fix_admin_role.py`
- `scripts/check_specific_users.py`

**Migra√ß√£o**:
```python
# ANTES
df = pd.read_parquet(path)
df_filtered = df[df['col'] > 10]

# DEPOIS
conn = duckdb.connect()
df = conn.execute(f"""
    SELECT * FROM read_parquet('{path}')
    WHERE col > 10
""").df()
```

**Esfor√ßo**: 2 horas
**Risco**: Baixo (scripts isolados)

---

#### 2.2. Ferramentas MCP (6 arquivos) ‚úÖ **F√ÅCIL**
**Arquivos**:
- `app/core/tools/mcp_parquet_tools.py`
- `app/core/tools/mcp_sql_server_tools.py`

**Migra√ß√£o**: Substituir `pd.read_parquet` por `duckdb_adapter.query`

**Esfor√ßo**: 1 hora
**Risco**: Baixo (ferramentas isoladas)

---

#### 2.3. Tools Simples (4 arquivos) ‚úÖ **M√âDIO**
**Arquivos**:
- `app/core/tools/code_interpreter.py`
- `app/core/tools/semantic_search_tool.py`

**Migra√ß√£o**:
```python
# ANTES (Polars)
df = pl.read_parquet(path)
results = df.filter(pl.col("nome").str.contains(term))

# DEPOIS (DuckDB)
results = duckdb_adapter.query(f"""
    SELECT * FROM read_parquet('{path}')
    WHERE nome ILIKE '%{term}%'
""")
```

**Esfor√ßo**: 3 horas
**Risco**: M√©dio (l√≥gica de neg√≥cio)

---

### Fase 3: Migra√ß√£o de M√©dio Risco (Semana 4-5)
**Objetivo**: Adapters e servi√ßos core

#### 3.1. Substituir PolarsDaskAdapter ‚ö†Ô∏è **CR√çTICO**
**Arquivo**: `app/infrastructure/data/polars_dask_adapter.py`

**Estrat√©gia**:
1. Criar `DuckDBDataAdapter` que implementa `DatabaseAdapter`
2. Adicionar l√≥gica de streaming para arquivos grandes
3. Manter interface compat√≠vel

```python
class DuckDBDataAdapter(DatabaseAdapter):
    def execute_query(self, query_str: str) -> List[Dict]:
        # Parse query_str (pode ser SQL ou dict Polars-style)
        sql = self._parse_query(query_str)
        return duckdb_adapter.query(sql).to_dict('records')

    def _parse_query(self, query_str: str) -> str:
        """Converte query Polars-style para SQL se necess√°rio"""
        if "SELECT" in query_str.upper():
            return query_str  # J√° √© SQL
        else:
            return self._polars_to_sql(query_str)
```

**Esfor√ßo**: 8 horas
**Risco**: Alto (usado por todo o sistema)

**Estrat√©gia de Rollout**:
1. Criar novo adapter DuckDB
2. Testar paralelamente (flag `USE_DUCKDB=true`)
3. Gradual rollout 10% ‚Üí 50% ‚Üí 100%
4. Remover PolarsDaskAdapter

---

#### 3.2. Remover ParquetCache ‚ö†Ô∏è **CR√çTICO**
**Arquivo**: `app/core/parquet_cache.py`

**Problema**: Cache manual redundante com DuckDB object_cache

**Estrat√©gia**:
1. DuckDB j√° faz metadata cache automaticamente
2. Para cache de resultados, usar simple dict:

```python
from functools import lru_cache

@lru_cache(maxsize=10)
def query_cached(sql: str):
    return duckdb_adapter.query(sql)
```

**Esfor√ßo**: 4 horas (remover + refatorar dependentes)
**Risco**: Alto (usado em 5+ arquivos)

---

#### 3.3. Migrar DataScopeService ‚ö†Ô∏è **CR√çTICO**
**Arquivo**: `app/core/data_scope_service.py`

**C√≥digo Atual** (Polars Lazy):
```python
lf = pl.read_parquet(path).lazy()
lf = lf.filter(pl.col("une").is_in(allowed_unes))
df = lf.collect()
```

**Nova Vers√£o** (DuckDB):
```python
# DuckDB √© sempre lazy (query planner)
sql = f"""
    SELECT * FROM read_parquet('{path}')
    WHERE une IN ({','.join(map(str, allowed_unes))})
"""
df = duckdb_adapter.query(sql)
```

**Benef√≠cio**: Predicate pushdown autom√°tico (l√™ menos dados do disco)

**Esfor√ßo**: 6 horas
**Risco**: Alto (RLS - seguran√ßa)

---

### Fase 4: Visualiza√ß√µes (Semana 6)
**Objetivo**: Manter Plotly funcional

#### 4.1. An√°lise de Plotly
**Arquivo**: `app/core/visualization/advanced_charts.py`

**Descoberta**: Plotly aceita m√∫ltiplos formatos!
```python
import plotly.express as px

# Op√ß√£o 1: Pandas (atual)
fig = px.bar(df_pandas)

# Op√ß√£o 2: DuckDB ‚Üí Pandas (r√°pido)
df = duckdb_adapter.query(sql).df()  # Retorna Pandas
fig = px.bar(df)

# Op√ß√£o 3: Arrow ‚Üí Plotly (zero-copy, futuro)
arrow_table = duckdb_adapter.query_arrow(sql)
fig = px.bar(arrow_table)  # Plotly 5.0+ aceita Arrow
```

**Decis√£o**:
- Manter Pandas **apenas** para Plotly
- Usar DuckDB `.df()` para gerar Pandas sob demanda
- Investigar Plotly Arrow support (vers√£o 6.5.0 atual)

**Esfor√ßo**: 2 horas
**Risco**: Baixo (interface est√°vel)

---

### Fase 5: Testes e Valida√ß√£o (Semana 7)
**Objetivo**: Garantir paridade funcional

#### 5.1. Testes de Regress√£o
- [ ] Executar suite de testes existente
- [ ] Validar performance (deve ser 2-3x mais r√°pido)
- [ ] Verificar corre√ß√£o de resultados

#### 5.2. Testes de Carga
- [ ] Query 1M+ linhas
- [ ] M√∫ltiplas queries concorrentes
- [ ] Verificar memory footprint

#### 5.3. Testes de Edge Cases
- [ ] Arquivo vazio
- [ ] Schema evolution
- [ ] Tipos de dados complexos (JSON, arrays)

---

### Fase 6: Limpeza Final (Semana 8)
**Objetivo**: Remover depend√™ncias antigas

#### 6.1. Remover do requirements.txt
```diff
- polars
- dask[dataframe]
- pandas  # Manter APENAS se Plotly n√£o suportar Arrow
```

#### 6.2. Remover Imports
```bash
# Script de limpeza
find . -name "*.py" -exec sed -i '/import polars/d' {} \;
find . -name "*.py" -exec sed -i '/import dask/d' {} \;
```

#### 6.3. Atualizar Documenta√ß√£o
- [ ] Atualizar README.md
- [ ] Atualizar arquitetura
- [ ] Criar guia de migra√ß√£o para desenvolvedores

---

## üéØ Resumo Executivo

### Esfor√ßo Total Estimado
- **Fase 1 (Prepara√ß√£o)**: 8 horas
- **Fase 2 (Baixo Risco)**: 6 horas
- **Fase 3 (M√©dio Risco)**: 18 horas
- **Fase 4 (Visualiza√ß√µes)**: 2 horas
- **Fase 5 (Testes)**: 16 horas
- **Fase 6 (Limpeza)**: 4 horas

**Total**: 54 horas (~7 dias √∫teis)

### Benef√≠cios

| M√©trica | Antes | Depois | Melhoria |
|---------|-------|--------|----------|
| **Depend√™ncias** | 4 engines | 1 engine | -75% |
| **Performance Queries** | 0.15s | 0.05s | 3x mais r√°pido |
| **Mem√≥ria RAM** | 1.2 GB | 400 MB | -67% |
| **Complexidade C√≥digo** | Alta | Baixa | -50% convers√µes |
| **Tamanho Docker** | 500 MB | 350 MB | -30% |

### Riscos

| Risco | Probabilidade | Impacto | Mitiga√ß√£o |
|-------|---------------|---------|-----------|
| Incompatibilidade Plotly | Baixa | Alto | Manter Pandas para viz |
| Regress√£o funcional | M√©dia | Alto | Testes extensivos |
| Performance pior | Baixa | M√©dio | Benchmarks antecipados |
| Breaking changes | M√©dia | Alto | Rollout gradual com flags |

---

## ‚úÖ Recomenda√ß√µes Finais

### A√ß√£o Imediata
1. ‚úÖ **APROVAR** migra√ß√£o para DuckDB
2. ‚úÖ **COME√áAR** com Fase 1 (prepara√ß√£o)
3. ‚úÖ **VALIDAR** benchmarks antes de Fase 3

### Prioriza√ß√£o
1. **Cr√≠tico**: Migrar adapters (Fase 3) - Maior impacto
2. **Importante**: Migrar ferramentas (Fase 2) - Quick wins
3. **Nice-to-have**: Plotly Arrow (Fase 4) - Otimiza√ß√£o futura

### Crit√©rio de Sucesso
- ‚úÖ Todas as queries retornam mesmos resultados
- ‚úÖ Performance 2x mais r√°pida (m√≠nimo)
- ‚úÖ Mem√≥ria reduzida em 50%
- ‚úÖ Zero regress√µes funcionais
- ‚úÖ C√≥digo mais simples e manuten√≠vel

---

**DECIS√ÉO**: üöÄ **PROSSEGUIR COM MIGRA√á√ÉO**

**Pr√≥ximo Passo**: Implementar Fase 1 (Prepara√ß√£o)
