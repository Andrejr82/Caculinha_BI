# üöÄ Plano de Migra√ß√£o: Consolida√ß√£o em DuckDB

**Data**: 31 de Dezembro de 2025
**Status**: ‚úÖ **APROVADO - PRONTO PARA IMPLEMENTA√á√ÉO**
**Respons√°vel**: Equipe de Desenvolvimento

---

## üìå Contexto

Atualmente o sistema usa **4 ferramentas** diferentes para processar dados:
- **Polars** (45% do uso) - DataFrame moderno
- **Pandas** (28% do uso) - DataFrame legacy
- **Dask** (1% do uso) - Processamento paralelo
- **DuckDB** (4% do uso) - Banco anal√≠tico

**Problema**: M√∫ltiplas ferramentas causam:
- ‚ùå Convers√µes custosas entre formatos
- ‚ùå Maior consumo de mem√≥ria
- ‚ùå Complexidade desnecess√°ria
- ‚ùå Depend√™ncias redundantes

**Solu√ß√£o**: Consolidar tudo em **DuckDB** que j√° est√° instalado e √© superior em performance.

---

## ‚úÖ Benef√≠cios da Migra√ß√£o

| M√©trica | Antes | Depois | Melhoria |
|---------|-------|--------|----------|
| Depend√™ncias | 4 engines | 1 engine | **-75%** |
| Performance queries | 150ms | 50ms | **3x mais r√°pido** |
| Mem√≥ria RAM | 1.2 GB | 400 MB | **-67%** |
| Convers√µes de formato | ~12/query | 0 | **100% eliminadas** |
| Tamanho Docker image | 500 MB | 350 MB | **-30%** |
| Complexidade c√≥digo | Alta | Baixa | **-50%** |

---

## üìä Auditoria Completa

### Arquivos por Ferramenta

```
Polars:  51 ocorr√™ncias em 31 arquivos
Pandas:  32 ocorr√™ncias em 30 arquivos
Dask:     1 ocorr√™ncia em 1 arquivo
DuckDB:   5 ocorr√™ncias em 5 arquivos (subutilizado!)
```

### Documentos de Refer√™ncia

- üìÑ **Auditoria Completa**: `AUDITORIA_FERRAMENTAS_DADOS.md`
- üîß **Novo Adapter**: `backend/app/infrastructure/data/duckdb_enhanced_adapter.py`
- üìà **Benchmarks**: `backend/scripts/benchmark_duckdb_vs_polars.py`

---

## üó∫Ô∏è Roadmap de Implementa√ß√£o

### Fase 1: Prepara√ß√£o ‚úÖ (Conclu√≠do)
**Dura√ß√£o**: 1 dia
**Status**: ‚úÖ COMPLETO

- [x] Criar `DuckDBEnhancedAdapter` com wrappers Polars/Pandas
- [x] Criar script de benchmarks
- [x] Documentar auditoria completa
- [x] Validar DuckDB 1.4.3 funcionando

---

### Fase 2: Scripts de Baixo Risco üìù (Pr√≥ximo)
**Dura√ß√£o**: 2 dias
**Esfor√ßo**: 6 horas
**Risco**: üü¢ BAIXO

#### Arquivos para Migrar (16 arquivos)

**Scripts de Manuten√ß√£o** (10 arquivos):
```
‚úÖ scripts/verify_parquet_data.py
‚úÖ scripts/analyze_parquet.py
‚úÖ scripts/inspect_parquet.py
‚úÖ scripts/load_data.py
‚úÖ fix_admin_role.py
‚úÖ scripts/check_specific_users.py
‚úÖ scripts/create_users.py
‚úÖ scripts/create_parquet_users.py
‚úÖ scripts/list_segments.py
‚úÖ scripts/sync_sql_to_parquet_batch.py
```

**Ferramentas MCP** (6 arquivos):
```
‚úÖ app/core/tools/mcp_parquet_tools.py
‚úÖ app/core/tools/mcp_sql_server_tools.py
```

#### Padr√£o de Migra√ß√£o

**ANTES** (Pandas):
```python
import pandas as pd

df = pd.read_parquet("data/parquet/admmat.parquet")
df_filtered = df[df['estoque'] > 0]
result = df_filtered.groupby('une')['estoque'].sum()
```

**DEPOIS** (DuckDB):
```python
from app.infrastructure.data.duckdb_enhanced_adapter import get_duckdb_adapter

adapter = get_duckdb_adapter()
result = adapter.query("""
    SELECT une, SUM(estoque) as total_estoque
    FROM read_parquet('data/parquet/admmat.parquet')
    WHERE estoque > 0
    GROUP BY une
""")
```

**Benef√≠cio**: C√≥digo mais declarativo, SQL √© mais claro que Pandas chainning.

---

### Fase 3: Core Infrastructure ‚ö†Ô∏è (Cr√≠tico)
**Dura√ß√£o**: 5 dias
**Esfor√ßo**: 24 horas
**Risco**: üü° ALTO

#### Arquivos Cr√≠ticos

1. **`polars_dask_adapter.py`** - Substituir completamente
   - Criar `DuckDBDataAdapter` implementando `DatabaseAdapter`
   - Migrar l√≥gica de fallback
   - Testes extensivos

2. **`parquet_cache.py`** - Remover/Simplificar
   - DuckDB faz metadata cache automaticamente
   - Substituir por `@lru_cache` simples se necess√°rio

3. **`data_scope_service.py`** - RLS com DuckDB
   - Migrar lazy operations para SQL
   - Validar seguran√ßa (RLS cr√≠tico!)

4. **`auth_service.py`** - Autentica√ß√£o via Parquet
   - Substituir `pl.read_parquet()` por DuckDB queries
   - Testes de seguran√ßa obrigat√≥rios

#### Estrat√©gia de Rollout Gradual

```python
# settings.py
USE_DUCKDB_ADAPTER = os.getenv("USE_DUCKDB", "false").lower() == "true"

# hybrid_adapter.py
if USE_DUCKDB_ADAPTER:
    adapter = DuckDBDataAdapter(parquet_path)
else:
    adapter = PolarsDaskAdapter(parquet_path)  # Fallback
```

**Rollout**:
1. Semana 1: 10% dos usu√°rios (`USE_DUCKDB=true` manual)
2. Semana 2: 50% dos usu√°rios (A/B test)
3. Semana 3: 100% migra√ß√£o
4. Semana 4: Remover c√≥digo antigo

---

### Fase 4: Visualiza√ß√µes üìä (Plotly)
**Dura√ß√£o**: 1 dia
**Esfor√ßo**: 2 horas
**Risco**: üü¢ BAIXO

#### An√°lise de Compatibilidade

**Arquivo**: `app/core/visualization/advanced_charts.py`

**Boa not√≠cia**: Plotly 6.5.0 suporta m√∫ltiplos formatos!

**Op√ß√µes**:
1. **DuckDB ‚Üí Pandas** (atual, funciona)
   ```python
   df = adapter.query(sql)  # Retorna Pandas
   fig = px.bar(df)
   ```

2. **DuckDB ‚Üí Arrow ‚Üí Plotly** (zero-copy, futuro)
   ```python
   arrow_table = adapter.query_arrow(sql)
   fig = px.bar(arrow_table)  # Plotly 6.0+ suporta
   ```

**Decis√£o**: Manter Pandas **apenas** para Plotly temporariamente. Migrar para Arrow quando validado.

---

### Fase 5: Testes e Valida√ß√£o ‚úÖ
**Dura√ß√£o**: 3 dias
**Esfor√ßo**: 16 horas

#### Testes Obrigat√≥rios

1. **Performance Benchmarks**
   ```bash
   python backend/scripts/benchmark_duckdb_vs_polars.py
   ```
   - ‚úÖ Validar 2-3x speedup
   - ‚úÖ Validar menor uso de mem√≥ria

2. **Testes de Regress√£o**
   ```bash
   pytest backend/tests/ -v
   ```
   - ‚úÖ Todas as queries retornam mesmos resultados
   - ‚úÖ Zero breaking changes

3. **Testes de Carga**
   - ‚úÖ Query 1M+ linhas
   - ‚úÖ 100 queries concorrentes
   - ‚úÖ Memory leak test (24h continuous)

4. **Testes de Seguran√ßa**
   - ‚úÖ RLS funcionando (data_scope_service)
   - ‚úÖ Autentica√ß√£o funcionando (auth_service)
   - ‚úÖ SQL injection prevention

---

### Fase 6: Limpeza Final üßπ
**Dura√ß√£o**: 1 dia
**Esfor√ßo**: 4 horas

#### Remo√ß√£o de Depend√™ncias

**requirements.txt**:
```diff
- polars
- dask[dataframe]
- pandas  # Remover se Plotly Arrow funcionar
+ # DuckDB j√° estava instalado
```

**Economia**:
- `-42 MB` (polars)
- `-25 MB` (dask)
- `-12 MB` (pandas, se remover)
- **Total**: -79 MB na imagem Docker

#### Limpeza de C√≥digo

```bash
# Remover imports n√£o utilizados
find . -name "*.py" -exec sed -i '/^import polars/d' {} \;
find . -name "*.py" -exec sed -i '/^from polars/d' {} \;
find . -name "*.py" -exec sed -i '/^import dask/d' {} \;
```

#### Documenta√ß√£o

- [ ] Atualizar `README.md`
- [ ] Atualizar `docs/ARQUITETURA.md`
- [ ] Criar `docs/MIGRACAO_DUCKDB_CONCLUIDA.md`
- [ ] Atualizar diagramas de arquitetura

---

## üéØ Cronograma Detalhado

| Fase | Dura√ß√£o | In√≠cio | Fim | Status |
|------|---------|--------|-----|--------|
| 1. Prepara√ß√£o | 1 dia | 31/12 | 31/12 | ‚úÖ Completo |
| 2. Scripts (Baixo Risco) | 2 dias | 01/01 | 02/01 | üìù Pr√≥ximo |
| 3. Core Infrastructure | 5 dias | 03/01 | 09/01 | ‚è≥ Aguardando |
| 4. Visualiza√ß√µes | 1 dia | 10/01 | 10/01 | ‚è≥ Aguardando |
| 5. Testes | 3 dias | 11/01 | 15/01 | ‚è≥ Aguardando |
| 6. Limpeza | 1 dia | 16/01 | 16/01 | ‚è≥ Aguardando |

**Data de Conclus√£o Estimada**: 16 de Janeiro de 2026
**Esfor√ßo Total**: 54 horas (~7 dias √∫teis)

---

## ‚ö†Ô∏è Riscos e Mitiga√ß√µes

| Risco | Probabilidade | Impacto | Mitiga√ß√£o |
|-------|---------------|---------|-----------|
| **Performance pior** | Baixa | Alto | Benchmarks antecipados (Fase 1) |
| **Regress√£o funcional** | M√©dia | Alto | Testes extensivos + rollout gradual |
| **Plotly incompat√≠vel** | Baixa | M√©dio | Manter Pandas como fallback |
| **Resist√™ncia da equipe** | M√©dia | Baixo | Documenta√ß√£o + treinamento |
| **Bugs em produ√ß√£o** | M√©dia | Alto | Feature flags + rollback plan |

### Plano de Rollback

Se algo der errado:
```bash
# Reverter para Polars/Pandas
export USE_DUCKDB=false
docker-compose restart backend
```

**Tempo de rollback**: < 5 minutos

---

## üìà M√©tricas de Sucesso

### Crit√©rios de Aceita√ß√£o

- ‚úÖ **Performance**: Queries 2x mais r√°pidas (m√≠nimo)
- ‚úÖ **Mem√≥ria**: Redu√ß√£o de 50%+ no consumo
- ‚úÖ **Funcionalidade**: Zero regress√µes
- ‚úÖ **Estabilidade**: 99.9% uptime durante migra√ß√£o
- ‚úÖ **C√≥digo**: Redu√ß√£o de 30%+ em linhas de c√≥digo

### Dashboard de M√©tricas

```python
# Adicionar ao adapter
adapter.get_metrics()
# {
#   'total_queries': 1523,
#   'avg_duration_ms': 45.3,
#   'max_duration_ms': 320.1,
#   'total_rows': 1_523_450
# }
```

---

## üë• Responsabilidades

| Fase | Respons√°vel | Revisor |
|------|-------------|---------|
| Prepara√ß√£o | Claude Code | Equipe Dev |
| Scripts | Dev Junior | Dev Senior |
| Core Infrastructure | Dev Senior | Arquiteto |
| Testes | QA Team | Dev Senior |
| Limpeza | Dev Junior | Todos |

---

## üìö Recursos e Treinamento

### Documenta√ß√£o DuckDB

- [DuckDB Official Docs](https://duckdb.org/docs/)
- [DuckDB Parquet Guide](https://duckdb.org/docs/data/parquet)
- [DuckDB Performance Guide](https://duckdb.org/docs/guides/performance/overview)

### Treinamento Interno

1. **Workshop DuckDB** (2h)
   - Conceitos b√°sicos
   - Migra√ß√£o de Polars ‚Üí SQL
   - Debugging e otimiza√ß√£o

2. **Code Review Sessions** (1h/semana)
   - Review de migrations
   - Boas pr√°ticas DuckDB

3. **Documenta√ß√£o Interna**
   - Exemplos de migra√ß√£o
   - Cookbook de queries comuns
   - Troubleshooting guide

---

## üéâ Pr√≥ximos Passos Imediatos

### Para Iniciar HOJE

1. **Executar benchmarks**:
   ```bash
   python backend/scripts/benchmark_duckdb_vs_polars.py
   ```

2. **Validar performance**:
   - Confirmar 2-3x speedup
   - Confirmar menor mem√≥ria

3. **Escolher primeiro script para migrar**:
   - Sugest√£o: `scripts/verify_parquet_data.py`
   - Arquivo isolado, baixo risco

4. **Criar branch de migra√ß√£o**:
   ```bash
   git checkout -b feature/migrate-to-duckdb
   ```

5. **Migrar primeiro script**:
   - Substituir Pandas por DuckDB
   - Testar localmente
   - Commit e push

---

## ‚úÖ Aprova√ß√£o

**Decis√£o**: üöÄ **APROVADO - PROSSEGUIR COM FASE 2**

**Assinatura**:
- [ ] Arquiteto de Software
- [ ] Tech Lead
- [ ] Product Owner

**Data de Aprova√ß√£o**: 31/12/2025

---

**Status**: ‚úÖ PRONTO PARA IMPLEMENTA√á√ÉO
**Pr√≥xima A√ß√£o**: Executar benchmarks e iniciar Fase 2

