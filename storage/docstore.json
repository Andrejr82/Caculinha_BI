{"docstore/metadata": {"backend\\app\\api\\dependencies.py": {"doc_hash": "34876df90b5ac8d7e9292b8eca020634a0098d5415113a04a074aa46c4022483"}, "backend\\app\\api\\v1\\router.py": {"doc_hash": "378b8bbfd5770ef3928a007b16ae05259b67da950864505a6fafeb394d5fe311"}, "backend\\app\\api\\v1\\endpoints\\admin.py": {"doc_hash": "e7931a846e05abf63abfffe6929c000323ecd3901ab23c425f2fc86061bba74a"}, "backend\\app\\api\\v1\\endpoints\\analytics.py": {"doc_hash": "9bd15d3ff0d618fd6d3e71da78e013220daed52f3217103669879911d4ef18bc"}, "backend\\app\\api\\v1\\endpoints\\auth.py": {"doc_hash": "5dd6e049f58818231fc1450bc7894ea1c3c04e583c2eab006bbc3608532d3be1"}, "backend\\app\\api\\v1\\endpoints\\auth_alt.py": {"doc_hash": "c843862ca91ec9dfcf58294d3b24aeb97f100b85f43cd8603b5eade2ab119fa8"}, "backend\\app\\api\\v1\\endpoints\\chat.py": {"doc_hash": "2c06578190f0b9f3509ac2172bb890f2cd0f68e54b5fefa866105ed665bdd8b4"}, "backend\\app\\api\\v1\\endpoints\\code_chat.py": {"doc_hash": "def5a6c5a2d62ae673913e011addd895772b94902c1583a2040e22491b8502e9"}, "backend\\app\\api\\v1\\endpoints\\diagnostics.py": {"doc_hash": "9655e95b6f2296b3c619f29278962101e685ddf833752d5ab861f895eecfcf14"}, "backend\\app\\api\\v1\\endpoints\\frontend_logs.py": {"doc_hash": "94a234e41c07144ded4792e4698591271555164f5b55685d21c08740fa3b51a3"}, "backend\\app\\api\\v1\\endpoints\\health.py": {"doc_hash": "2cd84419725f3853032903a28de9172d2a8f1d98b840dde8a6710ff2c0d87a05"}, "backend\\app\\api\\v1\\endpoints\\insights.py": {"doc_hash": "0c0aba62e3c72d90b70e66076914bee19a8753f3c97cfb171c67a1290cea34b7"}, "backend\\app\\api\\v1\\endpoints\\learning.py": {"doc_hash": "da25e8192cd2942590dba7ed2843e471032e00dce8489cdc78f7302fab5ebba5"}, "backend\\app\\api\\v1\\endpoints\\metrics.py": {"doc_hash": "780d95aeddf56c2fd5e0f4e9b7d61d31e41d948ab8a24418e7bfa5bbb168a1d6"}, "backend\\app\\api\\v1\\endpoints\\playground.py": {"doc_hash": "d9d4e3df7bb52202430de2949d9a138abb3e568fefa1c3e1bfedb441127ee8ae"}, "backend\\app\\api\\v1\\endpoints\\preferences.py": {"doc_hash": "0798f7432b97b9ff14bf5bf6909a61aae39736e3aa0e8c826064632893044516"}, "backend\\app\\api\\v1\\endpoints\\reports.py": {"doc_hash": "2d5deadf72239112213776ae2fbd7f4082e68f36fa69ad555125b9f54783d77d"}, "backend\\app\\api\\v1\\endpoints\\rupturas.py": {"doc_hash": "8817a2b0912f4ff98534832eb60ca9ebaccae0c1d60b07aa8c41a0ee97d27953"}, "backend\\app\\api\\v1\\endpoints\\shared.py": {"doc_hash": "2a6f44782c74179fbb4458821d3743064189abb234933681fba77d30cddde412"}, "backend\\app\\api\\v1\\endpoints\\test.py": {"doc_hash": "19e15495208dd30b335e7e5fc5e737da0f77063faef403b9526ddbb82e3a2e39"}, "backend\\app\\api\\v1\\endpoints\\transfers.py": {"doc_hash": "297a0d8922026770a8af137557331aafd15f2d1728c5dfc2ca8e0b2705bb5452"}, "backend\\app\\api\\v1\\endpoints\\__init__.py": {"doc_hash": "ad6ae0cd9a9fc8d37b0abef9d52f3ab5420e9f3f617a2e703682d792e5acc488"}, "backend\\app\\config\\database.py": {"doc_hash": "50a7e9c8789b055476bdefbeb6606b61f2fb2dafa9729d9b712fbc057e9f7a87"}, "backend\\app\\config\\logging_config.py": {"doc_hash": "09a3a017795474c13d057d9df35f705dc3d37cdfe9dd6274782144e26f8913ae"}, "backend\\app\\config\\security.py": {"doc_hash": "02bfbc9425e58bbf4fa4b1b0c322484b645e4849f74689fee33938eeda491b30"}, "backend\\app\\config\\settings.py": {"doc_hash": "3e34599a8735f5e72b37bfe59289a09283c2f62bcf78fb9dd83683f9df347a89"}, "backend\\app\\core\\agent_state.py": {"doc_hash": "ad6f614b1a8e728895bca30cff8036b0d554a68cafd18fa637c376b60a6502d6"}, "backend\\app\\core\\agent_wrapper.py": {"doc_hash": "60b6ccfb7b90d5e898d2d7c849e31799ac9ab45f06b28cde102f57dcde569eb8"}, "backend\\app\\core\\auth_service.py": {"doc_hash": "12dd6f06677beadc909093b7125e67e7ebb1bddc56cd5a4b4d7a4a2431b663a3"}, "backend\\app\\core\\cache.py": {"doc_hash": "e596ec327ad0a5b9795d1a0ab8cdc5bac6c2a0bc0256b31bbe3f50a06f50eae2"}, "backend\\app\\core\\code_rag_service.py": {"doc_hash": "ab25d4c9286fe4f3078257a840ddf5ecd35e5e8633204f2fafb0b6fd8ffd3da4"}, "backend\\app\\core\\data_scope_service.py": {"doc_hash": "1c3b278e30ce3a49787cbf1e762180d7d4fa173da2de18b2b065eb6501abd802"}, "backend\\app\\core\\data_source_manager.py": {"doc_hash": "12c638b177503a5e9b7ec28f2fb997a4398458df5931398bac31766c6517cd1f"}, "backend\\app\\core\\intelligent_chatbi.py": {"doc_hash": "d54dca90dce897c71ca826103532740981e3930d5c0d5ee9683d01677fbf1cee"}, "backend\\app\\core\\llm_base.py": {"doc_hash": "5b370c648ec9201731d517f648e8dbaaea4c596f5e8596d076a9363354932a10"}, "backend\\app\\core\\llm_factory.py": {"doc_hash": "640cdc05ad8982aac2e1cfd32520eac26a8a10375c37db0a29f60d9eac677e0a"}, "backend\\app\\core\\llm_gemini_adapter.py": {"doc_hash": "d06697dc24df2ae1f95261aeb6ee3c6d3fde79d5e8a7ea8cdcffb66a2c2354f1"}, "backend\\app\\core\\llm_gemini_adapter_v2.py": {"doc_hash": "9d5fa29ea6c43a3f61a3d5af91adf0e3988b98de98c92478808ea4cd62126550"}, "backend\\app\\core\\llm_langchain_adapter.py": {"doc_hash": "f2b4601f3df3837beb8060dc7bdadf04ea6f5d127386677608146fbba6ab973f"}, "backend\\app\\core\\logging_config.py": {"doc_hash": "b1cd67b7cbd2f4349ca4d2b94548be432e8cfadc3cb9739446ab380aeb6f9694"}, "backend\\app\\core\\logging_middleware.py": {"doc_hash": "223c958b5d3a46b4fde646ce95a4b24ae08926bc449fbdd53fd2bd6b2595ef56"}, "backend\\app\\core\\parquet_cache.py": {"doc_hash": "252ba8607c76a5604c190d2319d4aaead5f5cd089bafb28d3390913e7925f2a7"}, "backend\\app\\core\\query_processor.py": {"doc_hash": "cb6954c9b10f2f62647b947e3144673779d44d13293a849da6f53d28deb9572b"}, "backend\\app\\core\\robust_chatbi.py": {"doc_hash": "6c1fc9b5a5bc689f5d1ace9af8cfd752cde8db64d642b754548a00844af26a3e"}, "backend\\app\\core\\supabase_client.py": {"doc_hash": "0a9d1c86d0356b24c767c3afbb6587bb87a182264a7259bdaed586c1f13cc490"}, "backend\\app\\core\\supabase_user_service.py": {"doc_hash": "65a6844158b2820a9376726a19423455c99b260ecc8a64eac589d7449db66b6f"}, "backend\\app\\core\\sync_service.py": {"doc_hash": "43c4bbeb3fd35b4d7662861a424ab1879331a41a7ccc3df251cb3a4b7631e4eb"}, "backend\\app\\core\\agents\\base_agent.py": {"doc_hash": "f2874b9b6e17789634a496ad1e7b92701064ecd2699d37c3b351ecf7852f6f3e"}, "backend\\app\\core\\agents\\caculinha_bi_agent.py": {"doc_hash": "082f49344c14c67ec249a6c28a5eb407943cfb766900b20ede570efe85a7f9ac"}, "backend\\app\\core\\agents\\code_gen_agent.py": {"doc_hash": "1a3da5174f5a007cec5b1f7ed4428d4e5a551f4324693b2e749aa2d6495b8ea5"}, "backend\\app\\core\\agents\\developer_agent.py": {"doc_hash": "b00ee088fba8a7d25cd80a265255160b0bde40e496a9b8d80749b67fe382bd1f"}, "backend\\app\\core\\agents\\multi_step_agent.py": {"doc_hash": "9d05a2ba33cc7e59695b6fa69fc413e7f4bcdc6a3cade68e433f17e3870bdfb8"}, "backend\\app\\core\\agents\\product_agent.py": {"doc_hash": "3368c356670aa6164e34c001d5fe582690b9c9fef3f4e47a1702be6be756b785"}, "backend\\app\\core\\agents\\prompt_loader.py": {"doc_hash": "8808cf113ea815487ce9f35b554b26b5766fb905bbf16863143a9fecf49df224"}, "backend\\app\\core\\agents\\supervisor_agent.py": {"doc_hash": "f3ad81ba43b19a7f5bcf823c9a29b8ede99e6a68b2d3221ecfdaa018d8fccc3a"}, "backend\\app\\core\\agents\\tool_agent.py": {"doc_hash": "6dfd4cdf63ac3baa2a2ed6fdaeaf62ddda05cd0e81138d4d8002240122cafae2"}, "backend\\app\\core\\agents\\__init__.py": {"doc_hash": "3cde386aecad6ce33e15c60e4c24ff117c2a300ed77af7a00ff4af14d51c0796"}, "backend\\app\\core\\factory\\component_factory.py": {"doc_hash": "471fcd0581c7da0fba372d822d85cdd68c7e16ea1b75859d7cdc5ce59b615e80"}, "backend\\app\\core\\factory\\__init__.py": {"doc_hash": "bedf6a97d92ad7dbbdac943e34c67c726b1de0ba60653481b55972d9c9043897"}, "backend\\app\\core\\graph\\agent.py": {"doc_hash": "9987ab5953334bede5a15b049f1e4beb39fd0909cab93023cf6fc1d8c5b89ecb"}, "backend\\app\\core\\graph\\__init__.py": {"doc_hash": "792ce3e7808c8e34ffeed6006585cacc825f320a66e79ff76863bf01dc451004"}, "backend\\app\\core\\learning\\feedback_system.py": {"doc_hash": "7a1dc34ccfd018bcbe3d29a59c6c12410b1fb615a85309a88ef06da11b620789"}, "backend\\app\\core\\learning\\pattern_matcher.py": {"doc_hash": "5719938a7396cad4c96c5124792a5de5a4665493663cd9cf739a95f1a1c31aeb"}, "backend\\app\\core\\monitoring\\metrics_dashboard.py": {"doc_hash": "ee165176bf37cf336bb176461489ea1a4b118151cb38cc860b2948149718b6bc"}, "backend\\app\\core\\rag\\example_collector.py": {"doc_hash": "b2a2c0e4116678b6756c8b7922c017eb670dcaba7c2106f4cdad5bd0578af7f8"}, "backend\\app\\core\\rag\\query_retriever.py": {"doc_hash": "da5b23b78208c811a4f1817c7908848058a0e584d91a4328d66db237b759a486"}, "backend\\app\\core\\security\\data_masking.py": {"doc_hash": "ae7a396361b4987e4ddc1e3443d287ce11d94ede1b5d7c47f81fb8b73b43ade4"}, "backend\\app\\core\\security\\input_validator.py": {"doc_hash": "9323b43e8543abebde729785ad2cb2a8bf4a314018ca58e8c78d1f9e3c24b412"}, "backend\\app\\core\\tools\\chart_tools.py": {"doc_hash": "9ac656311e15dc4fad15c54781c106118803f6fcff851c0b9365e30f3ec6b45b"}, "backend\\app\\core\\tools\\check_gui_dependencies.py": {"doc_hash": "eb9d7d5e4b4c840e3e2a412345a9f968cf3d8fbf7d6c3de3f7baaf5c8960a796"}, "backend\\app\\core\\tools\\check_integration.py": {"doc_hash": "617ead1e7d47da0e80463a2765a919d99cbdbe456de0edfe08b229bc04c4b876"}, "backend\\app\\core\\tools\\code_interpreter.py": {"doc_hash": "a44b4c5d59e15ebda127f4148bff78e45d2a1a2f45202f3c3608cd1179073e03"}, "backend\\app\\core\\tools\\date_time_tools.py": {"doc_hash": "be8e274efd9b8359ee0b189358912bf331008fe603d0b8b5bc306b51b3d0235a"}, "backend\\app\\core\\tools\\debug_server.py": {"doc_hash": "4c62c7ff5573beff15464ad196663f202f53de85ee379d940cb20ec6257c69a6"}, "backend\\app\\core\\tools\\flexible_query_tool.py": {"doc_hash": "6f7cc62fdba0819568612ac8b01355db698553cfdb3f10e74d0158e966eac4b1"}, "backend\\app\\core\\tools\\graph_integration.py": {"doc_hash": "fec170da759553f4d2679a18e5b537da5c53c8783a0a2ab9da42df0f2ffaa1a1"}, "backend\\app\\core\\tools\\mcp_parquet_tools.py": {"doc_hash": "fb3582eef411a87bbaab500cdefff7bc8c39a33c18f1354e25e38becf125003d"}, "backend\\app\\core\\tools\\mcp_sql_server_tools.py": {"doc_hash": "ebb3381e1bbc30d0b02eeb6c689844992a26df5328c4b28b826825c840b60240"}, "backend\\app\\core\\tools\\quick_response.py": {"doc_hash": "96bb5b38e1ed91e95264cba170bde009d79a5c001ca85893e73b8a4017e5fb9c"}, "backend\\app\\core\\tools\\sql_server_tools.py": {"doc_hash": "0d7cdfb3a05103e3e035605f2e78ba02d4eaf1071674ee1e46ee700e8901c444"}, "backend\\app\\core\\tools\\une_tools.py": {"doc_hash": "6be71c03f1dbd133b8014d5fb2f91199903471679ebe934e02f7f588603f785a"}, "backend\\app\\core\\tools\\une_tools_backup_old.py": {"doc_hash": "8147ecb1d0427740339c7cdd9bef0240314d9a5e92081d5b1d898a82d9e1e082"}, "backend\\app\\core\\tools\\unified_data_tools.py": {"doc_hash": "34b5a0ff8cea7840dffcfd8871e4f93f2f6f4cf8de7d1c79b9c58ec34b1b05da"}, "backend\\app\\core\\tools\\verify_imports.py": {"doc_hash": "c814a22325fcb0f77bfbbe9a3d03cbe44abbc939b55e836b978b25e721bccdcd"}, "backend\\app\\core\\tools\\__init__.py": {"doc_hash": "9cf1be337c0f92a15a8759231532c8f78b212e7a952b39498987a2132a717380"}, "backend\\app\\core\\utils\\agent_cache.py": {"doc_hash": "8ec758f433940aa99815f332f7543ec56c9769164069b2d1fec37f3c9c7fc81a"}, "backend\\app\\core\\utils\\cache_cleaner.py": {"doc_hash": "73774af184d72b5edd74bb878904865977b2995c9168d897de4e1723bec16ed6"}, "backend\\app\\core\\utils\\chart_saver.py": {"doc_hash": "ab463e10c7bbd7f5875cdc90b5cab35a96ed159b7f89b62b76d3bdf76fbe967d"}, "backend\\app\\core\\utils\\error_handler.py": {"doc_hash": "cac70a97617de1a482a2d5afce5e4935016460b39b5669d007560b98b276cd06"}, "backend\\app\\core\\utils\\error_handler_backup.py": {"doc_hash": "af3df6f7885a3dbd73ffaa7af4e387a371df7e753f172974d8b523912e7f05e8"}, "backend\\app\\core\\utils\\fast_path_detector.py": {"doc_hash": "b414a4980aa25ed7f21435c83abb75cfc5a4c912b96e10e380b30370959f0640"}, "backend\\app\\core\\utils\\field_mapper.py": {"doc_hash": "451b96040052323ee3a70f95c13815edadb45157036ed2b5ab97170348b8bab3"}, "backend\\app\\core\\utils\\query_history.py": {"doc_hash": "c8899e5d1173288cd1a41ce5b8d7ac6996c2af2ac03e14dbf9eb8806e4db85c3"}, "backend\\app\\core\\utils\\query_validator.py": {"doc_hash": "778eb01314e93fc6278b03666695890b4e6a00f5250134c33ce548287e806d39"}, "backend\\app\\core\\utils\\response_cache.py": {"doc_hash": "87c571361a1f167bf00f1ee4ccd728d7b69ff159abaf3a678156c7c9d6745f3c"}, "backend\\app\\core\\utils\\response_parser.py": {"doc_hash": "f87527406b4782961aef2b75055c75387b176ddbec542409cc63fc668af83a89"}, "backend\\app\\core\\utils\\response_validator.py": {"doc_hash": "7451285ad96adcaa7f1fb8d5512ac4c05a3dfa1a650c438933376af1c3a17530"}, "backend\\app\\core\\utils\\semantic_cache.py": {"doc_hash": "a2fce3c96d949a30bdbb2a00a508ba586a07a4df14fb328f9ac9e9efb1395332"}, "backend\\app\\core\\utils\\serializers.py": {"doc_hash": "0496d65f8691200b0a6bed3d976b43b9b729417deb4166cb9091a3faea40e936"}, "backend\\app\\core\\utils\\session_manager.py": {"doc_hash": "568775c628c6c9f076e742053015a03812fe7a2a5b485d10be3d81c27eecf64a"}, "backend\\app\\core\\utils\\__init__.py": {"doc_hash": "0446435eee3a78d18e2c49c18d55ee844a6e7d4e640efb0da313762c14696c12"}, "backend\\app\\core\\validators\\schema_validator.py": {"doc_hash": "c226472c193f365792fa8e202d99cdd7c528e3b2f80f92752c596ca0af27cf65"}, "backend\\app\\core\\validators\\__init__.py": {"doc_hash": "1a9868580af7d1a5cdd83c625b8db626e64d9c1b4511efab6e45a8e18bb8a8ca"}, "backend\\app\\core\\visualization\\advanced_charts.py": {"doc_hash": "26fbe7f779069d1b5b83cc98f9fb0514597ca3265a33f5f5bede5ea448fb9474"}, "backend\\app\\core\\visualization\\__init__.py": {"doc_hash": "08476213480c33d54e9ec65bc063de139587a1dfc546d3adadc5ab60fb1994eb"}, "backend\\app\\infrastructure\\data\\base.py": {"doc_hash": "dd35592a09cb43165668ddef14c70b0ec0c5ee6c3facff956d7fff1270e37385"}, "backend\\app\\infrastructure\\data\\dependency.py": {"doc_hash": "e5f91be7ef0944b73ac4b814274669870bcadab8c1e460106f457c3e86dfef8a"}, "backend\\app\\infrastructure\\data\\duckdb_adapter.py": {"doc_hash": "094d1d2b2f0635842d19ed789c725e860a7dc85c9358c3a2559a82d70c728d63"}, "backend\\app\\infrastructure\\data\\hybrid_adapter.py": {"doc_hash": "202aa4c1224859ae66d5543d49f6c71d3800342d89ea8c50ad5c87d2aaf27ef6"}, "backend\\app\\infrastructure\\data\\parquet_adapter.py": {"doc_hash": "90c536260c8b796d63ea8d73ea2507d3d7b28efd0ba210c87237929f935c2962"}, "backend\\app\\infrastructure\\data\\polars_dask_adapter.py": {"doc_hash": "40fd3f1918dfdde724af13356629f44a60855390aa8ded976157a7079914c52b"}, "backend\\app\\infrastructure\\data\\sql_server_adapter.py": {"doc_hash": "44ffb640feb0150ba3db450afcf8c9ab92fe5a7b702d3448ffbaa242306cbfcc"}, "backend\\app\\infrastructure\\data\\config\\column_mapping.py": {"doc_hash": "b0fbcd1fec2b4ec7a24a5f74d6d5686fa1c67a9cad2fff4bb6e1b1ed61818e74"}, "backend\\app\\infrastructure\\data\\utils\\column_validator.py": {"doc_hash": "0c8a300da6a958b3c64fc92831b4ed36a98ace9ecd75d64fe2cde7e59eab3e00"}, "backend\\app\\infrastructure\\data\\utils\\query_optimizer.py": {"doc_hash": "69ab2abb3ad500b2f38db8bc0447db394c24f464c20089f8578f8ccdabd617c1"}, "backend\\app\\infrastructure\\database\\migrations\\env.py": {"doc_hash": "297cecd42cd3d5dbd9570a606fd0d90e82b5ac71bad105e22374ff2944638fee"}, "backend\\app\\infrastructure\\database\\migrations\\versions\\fresh_start_migration.py": {"doc_hash": "abe7121583f62dc7cc036480ce40b4e2c5d4ab9d6c228f723d023875af218290"}, "backend\\app\\infrastructure\\database\\models\\admmatao.py": {"doc_hash": "9d929c4e5a9b743d2966a06d8b15f1a0d96152c2cf3aea49192b21a1f398960e"}, "backend\\app\\infrastructure\\database\\models\\audit_log.py": {"doc_hash": "9e3a54b59ae3749b8fb7b9dfd8ee40add6ac7f8534a84f467015428cde4c0ccc"}, "backend\\app\\infrastructure\\database\\models\\report.py": {"doc_hash": "a48d217b4a87e24be42006ff7eb5957421bee67c0317c43cbe0173adb27f56d4"}, "backend\\app\\infrastructure\\database\\models\\shared_conversation.py": {"doc_hash": "de596955dcef93fb1100b1e4302317cf59bf30b34a55f10c69b087b2a9286595"}, "backend\\app\\infrastructure\\database\\models\\user.py": {"doc_hash": "325d51f0eda5a9359737d359422e6522067a8acefa89abd183249328de33107f"}, "backend\\app\\infrastructure\\database\\models\\user_preference.py": {"doc_hash": "f21a055fcac15d4bd80a169733a99e6109413ed5a4163ef45e8768a7953ac97f"}, "backend\\app\\infrastructure\\database\\models\\__init__.py": {"doc_hash": "d378deb691d6ac857b6d44836e3d38f8524c3c02e8fe21bd26cbab14eb2d18f1"}, "backend\\app\\schemas\\analytics.py": {"doc_hash": "32b645bf03ede9236c28a3ffc5fd052cdef00931c9c1c97c9382a88e5342d42a"}, "backend\\app\\schemas\\auth.py": {"doc_hash": "9e43766ffa346b1d77e561c9184111d60983701728b2f25b8596a8b375639d9e"}, "backend\\app\\schemas\\report.py": {"doc_hash": "911c8ad75ef2db7945f3df39f6001bcef35d2163de1f6753f9b5285f17f62479"}, "backend\\app\\schemas\\user.py": {"doc_hash": "2643d840f3e164327aa52a4abd3618db62eb153bf14011a31d2c54d2868aca89"}, "frontend-solid\\src\\index.tsx": {"doc_hash": "0fc681121e9a1f1ef5121fc317659006356f373387dcc07c480c8d130bd6cf25"}, "frontend-solid\\src\\index_minimal_test.tsx": {"doc_hash": "d5d6b73ee3301ada46907d61a30f282752a6db7232d5f14f94dcb2fd1342d89a"}, "frontend-solid\\src\\Layout.tsx": {"doc_hash": "bac9cb7cc2646c49701a6cacceeb0ea24de2513dc187b423d1381f489fc0ddbd"}, "frontend-solid\\src\\components\\AIInsightsPanel.tsx": {"doc_hash": "1f31b5cd2363a561a4b6d1876967e6a0a5fb54b066bd7c68429e3f3ef1036cb6"}, "frontend-solid\\src\\components\\ChartDownloadButton.tsx": {"doc_hash": "a84d3b3a70717d513db5d7b42d0e2071f5ad33aa80fdf937245e5ee51e5c5118"}, "frontend-solid\\src\\components\\DataTable.tsx": {"doc_hash": "d01e5fb8512021e3f7567de5bf5362fa790977339703f93f70626f95ec247eaa"}, "frontend-solid\\src\\components\\DownloadButton.tsx": {"doc_hash": "9fd1af1aa9c29f1f9f3c70ee273ab2dd88f2815cf0e42b3fd2aa1fec3530e765"}, "frontend-solid\\src\\components\\ErrorBoundary.tsx": {"doc_hash": "061d590a5ba4aef516fb8c72a1fb3b78eab6a1e5bf176254140e00ef4db834ac"}, "frontend-solid\\src\\components\\ExportMenu.tsx": {"doc_hash": "c4129d9bc8556b740d61bf07a718240ff792249ec281cb9860fd4be018e12219"}, "frontend-solid\\src\\components\\FeedbackButtons.tsx": {"doc_hash": "5aa4c587ed05070cebd1937f3698bce119fd8758ffd4f291d1d54194f2f3bc0e"}, "frontend-solid\\src\\components\\index.ts": {"doc_hash": "d882a333d75b75dab189836a584779cdb642cd905a8127bb08ae76a9a1d45f83"}, "frontend-solid\\src\\components\\Logo.tsx": {"doc_hash": "298d9f7a04195d46088c17438f563d8333e55a76ec7fddb9c01641b0cac8ff77"}, "frontend-solid\\src\\components\\MessageActions.tsx": {"doc_hash": "3306a957ef02f1e648dcdd235b86f136e333b85ff2bc9b937407813d85924349"}, "frontend-solid\\src\\components\\PlotlyChart.tsx": {"doc_hash": "c1674c8971a0a46999aa7197d8c5096e54363c9fc5768445a5e5acfab7493d34"}, "frontend-solid\\src\\components\\ShareButton.tsx": {"doc_hash": "96815596cb2700df214912352706cf9593b55a9918fbbf59c50110e0ca65fa18"}, "frontend-solid\\src\\components\\Typewriter.tsx": {"doc_hash": "0e6dd25f31f7a1c09104a65b81abe32b7570353b95b6e799f453abd0b29827b3"}, "frontend-solid\\src\\components\\TypingIndicator.tsx": {"doc_hash": "7999182c6b7033ee40c225f09e99ba1875fa98483d37c1a3c3dd4a5f69be60b7"}, "frontend-solid\\src\\components\\UserPreferences.tsx": {"doc_hash": "d7af2f90dc4cb43a7c98b2feb95e469587d99716da1185deae5bdb0c2a8190af"}, "frontend-solid\\src\\components\\__tests__\\Chat.test.tsx": {"doc_hash": "b8d3448bcb8f04a07b5278237f78baffabf4560ce7b603bd224d57abb7305183"}, "frontend-solid\\src\\examples\\ComponentsDemo.tsx": {"doc_hash": "0c7c1c669410d34e60cecf09c0cd805c0a0fb4ead64e817b9b945c8e7b02cff3"}, "frontend-solid\\src\\examples\\MinimalLogin.tsx": {"doc_hash": "3f979a68a0df2deaa7f268e63b33169aef443950a192106573c4424a8dee151a"}, "frontend-solid\\src\\examples\\SkeletonDemo.tsx": {"doc_hash": "1fade4619c85092481e2ae9c4f6ee3a5590d782aee023081f4c0d59dade97893"}, "frontend-solid\\src\\hooks\\useAdmin.ts": {"doc_hash": "3483d759b7a19679127a4db649f7e8c9d52362d0c93a0d455a6dbc00af8b2a56"}, "frontend-solid\\src\\hooks\\useAnalytics.ts": {"doc_hash": "3f76738b0082effca682b8e698a924d8c3c3e76249d49d9c6d7801730960d0e1"}, "frontend-solid\\src\\hooks\\useMediaQuery.ts": {"doc_hash": "7d28d0d64bf331e238ca9d1d71801fe0ff77dc8c6083f25742945f1e5b21f02c"}, "frontend-solid\\src\\hooks\\useReports.ts": {"doc_hash": "b4795659aab5d16c69cdda0025834c687157bf14130bb11e0c529217965f5bcb"}, "frontend-solid\\src\\lib\\api.ts": {"doc_hash": "142326c3a5f15dd3ba899ff7da3ae2e6d97727abafdb73d572c1bb19690eadd4"}, "frontend-solid\\src\\lib\\export.ts": {"doc_hash": "9f8fe879fffef62ae762ba18d5876e0677ae1cc37bb69bd15afcdc161e658a1b"}, "frontend-solid\\src\\lib\\formatters.ts": {"doc_hash": "301c56f6d5e0dd94f692b7696cc8d71ea3aadd23376058e19f2a83d5ee707448"}, "frontend-solid\\src\\lib\\supabase.ts": {"doc_hash": "31a459649872274674b41fd9c38c0225cb40c183f6dc0a1a48e298b379e7f04b"}, "frontend-solid\\src\\lib\\api\\client.ts": {"doc_hash": "d78439aa77930a476c1d083a1f5672f78c2184a93091c1c34fdade6b4737a45d"}, "frontend-solid\\src\\migrated-components\\components\\ui\\Alert.tsx": {"doc_hash": "bc5a001afdada1563a96298e66370f727a806922efb2767e961e6007efe11daa"}, "frontend-solid\\src\\migrated-components\\components\\ui\\Avatar.tsx": {"doc_hash": "dd2010ac4a407829ce028dcbd6ea4a50097c41af8585103129722e446643d808"}, "frontend-solid\\src\\migrated-components\\components\\ui\\Badge.test.tsx": {"doc_hash": "9ddeac15578b318dd836f3a66ba30b6b70049f7580391fafb96955c972ad0139"}, "frontend-solid\\src\\migrated-components\\components\\ui\\Badge.tsx": {"doc_hash": "3debf9f5fcba025cc4f88d573221ef42b8b5013ef01815e7f7d76cba5b5edcf3"}, "frontend-solid\\src\\migrated-components\\components\\ui\\Button.test.tsx": {"doc_hash": "775f8b4f5fab465cf629171c4db07af8e8b3835695e54cfc76fd67ddc7e993f4"}, "frontend-solid\\src\\migrated-components\\components\\ui\\Button.tsx": {"doc_hash": "fd93c6fac83c9483268a8f203b2abf8a1021311668b1ed4d1ad7f9b9a337aa3a"}, "frontend-solid\\src\\migrated-components\\components\\ui\\Card.tsx": {"doc_hash": "0876bf683b6b19d18fd395079c9c3ca7eee510d1ab596965a93576ce9c2b6c1c"}, "frontend-solid\\src\\migrated-components\\components\\ui\\Dialog.tsx": {"doc_hash": "d846e02c1d76c91d4b20d59102d818963d0aa8b1f0ef809b77e7bccec4ce86e5"}, "frontend-solid\\src\\migrated-components\\components\\ui\\DropdownMenu.tsx": {"doc_hash": "6dc2c4abeddd4aa148884de53d33c254ddb2083812aee291e6247d32b7a755a0"}, "frontend-solid\\src\\migrated-components\\components\\ui\\index.ts": {"doc_hash": "b758d6a2d81aac08594389d852d54ffb861b4cc5330dcb7cbe85da66f1f55336"}, "frontend-solid\\src\\migrated-components\\components\\ui\\Input.tsx": {"doc_hash": "ac1a1d3537e6ca739f2a5dacb503da95eb612fa6af2015207bd6af9b8250f1d0"}, "frontend-solid\\src\\migrated-components\\components\\ui\\Label.tsx": {"doc_hash": "33646e58b854b93d520cf8b0f73fe5d0e2197f6bacc10d81a51443adeb096797"}, "frontend-solid\\src\\migrated-components\\components\\ui\\LazyImage.tsx": {"doc_hash": "9080cdda6097c01f7efb41e2131e4f00b3b47b6d04c80a50013e28ba13c45aa7"}, "frontend-solid\\src\\migrated-components\\components\\ui\\Select.tsx": {"doc_hash": "ab192724e402ffc1711cca79c6658a2d5e1e53dec6dceafea232f655ce96fe6a"}, "frontend-solid\\src\\migrated-components\\components\\ui\\Separator.tsx": {"doc_hash": "904a3cb430c158b705958de67ae2cdb0b7f6e932ff1ac28a66b64b96fcb3cf37"}, "frontend-solid\\src\\migrated-components\\components\\ui\\Sheet.tsx": {"doc_hash": "2f7e0ad1040cfa8868a6e50fb5b534405e6081ae8da3058ce68e3eb7466fbb0f"}, "frontend-solid\\src\\migrated-components\\components\\ui\\Skeleton.test.tsx": {"doc_hash": "aaf39922c3abcadf82b92785e83b4585b5487789c666ce779fb7acaf0495fbde"}, "frontend-solid\\src\\migrated-components\\components\\ui\\Skeleton.tsx": {"doc_hash": "f62cc6e1de8c9ec0dde79a03028f25aca6cd27b45e75a6ba6cabbc159d49f4aa"}, "frontend-solid\\src\\migrated-components\\components\\ui\\SkipLink.tsx": {"doc_hash": "f88e8a8d015646569af4f2a37f3ed5800af52c601fe3eb7c930cbc6fb828fdce"}, "frontend-solid\\src\\migrated-components\\components\\ui\\Sonner.tsx": {"doc_hash": "bde1d31656ec369111d87ff505deb053c1774bcfa8fc9071a91e4ef682f0804a"}, "frontend-solid\\src\\migrated-components\\components\\ui\\Table.tsx": {"doc_hash": "bd5da92c92da49f58fe23e19b674131a236b6bd9ceb8ea4f310135f7b9097d4c"}, "frontend-solid\\src\\migrated-components\\components\\ui\\Tabs.tsx": {"doc_hash": "f56c3c1bf1febb7fd49256eca0ac5de9ec357abd2e935f02449af022854ba404"}, "frontend-solid\\src\\migrated-components\\utils\\a11y.ts": {"doc_hash": "aab803df771939c68093142acf7cdbdaa2a623e29fa4d65bcb86bcb73c2c32e0"}, "frontend-solid\\src\\migrated-components\\utils\\cn.ts": {"doc_hash": "6ed9ce317395af93e46967911a93a93063c7a84b721fec261467e60462e61280"}, "frontend-solid\\src\\pages\\About.tsx": {"doc_hash": "4b0f263ca1d058d72ee78ac1e07af6507a060ffffffe30892d928d387f7e0b97"}, "frontend-solid\\src\\pages\\Admin.tsx": {"doc_hash": "d517721f3fca5768291d888ecf4f768fb8530a84952e1df64146367132223087"}, "frontend-solid\\src\\pages\\Analytics.tsx": {"doc_hash": "f1037c387ed90c74a3971c94edda0cf1fee332e8bb5511cad2ded381b4034020"}, "frontend-solid\\src\\pages\\Chat.tsx": {"doc_hash": "7de43e1e677d2ba52a2cbc2c60b3b272fdd26fca855d3fbb3a6d23b6e86dbb81"}, "frontend-solid\\src\\pages\\CodeChat.tsx": {"doc_hash": "490ca6e94b437fa869db2ca381cf1181eeaad339c4824b883993ed97a5a9ad54"}, "frontend-solid\\src\\pages\\Dashboard.tsx": {"doc_hash": "9929cdc1c7dab1254cee1df427feea209f7ec02f565925f27982070f050573c6"}, "frontend-solid\\src\\pages\\Diagnostics.tsx": {"doc_hash": "bea365b0eb9bd22c3dbb453ccb624852d13e0f8f0c3874bf841e4efab96e240b"}, "frontend-solid\\src\\pages\\Examples.tsx": {"doc_hash": "565aeb64bbf6de6cd8283831f0d459208c10d0bd5d7d9a36f0cb29f1dceb52a7"}, "frontend-solid\\src\\pages\\Help.tsx": {"doc_hash": "69f36e5c5fb45b3dd92a6c39c2e10eb4fab88afd8fc93279f6cbcfbf99428d40"}, "frontend-solid\\src\\pages\\Learning.tsx": {"doc_hash": "8e199b17f19041227ee67c283be5256d3f6992491e9b5af18aba223b05443ec1"}, "frontend-solid\\src\\pages\\Login.tsx": {"doc_hash": "eaf08b903345ec6f0d748688f018abb9f5976fd77b2e8b81f03709037f7df50d"}, "frontend-solid\\src\\pages\\Playground.tsx": {"doc_hash": "468248c8d9bd9bd03d5b0c543d3fb649874259f6efcd70d50c39fb98c64aab32"}, "frontend-solid\\src\\pages\\Profile.tsx": {"doc_hash": "ba2e215bfd07f43a5c1cf46b4e9d2180018d8959177ced458fe20497f251d984"}, "frontend-solid\\src\\pages\\Reports.tsx": {"doc_hash": "c67681e527d4153739237249e66da62bd63811f6ade969278a91de42cfa86041"}, "frontend-solid\\src\\pages\\Rupturas.tsx": {"doc_hash": "6c3ac5e8d5389ace041363c08de4fb4343002dc0a0ac1e92ea30bb7113d8f379"}, "frontend-solid\\src\\pages\\SharedConversation.tsx": {"doc_hash": "ab1b4db2a750c56cc0c2bc85d3962b55f51a3705b63d171fa879c6c59fb276e6"}, "frontend-solid\\src\\pages\\Transfers.tsx": {"doc_hash": "ed1053a56baec267223bd6f172dfcc8c974cdd96419bc89bb406804f2ceabe4f"}, "frontend-solid\\src\\services\\admin.service.ts": {"doc_hash": "542cbe89b0e30c8430ec1f8cb7bb5ea336227f4564aa4c5b8ff4e1ce07671c0f"}, "frontend-solid\\src\\services\\analytics.service.ts": {"doc_hash": "84f7f12ef7b4718126a4d15733f3abf408da6861c0570df331ef6cb0153e6959"}, "frontend-solid\\src\\services\\auth.service.ts": {"doc_hash": "00b2a00cb4ce85a11639b01764a0bbb182e5ea7f9a3347700b351848c725bbbf"}, "frontend-solid\\src\\services\\logger.service.ts": {"doc_hash": "b98f75dd71052bb4ac94ae5f286b538a853948999d8158db31a31c66e1ee2538"}, "frontend-solid\\src\\services\\reports.service.ts": {"doc_hash": "7c0e34edddb37adc9d26b42bc963a0ccfff373f8b3c407671eb705ca40b1344d"}, "frontend-solid\\src\\store\\auth.ts": {"doc_hash": "e3bff71ac5805e3ef8e65255588249888b1e0ec383ac753a036d5058456ea042"}, "frontend-solid\\src\\store\\dashboard.ts": {"doc_hash": "3055d552e0f65a8e9a395c85f531562b884f536387d3589aeb15808434c00a2a"}, "frontend-solid\\src\\__tests__\\App.test.tsx": {"doc_hash": "c57ce749fe3f44a745828b4d5a08f4ba040b9ef6c8bd26412ff3e68d98e64a41"}, "frontend-solid\\src\\__tests__\\ErrorBoundary.test.tsx": {"doc_hash": "0a6582ddda2a4f114b582e1f74644179c8a47430046d240b04573e6b4abcaf28"}, "frontend-solid\\src\\__tests__\\Layout.test.tsx": {"doc_hash": "95085520cc5069d4836c7d9ac4e97b66dad523c71c55a6b1cae70aa4d372cf2e"}, "58082931-32a8-41ca-9f7b-4531bb3030f8": {"doc_hash": "2db7447c5bc317c6d4e5bc92821f1508155d35641e74721415d8a5d461735e87", "ref_doc_id": "backend\\app\\api\\dependencies.py"}, "150d3cb4-9dc9-4610-a4a6-8b6931d11879": {"doc_hash": "fae4a8408ce990e6cfc561813442b27250c7eb1edd6f4d68fe1d3e4dc12187a3", "ref_doc_id": "backend\\app\\api\\dependencies.py"}, "d3f34b2e-86dd-4b56-9a26-eaae7d8814fc": {"doc_hash": "899c9274fe5ab2c805f7ced6517ec448ede25bbb54bec223cda7cda442e85576", "ref_doc_id": "backend\\app\\api\\dependencies.py"}, "d8b2fcdf-49bd-4e88-88bd-08f9ef25e748": {"doc_hash": "bc814ee5d346494ed4990f4a8771561d719267b9d362a18555c3c4edf3d76b73", "ref_doc_id": "backend\\app\\api\\dependencies.py"}, "f7f4c971-2a77-4b85-bb5d-226b0d406eec": {"doc_hash": "a9863c7f7a476c07ddf8fa08015a045acee4a1a1a954d8c2d5bed853e8eff5eb", "ref_doc_id": "backend\\app\\api\\v1\\router.py"}, "24fa9906-3cad-41c6-ae10-fd8dd4b60d18": {"doc_hash": "3d123170e8fd8ed39704f0221db7cbbe024c417504383545d0a4df58a9628cb0", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\admin.py"}, "778d9629-eb76-4f1b-b494-90248ab210a1": {"doc_hash": "cd51f2e1b442ec50e9c6944eab06cf55448c88f270191d10bd0aca5dcc289ba1", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\admin.py"}, "bb585dcc-79e2-4fcb-9f92-6f675fbc5332": {"doc_hash": "5832dd85876e232f19fcacc63259fb2b5f86a5868174f966e8576be0ff7180dc", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\admin.py"}, "6006d213-3d66-4cb9-ac06-239bd70f8986": {"doc_hash": "020b35f5c0e3591560e627821ef9a0803a404742610934057e9ffee6f6c58c71", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\admin.py"}, "3a6bffc2-8cb7-4352-8d0c-81674ee80795": {"doc_hash": "9cd4a3e3160b1759b9097d59d8791a589f10d99548fe81463e809ec2a20c011b", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\analytics.py"}, "70ed68cc-ed6f-48e6-8178-31378d6d21a1": {"doc_hash": "fa8e18c7dfb1a4545ae1e361ec013993882187df8c0cdfdabd2e2c815e62223a", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\analytics.py"}, "fb9be564-efa9-46de-84df-0852fd326ca2": {"doc_hash": "5fbb4e4300cf70253ae1bde9f32bec48e2f506b727abc11e45bfa200a6629f75", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\analytics.py"}, "45471034-6b11-46d1-b4a2-ca4e00baf851": {"doc_hash": "f25e5b53bb0e7523e07a32943bacf5407791bb1113cff80641c80fafb4f220e3", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\analytics.py"}, "b47c3bf5-687e-4bac-97e2-9274275d9a8a": {"doc_hash": "df06f7d7454262095fe51ef673addf122ca8b8684a926823784a78c30428ce5f", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\auth.py"}, "635160bc-52a6-449a-acce-136a0dee2374": {"doc_hash": "a83508c72289d9dbb97b653c398c2a05dc40ae0fc6b0f53a8804f959e2cf2c8c", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\auth.py"}, "dd09dfc8-7cfe-41d2-987c-b62264e44525": {"doc_hash": "64f00add3f078fa8823e31445475f6933ff5c25202419c5a60bb173c9447f258", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\auth_alt.py"}, "91612fbb-cb7e-42fb-ab78-df07c3ebbb85": {"doc_hash": "4a1bff4b17dbb50942a60682b41f8a0f952b570dfb6d876a50547619e91aeccd", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\chat.py"}, "27e3ff59-e1f3-427a-8b83-ec964e4701d5": {"doc_hash": "695efd5556fa8c1f83de8926cc100c3602d8b4d4b0480168ab6f150794c66d27", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\chat.py"}, "e38fbc5f-1c4c-4818-ae07-6c418132ec36": {"doc_hash": "9aa7dcd8d8e1ae0a055bb09cd517ab652537f4f2634c67f90a336c7beb379649", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\chat.py"}, "f25adcf7-38a7-4055-b970-333afdd83698": {"doc_hash": "b1cfa74e21c74ed68f9655e30f0fb6239bb0b0655b801318f4b56a0cadf694c6", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\chat.py"}, "4c50e44a-5fde-490c-b0d3-2d73cf899d71": {"doc_hash": "e3d2a949bcf2a8b99af384ae6c1fad2b20cc43bb826c55b90a352be3ab07192e", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\chat.py"}, "45494706-a389-40bc-b49d-7b378c0b4e34": {"doc_hash": "7419b2b5dfae3dffb3b933163cda426055fd5dd429168269ff4b6b122902f0f0", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\chat.py"}, "48e8bdda-e374-42f2-b5bf-465b0c38bda0": {"doc_hash": "ef730189f59e9cc1bcfa4375eb9ad9d15dd53ba89e45de893f1397503e50af13", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\chat.py"}, "9da2c8e9-0322-48fd-b2a3-e754d4df53f1": {"doc_hash": "71dddc8ccee4d637b8080744b8574a72c75f173e4fdc5abeab9cabb87f74fba0", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\chat.py"}, "ff1f9730-47f9-4a75-8c52-d9f6c0c7f8cb": {"doc_hash": "a215f26d6377fca4aaf7e5b064ef1e5fb9b81c77ac5b058814f1fa9a6941c2da", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\chat.py"}, "d5c0c5b5-e7f8-48c3-9044-473ad098f0d6": {"doc_hash": "82a959b81fa32d7c50a57ac32ad2f0dedcb9a8cb6c3251677f641d30444f092a", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\chat.py"}, "8e225a93-bf20-4111-bf8b-7221b3da0170": {"doc_hash": "0c8d222b6b7d819b8275896ce76391919e157397d10cfc7d0cb17893080bb8b1", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\code_chat.py"}, "b7deae1f-eb45-4224-bfe1-10e95204b01e": {"doc_hash": "09356bbd0a90df7b80b0e15c144acd318c722af5c531e00b0c4505e54768f193", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\diagnostics.py"}, "2f60a0b4-329a-4bb7-b983-4940ae84d80a": {"doc_hash": "93ae8f7dbf5590c96f3158a4bc960f06b908ad67cd7c432f5bfb9e96de64b884", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\diagnostics.py"}, "097482aa-c5ec-4976-9d4d-d166c808493a": {"doc_hash": "2dbf430d1fba7c930576c2a79865cde9423ad35d5374b7312c615e29b5a32de1", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\frontend_logs.py"}, "51a7b37d-eb41-4809-a1d6-3e1b2a18077d": {"doc_hash": "f5b3d27a16309897108ad058392c42623175f89c892a6a8daa44c6942f7406ef", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\frontend_logs.py"}, "f056961d-269c-488d-b7df-a5fdd3e14549": {"doc_hash": "12e7c03fd40f781da2f80faa4b6ee55d8af5867af19de6f99848729b11ff85c2", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\health.py"}, "a9989792-b93c-4b0c-99d3-4a63182d8654": {"doc_hash": "d058d2ec57b8c1dfd8d2a22f47440afb59ec26b04ac797002ad41a2af1817164", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\health.py"}, "82031e68-f69b-4eef-854c-78fb083d54ea": {"doc_hash": "5324a73fdef637eef2e22d54611bdda4e6cdc991ad17262a14d97b413d703df5", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\insights.py"}, "c7ab3d6b-acee-498d-b53d-c0f36cac4b84": {"doc_hash": "0e48f03b024dc864e7346cae9eb5c280cdf3aaebfbc9d39a7564d45c5b50e815", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\insights.py"}, "1c507a39-2102-427d-9d63-44048c7ccbfc": {"doc_hash": "735387eba878faf2dd9949594c6ae130814a3bab61291117650e7b4479bae689", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\insights.py"}, "6f5a3cad-b49d-4c0a-8dcf-15b2b4489d36": {"doc_hash": "202cb443fcf3534f11d4d9442f1007d7ef791756c9f5825df8cd89bd313f4678", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\learning.py"}, "e02d81be-029d-4132-bb04-6f2b6fa248fb": {"doc_hash": "9a2013b2c7c86fc01f9257f91a96ffa5745c69baf73a8f7aac5b548f616afbbb", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\learning.py"}, "88c1671f-fc8f-448b-8392-842a9b530b5a": {"doc_hash": "2748e1fe804b3c37a9a949006854c17f7f75a77271117448a9c8ca0980ad8b67", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\learning.py"}, "b27338c8-8188-4cdc-9ef9-a5e3b6659293": {"doc_hash": "f8d9981404548be4c961493c0ad71787178e95daab650cf28f91eeafd1a185cf", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\learning.py"}, "2f924312-872a-4707-8b78-1e207f2afbe2": {"doc_hash": "64ceaf5d3f51671f9242028484e03bda4e3d94da4fe5e84736c6a7762be66a01", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\metrics.py"}, "37f0710a-6e73-4f24-b22d-6bcbcc976516": {"doc_hash": "a466c6d08938600b9daab2680255d7b86ad59de0c5d55017e1ec34be27babb35", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\metrics.py"}, "d38cb375-7122-49be-b411-ab60d4866688": {"doc_hash": "f78d11cd5166aef248d29f62bd59f2ab54e108e3820d5f4caa83de6aeb36052a", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\metrics.py"}, "82d936e7-0653-4ed4-9bfe-fd31b30a7b00": {"doc_hash": "d6a7263b96477c33bb46b5fa728133ca1b6589862c9b3ac713a254b604b42ee6", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\metrics.py"}, "0fdf0b74-991c-4d12-899c-d547d926ecad": {"doc_hash": "ecc0ac95da09447b69e91cd54a6a83fd99738d5728b234572e9acd2135654409", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\playground.py"}, "5e1b27b7-f333-425f-acbc-5fe083d403f6": {"doc_hash": "4d65775992c190ec593adeedc74f6be63e8792fa6ee8ebc9621f9871b0d00444", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\playground.py"}, "cd6f9f9b-001b-4617-bed7-e9ab7e311471": {"doc_hash": "124eda212ea905559e557da8d563175b50733f461d07ae4ce62edbed9b28cf32", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\preferences.py"}, "d0290f4a-517e-45ea-a30d-4aad9e0cf542": {"doc_hash": "1c096e460bd5f4113a2d2e9c8ab95db25cd1c45d9634a238d55a305c8ce25b8a", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\preferences.py"}, "71c035d9-d7a1-479e-924a-c5bc238b1df3": {"doc_hash": "3dc4ff7ef821aede2e6efe2865150263f6cf18ceeeee4d9fc67d05fbc55b9308", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\reports.py"}, "bbcfc8f0-9aa1-4511-9f6c-49b7c3acc98e": {"doc_hash": "f8ad277275acb9f912cccad17fed2f169af284768dd6f0fd5bd6a0627aecdc19", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\reports.py"}, "c879c073-5889-49e5-9bd0-d336a3623939": {"doc_hash": "928136b175700e65ae9b2f4491bef137733f640dbd4a5060dcad6e2f59d8764d", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\rupturas.py"}, "2eafb285-318d-49e8-baa9-76d9f9d66bc5": {"doc_hash": "3b908c54d8da7fc4e646e25006ed692c288075c46ffda78080960cc37806ec7e", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\rupturas.py"}, "e2a7c042-fe91-42d9-b4a2-e7ba431684c4": {"doc_hash": "55769b9cdf85b11532173fbd39b51428ec131353dc22ebe388587845eb88b9f3", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\rupturas.py"}, "bc409440-e61a-4817-8a40-cf2c8dc3424a": {"doc_hash": "d69fa86276697666b33116e88eda49fa8c9c99e77f6fb0ff745da944435e33a0", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\rupturas.py"}, "545248e8-3e14-4af6-b6bb-9f151b084be0": {"doc_hash": "c67a462069387354f04705a1131eba061adeef3008c69fc30177180d13ab2b1f", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\shared.py"}, "bee91eee-1fff-4ff1-b3cb-80e20cdeec22": {"doc_hash": "28148d69ec141214e9b17bf611e18ac4982a1ac73db9a4a95347dc205b279c88", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\shared.py"}, "28eff17a-aedb-4967-9386-8c93300eea8f": {"doc_hash": "af319ac673aab06b42ebbbb6ecb62e57af051d54f8c05eb0bd14a6c2e0d5ebba", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\test.py"}, "70fc8a6c-750b-4098-a4b3-382346c31709": {"doc_hash": "31487cbac2b20ba931ae92df24836e84adf6608b5acf6c538f0cf1763fb5b66d", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\transfers.py"}, "047d89d4-ae5c-4452-acac-bb2c40b301a6": {"doc_hash": "eb22b4d2ecfdbf5a2255493ec52a50ce449a64cdf08c32f154ecdb3e7e3edbb4", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\transfers.py"}, "145cd032-9fd0-4da4-a6c5-5d12fc566986": {"doc_hash": "a384aa558ce453f6a7c8da8bf330b3f3209dac9c8564d5f9d2cc524b64104e85", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\transfers.py"}, "268fc4d1-7c00-4d08-b513-bf8f70fb14ed": {"doc_hash": "10ba451ef6afc6e06ff2efcd9b6766203f602da00af896bfe92f7a0faf0826a3", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\transfers.py"}, "4c79efcb-2de1-445a-a099-a72ac14ab0cf": {"doc_hash": "ef7660a0ef4cb538327608887758daff40e38f25ff2fba28cfc8867a525676a1", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\transfers.py"}, "a89b94a7-3062-4513-85ae-c51ee9268fdc": {"doc_hash": "9015ebb32fd32f820a8b7808c08ce0f990328cecd0ed2232740baf21f4d5d9e0", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\transfers.py"}, "c0e650a0-f70f-4fea-b649-49819858b4a3": {"doc_hash": "a7a76b0dd19156d65cd4125634451cc7e1bba50a4f68ea9ea6a6184b96c68314", "ref_doc_id": "backend\\app\\api\\v1\\endpoints\\__init__.py"}, "fde7c6d0-075d-4888-af08-44a378fedd82": {"doc_hash": "50ee9813af5d14827f7593c72a6db1b8663afedda6619036d95f10e84bbf209d", "ref_doc_id": "backend\\app\\config\\database.py"}, "892e0ab9-9f58-4c07-8b1f-e8a0d0194f49": {"doc_hash": "effe423609fbc00edd50adbb28e4907565b2cdbfab047fbae75901c850a94afc", "ref_doc_id": "backend\\app\\config\\logging_config.py"}, "caad3ebd-5e8f-4b58-8768-725e8d491b31": {"doc_hash": "f82fafa33c5225690bb41a73e94968bc2992904402c4f20d8fb3a0ad9da3cce8", "ref_doc_id": "backend\\app\\config\\security.py"}, "c9780eb1-8803-4602-ae4c-d9f3cfb1046a": {"doc_hash": "f40ab8bd6c58c5822b715d52e82010f33ea7ebb30011eaae3eaa185ddf8521f1", "ref_doc_id": "backend\\app\\config\\settings.py"}, "18dfbd0a-b90d-4e53-a08e-4900b6e34454": {"doc_hash": "4194eb60e48d05e88f171971a265f2046a573157f83059d2cf0f822b1133fec0", "ref_doc_id": "backend\\app\\config\\settings.py"}, "35df4a91-3d5d-4e96-b018-1b82d07b98e8": {"doc_hash": "743a146a1d6198749e2ae7224ea923e74ba63cbb86a051b94768918029c47561", "ref_doc_id": "backend\\app\\core\\agent_state.py"}, "79309bb5-8fe3-4a70-962d-6f66f5de2e63": {"doc_hash": "c25701a2aeff89a492d9385bb74408153987c0b42f55265a7869ef640b5130e1", "ref_doc_id": "backend\\app\\core\\agent_wrapper.py"}, "bfefa093-8c3c-442a-8496-90cacf6761f7": {"doc_hash": "b60959c1504a3bd9ab872dbf0fd44a99d43b293592122254753412845af91017", "ref_doc_id": "backend\\app\\core\\auth_service.py"}, "1d00a343-dd45-45dd-9e14-d5fefa7b90c0": {"doc_hash": "078e0332f61d6a876d699af069a1bb0bbc8fbcfd47e2f36e5c837a29a9fdbc36", "ref_doc_id": "backend\\app\\core\\auth_service.py"}, "ac60eb75-87ba-478f-8084-7969d72da354": {"doc_hash": "5fac8459f61651a883263dd36bfbab72445eef1368f3904f6ecab4e81c0fc299", "ref_doc_id": "backend\\app\\core\\auth_service.py"}, "c91b6aa7-bf89-4813-a0e4-e94cc922a71c": {"doc_hash": "0c73387449e1dc47b6fa8020a8e09cc630cfcf5cad966dba7ed272361b3b39f3", "ref_doc_id": "backend\\app\\core\\cache.py"}, "56c2701e-ad67-46c0-a8ed-9fe1a6e25581": {"doc_hash": "707e337cdb8842bf451095a5a2646a29ac43e0f34192abb63dabaf2e7a927f26", "ref_doc_id": "backend\\app\\core\\cache.py"}, "b1a9e8f5-5e17-43a5-9bb4-3c6744a8bd93": {"doc_hash": "a79ee5ba368e9a3c694ba380134702c5945f302006423be2f39da63b41da5141", "ref_doc_id": "backend\\app\\core\\code_rag_service.py"}, "6403afba-51c1-4f6c-b365-efafee85b144": {"doc_hash": "464cc387df0a44a6835cada66e08e941592b8f43e1287a3d44a47fbea5a9f874", "ref_doc_id": "backend\\app\\core\\code_rag_service.py"}, "e97473d7-a5f6-46f1-9d9e-99631575d09b": {"doc_hash": "59cda55d1d25c50f5680d909ccff831e7c02bf075bd1ba09a0723a1a719118bb", "ref_doc_id": "backend\\app\\core\\code_rag_service.py"}, "42732543-6c2f-4e73-8dd6-ac4be898b5b1": {"doc_hash": "44975645befb3ad72d792cef0609fbf1da0c748f70fdba7d9266649d118fa7d2", "ref_doc_id": "backend\\app\\core\\data_scope_service.py"}, "99a8af09-6eb6-469c-919f-60416aaa9a3c": {"doc_hash": "b9d904088d6c393c37986ee032c30b068f3f4058cf8f24ec1838162b34708fc0", "ref_doc_id": "backend\\app\\core\\data_scope_service.py"}, "7ea3a0e3-5c01-4c32-b45e-03d6bae9f502": {"doc_hash": "e04297cc4b0bc8f8124aa6694a46a3ceb98160ea7e0b0b0102eafbfbc9325125", "ref_doc_id": "backend\\app\\core\\data_source_manager.py"}, "86368921-8967-43d9-9aaa-00cb2893ad8a": {"doc_hash": "d51fa6bb26ec925a7ce5d905954f6051ce520229329fc1b5bb8e8ced43ef1054", "ref_doc_id": "backend\\app\\core\\data_source_manager.py"}, "65264fb7-389f-4fff-afb8-9ea43ccfb1dd": {"doc_hash": "66a602e4df644127e9e44369c02a5c796c05ad70541203aecb609a4fcf248cf8", "ref_doc_id": "backend\\app\\core\\intelligent_chatbi.py"}, "56df4def-f334-41fe-a1ef-e6132e2289e6": {"doc_hash": "31aeb681d0b2fa49f757e262572aa944e7210b39f0fa7fbf8ab286e66238f096", "ref_doc_id": "backend\\app\\core\\intelligent_chatbi.py"}, "23ff1bc8-8bbb-4c2f-8901-34cc3266eebf": {"doc_hash": "bb864b7966d333dc7aca491248e025e1ddfc8ef5c8c2a9dc73150aa95ee8495c", "ref_doc_id": "backend\\app\\core\\llm_base.py"}, "73e8fe35-2841-443a-8b49-759ef6bde37c": {"doc_hash": "4d5fadaaa55a6e49f7f757c892e73a0dc1344e75ae9dae4e62b7598ceef2d682", "ref_doc_id": "backend\\app\\core\\llm_factory.py"}, "c830c9da-4199-4468-879e-d54b48f30318": {"doc_hash": "cc00aeefd7fe0ef02d8a498559a427c8c2c78d5939024a6d3708a305c68eec0e", "ref_doc_id": "backend\\app\\core\\llm_gemini_adapter.py"}, "9c7ad729-e66b-4206-9169-fee6ff3780d0": {"doc_hash": "24a8e8c71b9ca223471f048e1e7381c9e0f6e23633a1873b1d6dbdc58f06e260", "ref_doc_id": "backend\\app\\core\\llm_gemini_adapter.py"}, "4edce7b2-f4dd-4e94-9742-02aa6b759f21": {"doc_hash": "04f15cce2c0d0c1ffacf88a10ec6bcffa958d58d1e2699c939d6039050a165a1", "ref_doc_id": "backend\\app\\core\\llm_gemini_adapter.py"}, "91e58a52-b4a0-4234-893c-1c1442345eba": {"doc_hash": "a06f8cf3a05f7a485fa6b0109311455a8a65aa9101ac9ede85bacc88ad2a8767", "ref_doc_id": "backend\\app\\core\\llm_gemini_adapter.py"}, "5ddeeda6-58a7-4f49-a73d-a242b805006b": {"doc_hash": "46e41eec3773ae5aa6c43deec16b7da8906a4cc16ae5890452b066217fbb2537", "ref_doc_id": "backend\\app\\core\\llm_gemini_adapter_v2.py"}, "24002163-0b97-45a5-afc8-b17d0d962528": {"doc_hash": "1c9fc59abbbeff5f437d23604eb8cd4731ad6e138e07b6b556b921075f4bfe09", "ref_doc_id": "backend\\app\\core\\llm_gemini_adapter_v2.py"}, "cf4bdbbf-4b76-46a5-ad26-579a59339ae8": {"doc_hash": "a259dc5b710f7430af187d2f3fbcefa1641b4a3233f4b1748944c33f8371dc34", "ref_doc_id": "backend\\app\\core\\llm_gemini_adapter_v2.py"}, "3502d494-611d-4d04-a04a-db3c6ad9803c": {"doc_hash": "556886f0c6a57df9530ea499a024f52639784989e84e17aa53a3771d17a0acc6", "ref_doc_id": "backend\\app\\core\\llm_langchain_adapter.py"}, "a775e479-8542-4ec8-9fb6-998e9899ac27": {"doc_hash": "0369a53120c7f39b12404220af1a91c0da17aa872d2f24903a4c7c3f0eeaf2c8", "ref_doc_id": "backend\\app\\core\\llm_langchain_adapter.py"}, "54139b18-3bec-4872-a986-15e94f97d4f9": {"doc_hash": "2be21abe40a91267c7e8ed747441ceb77e71e76d0234eb35425aa7037467f782", "ref_doc_id": "backend\\app\\core\\llm_langchain_adapter.py"}, "87bb6590-62bf-4756-927b-cb395ca8c0b5": {"doc_hash": "82821470289099a3cd3b3ee05a5579142272f2aab4db6bbbe1ce12aaeed62397", "ref_doc_id": "backend\\app\\core\\logging_config.py"}, "6ae21694-0a16-4722-bd7c-64ad2a0bd6cb": {"doc_hash": "1bab1918e2e14252d8136c79ee2f9ca10c1c779b8360bb310f166554c071e717", "ref_doc_id": "backend\\app\\core\\logging_config.py"}, "158bb008-e571-4c8d-9086-d99eee39d4fa": {"doc_hash": "5d77d890b8469d7113c1e07004265d19e81e63cc6ca55ffba943ede09e715d86", "ref_doc_id": "backend\\app\\core\\logging_config.py"}, "f8127b43-7e24-4fa1-af64-dfae1d2258f1": {"doc_hash": "8624f7323191e208b631f9abf8ac93290cef4c7910dda9631abe5d1e96d25380", "ref_doc_id": "backend\\app\\core\\logging_config.py"}, "bf5772b8-5805-4976-bf48-cf30ea5fbd1e": {"doc_hash": "a6196c2b8084984976628107275bfc58eba33ede151f86cbbef2b39a933dec39", "ref_doc_id": "backend\\app\\core\\logging_middleware.py"}, "f8e1a478-0729-405b-9d67-fde5c02cb13f": {"doc_hash": "0608cf6aaa3c89f3b213fc3e475d3019a8602e20910c380f4b2792a29fdbb17e", "ref_doc_id": "backend\\app\\core\\logging_middleware.py"}, "8b299532-3bd7-4cda-8c38-a95e51ea8b7f": {"doc_hash": "d7a70190f4612425eaaac7841e7e7cc3db40544893153243c1cfbea41d2199ad", "ref_doc_id": "backend\\app\\core\\logging_middleware.py"}, "64ecbbc7-b695-41e1-8b20-0236d8ecef05": {"doc_hash": "73ca9dacc41b3646ac3bf6f5d593e16deced771749f04498e823a074aa4c2ac9", "ref_doc_id": "backend\\app\\core\\parquet_cache.py"}, "6a5771e6-6c98-4601-8b3c-f482e6650bb4": {"doc_hash": "8b91c0b79d812642289385884e26fd9e75c8097f54121a9138a263669e8a81d2", "ref_doc_id": "backend\\app\\core\\query_processor.py"}, "d3d29dc1-a1cd-4bff-aee9-9faf609c75f9": {"doc_hash": "bbd3e173f09fb1395d8b09fcb7a7c6354969708e8bc13e9bb961f6804def70bd", "ref_doc_id": "backend\\app\\core\\query_processor.py"}, "ba52c219-6524-40f0-9eab-9073505fa1ec": {"doc_hash": "14b2b996c0c7584e458a6180b68ee64315deedb60142bcc770a7a8c44a73e439", "ref_doc_id": "backend\\app\\core\\robust_chatbi.py"}, "1e3feb3f-b17d-4af3-82a5-0e5d36180f83": {"doc_hash": "827c28f74dfc3da85d6c019b070721bf33aaf305461dd4f1834196a0b52c2e5e", "ref_doc_id": "backend\\app\\core\\robust_chatbi.py"}, "5e7c0ee4-5508-44f0-a41e-845d536efafa": {"doc_hash": "2dbe9e566b2c10e4ce39e9257686d09d8c9d3a98f1895eb663629b67fb4b785d", "ref_doc_id": "backend\\app\\core\\robust_chatbi.py"}, "d51869ec-548e-43f7-ac9c-a6c2dc2c3c71": {"doc_hash": "7d303b6a5f6567fea0b9e1bac97885a8cd4b2f93e9dcd92ff04c8ed02463f713", "ref_doc_id": "backend\\app\\core\\robust_chatbi.py"}, "766ada64-ad24-43aa-a820-21d7237d2949": {"doc_hash": "b45701d12e5bdaf798079c862ad6470c5c23298ae8078b7d8833fdde3542a9d2", "ref_doc_id": "backend\\app\\core\\supabase_client.py"}, "f8d95136-8ae4-4653-b70b-40732bd50f33": {"doc_hash": "a92b0584312935ac14f93b4da6c7291ed71701444af0b2ea10a3e47196c692db", "ref_doc_id": "backend\\app\\core\\supabase_user_service.py"}, "6f05f933-a8ab-4fa9-a1ff-16837e5f6bce": {"doc_hash": "cd35877b33d3e5de23e9e4bed54d155df8932f2bfb000f7aeab06f1899cb0dfb", "ref_doc_id": "backend\\app\\core\\supabase_user_service.py"}, "dc1b766f-8d21-4d66-98b9-a8a45ec5e5e8": {"doc_hash": "f0458160f96d05b3be3366c12ad87d627836d8e3c0459abc1390371e92b9ed0c", "ref_doc_id": "backend\\app\\core\\supabase_user_service.py"}, "ed69023f-2dd5-49d7-89b1-960a384e0ad3": {"doc_hash": "2cf85fb4b1b3963459536db048480caa497eb8167bd652bac9713efb8705f90f", "ref_doc_id": "backend\\app\\core\\sync_service.py"}, "30774f0c-f1f7-47de-987c-47698dcd75fb": {"doc_hash": "f1d8d4265cc0d272d321d513bad400cb8019031de0195ae39349799696a88a57", "ref_doc_id": "backend\\app\\core\\agents\\base_agent.py"}, "3bb372d1-cb9b-4496-937c-d4f2ac459df3": {"doc_hash": "24131a36c45c2cd6f219c9bbd810ead3df4a0afbf5bdf8dec162231aa0ad48aa", "ref_doc_id": "backend\\app\\core\\agents\\caculinha_bi_agent.py"}, "06a5fb52-7562-4c5a-9a85-cd8ad763dce0": {"doc_hash": "f314bcf409946a77c0a78c0c1fbf3c5a1452854c999d8c2347c80a3d49904312", "ref_doc_id": "backend\\app\\core\\agents\\caculinha_bi_agent.py"}, "e5b2b21f-921a-48d2-96fd-d0ebd2911868": {"doc_hash": "1a1ebe8edd25dfb1a1409290a2032bf7562931e8b41ed756fe9c0933cf9f7444", "ref_doc_id": "backend\\app\\core\\agents\\caculinha_bi_agent.py"}, "3b3a80b2-bf4d-4bc9-aecb-5d140878e2cd": {"doc_hash": "129f5549656002f1945fa43134ef37404190b6d3f01d91d74cc0254109dd3004", "ref_doc_id": "backend\\app\\core\\agents\\caculinha_bi_agent.py"}, "c7e840a8-383a-4625-be80-70964df4672c": {"doc_hash": "b52d51b590295662139d46fef776eea1a8097aa6140cfe39ad3e0285893ef947", "ref_doc_id": "backend\\app\\core\\agents\\caculinha_bi_agent.py"}, "44e40181-e2fd-4e3c-b89a-fbb3c9d714e3": {"doc_hash": "ac4a771a30265a7d529a0f8b41d5449b12f07eddbb53c77a490ab34dd8cc49c6", "ref_doc_id": "backend\\app\\core\\agents\\caculinha_bi_agent.py"}, "898b371c-db32-47db-a3a3-7ab2c4205440": {"doc_hash": "d68164b19f24fbbbda0af95df3814bba4c51da0965c054f06652497829c2e468", "ref_doc_id": "backend\\app\\core\\agents\\caculinha_bi_agent.py"}, "5c51cdf6-258f-4d03-9deb-bf1ccbbe9f16": {"doc_hash": "bc72b15fcbf56fb1bf01e17a55c99cbc9ff8ada21fe7943139e9b4a49aacbb78", "ref_doc_id": "backend\\app\\core\\agents\\caculinha_bi_agent.py"}, "1eb0e2b2-8f38-46cd-a670-808454068195": {"doc_hash": "67586aa12963c320094c3db27ffcdb7b102f94b1fd5f54e4a4a34e4aa86d9f83", "ref_doc_id": "backend\\app\\core\\agents\\caculinha_bi_agent.py"}, "c60fc81e-6786-4c41-9fe2-b5b8815533f0": {"doc_hash": "475ea0d54e305761b580df19970bcb61c63d43f359b48336c46d191c55121b26", "ref_doc_id": "backend\\app\\core\\agents\\caculinha_bi_agent.py"}, "f3855e40-0bfb-4cdf-a3b5-ad5fea600a50": {"doc_hash": "24a7531ee253304fc4c28855bf09cecb9623a04ce62fbc6134927b7e32cd559b", "ref_doc_id": "backend\\app\\core\\agents\\code_gen_agent.py"}, "25796a1d-8fb8-4cd2-b811-fcc5610dc200": {"doc_hash": "db7791a9f19284c3a3f40850d26b91021d7de29bc8bb0f3222fd24c49a6e3554", "ref_doc_id": "backend\\app\\core\\agents\\code_gen_agent.py"}, "c12f18ea-55da-4068-9f4a-2a62625fd3f8": {"doc_hash": "05a6f12057154b2e933dde67cdb53c93be5d3b17ac75e84c8f33529bf1f4fc06", "ref_doc_id": "backend\\app\\core\\agents\\code_gen_agent.py"}, "556c4691-024e-4413-9a7d-49ef17673983": {"doc_hash": "592d9b9e5c487d5e0f0245f78f6403fc1d174d0e536bc65015005b5ea978f911", "ref_doc_id": "backend\\app\\core\\agents\\code_gen_agent.py"}, "abcae947-3821-4ec5-9abb-ac3ecb4cf121": {"doc_hash": "16f34578596eba01f1c7fd9d1fe0ab484d6c6656c794f1ce2bc5a50c0d502e4b", "ref_doc_id": "backend\\app\\core\\agents\\developer_agent.py"}, "a55741f0-4179-4fab-af05-bdbf006e9dd7": {"doc_hash": "ee699ebe3e18fb5e5e944954574b2f55f24c8ab948ddc7f11550374b61d6a200", "ref_doc_id": "backend\\app\\core\\agents\\multi_step_agent.py"}, "741abada-4bf1-4758-bed8-30d4f8fb5aa0": {"doc_hash": "09e1df4346d0a83cb409d4b0f5a7f3cdb98657385e42c440252b07ebdd27dcfe", "ref_doc_id": "backend\\app\\core\\agents\\multi_step_agent.py"}, "89d236b9-f029-4959-b677-aa92c10b740a": {"doc_hash": "7ae409c09a7803d4b45b05f52d77375de942286399e7e898c2300f529553896a", "ref_doc_id": "backend\\app\\core\\agents\\multi_step_agent.py"}, "f5d22f14-d91d-4179-9e5b-dc8429195921": {"doc_hash": "1db08706445997a5792ab8e4cddd585b358ee3c8e92df702002aa0c10d0ee07a", "ref_doc_id": "backend\\app\\core\\agents\\product_agent.py"}, "853be3c2-b53e-406a-a8d7-64e6cd41be26": {"doc_hash": "d311396d17ec0c876873ef98710fcc667f3f04a72b00d87da530cfe574d98fee", "ref_doc_id": "backend\\app\\core\\agents\\product_agent.py"}, "ab396180-76a2-46dc-b858-d4ceb94476c4": {"doc_hash": "d9e5e2950e1e3df04a6a220a33344afd13f2985dd2d3fa07026b89aea2e59bdd", "ref_doc_id": "backend\\app\\core\\agents\\product_agent.py"}, "71452bd2-2aee-405a-b872-6cfc528ca98c": {"doc_hash": "1bd875f7b85c9748299df2aa2871c5934a0630fe24e53c781fd1813284828040", "ref_doc_id": "backend\\app\\core\\agents\\product_agent.py"}, "09a50ea9-8734-4a05-af88-75e345d3954b": {"doc_hash": "d6484a8fae30bc1f3a04d22cca074bc58fa0f2c1e889704823126d437c84bcc2", "ref_doc_id": "backend\\app\\core\\agents\\prompt_loader.py"}, "9297d392-c2b3-45c3-92e1-a7c2df1a3b0c": {"doc_hash": "9f3e2a9872eae835a36ead66e25055af06dc83699beb7fe556e5ec9fb474c0d7", "ref_doc_id": "backend\\app\\core\\agents\\prompt_loader.py"}, "a2d303c8-8f09-4d97-b048-67f5f8fda439": {"doc_hash": "fd8670428abc0cc04ab35fb54844a4e469d6d66f54d0f1c62fe86b122650db26", "ref_doc_id": "backend\\app\\core\\agents\\supervisor_agent.py"}, "07bc0f44-9daf-426b-8c14-4acc43fa1f30": {"doc_hash": "08445dbb58bb6366d878af18e3bda1f535cade4c1df61c6d30c6c40193f806a9", "ref_doc_id": "backend\\app\\core\\agents\\tool_agent.py"}, "a3ea291f-822d-4eed-9e86-12ab3439f7ad": {"doc_hash": "6e5c29904ad100dfd59b3a3de39fa7d17a6571a6dd959bc5c21250fdb40ae491", "ref_doc_id": "backend\\app\\core\\agents\\tool_agent.py"}, "c75cd658-ef16-4f71-b7c6-8816faf4d5d2": {"doc_hash": "635856480a4fd02d1ecb46f2cefa50f86641797e0877ea123448ef2a6ab8c5fd", "ref_doc_id": "backend\\app\\core\\agents\\__init__.py"}, "157ea64c-29a0-417b-8561-29707217607d": {"doc_hash": "ea97f5f12fe72144d328ec0e659366c09ea542570971259c9405eaf5a56f8fea", "ref_doc_id": "backend\\app\\core\\factory\\component_factory.py"}, "9262ea5b-daff-4eb0-8f66-55f44a38f11d": {"doc_hash": "bceff5a655c5a2f61be7bdc35003eed80946fb2fb5b7d8c7edfc9cfdba5435dd", "ref_doc_id": "backend\\app\\core\\factory\\__init__.py"}, "0b3d75a7-d12e-4822-b714-48380c02b354": {"doc_hash": "d9957f66ddd5cff30ba9eafed0bde7384b3b492bf6667c523bcc9d0c2a4f8075", "ref_doc_id": "backend\\app\\core\\graph\\agent.py"}, "e5c247c5-c1de-4686-b6b8-e95869bf0a56": {"doc_hash": "5db8f882aeac7cfe4e667de549ba04621052284c5ba149d441f29ce43e9f2c7a", "ref_doc_id": "backend\\app\\core\\graph\\__init__.py"}, "922d2f8c-ae8e-4779-b2e0-e079ae3f271c": {"doc_hash": "d33f0863e3e720a6ae026260f64371bf8e29267657b77ede6747db08931b74b0", "ref_doc_id": "backend\\app\\core\\learning\\feedback_system.py"}, "1c5baf03-8174-46e7-99a6-6266f85a45e2": {"doc_hash": "eada4e2ff2d4cd74953158dd26709dd34ec71502dd9ade335b67f5ceace108e5", "ref_doc_id": "backend\\app\\core\\learning\\feedback_system.py"}, "90ac3a75-05f0-4289-948b-430d3a053aff": {"doc_hash": "0694a72a7b4065ace761d30f633692dae5436cd0fdd7e67b900e3b8e0b19a529", "ref_doc_id": "backend\\app\\core\\learning\\feedback_system.py"}, "b4c9d948-edb7-4948-9632-ce4b6a32335b": {"doc_hash": "9fb11d7e7d41e4365526b50b21c10eb8e6530a8d911a53d644dffca0d0f85358", "ref_doc_id": "backend\\app\\core\\learning\\pattern_matcher.py"}, "b0f78a20-e1be-4614-8cfe-f7975e3e265b": {"doc_hash": "683af168a37c4c2649b76a54b385da6ba04ebfa9fc3a421c72a000bea8d776e7", "ref_doc_id": "backend\\app\\core\\monitoring\\metrics_dashboard.py"}, "d2cb0dd5-b8cb-4501-8ee2-236dd56a174b": {"doc_hash": "0eae5f819f5295a07f6a7a8644232ce2880640cf89bdac75b6d41099fbad6166", "ref_doc_id": "backend\\app\\core\\monitoring\\metrics_dashboard.py"}, "19f2d2e3-aa6c-44d4-9c78-09ee0a97ec6d": {"doc_hash": "d8b18d6d9122f7706872257c3ca7d939f7d1dcfe72ae74e61da29f107c883d8c", "ref_doc_id": "backend\\app\\core\\rag\\example_collector.py"}, "289f6ffd-cf92-44a3-ab99-9cd883d65803": {"doc_hash": "70c012bf7c0c085dfcc8bf5729e105de30377a1859481e5d20d4a6e46af179c4", "ref_doc_id": "backend\\app\\core\\rag\\example_collector.py"}, "b3012dee-1841-40be-b766-5b8d59b7b4b3": {"doc_hash": "5756f362817482687e06d10021993717254bfb151baf16a24df2bcdce5840bb5", "ref_doc_id": "backend\\app\\core\\rag\\query_retriever.py"}, "4f1464ba-77ec-43c7-aa8c-ef4b54a75920": {"doc_hash": "6c1229c7ddfdc9f2ac9caba97cb5479f912c0e2a48e90c1d251e4057f366fc76", "ref_doc_id": "backend\\app\\core\\rag\\query_retriever.py"}, "58fc70ee-b486-4e44-815f-876b9e935eb5": {"doc_hash": "0bd9724bf54f2b207fdd56e7430548b0dfae47cb0d17b81d071ca5714054025a", "ref_doc_id": "backend\\app\\core\\security\\data_masking.py"}, "ac11fc4e-22db-437a-bf6a-f372bf494216": {"doc_hash": "e3ee0b295fb4033a01076c8054251dcf01a80f07fd497bdff3c8d704f36b203d", "ref_doc_id": "backend\\app\\core\\security\\input_validator.py"}, "fc19df88-bdc1-4ab5-bc46-c91f9d7c23f0": {"doc_hash": "05be7a711e3a84458563fa51e1cf0e6fbf0d3f199887a2344ac6c8b9f55eecd6", "ref_doc_id": "backend\\app\\core\\tools\\chart_tools.py"}, "27613711-c0aa-4f0e-b0e4-9bcd68a4ea59": {"doc_hash": "ef731ae75ca65356d69a750702802e871485fa4d3c1d265dc2aa9f38cd38a21e", "ref_doc_id": "backend\\app\\core\\tools\\chart_tools.py"}, "ad4d0279-ee52-4580-ba94-041ded31a9e4": {"doc_hash": "57b3cceed43ca96846354fe2d4ab03cb418c67e9cc76f45f708b70925be61712", "ref_doc_id": "backend\\app\\core\\tools\\chart_tools.py"}, "19717d32-23c3-4402-9c6b-96d32ee3982c": {"doc_hash": "92f5b3ec2f0b6e65fbc4454e1c1a387dc7c31ff13058570269179ea24b563db6", "ref_doc_id": "backend\\app\\core\\tools\\chart_tools.py"}, "ffdee957-9a55-453b-8db4-29720e371074": {"doc_hash": "a1b15adebe47696853e4e1bac8a9a8da4c5f42063cabb87fce249e55f84e00e9", "ref_doc_id": "backend\\app\\core\\tools\\chart_tools.py"}, "a1be6b57-b747-44dc-8294-377c6100a1f8": {"doc_hash": "ef4899214e5fd06f070a4fec226390656e212a148fcc61e875f13b1fa3c94c9a", "ref_doc_id": "backend\\app\\core\\tools\\chart_tools.py"}, "4d156409-ea01-4576-a226-12bd402a946d": {"doc_hash": "e6f59fef71d2690d20114f3e0c76b436a8234198665d9fee781b3dfac5b70c64", "ref_doc_id": "backend\\app\\core\\tools\\chart_tools.py"}, "1606ec3f-0a65-480c-b34e-cafc98c60b30": {"doc_hash": "942eb42521b964b81faf5d19756693ec1fe50caa0b11f8842e618fd158b334de", "ref_doc_id": "backend\\app\\core\\tools\\chart_tools.py"}, "8aaa3dd6-2ec4-4b7a-8ebb-73e6223af0a1": {"doc_hash": "b78c1af301175c5cefeee8a0f666adebb2f9ca6292b6857ab1b2fec189a38713", "ref_doc_id": "backend\\app\\core\\tools\\chart_tools.py"}, "be7f8ffa-f847-4e3c-a5ab-4f416adcf866": {"doc_hash": "ab7aba3d2caee8fdd8580a5150d4c013bad40cd6366bcf5ecab2b7db4ca0fdf5", "ref_doc_id": "backend\\app\\core\\tools\\chart_tools.py"}, "00d1c81a-c75d-427a-8443-115c24dd707d": {"doc_hash": "fc243a52b1132802dc77071d8d550b3f02c11b98491539b021e42ea149c0a57e", "ref_doc_id": "backend\\app\\core\\tools\\chart_tools.py"}, "a57e879b-96c0-418e-bdb6-2e08f2839740": {"doc_hash": "fe1135c120f7d112950ee07c8d7598a6f14b28baff20898cae34aba16f62ad6d", "ref_doc_id": "backend\\app\\core\\tools\\chart_tools.py"}, "015dfa15-f3dd-4a79-9ca4-b7fb0dc869ee": {"doc_hash": "3b0bcabbb5526bd3b54949fea0c28e4b0bb077cccca81a86792d89f4fbeca09e", "ref_doc_id": "backend\\app\\core\\tools\\chart_tools.py"}, "48b9bfc9-92dd-4f6d-8978-059a58a077c7": {"doc_hash": "66368fcd85a3371d3b547a5f6efc9d89fea52879b3e4762b2648e7d41f1e9407", "ref_doc_id": "backend\\app\\core\\tools\\chart_tools.py"}, "cfe7de0e-8e6c-4967-8d24-e58678a36644": {"doc_hash": "7c1effa12426093f2b459883fccf792b323518ebff856326d23ea59d3c9dcf86", "ref_doc_id": "backend\\app\\core\\tools\\chart_tools.py"}, "9604cba0-85d3-42f0-89cf-b8dfd4d68d71": {"doc_hash": "1c32529b20bcaf80ae9c4d547798f5ee28dbb319b23f0d883b738498e0976c24", "ref_doc_id": "backend\\app\\core\\tools\\chart_tools.py"}, "0d5fc255-5de0-4cf1-abf0-7c5099d90fc0": {"doc_hash": "2393fe8ad294dbaf016145a9a5a211a93317eb12c644047c3b0516cf0f34a5f5", "ref_doc_id": "backend\\app\\core\\tools\\chart_tools.py"}, "57cd3ee1-f53a-4a22-af63-10157d71029e": {"doc_hash": "d3fee61d8e629bee867639e31d674edf0203f7a48a3acc81e93a6f2aef8e8a92", "ref_doc_id": "backend\\app\\core\\tools\\chart_tools.py"}, "2b1628d6-ac21-499b-8876-9c8ebbf63327": {"doc_hash": "cfcee0f229213d1f245301a77d20c74bbc87a940eabe15a3616ae4a33e4de230", "ref_doc_id": "backend\\app\\core\\tools\\chart_tools.py"}, "10204078-1621-46d0-a928-c43be2ca7d54": {"doc_hash": "e174e9357d405644cffbcba2f01ea347e86afa406048755010e1bc286eeeed9c", "ref_doc_id": "backend\\app\\core\\tools\\chart_tools.py"}, "c29a704d-ed32-4598-aca2-c4cdff6f40e2": {"doc_hash": "32e51513ede4e62230ee004c8db01d4fee414e4f710a4d38c892336714b1cc66", "ref_doc_id": "backend\\app\\core\\tools\\chart_tools.py"}, "deac9ae4-ca57-4a3d-b12b-de04b42cff74": {"doc_hash": "96cb1dbd56cd98a5006a0d6734b2acc6e193718f71bc8840ba4c9b32f298064e", "ref_doc_id": "backend\\app\\core\\tools\\chart_tools.py"}, "d9153119-d2df-4528-ac79-1abf29261045": {"doc_hash": "d6b4371ba72ad18e7a439e533f7bce70e8e86a42b3ea5cee3cf7ac9718fb8679", "ref_doc_id": "backend\\app\\core\\tools\\check_gui_dependencies.py"}, "343ec929-0561-49f5-96d0-0fcf7a7a99f3": {"doc_hash": "5211a7a46b1361f834e3f234797645825ccd7815c8f6dc9c1615e72adf61458e", "ref_doc_id": "backend\\app\\core\\tools\\check_integration.py"}, "264211dc-aa95-486e-9733-e33f44cdb262": {"doc_hash": "3db46f196eef5b41f0a363ac4ba7b2d4dbfe4695a3e4fa0c6b5670f803a1eb9c", "ref_doc_id": "backend\\app\\core\\tools\\code_interpreter.py"}, "b34e3d22-6348-4505-abd3-a34dd5621b6a": {"doc_hash": "d5cf69bfa8d6d9df1c556fadb5d4e0f7a670f7373777a60c2b5d3acc0cdadc78", "ref_doc_id": "backend\\app\\core\\tools\\code_interpreter.py"}, "e5e9f0da-9ccb-48df-9a6b-16ce16aaff27": {"doc_hash": "3b8187912cabb12617eab2dbf29f8626deb62f96bd896e96029025fa33b77d9b", "ref_doc_id": "backend\\app\\core\\tools\\code_interpreter.py"}, "ac330131-3a1d-494c-bfdc-4f69105871b5": {"doc_hash": "9248ce578a62f4a2bfed12cbf29202eb392494e03b660a7524c5f70eb11e6973", "ref_doc_id": "backend\\app\\core\\tools\\date_time_tools.py"}, "539ff5b4-252d-43a0-b951-9e8d7c2de8c1": {"doc_hash": "fa7107702b18fd7aae1c4f0c1c6eb32daab6ef3a7e3e25fa2786217838f96d5b", "ref_doc_id": "backend\\app\\core\\tools\\debug_server.py"}, "216b2743-84d1-4c4d-b855-57f657a2df1a": {"doc_hash": "0ec55ac171b3f9d88668ba252473a8b0e6c81031af9d7061461beb0c0e8bd673", "ref_doc_id": "backend\\app\\core\\tools\\flexible_query_tool.py"}, "9d2088a2-319a-4c3d-8dd1-c32148ba8040": {"doc_hash": "7ef8015f71d383237d160dcdbf6fdb650d8d0860aaf588223b1642cbfdafae70", "ref_doc_id": "backend\\app\\core\\tools\\flexible_query_tool.py"}, "e098c6f5-fced-4d63-84a9-c4e675149d5c": {"doc_hash": "ff4cb3207c4b58daf9fae6b406567f59e81c3d85ec998894fcd22945529c4e70", "ref_doc_id": "backend\\app\\core\\tools\\flexible_query_tool.py"}, "d384c133-b0fc-4463-85b8-e078ea1bbf0a": {"doc_hash": "e8d1a8491cc8822b4000966d95f887f985543e22fe1eec4a1ecedaf27654d448", "ref_doc_id": "backend\\app\\core\\tools\\graph_integration.py"}, "7c06d9d3-37fa-4df9-a680-9ca51b150821": {"doc_hash": "b10178a24d68ad57f210766fc9bf451ccbef65be2f11326458415edbdd1ebf22", "ref_doc_id": "backend\\app\\core\\tools\\graph_integration.py"}, "dc9fa2c7-02a9-48ad-82c6-783b3f834c9b": {"doc_hash": "e8a3b390058bbfd7d905b324f2d0f4230ae3974217ec00651baa0b5f624da553", "ref_doc_id": "backend\\app\\core\\tools\\graph_integration.py"}, "68b89e98-1ec6-4c40-af62-925e9938a6b1": {"doc_hash": "810c080a01ca227fdf6ea00932db075a10101705f63677b65d9933ab29a6ba0a", "ref_doc_id": "backend\\app\\core\\tools\\mcp_parquet_tools.py"}, "5b40b53a-11ae-4e6f-97da-f81ba7a35653": {"doc_hash": "472dbe38272bbcfdec7da86bea57427b1e3787e8ab0e6ad82d1cb5832b1bd0b2", "ref_doc_id": "backend\\app\\core\\tools\\mcp_parquet_tools.py"}, "f0483fb3-a796-45d3-bc56-bd8df7f1bc3e": {"doc_hash": "2f3a43a38a384b2a5ee4f70c833ce486cf74549de4cca2d102b1dfff2c4a939e", "ref_doc_id": "backend\\app\\core\\tools\\mcp_sql_server_tools.py"}, "5a0b1bf2-1986-4b95-82b2-90b4d31b46b1": {"doc_hash": "35134680e69e5ae612106959924367330c160c0023ee1953353caf2d5affdc85", "ref_doc_id": "backend\\app\\core\\tools\\mcp_sql_server_tools.py"}, "f8a3181a-92ca-4872-8773-c0558406f5c9": {"doc_hash": "997d815b0997f2edaae519a68d5f20610dbfd7c49adea68fdbb3e7911f827d3b", "ref_doc_id": "backend\\app\\core\\tools\\quick_response.py"}, "6123a6bc-6a11-4547-8b01-ed976f4a58bc": {"doc_hash": "714c41b0ad314494a3c985f734c366f8638b31085b2ae384208af32f11189c28", "ref_doc_id": "backend\\app\\core\\tools\\quick_response.py"}, "b73b4fe5-3127-4629-9e0a-a0d2506f1767": {"doc_hash": "7b77fe33472d3a43aa75652d1e6322c69f15f398442d8ce816bc9d19304218f9", "ref_doc_id": "backend\\app\\core\\tools\\sql_server_tools.py"}, "75e46973-2e0f-4855-bfae-411ccc0c8d8a": {"doc_hash": "3c621077e2bd7bbf115a079df019b7b9437b7171c06280e4c68bf06c431d77f2", "ref_doc_id": "backend\\app\\core\\tools\\sql_server_tools.py"}, "8179d88c-e69b-4d4a-bb74-4d40182d5525": {"doc_hash": "b0312dedcce5f2bd1ab414ab786eafcf650979732c7fc292067a11535847ae41", "ref_doc_id": "backend\\app\\core\\tools\\sql_server_tools.py"}, "62757858-327a-4b9b-9bbf-ce676510dc81": {"doc_hash": "7ca8315a64b04cdb381b5afaba7ff4f30966af28af4033c330622ef006848830", "ref_doc_id": "backend\\app\\core\\tools\\une_tools.py"}, "d9a14ce9-69e7-47fd-ae7b-efec0ef36f30": {"doc_hash": "92029866abb2446a887e2d64a07c89c1a7e65e57589d411468789ddbd704c3a1", "ref_doc_id": "backend\\app\\core\\tools\\une_tools.py"}, "41fd96d5-44f4-478d-967f-8c644d2fdbf4": {"doc_hash": "f0575e15245f5d63e96ebcf0212a7af77c711893129716f2622bc306b6c6a8b2", "ref_doc_id": "backend\\app\\core\\tools\\une_tools.py"}, "f9ad5787-cd9a-4268-8aaf-9dd8da2c81f2": {"doc_hash": "1614d2f3d1e63bd7b2db2ffa5db9fc6cd6b15b52a41fb9e49c7083ff8efd44ee", "ref_doc_id": "backend\\app\\core\\tools\\une_tools.py"}, "082afb91-c0cf-409a-b54b-1ea23be69480": {"doc_hash": "54ab6caa0281ea391f0c20e729a266f6867a4f1fa442babc798e9a236bc47e95", "ref_doc_id": "backend\\app\\core\\tools\\une_tools.py"}, "e32aece9-bd76-4b6f-b0f3-a9109da53fd3": {"doc_hash": "b1c9cd1215f32d976c901cc407e784e52c8077fa404a962b78cc39c4b0440393", "ref_doc_id": "backend\\app\\core\\tools\\une_tools.py"}, "7e939a50-9468-4b1f-93d2-3723297d305d": {"doc_hash": "a05c096f7da64f88b6335ba7fce586ebbc456dfe5aa7ee5f1f33d5e0806a1e92", "ref_doc_id": "backend\\app\\core\\tools\\une_tools.py"}, "f0ee5031-178d-417e-b4c8-0256bd849e5c": {"doc_hash": "37a85b65d620a7b2f9b6621ffc1e5666299b81c130538b3b2c0a17beffae13ca", "ref_doc_id": "backend\\app\\core\\tools\\une_tools.py"}, "e0ed09dc-b984-4e76-9419-03dad06b2817": {"doc_hash": "cdba81270d70917d2443ed2c57b6dd9f2338a42467ca8eebcb0831e0af6fd96e", "ref_doc_id": "backend\\app\\core\\tools\\une_tools.py"}, "87153257-9812-4e17-a765-40e05dda0340": {"doc_hash": "957dc6b35fe08790f0b896b3e983a483d2691887db8738c604e0b981e2df0114", "ref_doc_id": "backend\\app\\core\\tools\\une_tools.py"}, "0800b633-5544-4836-970b-1b5629a6d124": {"doc_hash": "17ebc45ebd0c9cf94f8d91544a1045b5ddab03b811a7bcaa5e482521bd579cc2", "ref_doc_id": "backend\\app\\core\\tools\\une_tools.py"}, "1d273463-c8cc-458b-9768-df6140e41abe": {"doc_hash": "766e3caa0de6d43a829ad15181e1992ce14c92a219395e41f020f90745fa4b7b", "ref_doc_id": "backend\\app\\core\\tools\\une_tools.py"}, "62947953-7189-4748-9b39-49ad0621414d": {"doc_hash": "9a77f9d0b98b4232f6a8689c519e1a889dce5317224e9591360b6973d1f25d91", "ref_doc_id": "backend\\app\\core\\tools\\une_tools.py"}, "b53d8228-a69d-4ffe-88cd-2859cd2162ef": {"doc_hash": "cfa99e3fe56825a54382d8e53e08665c8dac56e2fe9aae565a45ce0e7fabb5af", "ref_doc_id": "backend\\app\\core\\tools\\une_tools.py"}, "c4055a18-4955-4d21-b58e-e9a718e5ff20": {"doc_hash": "5e9e3e38e95b64db2859c5d458e67c903ca7fd922c5e720ff5f9d662c88125ce", "ref_doc_id": "backend\\app\\core\\tools\\une_tools.py"}, "3d831c33-df11-4e14-93b2-512f18f0a3c6": {"doc_hash": "7ec547afdf7f194793b86d990df46cd42c10eec06564aba245aac399cf70502d", "ref_doc_id": "backend\\app\\core\\tools\\une_tools.py"}, "9ce7b2f0-913f-4772-8319-ed275b8b2315": {"doc_hash": "afccbd26252147aa11b6c0272b0d5974b55603d60e1bd41d09b3ea09ef0304f1", "ref_doc_id": "backend\\app\\core\\tools\\une_tools.py"}, "3c59032c-76b9-44ab-b1e2-56b73ac084d9": {"doc_hash": "03fc97ff2f11dcd08964bdf67c51654e33de3ffdbe5c46017f4c0d87107bdc6f", "ref_doc_id": "backend\\app\\core\\tools\\une_tools.py"}, "0548c04f-e9b5-459a-a051-aca97df49241": {"doc_hash": "a3f8dd56b3bb3d1c84efdfb2a70d7833b7b69825cad7fc236c6750687c717f22", "ref_doc_id": "backend\\app\\core\\tools\\une_tools.py"}, "7a32339c-1917-4671-bccd-a5b1983affea": {"doc_hash": "16975d1ec407eaa1cebc804ca57436aa4197d4c11ba9c82f73363bd7b799f6ed", "ref_doc_id": "backend\\app\\core\\tools\\une_tools.py"}, "0277ad50-6a75-43a5-8ad2-db1db2a6384d": {"doc_hash": "ec977889c5c6e04d37efa107263001216fe238fcd67edb97113b91d37db953f1", "ref_doc_id": "backend\\app\\core\\tools\\une_tools.py"}, "385325ba-54d0-43a0-a6c5-d0a0d2ffdbff": {"doc_hash": "59c3a9978f8feddfef2e8ac6537c7cd65f8ed1daa51f881cb8758e0a1b6dab47", "ref_doc_id": "backend\\app\\core\\tools\\une_tools_backup_old.py"}, "bdf78d43-d49d-45be-aad2-71162b6607f0": {"doc_hash": "3aced4c9ea99492ce97b3de93cd3f303f871bb5d01e85d743d239c1a79e6ac22", "ref_doc_id": "backend\\app\\core\\tools\\une_tools_backup_old.py"}, "9fb87a2b-bf2d-4a69-bf54-658c8f40f557": {"doc_hash": "47c182b2f8a5997a5dbabf929546182f2231dae954a732832bccf87280a084ee", "ref_doc_id": "backend\\app\\core\\tools\\une_tools_backup_old.py"}, "c0d50bd7-8fbf-40c9-b1d5-f37507b1b994": {"doc_hash": "fdc31e211b02fd415f15fbd62f07710f6c93666317fb50262373a796b74d9188", "ref_doc_id": "backend\\app\\core\\tools\\une_tools_backup_old.py"}, "c2dcd50c-0af0-4117-85fb-e4e2c356e258": {"doc_hash": "8ff4f0b71f583e55f5ba2f95ddfe2b8a1b452f5e8b84bd9bbd0311ff36d8751a", "ref_doc_id": "backend\\app\\core\\tools\\une_tools_backup_old.py"}, "0cf02784-1747-4dad-b33a-398f712211ae": {"doc_hash": "39d275a42180da0655bd05e1bc6389a7da02b7396f178f30a513b17d42b260e6", "ref_doc_id": "backend\\app\\core\\tools\\unified_data_tools.py"}, "865602e3-ef29-44a4-b53a-cdb84e230443": {"doc_hash": "d9cbcc8478e41039a136e6c0d65ec7d87b0e3b7a221c4968554049dd944b6080", "ref_doc_id": "backend\\app\\core\\tools\\unified_data_tools.py"}, "75bae677-5492-448e-9603-323e1e85d15e": {"doc_hash": "6617f9777d9d3ca2f8f8d7cbdb8f8bef5a5cb76ed550369273c18db48ecbdc9c", "ref_doc_id": "backend\\app\\core\\tools\\unified_data_tools.py"}, "24511efe-6e77-4fc8-850c-9eeeae19df79": {"doc_hash": "44a19c528e72af67a60a9f8cbe3e9c3627190e902e920cff41cc84b8a7f79be7", "ref_doc_id": "backend\\app\\core\\tools\\unified_data_tools.py"}, "e8bed705-17b2-4773-bb68-0f0bf2be4c06": {"doc_hash": "dc8dc9175569f9954eb3c4c682ec043f6e2a38cd1d3064cebe39b8dd2d0a463c", "ref_doc_id": "backend\\app\\core\\tools\\verify_imports.py"}, "d95904f1-c546-4aee-99ba-7b526f88a907": {"doc_hash": "3420a063dd2f5b023079eafbfb1432695a46418829ebc45508c9c978b7499c4e", "ref_doc_id": "backend\\app\\core\\tools\\__init__.py"}, "b3315497-d5a1-4a30-a1cc-3d412493e979": {"doc_hash": "3d4af27bdf987e044f7c66b1080b3a048c51f4dc362d29be4e2a8704f7aa6d9a", "ref_doc_id": "backend\\app\\core\\utils\\agent_cache.py"}, "5e35dcbc-e278-4905-ab31-404d2ccff1e2": {"doc_hash": "3167d33190ab0910c175274223e95b085bd9661d3090c011f5007fa82bf2640f", "ref_doc_id": "backend\\app\\core\\utils\\agent_cache.py"}, "28621ebf-0236-4cd6-a122-1656099df066": {"doc_hash": "22b1ed5bcb4c371d3de4cb82abc95fa66b6c6255e300e0063b18e51c3def7f9d", "ref_doc_id": "backend\\app\\core\\utils\\agent_cache.py"}, "29af04a2-e38f-4f46-bd10-351c6bd07267": {"doc_hash": "979df02b0633eb98c8749ab2f6ccf9e01aac56773aee6100bb25f0b0f3b27846", "ref_doc_id": "backend\\app\\core\\utils\\cache_cleaner.py"}, "0cff6f1e-39d2-48cf-984b-e1de7c1994cc": {"doc_hash": "f1a6924ada1f2bb84ea0daa43eebd217440bb78138d86c863e8449ed07399ce0", "ref_doc_id": "backend\\app\\core\\utils\\cache_cleaner.py"}, "e96f435d-d657-44d4-aca1-8d417e131ddc": {"doc_hash": "86a6fd27423fb1be509e43e202c571a45177895d5c441106596869babb31e4b1", "ref_doc_id": "backend\\app\\core\\utils\\cache_cleaner.py"}, "4118601c-e883-4008-9bad-54bd869bf6f2": {"doc_hash": "434bb623aef3f3658c2000e8d1d9e533b66f83699a55d61c47f6398fd1e5d52a", "ref_doc_id": "backend\\app\\core\\utils\\chart_saver.py"}, "e44c79ee-0088-4d31-a65b-c7a4c805c24b": {"doc_hash": "99cf628916ba5c96a1c022f9005008ad5f4a6f35de044c5e226f0e29b122893f", "ref_doc_id": "backend\\app\\core\\utils\\error_handler.py"}, "47898aaa-cd17-4258-b6f7-633031a7b66c": {"doc_hash": "f50ae843f8ac0aed9cce4b8587492eb1fbe1e21ea1f2224dec63c2e141215ee1", "ref_doc_id": "backend\\app\\core\\utils\\error_handler.py"}, "4b57f713-1bcc-46b0-b366-7665ebac3ff9": {"doc_hash": "6269814eaf34359b5503fee6cf0e239d6bf7f14b442286eeec1038a240bddecc", "ref_doc_id": "backend\\app\\core\\utils\\error_handler.py"}, "ff8cbf0c-9e91-4cff-bcb7-d343fed7f9f5": {"doc_hash": "e3ae05600b552150f4124866957f3c0c2ee8ae94668be49249d5c904b2e67421", "ref_doc_id": "backend\\app\\core\\utils\\error_handler.py"}, "dd00cab5-67b4-49c9-8125-6b9ae42ad12d": {"doc_hash": "d76dd36d2546612e4480fadefb47d2e9e344057256168c041eb272c8853b22f5", "ref_doc_id": "backend\\app\\core\\utils\\error_handler.py"}, "cc24b328-654f-4eb6-86bb-2cc798a7b147": {"doc_hash": "640049eeb8f5ec2ffbeb996b35aedbe43b49ad26867d91de387de2a47f419059", "ref_doc_id": "backend\\app\\core\\utils\\error_handler_backup.py"}, "68952c1a-2574-4218-8627-81144f3e0f48": {"doc_hash": "3557265cf1ffd8b231a175799098f76544c079b312efdb8ddc295c6a1c929696", "ref_doc_id": "backend\\app\\core\\utils\\fast_path_detector.py"}, "8bb15477-2a99-4ab2-9324-3d47205c20fa": {"doc_hash": "ea5e89212abf524cf142c7e0deffea3b9f1b62f7488df0d8e74243684dd3a56a", "ref_doc_id": "backend\\app\\core\\utils\\field_mapper.py"}, "a0b35d7c-d9c5-42d3-bdee-01959a76702a": {"doc_hash": "253ae8f9ec4ef1fdd71419ef4828cf106da6bfa5ae7fec2010015a2dda6b8bbe", "ref_doc_id": "backend\\app\\core\\utils\\field_mapper.py"}, "9e384c65-3965-431a-8ab8-c790a273cf63": {"doc_hash": "1485ed09ab5c4b6734509d105d1e35e0f368b2cb1657d6298efc8736543fc33a", "ref_doc_id": "backend\\app\\core\\utils\\query_history.py"}, "d8e449e7-cd63-4e7e-b19c-27db8d1dab60": {"doc_hash": "d664e5eb026484c4000ebd1440ab5165a744c702acc32933ba6fdac63043a267", "ref_doc_id": "backend\\app\\core\\utils\\query_history.py"}, "8d1928ae-c73b-4672-a7ce-63d91c3d1ce5": {"doc_hash": "b1f8ffe2005621e560f1c80acbad8306c35ef5a8255d51e3139ca2bd834d735f", "ref_doc_id": "backend\\app\\core\\utils\\query_history.py"}, "7aa2b149-63e2-48fb-b8ca-5138e15c13ed": {"doc_hash": "68843e8e2edc0542dcbeb9887763b464f0675e818a7dc049b6f95122ba1aa0a7", "ref_doc_id": "backend\\app\\core\\utils\\query_validator.py"}, "e95fcc6f-a591-4093-af65-c3fa7fcebb4a": {"doc_hash": "7589da8c901d34f39aea6d8e5815e76aef88e9dbbb4710f53594aebf56208242", "ref_doc_id": "backend\\app\\core\\utils\\query_validator.py"}, "d39443ac-739d-491d-a0f5-8f9e0263ae00": {"doc_hash": "ec8618999ee0ba458cb87225a9ba13b9a4eaef3cb446da491531ed8d3799fad3", "ref_doc_id": "backend\\app\\core\\utils\\query_validator.py"}, "ba089853-133b-4bbb-af47-9d3e17cbb42d": {"doc_hash": "550bda7fd91b0217e03cfee11f9552c4aa3e6ad3f9dac8111b97327d09dcf8fc", "ref_doc_id": "backend\\app\\core\\utils\\response_cache.py"}, "942e8b74-74ec-400c-8e95-89a99229f4ec": {"doc_hash": "9ab0ea1f1823e82dd9fb708921e999f90647e91cc130c569a517900b5a6d1cca", "ref_doc_id": "backend\\app\\core\\utils\\response_cache.py"}, "708d713d-8f58-4653-8f50-599df5e6201e": {"doc_hash": "c102c57669f16c4c0abd5d6223e354b29a356314754146826bda8cc4e95fe20b", "ref_doc_id": "backend\\app\\core\\utils\\response_parser.py"}, "1d8f7810-9424-44c6-9cfb-9c616bb62f33": {"doc_hash": "a3b5c7ec5edeb1ff485ccdc2b4b62370aaa609aa06e2e2dc3e8ceab359d556a8", "ref_doc_id": "backend\\app\\core\\utils\\response_validator.py"}, "1d02909b-c274-477c-9a35-0dde32df4bb4": {"doc_hash": "6d9553d55fc11060514f0a75e253a49128a39610ffdaebe27c3a578ad4652cfb", "ref_doc_id": "backend\\app\\core\\utils\\response_validator.py"}, "15dc9f6f-6531-40b6-9aa3-cb64abd60217": {"doc_hash": "fdd61c9c6b4a92e54920ec70aae6d1307ecd4652a0d038122e2681d025fb795a", "ref_doc_id": "backend\\app\\core\\utils\\semantic_cache.py"}, "4404a5ce-abbf-4134-9cf1-711c7690c95a": {"doc_hash": "08a434365b9bde3ae5f761c79285e885fc7d201286fe3c3aed177ad04d317571", "ref_doc_id": "backend\\app\\core\\utils\\semantic_cache.py"}, "3c0703a9-f889-4804-b180-8951fd9e6f3d": {"doc_hash": "f1bd1363572c9f2f5620b465ef43c5c5c7e18e0cbe43d02a370fd8ee2b27b86a", "ref_doc_id": "backend\\app\\core\\utils\\serializers.py"}, "a90a9bac-f436-483a-8340-aea1491b2fc0": {"doc_hash": "0d43cf2acc3cd1372c05ed70c017bb58d942cba11a51e10f761de586fc9f7ab8", "ref_doc_id": "backend\\app\\core\\utils\\serializers.py"}, "206fd156-f82c-4487-868e-c230dd5b50e6": {"doc_hash": "834dfcde1b0c873f54184eb250f33bc3324fb45fa6527f6b375aeb3d0260476e", "ref_doc_id": "backend\\app\\core\\utils\\serializers.py"}, "b226e07b-8734-490a-9b84-fe9b3a3e031b": {"doc_hash": "3a0c1d073ffe55cfcc031d2e5e1a695c97672cbebf64d6b1ffd1d38a5614a323", "ref_doc_id": "backend\\app\\core\\utils\\session_manager.py"}, "a78c429f-eb14-4827-bded-1e9ed23bed4f": {"doc_hash": "36eb52b5c1b698de16fe871f861125a463079b3f6721cd72c9cd13d1a76bd5a7", "ref_doc_id": "backend\\app\\core\\utils\\__init__.py"}, "eb87491b-64b0-426e-b221-09e49323f382": {"doc_hash": "bf7036dc22d2d1cc1e8b14fc3d328d8cc82ccc8ef7603d2a1465bc50a1e00bae", "ref_doc_id": "backend\\app\\core\\validators\\schema_validator.py"}, "fee77b69-66d5-4194-ba7b-923360233275": {"doc_hash": "e3e55baa913e0cb94613a527efe843ffd908f1360b01a2f61bacdf368d707b5f", "ref_doc_id": "backend\\app\\core\\validators\\schema_validator.py"}, "74e18685-4e32-4ab1-9d5c-7b5c5c8cdb0f": {"doc_hash": "32b9b7c4712b96d3c0a3f85ab12a9445aa6ecfd847ea741313305933eefc3099", "ref_doc_id": "backend\\app\\core\\validators\\schema_validator.py"}, "ef3fd107-8fe2-413d-8e67-1ca870095783": {"doc_hash": "7120b9662dd4b3a70bbc9d88e34af9352a52c3c5e111120ed0ea5e9782dd8e6e", "ref_doc_id": "backend\\app\\core\\validators\\schema_validator.py"}, "34e2c144-8bf7-49f6-93ff-13184e2c87f4": {"doc_hash": "6d366fe1d8e760136eca55c1555cd58ffd66db2bb47df625b16efb4c71b28e5d", "ref_doc_id": "backend\\app\\core\\visualization\\advanced_charts.py"}, "2f5962ad-5033-43fa-93ec-82ef82d3a86e": {"doc_hash": "fcca4f2c4b00322f273f98db2d2faa23f64a1d72d3eaf4aade390a7e01f791b6", "ref_doc_id": "backend\\app\\core\\visualization\\__init__.py"}, "e05210ae-c769-4b40-90a3-7aa5885ce41c": {"doc_hash": "58e61c7839d3bea0ad7d9e72555612c23df32b3294d7c96edda17b5684eebdc5", "ref_doc_id": "backend\\app\\infrastructure\\data\\base.py"}, "7149ff09-2905-4593-90e7-db6da39ed0b0": {"doc_hash": "f5aae99f7549a788e620f5f69c2c30cdf742e8aa6f43ff3f3b1f6125c979913e", "ref_doc_id": "backend\\app\\infrastructure\\data\\dependency.py"}, "eb208ab1-05cd-4df6-809c-a9269ffc51e3": {"doc_hash": "293a3d8b5053369130ef92f0e75d6c2711c0622644c7e539c4f169651c96a408", "ref_doc_id": "backend\\app\\infrastructure\\data\\duckdb_adapter.py"}, "a188f464-6e85-415e-927f-f813a4b43719": {"doc_hash": "d4bf72c5fdf6d05a1ea370763e355da1f82c68363d1a6ec3712fb0d968628981", "ref_doc_id": "backend\\app\\infrastructure\\data\\duckdb_adapter.py"}, "ed2c99d0-fc50-4077-98b9-d9e7975cbed8": {"doc_hash": "23ffe6adc3421917279bca353c1be4ad52cf40a4b9aa188480d305458790528a", "ref_doc_id": "backend\\app\\infrastructure\\data\\hybrid_adapter.py"}, "f8a2635f-d21b-4981-a0c5-d932171b425a": {"doc_hash": "85b5d2375fb5f99ae2b0f446e08d274e0f60aa77c500ce15e76dfe2c77373fb7", "ref_doc_id": "backend\\app\\infrastructure\\data\\hybrid_adapter.py"}, "3dad3227-5cb1-4c8c-9e28-18ad1166f9b1": {"doc_hash": "eef3485cdda1256113feac908c8bfd98a5ab3861fbde5b67549f4eddebbab6c8", "ref_doc_id": "backend\\app\\infrastructure\\data\\parquet_adapter.py"}, "ec3a0eff-53fb-4be1-b1d5-bbebc5c93544": {"doc_hash": "c2ca5adfa1e5262348ae06a8cff0156b90f1b386efa54761a5b14b58e71f4bc5", "ref_doc_id": "backend\\app\\infrastructure\\data\\polars_dask_adapter.py"}, "467ef6d8-c4b6-4131-a1fb-e0f25900ffaf": {"doc_hash": "0f895de63351fcce83ae89f17728073c9fc8208a3e618114ab6ce8744b09f48d", "ref_doc_id": "backend\\app\\infrastructure\\data\\polars_dask_adapter.py"}, "e81b0293-2a24-42f3-b56f-e800794366d8": {"doc_hash": "483bb40fcd1a5cadd9a1cb29553687886ec3a2286adc5f3bb75b7e1cb8fc5f6c", "ref_doc_id": "backend\\app\\infrastructure\\data\\polars_dask_adapter.py"}, "ef9c8701-1fca-472c-9c31-0b8a0b6a2c81": {"doc_hash": "7a3a325e87098c6023a0e8f50f13618709b18cdecd580829c082271561606658", "ref_doc_id": "backend\\app\\infrastructure\\data\\polars_dask_adapter.py"}, "fe17e751-72c6-4bd0-96f6-0f525870f90f": {"doc_hash": "3a3b70b7c718cd40598f9d34dec5830928591e642aa5adc74bf31e23ae01d6e6", "ref_doc_id": "backend\\app\\infrastructure\\data\\polars_dask_adapter.py"}, "7028e6b4-c1e7-491f-bf8e-d4d01f52bbdd": {"doc_hash": "57243890adca0d18f4965ac855d8abc5446abfe64bbfaab2605ee52de93d24dc", "ref_doc_id": "backend\\app\\infrastructure\\data\\sql_server_adapter.py"}, "c6433296-9ddb-478c-a93a-fb43c172efad": {"doc_hash": "3fe027ed5e39adf35fd46cdb2cd1c942250034ecaf24def9e542aa2b075ce3d3", "ref_doc_id": "backend\\app\\infrastructure\\data\\config\\column_mapping.py"}, "5aac55ad-4c3c-40d0-95ee-c63aa5491c51": {"doc_hash": "e639ace93630a3ad7fb0f4002d575df238960c80a03fef74a221c0a0f6c7ebc1", "ref_doc_id": "backend\\app\\infrastructure\\data\\config\\column_mapping.py"}, "16caafe4-7e96-4acb-a5e5-8178615290f2": {"doc_hash": "138a6506ffd828ba0e911d1f3347dc5b79c0129f04f70097580f943c281a91aa", "ref_doc_id": "backend\\app\\infrastructure\\data\\config\\column_mapping.py"}, "53f253e5-e7f9-4ed1-a42b-d8d3ae97f089": {"doc_hash": "6a82cce84977540d20bad13ee3092c0e2125f18710ae72069cff7d97a7e49849", "ref_doc_id": "backend\\app\\infrastructure\\data\\utils\\column_validator.py"}, "5ac50642-ba4c-4d36-8a0e-2b665c9de822": {"doc_hash": "e170aacb182708dd8e7e15c594089078aea923a9a24dd190fcb145578a3768a2", "ref_doc_id": "backend\\app\\infrastructure\\data\\utils\\column_validator.py"}, "ef4c4e41-cb30-4173-9e2c-53d3fd4ba748": {"doc_hash": "775382f64c7f66e2befa06ebd976283d14f4efeb0d988355ab89b60c62e18429", "ref_doc_id": "backend\\app\\infrastructure\\data\\utils\\column_validator.py"}, "51df215b-5ec7-4db1-bb43-c4a31c406c13": {"doc_hash": "84c0a30ab64984a0b84ced47e54bc560fa8d43d7390746feb0fad35e64460bac", "ref_doc_id": "backend\\app\\infrastructure\\data\\utils\\column_validator.py"}, "df0c8d0e-9507-491b-8b43-ddd8eaf868b3": {"doc_hash": "a9a0bb236fbf2904f8748f742b8743cc58988184ac7a0f21cb6e296ad16ecfd8", "ref_doc_id": "backend\\app\\infrastructure\\data\\utils\\query_optimizer.py"}, "51de2d81-a0ce-4421-bf95-122327d8aea9": {"doc_hash": "e6eafe689f22e22ef2a6c108a374163c56bbd52a4c7bdb611de604f440806376", "ref_doc_id": "backend\\app\\infrastructure\\data\\utils\\query_optimizer.py"}, "38742e43-e4ac-48c1-98d2-76d7a5c30f42": {"doc_hash": "8534b0514befaf7b378d1750b9f5af965f517365cecffa57f60189e1586a7985", "ref_doc_id": "backend\\app\\infrastructure\\data\\utils\\query_optimizer.py"}, "091b5e28-0495-4f6e-b708-674464159c6c": {"doc_hash": "ff522447812fc75fe3771c296e7d2949d57f945b5db797be2f138efcc72b29a5", "ref_doc_id": "backend\\app\\infrastructure\\database\\migrations\\env.py"}, "8dac3e44-213d-4141-a1ab-bd7f21477505": {"doc_hash": "ad184febd79f219f609f988fc7a6d666639567fe4d8aa51e99c22f7164f0978b", "ref_doc_id": "backend\\app\\infrastructure\\database\\migrations\\versions\\fresh_start_migration.py"}, "867fc1a1-d047-4c06-9cc4-6f0935324800": {"doc_hash": "5c2b50cc89b72779b056a5d75f1a874f2bac8d1ff270b8445d5ad55ea6081c66", "ref_doc_id": "backend\\app\\infrastructure\\database\\models\\admmatao.py"}, "28456f1a-bf84-4d4f-aa05-20175d5411c9": {"doc_hash": "bf9c020f9b8d86219fda4e2c534bae73af09842d015959bc9c92414218c6ef63", "ref_doc_id": "backend\\app\\infrastructure\\database\\models\\admmatao.py"}, "5beb76f3-0ed7-4ae6-b28e-8a1cb924af59": {"doc_hash": "b7ecf8bc0c398c83bd324c938c9e2258269de4a29f1959f23fd30a547bec8d0e", "ref_doc_id": "backend\\app\\infrastructure\\database\\models\\audit_log.py"}, "127cfc0e-6c09-4997-8383-203cb5f5c8ee": {"doc_hash": "9aadf1486c78351cfe1895bc4c7f7656973de3dc334b9301c22004976051730d", "ref_doc_id": "backend\\app\\infrastructure\\database\\models\\report.py"}, "842b4f51-ef40-4e18-9462-4624cb9ec442": {"doc_hash": "f047b7f98a101b1997d207b87d0f4ea1231e44032131ed984f49ac6b0c3e3f23", "ref_doc_id": "backend\\app\\infrastructure\\database\\models\\shared_conversation.py"}, "e47efd9b-8969-4296-9ae8-4e57d1874c6c": {"doc_hash": "d412e30e02f052dfc19c42cd1e5b1104b0dbdc3b7b57707df0ad8f6039930e2b", "ref_doc_id": "backend\\app\\infrastructure\\database\\models\\user.py"}, "0e1052cc-8e88-4dff-8a8f-296df91f7a74": {"doc_hash": "ffa0e57d228988153ef39eae6d87fce4be014919fd58e9df3c9d21405fd1e7ed", "ref_doc_id": "backend\\app\\infrastructure\\database\\models\\user_preference.py"}, "50e72066-40de-4301-8a08-dbc7fa7741c7": {"doc_hash": "4275cdd32f659c0725afa28f50d2541853fc0a9454b4405a8b9353b9d6453f5d", "ref_doc_id": "backend\\app\\infrastructure\\database\\models\\__init__.py"}, "23dad50c-1ef4-4195-83ca-bf22fb6fc8a0": {"doc_hash": "8040889974e5b6c32eef2afc2e90ddbcd1a6f34c450ba82f1828c16c8f786110", "ref_doc_id": "backend\\app\\schemas\\analytics.py"}, "a4c28993-2c24-4f5f-852d-05637f56d487": {"doc_hash": "8ce6cbf7f4b3b83b7b12c819babaf909b54b60503128c09fe20cd2cace972038", "ref_doc_id": "backend\\app\\schemas\\auth.py"}, "a01c60f1-08df-4a58-a759-0b24ac3248df": {"doc_hash": "93d6208f9a40adfbe691e32d9844f1de4beecb3fd23ac3430f2b7d3b3566fac9", "ref_doc_id": "backend\\app\\schemas\\report.py"}, "a8fccb0b-a2c9-4c26-9fc9-41144c21744b": {"doc_hash": "24538fa20d6482679b423fa8ec248d4c16e20214907e25f5c2a688daf25fb7a1", "ref_doc_id": "backend\\app\\schemas\\user.py"}, "d6fc08b7-fb85-45d2-8613-87544686dcec": {"doc_hash": "4c23c71a34ba8b8df8dec38dbf5fd07caef9a060d8afee3aa346df69deaf7c3b", "ref_doc_id": "frontend-solid\\src\\index.tsx"}, "8279fa70-85ff-4d8e-96a1-0f4ef6f58192": {"doc_hash": "2054b8725289710927015eb814e5e822945dccaaf8549733338b13a3fdd66e03", "ref_doc_id": "frontend-solid\\src\\index.tsx"}, "2c39a102-fefa-40b0-af6b-420530b8184a": {"doc_hash": "9968f8f4bfd1db280ba1e19718c8265e6ac4bf1f4f19a0a71ec0ba86f3249b33", "ref_doc_id": "frontend-solid\\src\\index_minimal_test.tsx"}, "577b53eb-3e5b-46da-be5e-ebb95696085e": {"doc_hash": "d2f89c11f311033969b5f653a8e0708a78bc4fd384d59e37ae4c708c68a66033", "ref_doc_id": "frontend-solid\\src\\Layout.tsx"}, "41b65da6-ed9c-4f5c-bfe5-d0afcaad1c22": {"doc_hash": "c33fe9aa20df5c85021cc89f91c75b0086b63ae286dd38d45f532add9456794f", "ref_doc_id": "frontend-solid\\src\\Layout.tsx"}, "a0a33cde-f2e1-44c6-ad3d-f71cc29bc4cc": {"doc_hash": "f932806d2f4f1112be6401633d78492e1233765d261e79c139232ac92ba597b6", "ref_doc_id": "frontend-solid\\src\\components\\AIInsightsPanel.tsx"}, "c33591a7-b4a2-4f1f-916d-131bd55eb246": {"doc_hash": "becd34950e5f91c1ca15cfee963e129f9d094d7e83412859af10e2ffe06054a4", "ref_doc_id": "frontend-solid\\src\\components\\AIInsightsPanel.tsx"}, "f11eb096-68a8-4ec4-af79-04605d2a2aa8": {"doc_hash": "f217f5b65fd785a7ab42eafa6debacf8ee51e5f7c58c3d658a9bdee272482ced", "ref_doc_id": "frontend-solid\\src\\components\\AIInsightsPanel.tsx"}, "bbe924d7-467c-4e9d-8a74-89a65c2a15a7": {"doc_hash": "79abe222a05b4556a8d9af825241444496d7d1225afd3efbe9312af9148dbc4f", "ref_doc_id": "frontend-solid\\src\\components\\ChartDownloadButton.tsx"}, "ca0826c9-2f72-43fd-b39b-587a0c131cff": {"doc_hash": "67c1738d68e9660864a2c98d14fdd3066517caf0082f5cea4223c3634608e879", "ref_doc_id": "frontend-solid\\src\\components\\DataTable.tsx"}, "718cd41d-0475-4343-89a5-71a13c4e1847": {"doc_hash": "1d01534c0199efed98947db60168ec69e2ef7c13168e36915a08befa3fec81f3", "ref_doc_id": "frontend-solid\\src\\components\\DataTable.tsx"}, "47a420f5-843d-4c2a-a980-c27c170a4dd0": {"doc_hash": "b82253c049e19d3d5eea43f7ed0c9102ba14e819cf1cc370951c312d614f2337", "ref_doc_id": "frontend-solid\\src\\components\\DownloadButton.tsx"}, "7d55e5e9-7ac8-49cd-bda3-dfdc51e2b3e8": {"doc_hash": "875480055590763f0faba67ac3c097055179367a145fb62fc905037cb1640f11", "ref_doc_id": "frontend-solid\\src\\components\\ErrorBoundary.tsx"}, "b1121dbb-5b87-4c10-8911-9e270e9a2f95": {"doc_hash": "c8998c4a4d47695cd0c882316fe84b6afa43cf79ef166e2c8a35abcfa5f4e5e2", "ref_doc_id": "frontend-solid\\src\\components\\ExportMenu.tsx"}, "bb49a099-199f-422b-8b91-208001ae9e2b": {"doc_hash": "91fbf524fb67f2a7eef98a7e0f2c406a4fa4400d5d616bbff7bb9ba887f4cdc6", "ref_doc_id": "frontend-solid\\src\\components\\ExportMenu.tsx"}, "96644538-0383-4b5d-8c7a-f3af68a56ad0": {"doc_hash": "967fa56231919d768416dbf88500b55df3e9108d05946124aba66e6eec9822e5", "ref_doc_id": "frontend-solid\\src\\components\\FeedbackButtons.tsx"}, "f073d9cc-868f-4c84-92a7-a47680d3e96b": {"doc_hash": "de60815511ccc69fbeb544ac0aaa934241165dfc2ce2b83d195a09e5b305b5f6", "ref_doc_id": "frontend-solid\\src\\components\\index.ts"}, "e72a369a-dfe0-41f6-86ca-48ac6aa47742": {"doc_hash": "c3bd5f7a498f9d022fb5902f44682a1800f23f7a4ea68c154409bfe0d5bc8dde", "ref_doc_id": "frontend-solid\\src\\components\\Logo.tsx"}, "fb76c0fd-9c2e-4aa9-83b3-3551a28b57b8": {"doc_hash": "507ca3f2e3aaff2ceddbf7063aea67d0d3750357f3fc072c5a3d9914d8a7f8bb", "ref_doc_id": "frontend-solid\\src\\components\\MessageActions.tsx"}, "c2338493-f6ef-49fd-9066-11bd2f973be3": {"doc_hash": "09471597afc12214036e2a5d40f805da1986fa50a938da55a3ebd33d03ea237c", "ref_doc_id": "frontend-solid\\src\\components\\PlotlyChart.tsx"}, "5efc4b9e-a98e-44b7-8a2b-b91efb4a418a": {"doc_hash": "7bfa445c3963dcd78290ae140dd38c348f61c3352ae147ba85ddd1a84ccc07d1", "ref_doc_id": "frontend-solid\\src\\components\\PlotlyChart.tsx"}, "539cdc3e-8082-4669-adb7-563bb9c45a98": {"doc_hash": "ea6303893a016b6e8d0820a25957b9dedef172b8b000151fee1dbf60fffdd8c5", "ref_doc_id": "frontend-solid\\src\\components\\ShareButton.tsx"}, "74fd36b4-a43b-48dd-95bf-a4542230e8c5": {"doc_hash": "d61d847841c4d7cf78e029f4737fb86b34de29339ad0103cb4750e2dfe484a23", "ref_doc_id": "frontend-solid\\src\\components\\ShareButton.tsx"}, "b6262f19-5eaa-43b0-9684-64f4e7690847": {"doc_hash": "38b1aabf02c8c39cac727fc5db5b629d52895dfb5397419568ade87d38cd7762", "ref_doc_id": "frontend-solid\\src\\components\\Typewriter.tsx"}, "045f4874-3324-4ac5-ab6a-4b936c64e074": {"doc_hash": "f5584665bad5716b8f871c0fd3a9028a5bf162dfa27dd023207f6acb4d83fafb", "ref_doc_id": "frontend-solid\\src\\components\\TypingIndicator.tsx"}, "31a812da-583e-4a47-9001-464e6aa20463": {"doc_hash": "8813488edf066bede208b9e8dd4905b4f8e3cea83913728138cee183ffacb91b", "ref_doc_id": "frontend-solid\\src\\components\\UserPreferences.tsx"}, "526a6d51-227e-4fde-b8eb-cc5cfb3d1ce4": {"doc_hash": "bf3e66d112afc55891f40417635b705e54fcb33e24f2479acd99289e4a2c0bc9", "ref_doc_id": "frontend-solid\\src\\components\\__tests__\\Chat.test.tsx"}, "fdadf60d-92b9-411e-bf80-169904d910bc": {"doc_hash": "f0a8e592935864fe3101ed5a6d5e07047f32029d68198808032d3da091c88255", "ref_doc_id": "frontend-solid\\src\\components\\__tests__\\Chat.test.tsx"}, "c5ec22ec-a362-46d4-b036-15dcd534bbc2": {"doc_hash": "d41dd8849f64be82256bced5d0cf94b161e787200b9e8a2de6a9598ca18e4dbe", "ref_doc_id": "frontend-solid\\src\\components\\__tests__\\Chat.test.tsx"}, "cb8419bd-b7d9-4935-a5b9-9030cfbd884a": {"doc_hash": "b893e8c262d318b24ea2b2bc09cb6985c3bec0a4a94f6c71930252d9215f4ac6", "ref_doc_id": "frontend-solid\\src\\examples\\ComponentsDemo.tsx"}, "f9b17343-3f48-47a5-a0bc-1eb75919c430": {"doc_hash": "199056f6f79c824069e53d766f753aaa5fa5d9b01dfe3f1d61dd5b72b76aa6b9", "ref_doc_id": "frontend-solid\\src\\examples\\ComponentsDemo.tsx"}, "5ea31a2e-91c4-4ddb-aefa-3bef96f4ea9d": {"doc_hash": "25f7bf49d11d894a512d5cca9f4bfde031db125d5d99593c1e0c53424381deac", "ref_doc_id": "frontend-solid\\src\\examples\\ComponentsDemo.tsx"}, "665fe818-e55d-4265-81b1-0b90fabcd1b4": {"doc_hash": "9ad0d6bc9517430a4e3f6e150aac3a9419beabcb3e59b1a5944bba125319781e", "ref_doc_id": "frontend-solid\\src\\examples\\ComponentsDemo.tsx"}, "0528e03e-6b56-4cac-818a-d298e59ad66a": {"doc_hash": "04d35984740daddbd8e65ee6be5705eda7fc7357dd12c9c890c977a2e0e0015a", "ref_doc_id": "frontend-solid\\src\\examples\\MinimalLogin.tsx"}, "3574a84f-fbe5-4bcd-aa57-b4f5bcb0545a": {"doc_hash": "5ab43b1f88e8011d6db4813b9ae53197f3a778202d2b3c3371fbd85ce2db368e", "ref_doc_id": "frontend-solid\\src\\examples\\SkeletonDemo.tsx"}, "edd970e2-0290-4993-9756-4120a4c680d7": {"doc_hash": "c18ebb2eef4439069a96a2eca35640809b22c9e6a0e25ee89a2c6eab3d945da2", "ref_doc_id": "frontend-solid\\src\\hooks\\useAdmin.ts"}, "b1ddbd7d-c554-422a-b998-430c19e05160": {"doc_hash": "c979178c81e9334eed95739ded179af1e8f409968301c95db25a84c73b57ca0e", "ref_doc_id": "frontend-solid\\src\\hooks\\useAnalytics.ts"}, "95e21a36-204a-47e0-b1f4-cf4edeff847c": {"doc_hash": "311013f597373d4173f761a673aeea103bb93301383116a5706ce30d40ad7342", "ref_doc_id": "frontend-solid\\src\\hooks\\useMediaQuery.ts"}, "551d8ef5-9dec-4166-a102-d554782e9396": {"doc_hash": "0818df5283f19209ed26df65bef885a34be68d5463fc942876be0a88681a38b6", "ref_doc_id": "frontend-solid\\src\\hooks\\useReports.ts"}, "13a96b83-e162-4fe1-9cd6-6a66528e7353": {"doc_hash": "163f3abdaecc08c07f1f9b3adcc59c1ab481a1a170037c06ddfe33613233f2f1", "ref_doc_id": "frontend-solid\\src\\lib\\api.ts"}, "5d5792c4-611e-4dbe-92f4-ed9582431f3b": {"doc_hash": "92e5114bf63366fcc39a4f59b331d707213d46824a2074b43ee4a27ac6ec547b", "ref_doc_id": "frontend-solid\\src\\lib\\api.ts"}, "2ff415f6-3e59-4d8a-93d2-f113ff1a1aa6": {"doc_hash": "f8489ee33f5ff0d862643b030066da94432fc9654887dfd452f87e01a4223543", "ref_doc_id": "frontend-solid\\src\\lib\\export.ts"}, "205db90c-727f-437f-91a6-111e971d9396": {"doc_hash": "66bf2f807ec7a6eee6ac9fec6690865d927a2b5472e5c33d529288a3e6aa32ea", "ref_doc_id": "frontend-solid\\src\\lib\\formatters.ts"}, "d96103cc-467e-45d9-8558-a76f9aba0cf6": {"doc_hash": "fe231367cd50f9195a7f3084c42c68480c6f97318208336ec39dd30f7312d763", "ref_doc_id": "frontend-solid\\src\\lib\\supabase.ts"}, "d1879763-af41-4e5c-8d31-f9e67a55d14a": {"doc_hash": "0a49d3287c925c72f45ccc0c91d928a7cb1e1d841d04f46ef687e4aac92f58b1", "ref_doc_id": "frontend-solid\\src\\lib\\api\\client.ts"}, "6c9530cc-097f-456f-8d4c-2b39f1fbecde": {"doc_hash": "d0cff3be70d03352b14ec48d559d4a69d44c315e8ff4fc2bc5ae01882173cfed", "ref_doc_id": "frontend-solid\\src\\migrated-components\\components\\ui\\Alert.tsx"}, "0fd3857c-c8d4-4fd1-82c4-7ab66cb373bb": {"doc_hash": "035c3c8a08655abe942d31d762ffbd4c8da42bce9b32ce47617ae4d998fdf501", "ref_doc_id": "frontend-solid\\src\\migrated-components\\components\\ui\\Avatar.tsx"}, "b4b463b7-c95e-43df-a881-f31af0c7e79e": {"doc_hash": "7b501d9300821f9b0febcf668bd6c5773aeae9c4e1164c5a065051733f6099e0", "ref_doc_id": "frontend-solid\\src\\migrated-components\\components\\ui\\Badge.test.tsx"}, "e7a9303d-ed86-4442-9546-55f84bb1cbff": {"doc_hash": "973a4e0556e947f439e0ef069180c6ded56a568f14b3e22629281db3a60b2001", "ref_doc_id": "frontend-solid\\src\\migrated-components\\components\\ui\\Badge.tsx"}, "84dbd673-7a65-4024-9adc-783c2569b7c9": {"doc_hash": "63cc75b0875c2cbadf871526fee5b04bbce730375ba20650b5205d19dbe5f711", "ref_doc_id": "frontend-solid\\src\\migrated-components\\components\\ui\\Button.test.tsx"}, "42956a5d-0ad5-435c-9eab-1fb593b535ec": {"doc_hash": "e7134e97a44188a40b66eaf9c74c258ec90aae92ed6a04a13b712c94e2627923", "ref_doc_id": "frontend-solid\\src\\migrated-components\\components\\ui\\Button.tsx"}, "ad5f1022-a084-437a-a55d-ffa96f1f2a4d": {"doc_hash": "b19217fb8eb60ff040b4d150f99cfea60d1830797e4fa6cf380340ba5b1baf78", "ref_doc_id": "frontend-solid\\src\\migrated-components\\components\\ui\\Card.tsx"}, "999fbd0b-679a-48bb-a093-7a950e57a036": {"doc_hash": "4d0c6d0adfcd028e8ec50c441822a086f55354a24c1e10534d81dfa8230613f2", "ref_doc_id": "frontend-solid\\src\\migrated-components\\components\\ui\\Dialog.tsx"}, "b2c1f7d8-af10-4573-a9c7-dd590458f4ee": {"doc_hash": "4d90d1b34fafea7d44ebe33d1a9145a1322c9b78da35d7edec01c08c956c3218", "ref_doc_id": "frontend-solid\\src\\migrated-components\\components\\ui\\DropdownMenu.tsx"}, "099c0ca5-424b-44d8-8189-bd8edf5eabd6": {"doc_hash": "cac890d7a91a1f14d0f82e9ac3084f4f3ee8b2abd5718e92622e1ed25995ee72", "ref_doc_id": "frontend-solid\\src\\migrated-components\\components\\ui\\index.ts"}, "901fd6af-fb2c-4d16-8eb3-81ca630c2fd9": {"doc_hash": "f188b0e4aee3d4dc480658361dd17c0b26bea2c7f65bccf726b7715717336be0", "ref_doc_id": "frontend-solid\\src\\migrated-components\\components\\ui\\Input.tsx"}, "192a4829-691b-402f-b806-39b9012d7819": {"doc_hash": "6d205363660d61005c9feb55dbd36133d35636cc24a9ce4e7c86c1dd62b9535f", "ref_doc_id": "frontend-solid\\src\\migrated-components\\components\\ui\\Label.tsx"}, "bd4aabfa-865c-48e8-9853-fba953f3fa21": {"doc_hash": "80c7965ed302612c41b967e1880e38be9e778eb5a3dde243cce2a6215abb30f3", "ref_doc_id": "frontend-solid\\src\\migrated-components\\components\\ui\\LazyImage.tsx"}, "26c0703c-658d-421c-9382-409e0b4701de": {"doc_hash": "b05c65cb8462bc67d270b79c4e775272f621ffa104f56df2f81913f146488ff1", "ref_doc_id": "frontend-solid\\src\\migrated-components\\components\\ui\\Select.tsx"}, "6dabe135-ad7b-49be-92e2-4bf518bdef46": {"doc_hash": "c97e910402ec684e098c229c33d418f437a97fba1cdf8d78ece0f58825f534a0", "ref_doc_id": "frontend-solid\\src\\migrated-components\\components\\ui\\Separator.tsx"}, "6bc81be8-5b4d-48bd-9a7b-cbeece371efb": {"doc_hash": "dbc570c217757eb851857b51e92eb2d93a2c3170849c3ce37cab6550a1fc7c94", "ref_doc_id": "frontend-solid\\src\\migrated-components\\components\\ui\\Sheet.tsx"}, "6f818f14-f512-4ae5-a7de-c6987bee6c04": {"doc_hash": "a3016effdcc0736f6cdbbe3d24c1373b0f2ffa776d1ed1b83eb3ee23a1ff52e0", "ref_doc_id": "frontend-solid\\src\\migrated-components\\components\\ui\\Skeleton.test.tsx"}, "04fd7185-6861-4825-a3c2-d1c7bd295ff2": {"doc_hash": "978d0e0dd1317bfe9576360c6322107272aab4ad4903d1aad748d74089235534", "ref_doc_id": "frontend-solid\\src\\migrated-components\\components\\ui\\Skeleton.tsx"}, "cb1b89b6-6990-4702-9fbb-b52c6aada0ea": {"doc_hash": "a3caf83690423b228aded1fa949670a6871dc328ef32cce2bc0d2623274bb2ca", "ref_doc_id": "frontend-solid\\src\\migrated-components\\components\\ui\\SkipLink.tsx"}, "3c12e533-5193-40ad-be03-4c777c9b105b": {"doc_hash": "ee5b49a842e17be08ed5066ebf63caad648d1a805f80a51233b256059e08bee7", "ref_doc_id": "frontend-solid\\src\\migrated-components\\components\\ui\\Sonner.tsx"}, "996eb9d7-a9df-411e-ab11-c399140d63a3": {"doc_hash": "7ce5e64cc0553eff84f7e108c2006ad2f8738286a8628fe9cf5c023f6dd231ab", "ref_doc_id": "frontend-solid\\src\\migrated-components\\components\\ui\\Table.tsx"}, "0cae4cc5-b634-47fe-af4a-0041cdecac6f": {"doc_hash": "bf8df7d2c18dd13d5820d5da78c7d43039a63c8df255a131e19fd795c5172205", "ref_doc_id": "frontend-solid\\src\\migrated-components\\components\\ui\\Tabs.tsx"}, "a47598b0-9aad-43a0-ac0d-c8c192098b86": {"doc_hash": "41e3560106010c6b007de17e1768d80de6dce5ba623af9e6cc0b95f0ea860743", "ref_doc_id": "frontend-solid\\src\\migrated-components\\utils\\a11y.ts"}, "088cb1cf-31e9-4527-82a6-a7681b9dda7f": {"doc_hash": "62907fefe670bf045e9d9a101439b5f73b4e0fa24ada1f9b3a4fcb0486336a43", "ref_doc_id": "frontend-solid\\src\\migrated-components\\utils\\cn.ts"}, "231660b1-5b39-4427-b83d-10aa59ccd056": {"doc_hash": "4207f7442b006e96f66afc8e3a1d61eb18518c254929213d96b9bf80340847cd", "ref_doc_id": "frontend-solid\\src\\pages\\About.tsx"}, "b9e5547a-2ed6-43e2-9a81-68224c893eed": {"doc_hash": "8eb79b92ac7d73a5bcdd23cfb10226fee3017db241b18de04d69865bc378bbbd", "ref_doc_id": "frontend-solid\\src\\pages\\About.tsx"}, "cc116702-974c-415c-aeb8-ed23b71cad48": {"doc_hash": "c4f299d96f989be490d184ea31dee57f9447e8139de82c971b043532d64c1182", "ref_doc_id": "frontend-solid\\src\\pages\\Admin.tsx"}, "13f4e010-9e4d-4424-9da9-cf965a88ba87": {"doc_hash": "77b90c98e40100220ebba467cfdc8aa0a376bd3fbd58f15655ed71e3179f7468", "ref_doc_id": "frontend-solid\\src\\pages\\Admin.tsx"}, "58452bc4-426f-477c-8c8c-b376cb1e766f": {"doc_hash": "b4cf7e60a3c286072d510d3e9576eb44facae948e05edec7c2ce4519e370b4e5", "ref_doc_id": "frontend-solid\\src\\pages\\Admin.tsx"}, "7119060c-c3dc-422b-8d3f-6e2e771a35d4": {"doc_hash": "b6d71a12caec19842639be79aad8955136bf7fe5e785ec7aa67d4451bc03ea55", "ref_doc_id": "frontend-solid\\src\\pages\\Admin.tsx"}, "771302d9-ea6c-4b8a-9c33-73e2503ed4a7": {"doc_hash": "7d823123ec5ccdb8e7209339c88c90f02b3b87a136934a95c02673c1dc1add6a", "ref_doc_id": "frontend-solid\\src\\pages\\Admin.tsx"}, "46ad38f6-2b5c-40d7-9716-2adfe2e3adc6": {"doc_hash": "175479c97686fbd1128d624a80486e9c07b3d23d43ef6d4fd996a47985f6fc5e", "ref_doc_id": "frontend-solid\\src\\pages\\Analytics.tsx"}, "125b0a07-a31d-4b77-8143-18035ead4490": {"doc_hash": "c8f775c7db16b95ce340e75df9731441544497cc5ecb29fb8b70ec21821b9f0a", "ref_doc_id": "frontend-solid\\src\\pages\\Analytics.tsx"}, "0af46465-7e9d-446d-814d-0c8d5ef87710": {"doc_hash": "2d46e8aa4614052d903a9c8704c8c075b9b669067d6b16aa1357ddae324d2a2d", "ref_doc_id": "frontend-solid\\src\\pages\\Analytics.tsx"}, "71cfb93e-0a6f-4827-b80f-e555c33b1027": {"doc_hash": "750f5b0ed42f79759eebb08a2e4f9a35d131c3081245dba5ead1d2363ea79970", "ref_doc_id": "frontend-solid\\src\\pages\\Analytics.tsx"}, "5c99679d-fe0a-4654-acba-4b841f4ccfb0": {"doc_hash": "cfca32076d6738aa3c60b4d5cdb4bb5e40c0dee86a78a0799faf8fe0acd945ac", "ref_doc_id": "frontend-solid\\src\\pages\\Analytics.tsx"}, "bc5324b1-310e-4969-b479-f4708d5184c9": {"doc_hash": "e99447985ae577f545ec2f0c9c5f936ce11c53e9a3f4800db1979c22511e9b89", "ref_doc_id": "frontend-solid\\src\\pages\\Analytics.tsx"}, "b153117a-8cd6-46b5-8c4b-6209f658ce80": {"doc_hash": "cf603a96c866d4cc605cbdc08d3a5bb48bd6b6352d4885faddfe4e8aee9a6d13", "ref_doc_id": "frontend-solid\\src\\pages\\Analytics.tsx"}, "c1b8ca0d-85c5-42ba-97f1-a88ad788f56e": {"doc_hash": "0b1b951a3a79c1aa10c4e031f91b77f02e584486268c0a282744305d668ac552", "ref_doc_id": "frontend-solid\\src\\pages\\Chat.tsx"}, "c74d92bb-b9ea-44b3-a04e-d9f8f68e14d3": {"doc_hash": "784706da304ad1d4389ead21049c480bcf3be2c613da87f6c40498446dd5106e", "ref_doc_id": "frontend-solid\\src\\pages\\Chat.tsx"}, "c806f337-9a88-4fa6-829c-5f10e82021e9": {"doc_hash": "8e4193daa72e9ac6e037647cbaa9cae8515d130bcab64285537af93e9ae3f7af", "ref_doc_id": "frontend-solid\\src\\pages\\Chat.tsx"}, "f35d21b8-601f-4ab5-8530-0a1dc44a465b": {"doc_hash": "4bc00e78b79b197ad78a207e5a28cc49d9e4b54c59aa045141e27b471098d6dc", "ref_doc_id": "frontend-solid\\src\\pages\\Chat.tsx"}, "d28569c4-e06e-4019-81d5-751913d00cfe": {"doc_hash": "32b64ab089c092e9037178b7bd173f8b27f4e8e1cc7fd9aa7962632ad7088fbd", "ref_doc_id": "frontend-solid\\src\\pages\\Chat.tsx"}, "0f442b02-fdf9-4428-914f-329d17c0cea2": {"doc_hash": "4ac770e2af037ecc7a592d07522f6e954d85cdd21cfacf372e7225fd0e3badcd", "ref_doc_id": "frontend-solid\\src\\pages\\Chat.tsx"}, "dc49b4bb-a106-4513-8053-d0e642ed72b6": {"doc_hash": "ac523c3708c6b4286be4d737e3363e5b21a08d08a6e5f2f150bc016419fc31f8", "ref_doc_id": "frontend-solid\\src\\pages\\Chat.tsx"}, "02072b6b-dec7-412c-8869-dfa97dd6b0a3": {"doc_hash": "f15f299211cd8ef19146f6b668a4efffea3ee2f19c96f812c7a709556c8b6b6e", "ref_doc_id": "frontend-solid\\src\\pages\\CodeChat.tsx"}, "b1cf1732-fe37-482d-b375-d33188aa30e7": {"doc_hash": "20fb2281d48a22bc1187e64c6bb8f8db57e72dfc077397b57266e86db754143c", "ref_doc_id": "frontend-solid\\src\\pages\\CodeChat.tsx"}, "fc3383ac-f44a-4087-bbd0-6e49f88a87f8": {"doc_hash": "7e1fcce7983e03740c40d48b32f98c17725e2b84d68904c1e53b3ae77996bbaf", "ref_doc_id": "frontend-solid\\src\\pages\\CodeChat.tsx"}, "bfe1382a-ecfa-4ccc-867b-333a033b3fb5": {"doc_hash": "4bb861267b833a3acbaec4ae25a9b1c01485720fce6407bcaa88034a9ffe8531", "ref_doc_id": "frontend-solid\\src\\pages\\CodeChat.tsx"}, "765541a8-fcba-40f5-8a5f-bf59708da45c": {"doc_hash": "87ab8784749597e0046f19b3718040ca68f48412f24576d7aeb8b35b1b9ee1f1", "ref_doc_id": "frontend-solid\\src\\pages\\CodeChat.tsx"}, "efeb717a-b222-49e2-a8d5-ba479f9f6937": {"doc_hash": "ce8470423720f87d0507dc148842b36f4111086c04fde75f6ce679defbb11ea9", "ref_doc_id": "frontend-solid\\src\\pages\\Dashboard.tsx"}, "9c30ad13-eb99-4bf6-b176-b1f4cc62d939": {"doc_hash": "60135557081b5c032a06b3a67264b1944381641c996c5e79f02d518c9f9d9570", "ref_doc_id": "frontend-solid\\src\\pages\\Dashboard.tsx"}, "73bfb680-ca4f-4e75-9d51-c9570b6a79f2": {"doc_hash": "315aa820493ce8ab30fdd5d49797ff613ec3c8ede4545d2c6889c0d8ef7c1d58", "ref_doc_id": "frontend-solid\\src\\pages\\Dashboard.tsx"}, "0a426a7a-b823-4f5a-819f-d324a8428531": {"doc_hash": "b0c03fe7cf22183fe436401e64d7de61846edd2fdf42472f69bbd91649d48d37", "ref_doc_id": "frontend-solid\\src\\pages\\Dashboard.tsx"}, "2801aaee-711a-461b-847c-793625636be0": {"doc_hash": "7e02684e1dcb53ee43905a9b484fb8591be9ec9fe5d928f9c947c6eb128ffd30", "ref_doc_id": "frontend-solid\\src\\pages\\Dashboard.tsx"}, "924cef7d-e96c-46ed-9ee4-20b75841c052": {"doc_hash": "e3b249b01aa6abe8057a71ce186cf0df0311d99ff523a26e946a294c80fd9b31", "ref_doc_id": "frontend-solid\\src\\pages\\Dashboard.tsx"}, "cdae991b-7a93-49de-bae7-a82fcd867322": {"doc_hash": "69b1c0013b3465a15bd169414b8d4c4438bc221a832c2760ba797f2596c7f5ec", "ref_doc_id": "frontend-solid\\src\\pages\\Diagnostics.tsx"}, "d2d6f73c-2442-4e44-9ffa-5c739b8b98ca": {"doc_hash": "aeebdebe6b0d57cd4ce301bd24c0bc63b36531ce3381a06ba130581d398f6652", "ref_doc_id": "frontend-solid\\src\\pages\\Diagnostics.tsx"}, "85928c96-e47d-44e8-aae2-05f8c233d925": {"doc_hash": "d3fc027fdeff536992b4028ffdbfa938eeae226fef661328e7263f6f91563d37", "ref_doc_id": "frontend-solid\\src\\pages\\Diagnostics.tsx"}, "e65256f6-85fa-42fb-83d4-754d47fb6ba7": {"doc_hash": "471be14001cdd39d3840aa72238f43fc5987f38ddd2968389b504752bdff4470", "ref_doc_id": "frontend-solid\\src\\pages\\Diagnostics.tsx"}, "04568753-00e7-45cc-a978-62190ae02851": {"doc_hash": "9a1d0d820b1e64c9b9839f5a42ecb0024752773b8920bef46c8481afb862654a", "ref_doc_id": "frontend-solid\\src\\pages\\Diagnostics.tsx"}, "a2e6a2ad-7fb4-495c-8b76-6b8c14f0be07": {"doc_hash": "946923c26c356bc53844041f7885bdc41bdedf985394bcd0066cb8c0870337f4", "ref_doc_id": "frontend-solid\\src\\pages\\Examples.tsx"}, "64881022-f05f-4123-9bf4-ff4789664d5a": {"doc_hash": "c5631728b935537e2b183bd1f8a6e81b3d3a01c94a8e2a80868821081567119d", "ref_doc_id": "frontend-solid\\src\\pages\\Examples.tsx"}, "375cd63e-828a-4283-a164-ea621c19d391": {"doc_hash": "0d7f8383c27f153a542a8b1e2ba60c26d28f323d2d349a9b9e9dfc900f490b62", "ref_doc_id": "frontend-solid\\src\\pages\\Examples.tsx"}, "16708e65-9109-4ab4-93ed-a21f199d715d": {"doc_hash": "36166a3afdb982a33189176f35819a775f44e98a6549e77910b3211e0260d7c7", "ref_doc_id": "frontend-solid\\src\\pages\\Help.tsx"}, "0e2b0951-c75a-42ca-a966-ccc897660854": {"doc_hash": "ee27981c4c6b535f28fd8d3a50d6d4489a2efe49fc1a36fd573d2770cfb92bd2", "ref_doc_id": "frontend-solid\\src\\pages\\Help.tsx"}, "3a6d0f2b-774a-4967-b8a1-9696b2347dcd": {"doc_hash": "f6eb867c4c8f1d707940cd07215df43dfc19af896b37d9b5a986736bfe7b9175", "ref_doc_id": "frontend-solid\\src\\pages\\Help.tsx"}, "9e9526c7-62fa-4ae4-9010-89d7fd66f205": {"doc_hash": "24901f82002e1f12132060d8040dfa1613567e9c3b62e69c580e66391361bd3a", "ref_doc_id": "frontend-solid\\src\\pages\\Help.tsx"}, "60948662-4fd1-4dff-ac5f-3739a5c2e9f5": {"doc_hash": "746de65c08ab787158cfb6f6f12d64257e9c43c99aa7f0973e3ebf26ef32bc68", "ref_doc_id": "frontend-solid\\src\\pages\\Help.tsx"}, "8e499860-c6dd-422e-a48b-a721f9c08e65": {"doc_hash": "32afe6dfce018b2b8659d866039504a8755f051ce6c4109973693299ab4ca81a", "ref_doc_id": "frontend-solid\\src\\pages\\Learning.tsx"}, "d530ae07-b6a5-4662-a7dc-6838f9d2d7fc": {"doc_hash": "8e90ad76d2d4c00db74161fb63396bcf56aec0c6d4456452409825c027484e87", "ref_doc_id": "frontend-solid\\src\\pages\\Learning.tsx"}, "75298a21-66bb-44e6-a8bd-cd789118274f": {"doc_hash": "9fc60e349e079b8d14129e5c4b044c55972468942fbb0588875fd05716f1c5f8", "ref_doc_id": "frontend-solid\\src\\pages\\Learning.tsx"}, "975cfaa4-a5da-4d7f-baf7-3ac75c600398": {"doc_hash": "ef5f5d32e0d50a0df85ee92da3cd124ab2c79ee1407eeb936d85e7c84980c0c2", "ref_doc_id": "frontend-solid\\src\\pages\\Learning.tsx"}, "932bc291-0018-4ffa-a2c0-da21eb1b5dd7": {"doc_hash": "02bbe3760a9d3330b55c6588980d5e93adc4a6038f9a1e95ea983f72adc1b4be", "ref_doc_id": "frontend-solid\\src\\pages\\Learning.tsx"}, "6a9c5f82-1121-4cf7-8b4a-ca58bbe2658c": {"doc_hash": "7ea0b0e2f9ae6a27aaa5b71c230a6be071d64517d446f88fa12dcec8047290c4", "ref_doc_id": "frontend-solid\\src\\pages\\Login.tsx"}, "d2d4e083-23e1-4f05-b69f-87d83997d051": {"doc_hash": "b58f8a87865ea9806e41d7fa4ac9bf04927eb93c6128ee591c3baea7dd55ef28", "ref_doc_id": "frontend-solid\\src\\pages\\Login.tsx"}, "017d1aa9-0444-4c15-93fa-d0571a78809f": {"doc_hash": "538b3d02c58efb86b6ba6527f2aeeaf390ec4e0020817abfedc9df687b75144f", "ref_doc_id": "frontend-solid\\src\\pages\\Playground.tsx"}, "4e6bc397-75da-47b3-b250-ebe9895b1282": {"doc_hash": "688f86e18a43dcba7513ec572e928f8f5ea2c826114fc6eb5321eb260668efc6", "ref_doc_id": "frontend-solid\\src\\pages\\Playground.tsx"}, "6b1a7653-0aec-4a6c-8db1-b6511b5029fc": {"doc_hash": "eb2da4afc0e7aa908bd23c6daaecbf487714dee5a46bad316faf85f57d296e35", "ref_doc_id": "frontend-solid\\src\\pages\\Playground.tsx"}, "2ff36678-27aa-4e17-8c87-68dfb997fdba": {"doc_hash": "330696e64ced25bdee98826c8d1ab06b49bc125b6f8323106b3e5ac716ba21eb", "ref_doc_id": "frontend-solid\\src\\pages\\Playground.tsx"}, "92db475e-6fce-4f7d-a4d0-28e89bc7ef7f": {"doc_hash": "b8a76f5cacbfeaca7c2851eb131e496507ee92f33993951acb809d2f70c7c122", "ref_doc_id": "frontend-solid\\src\\pages\\Playground.tsx"}, "83b83e6c-4904-4431-9d61-4022dfe672cf": {"doc_hash": "ffc87b2f88e2e712d08080fdf767ab691946b9e0ce261e0b52ca5c51a0670c02", "ref_doc_id": "frontend-solid\\src\\pages\\Profile.tsx"}, "782b1e84-8cc5-4e24-9875-2a923f116f6e": {"doc_hash": "2c56d16dc2c769cab98e644331597ee5a027633852357dd8e6137de33cb06e57", "ref_doc_id": "frontend-solid\\src\\pages\\Profile.tsx"}, "00bddec0-cf4a-4ab0-b213-1df3ffff553d": {"doc_hash": "91b87ba6e55047aa7981d2f6d8afa356fbf0b42e7868a0ea5ca59ed28d9e4f87", "ref_doc_id": "frontend-solid\\src\\pages\\Profile.tsx"}, "62a41818-dc0c-4fdc-a9f7-b55b7b7b5a89": {"doc_hash": "b22ccdc6d315cb31755c0c3e50546426a35ec6c763988b19c72158a04fa4b1f0", "ref_doc_id": "frontend-solid\\src\\pages\\Reports.tsx"}, "e5fc96cf-2058-478b-9158-f3415c25a084": {"doc_hash": "3dbca206a203146d9e5e01b2322755b276c883b5b5d4bcf93f57f9c43ec21dd7", "ref_doc_id": "frontend-solid\\src\\pages\\Reports.tsx"}, "67b6bb4f-cf36-448a-8fbf-2da401c6577d": {"doc_hash": "a1c03d7dfa68378da121d1faa2f76e97bc0e1cdd1294a544d30f3fed0c575d90", "ref_doc_id": "frontend-solid\\src\\pages\\Reports.tsx"}, "77efd6df-db90-4010-8e2b-eccf5e9cebba": {"doc_hash": "b574d7376b52ff57146074a40e7a28b4a8b6e4719f2a4973fb1daed756ea3f20", "ref_doc_id": "frontend-solid\\src\\pages\\Reports.tsx"}, "610ceb31-d07c-4bb5-99ba-d3e80dc8b96e": {"doc_hash": "b72b07c5761823b75927d7db8f198c9c3b1e1fd5ac05a44ea21b8b1a057cec1a", "ref_doc_id": "frontend-solid\\src\\pages\\Rupturas.tsx"}, "cebd4b10-f6c8-4d6e-9567-5885ab4caebe": {"doc_hash": "b4a9441e92ae97e34e67d61aeb8eac872adaa9e2a9df2941dd7cb41fb911dafa", "ref_doc_id": "frontend-solid\\src\\pages\\Rupturas.tsx"}, "e3dd0afc-80ee-4e94-aed2-6bf0851711b1": {"doc_hash": "e487fbdbf438d3d66f0cc19c2df070b297cb318d3320dcab04bf1730593d6b52", "ref_doc_id": "frontend-solid\\src\\pages\\Rupturas.tsx"}, "a7a791e4-1c3d-4758-ab0a-dbc4203bc5e8": {"doc_hash": "11a46633d675c86cb54bfbb1b4972882e32d55f65a578b617f780b90d2abd5f8", "ref_doc_id": "frontend-solid\\src\\pages\\Rupturas.tsx"}, "f3f7a7a1-8290-4e6e-9e00-cd4e3bd5ef0e": {"doc_hash": "bffd9181f73b8b84f141fd08e92b52c1fa81e540a810b01e917e869029000360", "ref_doc_id": "frontend-solid\\src\\pages\\Rupturas.tsx"}, "1058bf3d-434b-4f79-a0fd-a0e30badcf09": {"doc_hash": "fd9543e7c4fdc8c3905842b267de23e9702e7fa185ccb450b7694377a5cb41d5", "ref_doc_id": "frontend-solid\\src\\pages\\Rupturas.tsx"}, "380bf732-80da-472b-85a4-9678851855a0": {"doc_hash": "325416f62bd53cddc0c330dafac8f62a91bbc0ef3a6b737fc8caa93252b3919d", "ref_doc_id": "frontend-solid\\src\\pages\\Rupturas.tsx"}, "0de7000f-9542-4dfc-89e0-46441c24e90e": {"doc_hash": "5b807c081d094404d05b4f75087dd9b55f9fafb9ee998740171f36e40cb8d3d2", "ref_doc_id": "frontend-solid\\src\\pages\\Rupturas.tsx"}, "d8b7ea61-33e5-43c7-a2e1-bc9f1558f210": {"doc_hash": "afa393d2ec39d123b2773693edfef5364a18a009156eb1aa74293c0c9666f9f1", "ref_doc_id": "frontend-solid\\src\\pages\\Rupturas.tsx"}, "c00fec59-5025-4d6b-99c9-ce5627118b39": {"doc_hash": "a1a06c67e73f93a76eb5a48829889b15f163a6aa3fc37dde3892bd3988778b66", "ref_doc_id": "frontend-solid\\src\\pages\\Rupturas.tsx"}, "f5ef7da5-b3f3-4740-9367-54388e71585b": {"doc_hash": "daf4b91f2282e3ac7db3129b5de3739de989de0ac23666bcbe27e2564550577d", "ref_doc_id": "frontend-solid\\src\\pages\\Rupturas.tsx"}, "59df1047-3596-4f74-9533-dc994a2ee903": {"doc_hash": "8f2de8ee44a37e8335f27cc5f7f6e85531b05a7a57bc868161185e6904f889b7", "ref_doc_id": "frontend-solid\\src\\pages\\Rupturas.tsx"}, "6438fd4d-7c87-465b-8977-2d4c620bd58d": {"doc_hash": "6cc28a1a34834f11410c31e05d71c281553f580579b4a81792ba19ad46054c34", "ref_doc_id": "frontend-solid\\src\\pages\\SharedConversation.tsx"}, "dafb873a-3fb0-4fdf-bfae-dde13420719a": {"doc_hash": "cc93521fdc60d39c39ef2fe0056878fc44842df91ffe4a3572d759b2cc7bf05d", "ref_doc_id": "frontend-solid\\src\\pages\\SharedConversation.tsx"}, "d624885c-e0aa-4f3f-9f3a-043b488c8f45": {"doc_hash": "2ce3cac77b86341b2a7b0a137f45014702e6ccd5206ac7174bedf2913b9aeb59", "ref_doc_id": "frontend-solid\\src\\pages\\Transfers.tsx"}, "c6142bd0-013d-4841-9d91-a9260c8bc7c0": {"doc_hash": "9dc7262c087b3cb08a3f19aaa95cf6d73ab4c4b96da881d6aa457714e21b3e3a", "ref_doc_id": "frontend-solid\\src\\pages\\Transfers.tsx"}, "227e8903-dc3c-4111-94ee-2e9151cd9709": {"doc_hash": "d351f2621464743c2553106b963da46ab1d20674db7bf00e3a593a04b0eeb55e", "ref_doc_id": "frontend-solid\\src\\pages\\Transfers.tsx"}, "7c77cd20-527a-49ff-83e1-3e3b5356ab81": {"doc_hash": "9caf801d93ae53f7feacd2a8f0eaa54fec1443b06b13e0a60175ffb38a2338fc", "ref_doc_id": "frontend-solid\\src\\pages\\Transfers.tsx"}, "be6c5c84-d247-440f-86fd-c2fda235a08c": {"doc_hash": "6138ff27cd74c449a4a0a0d1cb566eb8029fedb52b905df4b3a8ff29c69e5270", "ref_doc_id": "frontend-solid\\src\\pages\\Transfers.tsx"}, "d905c221-74ee-450c-8fc6-12d0d84d3e9e": {"doc_hash": "4900781ea6c3986a7f16cd9af31021c7a2a58710377e89c5d1fcce15f14d4d7e", "ref_doc_id": "frontend-solid\\src\\pages\\Transfers.tsx"}, "219a8f11-b53c-4766-9c05-394d87ddf89e": {"doc_hash": "6a34e68cc8fa5197e29ff1d2b2f86dcf2eb42fe2839a8f9a4918248197024958", "ref_doc_id": "frontend-solid\\src\\pages\\Transfers.tsx"}, "f66367f3-3b5d-44e4-8db0-cc3d70284946": {"doc_hash": "ddf7bf32cdf27239657c5d0b8172226daa6945fd5e46bb8cd720d675a02f9936", "ref_doc_id": "frontend-solid\\src\\pages\\Transfers.tsx"}, "578d5262-c066-4b46-b3f6-9d6c3e872f24": {"doc_hash": "b9818143e683b9802743cceeb567acf726772fbf973b2913df040e1162f86c04", "ref_doc_id": "frontend-solid\\src\\services\\admin.service.ts"}, "4a6bd569-ee9a-45c5-8eea-f90081432637": {"doc_hash": "48704d77e55fbb729284035fa170df99912a70593039b4612b8726dcf385f460", "ref_doc_id": "frontend-solid\\src\\services\\analytics.service.ts"}, "038eee7a-15a7-4da9-98f4-0522f2850aec": {"doc_hash": "4832d4810fcbb426680f128a12244b2f755754956ff970757154ce9e4e767d62", "ref_doc_id": "frontend-solid\\src\\services\\auth.service.ts"}, "1a4c65f3-ace8-499d-b418-53d3870c350e": {"doc_hash": "03f938e571147b8a3786cc23311b7906f8937452d7f015c77db00e89c34fe682", "ref_doc_id": "frontend-solid\\src\\services\\logger.service.ts"}, "d256cd8f-1612-48c7-891f-dc22562f58ef": {"doc_hash": "9e2bce9a8cabf02dc3bb6c0af41eb22a7b1a6c0dc54987390b9c880c3c3d498c", "ref_doc_id": "frontend-solid\\src\\services\\logger.service.ts"}, "72df7fa9-124c-492b-a8a0-af9f07dbd3fa": {"doc_hash": "9b589f49489adcad56b6a19c38e38c2dd47f43b3cc0f3ba32d04b0050ab31c07", "ref_doc_id": "frontend-solid\\src\\services\\logger.service.ts"}, "1e3eabea-2b0b-4c07-9b75-83c40ff7619c": {"doc_hash": "4cb32d0a7d89dbb56d6f00c80142ce1e21531ae210c9479b6f9990cafb232239", "ref_doc_id": "frontend-solid\\src\\services\\logger.service.ts"}, "159c2bba-be84-4209-a1bc-f8d2ba9f9e28": {"doc_hash": "0744a05b1d3361efe15c82e798c7b8415b8e0e54be119654097c1287e0992d79", "ref_doc_id": "frontend-solid\\src\\services\\reports.service.ts"}, "b551d08e-9f20-4596-9f2a-61beaac5d7fa": {"doc_hash": "f3c13d9fe648288fd2c135886ffb11946edfa7d83d5267309c59bbfc23d971a1", "ref_doc_id": "frontend-solid\\src\\store\\auth.ts"}, "280d9738-977a-46f6-962b-f0955985c6b1": {"doc_hash": "8af078a10c8cb7a8d021d199e5670f85bfd448ec18268d03392e8fdaa528c0f5", "ref_doc_id": "frontend-solid\\src\\store\\auth.ts"}, "c71cffb6-87e6-4b4f-9dd6-329d0b602386": {"doc_hash": "3961f5d91ad50d81104d563160c84fb5148f0919104d9c73e44753acd9ed2a08", "ref_doc_id": "frontend-solid\\src\\store\\dashboard.ts"}, "7432f979-1fa6-43ce-89a5-8e1f649657c4": {"doc_hash": "82bedda8193f5d591dcdf68b889c3113d1633e262d6715dc9ee51178d230e9ef", "ref_doc_id": "frontend-solid\\src\\__tests__\\App.test.tsx"}, "2c89f047-49ae-46a9-af99-88795c2208a0": {"doc_hash": "7a4c0717690ff2ab07184a0d3a1c17515bc5798d82e08baea373ed4318c1c57c", "ref_doc_id": "frontend-solid\\src\\__tests__\\ErrorBoundary.test.tsx"}, "dc9ae1a7-24a9-4db2-a52c-ac1320fbd083": {"doc_hash": "4bc343805fab72d2a430893a73e8904ce5e231bb9f3d991ad17f899eac0dc08b", "ref_doc_id": "frontend-solid\\src\\__tests__\\Layout.test.tsx"}}, "docstore/ref_doc_info": {"backend\\app\\api\\dependencies.py": {"node_ids": ["58082931-32a8-41ca-9f7b-4531bb3030f8", "150d3cb4-9dc9-4610-a4a6-8b6931d11879", "d3f34b2e-86dd-4b56-9a26-eaae7d8814fc", "d8b2fcdf-49bd-4e88-88bd-08f9ef25e748"], "metadata": {"file_path": "backend\\app\\api\\dependencies.py", "language": "python", "lines": 411, "filename": "dependencies.py"}}, "backend\\app\\api\\v1\\router.py": {"node_ids": ["f7f4c971-2a77-4b85-bb5d-226b0d406eec"], "metadata": {"file_path": "backend\\app\\api\\v1\\router.py", "language": "python", "lines": 56, "filename": "router.py"}}, "backend\\app\\api\\v1\\endpoints\\admin.py": {"node_ids": ["24fa9906-3cad-41c6-ae10-fd8dd4b60d18", "778d9629-eb76-4f1b-b494-90248ab210a1", "bb585dcc-79e2-4fcb-9f92-6f675fbc5332", "6006d213-3d66-4cb9-ac06-239bd70f8986"], "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\admin.py", "language": "python", "lines": 436, "filename": "admin.py"}}, "backend\\app\\api\\v1\\endpoints\\analytics.py": {"node_ids": ["3a6bffc2-8cb7-4352-8d0c-81674ee80795", "70ed68cc-ed6f-48e6-8178-31378d6d21a1", "fb9be564-efa9-46de-84df-0852fd326ca2", "45471034-6b11-46d1-b4a2-ca4e00baf851"], "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\analytics.py", "language": "python", "lines": 328, "filename": "analytics.py"}}, "backend\\app\\api\\v1\\endpoints\\auth.py": {"node_ids": ["b47c3bf5-687e-4bac-97e2-9274275d9a8a", "635160bc-52a6-449a-acce-136a0dee2374"], "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\auth.py", "language": "python", "lines": 207, "filename": "auth.py"}}, "backend\\app\\api\\v1\\endpoints\\auth_alt.py": {"node_ids": ["dd09dfc8-7cfe-41d2-987c-b62264e44525"], "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\auth_alt.py", "language": "python", "lines": 121, "filename": "auth_alt.py"}}, "backend\\app\\api\\v1\\endpoints\\chat.py": {"node_ids": ["91612fbb-cb7e-42fb-ab78-df07c3ebbb85", "27e3ff59-e1f3-427a-8b83-ec964e4701d5", "e38fbc5f-1c4c-4818-ae07-6c418132ec36", "f25adcf7-38a7-4055-b970-333afdd83698", "4c50e44a-5fde-490c-b0d3-2d73cf899d71", "45494706-a389-40bc-b49d-7b378c0b4e34", "48e8bdda-e374-42f2-b5bf-465b0c38bda0", "9da2c8e9-0322-48fd-b2a3-e754d4df53f1", "ff1f9730-47f9-4a75-8c52-d9f6c0c7f8cb", "d5c0c5b5-e7f8-48c3-9044-473ad098f0d6"], "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\chat.py", "language": "python", "lines": 725, "filename": "chat.py"}}, "backend\\app\\api\\v1\\endpoints\\code_chat.py": {"node_ids": ["8e225a93-bf20-4111-bf8b-7221b3da0170"], "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\code_chat.py", "language": "python", "lines": 152, "filename": "code_chat.py"}}, "backend\\app\\api\\v1\\endpoints\\diagnostics.py": {"node_ids": ["b7deae1f-eb45-4224-bfe1-10e95204b01e", "2f60a0b4-329a-4bb7-b983-4940ae84d80a"], "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\diagnostics.py", "language": "python", "lines": 199, "filename": "diagnostics.py"}}, "backend\\app\\api\\v1\\endpoints\\frontend_logs.py": {"node_ids": ["097482aa-c5ec-4976-9d4d-d166c808493a", "51a7b37d-eb41-4809-a1d6-3e1b2a18077d"], "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\frontend_logs.py", "language": "python", "lines": 158, "filename": "frontend_logs.py"}}, "backend\\app\\api\\v1\\endpoints\\health.py": {"node_ids": ["f056961d-269c-488d-b7df-a5fdd3e14549", "a9989792-b93c-4b0c-99d3-4a63182d8654"], "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\health.py", "language": "python", "lines": 259, "filename": "health.py"}}, "backend\\app\\api\\v1\\endpoints\\insights.py": {"node_ids": ["82031e68-f69b-4eef-854c-78fb083d54ea", "c7ab3d6b-acee-498d-b53d-c0f36cac4b84", "1c507a39-2102-427d-9d63-44048c7ccbfc"], "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\insights.py", "language": "python", "lines": 301, "filename": "insights.py"}}, "backend\\app\\api\\v1\\endpoints\\learning.py": {"node_ids": ["6f5a3cad-b49d-4c0a-8dcf-15b2b4489d36", "e02d81be-029d-4132-bb04-6f2b6fa248fb", "88c1671f-fc8f-448b-8392-842a9b530b5a", "b27338c8-8188-4cdc-9ef9-a5e3b6659293"], "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\learning.py", "language": "python", "lines": 297, "filename": "learning.py"}}, "backend\\app\\api\\v1\\endpoints\\metrics.py": {"node_ids": ["2f924312-872a-4707-8b78-1e207f2afbe2", "37f0710a-6e73-4f24-b22d-6bcbcc976516", "d38cb375-7122-49be-b411-ab60d4866688", "82d936e7-0653-4ed4-9bfe-fd31b30a7b00"], "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\metrics.py", "language": "python", "lines": 369, "filename": "metrics.py"}}, "backend\\app\\api\\v1\\endpoints\\playground.py": {"node_ids": ["0fdf0b74-991c-4d12-899c-d547d926ecad", "5e1b27b7-f333-425f-acbc-5fe083d403f6"], "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\playground.py", "language": "python", "lines": 169, "filename": "playground.py"}}, "backend\\app\\api\\v1\\endpoints\\preferences.py": {"node_ids": ["cd6f9f9b-001b-4617-bed7-e9ab7e311471", "d0290f4a-517e-45ea-a30d-4aad9e0cf542"], "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\preferences.py", "language": "python", "lines": 286, "filename": "preferences.py"}}, "backend\\app\\api\\v1\\endpoints\\reports.py": {"node_ids": ["71c035d9-d7a1-479e-924a-c5bc238b1df3", "bbcfc8f0-9aa1-4511-9f6c-49b7c3acc98e"], "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\reports.py", "language": "python", "lines": 218, "filename": "reports.py"}}, "backend\\app\\api\\v1\\endpoints\\rupturas.py": {"node_ids": ["c879c073-5889-49e5-9bd0-d336a3623939", "2eafb285-318d-49e8-baa9-76d9f9d66bc5", "e2a7c042-fe91-42d9-b4a2-e7ba431684c4", "bc409440-e61a-4817-8a40-cf2c8dc3424a"], "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\rupturas.py", "language": "python", "lines": 210, "filename": "rupturas.py"}}, "backend\\app\\api\\v1\\endpoints\\shared.py": {"node_ids": ["545248e8-3e14-4af6-b6bb-9f151b084be0", "bee91eee-1fff-4ff1-b3cb-80e20cdeec22"], "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\shared.py", "language": "python", "lines": 196, "filename": "shared.py"}}, "backend\\app\\api\\v1\\endpoints\\test.py": {"node_ids": ["28eff17a-aedb-4967-9386-8c93300eea8f"], "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\test.py", "language": "python", "lines": 15, "filename": "test.py"}}, "backend\\app\\api\\v1\\endpoints\\transfers.py": {"node_ids": ["70fc8a6c-750b-4098-a4b3-382346c31709", "047d89d4-ae5c-4452-acac-bb2c40b301a6", "145cd032-9fd0-4da4-a6c5-5d12fc566986", "268fc4d1-7c00-4d08-b513-bf8f70fb14ed", "4c79efcb-2de1-445a-a099-a72ac14ab0cf", "a89b94a7-3062-4513-85ae-c51ee9268fdc"], "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\transfers.py", "language": "python", "lines": 422, "filename": "transfers.py"}}, "backend\\app\\api\\v1\\endpoints\\__init__.py": {"node_ids": ["c0e650a0-f70f-4fea-b649-49819858b4a3"], "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\__init__.py", "language": "python", "lines": 6, "filename": "__init__.py"}}, "backend\\app\\config\\database.py": {"node_ids": ["fde7c6d0-075d-4888-af08-44a378fedd82"], "metadata": {"file_path": "backend\\app\\config\\database.py", "language": "python", "lines": 84, "filename": "database.py"}}, "backend\\app\\config\\logging_config.py": {"node_ids": ["892e0ab9-9f58-4c07-8b1f-e8a0d0194f49"], "metadata": {"file_path": "backend\\app\\config\\logging_config.py", "language": "python", "lines": 87, "filename": "logging_config.py"}}, "backend\\app\\config\\security.py": {"node_ids": ["caad3ebd-5e8f-4b58-8768-725e8d491b31"], "metadata": {"file_path": "backend\\app\\config\\security.py", "language": "python", "lines": 96, "filename": "security.py"}}, "backend\\app\\config\\settings.py": {"node_ids": ["c9780eb1-8803-4602-ae4c-d9f3cfb1046a", "18dfbd0a-b90d-4e53-a08e-4900b6e34454"], "metadata": {"file_path": "backend\\app\\config\\settings.py", "language": "python", "lines": 200, "filename": "settings.py"}}, "backend\\app\\core\\agent_state.py": {"node_ids": ["35df4a91-3d5d-4e96-b018-1b82d07b98e8"], "metadata": {"file_path": "backend\\app\\core\\agent_state.py", "language": "python", "lines": 35, "filename": "agent_state.py"}}, "backend\\app\\core\\agent_wrapper.py": {"node_ids": ["79309bb5-8fe3-4a70-962d-6f66f5de2e63"], "metadata": {"file_path": "backend\\app\\core\\agent_wrapper.py", "language": "python", "lines": 75, "filename": "agent_wrapper.py"}}, "backend\\app\\core\\auth_service.py": {"node_ids": ["bfefa093-8c3c-442a-8496-90cacf6761f7", "1d00a343-dd45-45dd-9e14-d5fefa7b90c0", "ac60eb75-87ba-478f-8084-7969d72da354"], "metadata": {"file_path": "backend\\app\\core\\auth_service.py", "language": "python", "lines": 340, "filename": "auth_service.py"}}, "backend\\app\\core\\cache.py": {"node_ids": ["c91b6aa7-bf89-4813-a0e4-e94cc922a71c", "56c2701e-ad67-46c0-a8ed-9fe1a6e25581"], "metadata": {"file_path": "backend\\app\\core\\cache.py", "language": "python", "lines": 197, "filename": "cache.py"}}, "backend\\app\\core\\code_rag_service.py": {"node_ids": ["b1a9e8f5-5e17-43a5-9bb4-3c6744a8bd93", "6403afba-51c1-4f6c-b365-efafee85b144", "e97473d7-a5f6-46f1-9d9e-99631575d09b"], "metadata": {"file_path": "backend\\app\\core\\code_rag_service.py", "language": "python", "lines": 282, "filename": "code_rag_service.py"}}, "backend\\app\\core\\data_scope_service.py": {"node_ids": ["42732543-6c2f-4e73-8dd6-ac4be898b5b1", "99a8af09-6eb6-469c-919f-60416aaa9a3c"], "metadata": {"file_path": "backend\\app\\core\\data_scope_service.py", "language": "python", "lines": 171, "filename": "data_scope_service.py"}}, "backend\\app\\core\\data_source_manager.py": {"node_ids": ["7ea3a0e3-5c01-4c32-b45e-03d6bae9f502", "86368921-8967-43d9-9aaa-00cb2893ad8a"], "metadata": {"file_path": "backend\\app\\core\\data_source_manager.py", "language": "python", "lines": 219, "filename": "data_source_manager.py"}}, "backend\\app\\core\\intelligent_chatbi.py": {"node_ids": ["65264fb7-389f-4fff-afb8-9ea43ccfb1dd", "56df4def-f334-41fe-a1ef-e6132e2289e6"], "metadata": {"file_path": "backend\\app\\core\\intelligent_chatbi.py", "language": "python", "lines": 195, "filename": "intelligent_chatbi.py"}}, "backend\\app\\core\\llm_base.py": {"node_ids": ["23ff1bc8-8bbb-4c2f-8901-34cc3266eebf"], "metadata": {"file_path": "backend\\app\\core\\llm_base.py", "language": "python", "lines": 8, "filename": "llm_base.py"}}, "backend\\app\\core\\llm_factory.py": {"node_ids": ["73e8fe35-2841-443a-8b49-759ef6bde37c"], "metadata": {"file_path": "backend\\app\\core\\llm_factory.py", "language": "python", "lines": 88, "filename": "llm_factory.py"}}, "backend\\app\\core\\llm_gemini_adapter.py": {"node_ids": ["c830c9da-4199-4468-879e-d54b48f30318", "9c7ad729-e66b-4206-9169-fee6ff3780d0", "4edce7b2-f4dd-4e94-9742-02aa6b759f21", "91e58a52-b4a0-4234-893c-1c1442345eba"], "metadata": {"file_path": "backend\\app\\core\\llm_gemini_adapter.py", "language": "python", "lines": 393, "filename": "llm_gemini_adapter.py"}}, "backend\\app\\core\\llm_gemini_adapter_v2.py": {"node_ids": ["5ddeeda6-58a7-4f49-a73d-a242b805006b", "24002163-0b97-45a5-afc8-b17d0d962528", "cf4bdbbf-4b76-46a5-ad26-579a59339ae8"], "metadata": {"file_path": "backend\\app\\core\\llm_gemini_adapter_v2.py", "language": "python", "lines": 276, "filename": "llm_gemini_adapter_v2.py"}}, "backend\\app\\core\\llm_langchain_adapter.py": {"node_ids": ["3502d494-611d-4d04-a04a-db3c6ad9803c", "a775e479-8542-4ec8-9fb6-998e9899ac27", "54139b18-3bec-4872-a986-15e94f97d4f9"], "metadata": {"file_path": "backend\\app\\core\\llm_langchain_adapter.py", "language": "python", "lines": 294, "filename": "llm_langchain_adapter.py"}}, "backend\\app\\core\\logging_config.py": {"node_ids": ["87bb6590-62bf-4756-927b-cb395ca8c0b5", "6ae21694-0a16-4722-bd7c-64ad2a0bd6cb", "158bb008-e571-4c8d-9086-d99eee39d4fa", "f8127b43-7e24-4fa1-af64-dfae1d2258f1"], "metadata": {"file_path": "backend\\app\\core\\logging_config.py", "language": "python", "lines": 477, "filename": "logging_config.py"}}, "backend\\app\\core\\logging_middleware.py": {"node_ids": ["bf5772b8-5805-4976-bf48-cf30ea5fbd1e", "f8e1a478-0729-405b-9d67-fde5c02cb13f", "8b299532-3bd7-4cda-8c38-a95e51ea8b7f"], "metadata": {"file_path": "backend\\app\\core\\logging_middleware.py", "language": "python", "lines": 302, "filename": "logging_middleware.py"}}, "backend\\app\\core\\parquet_cache.py": {"node_ids": ["64ecbbc7-b695-41e1-8b20-0236d8ecef05"], "metadata": {"file_path": "backend\\app\\core\\parquet_cache.py", "language": "python", "lines": 128, "filename": "parquet_cache.py"}}, "backend\\app\\core\\query_processor.py": {"node_ids": ["6a5771e6-6c98-4601-8b3c-f482e6650bb4", "d3d29dc1-a1cd-4bff-aee9-9faf609c75f9"], "metadata": {"file_path": "backend\\app\\core\\query_processor.py", "language": "python", "lines": 151, "filename": "query_processor.py"}}, "backend\\app\\core\\robust_chatbi.py": {"node_ids": ["ba52c219-6524-40f0-9eab-9073505fa1ec", "1e3feb3f-b17d-4af3-82a5-0e5d36180f83", "5e7c0ee4-5508-44f0-a41e-845d536efafa", "d51869ec-548e-43f7-ac9c-a6c2dc2c3c71"], "metadata": {"file_path": "backend\\app\\core\\robust_chatbi.py", "language": "python", "lines": 318, "filename": "robust_chatbi.py"}}, "backend\\app\\core\\supabase_client.py": {"node_ids": ["766ada64-ad24-43aa-a820-21d7237d2949"], "metadata": {"file_path": "backend\\app\\core\\supabase_client.py", "language": "python", "lines": 74, "filename": "supabase_client.py"}}, "backend\\app\\core\\supabase_user_service.py": {"node_ids": ["f8d95136-8ae4-4653-b70b-40732bd50f33", "6f05f933-a8ab-4fa9-a1ff-16837e5f6bce", "dc1b766f-8d21-4d66-98b9-a8a45ec5e5e8"], "metadata": {"file_path": "backend\\app\\core\\supabase_user_service.py", "language": "python", "lines": 323, "filename": "supabase_user_service.py"}}, "backend\\app\\core\\sync_service.py": {"node_ids": ["ed69023f-2dd5-49d7-89b1-960a384e0ad3"], "metadata": {"file_path": "backend\\app\\core\\sync_service.py", "language": "python", "lines": 94, "filename": "sync_service.py"}}, "backend\\app\\core\\agents\\base_agent.py": {"node_ids": ["30774f0c-f1f7-47de-987c-47698dcd75fb"], "metadata": {"file_path": "backend\\app\\core\\agents\\base_agent.py", "language": "python", "lines": 106, "filename": "base_agent.py"}}, "backend\\app\\core\\agents\\caculinha_bi_agent.py": {"node_ids": ["3bb372d1-cb9b-4496-937c-d4f2ac459df3", "06a5fb52-7562-4c5a-9a85-cd8ad763dce0", "e5b2b21f-921a-48d2-96fd-d0ebd2911868", "3b3a80b2-bf4d-4bc9-aecb-5d140878e2cd", "c7e840a8-383a-4625-be80-70964df4672c", "44e40181-e2fd-4e3c-b89a-fbb3c9d714e3", "898b371c-db32-47db-a3a3-7ab2c4205440", "5c51cdf6-258f-4d03-9deb-bf1ccbbe9f16", "1eb0e2b2-8f38-46cd-a670-808454068195", "c60fc81e-6786-4c41-9fe2-b5b8815533f0"], "metadata": {"file_path": "backend\\app\\core\\agents\\caculinha_bi_agent.py", "language": "python", "lines": 747, "filename": "caculinha_bi_agent.py"}}, "backend\\app\\core\\agents\\code_gen_agent.py": {"node_ids": ["f3855e40-0bfb-4cdf-a3b5-ad5fea600a50", "25796a1d-8fb8-4cd2-b811-fcc5610dc200", "c12f18ea-55da-4068-9f4a-2a62625fd3f8", "556c4691-024e-4413-9a7d-49ef17673983"], "metadata": {"file_path": "backend\\app\\core\\agents\\code_gen_agent.py", "language": "python", "lines": 317, "filename": "code_gen_agent.py"}}, "backend\\app\\core\\agents\\developer_agent.py": {"node_ids": ["abcae947-3821-4ec5-9abb-ac3ecb4cf121"], "metadata": {"file_path": "backend\\app\\core\\agents\\developer_agent.py", "language": "python", "lines": 136, "filename": "developer_agent.py"}}, "backend\\app\\core\\agents\\multi_step_agent.py": {"node_ids": ["a55741f0-4179-4fab-af05-bdbf006e9dd7", "741abada-4bf1-4758-bed8-30d4f8fb5aa0", "89d236b9-f029-4959-b677-aa92c10b740a"], "metadata": {"file_path": "backend\\app\\core\\agents\\multi_step_agent.py", "language": "python", "lines": 275, "filename": "multi_step_agent.py"}}, "backend\\app\\core\\agents\\product_agent.py": {"node_ids": ["f5d22f14-d91d-4179-9e5b-dc8429195921", "853be3c2-b53e-406a-a8d7-64e6cd41be26", "ab396180-76a2-46dc-b858-d4ceb94476c4", "71452bd2-2aee-405a-b872-6cfc528ca98c"], "metadata": {"file_path": "backend\\app\\core\\agents\\product_agent.py", "language": "python", "lines": 368, "filename": "product_agent.py"}}, "backend\\app\\core\\agents\\prompt_loader.py": {"node_ids": ["09a50ea9-8734-4a05-af88-75e345d3954b", "9297d392-c2b3-45c3-92e1-a7c2df1a3b0c"], "metadata": {"file_path": "backend\\app\\core\\agents\\prompt_loader.py", "language": "python", "lines": 133, "filename": "prompt_loader.py"}}, "backend\\app\\core\\agents\\supervisor_agent.py": {"node_ids": ["a2d303c8-8f09-4d97-b048-67f5f8fda439"], "metadata": {"file_path": "backend\\app\\core\\agents\\supervisor_agent.py", "language": "python", "lines": 138, "filename": "supervisor_agent.py"}}, "backend\\app\\core\\agents\\tool_agent.py": {"node_ids": ["07bc0f44-9daf-426b-8c14-4acc43fa1f30", "a3ea291f-822d-4eed-9e86-12ab3439f7ad"], "metadata": {"file_path": "backend\\app\\core\\agents\\tool_agent.py", "language": "python", "lines": 201, "filename": "tool_agent.py"}}, "backend\\app\\core\\agents\\__init__.py": {"node_ids": ["c75cd658-ef16-4f71-b7c6-8816faf4d5d2"], "metadata": {"file_path": "backend\\app\\core\\agents\\__init__.py", "language": "python", "lines": 8, "filename": "__init__.py"}}, "backend\\app\\core\\factory\\component_factory.py": {"node_ids": ["157ea64c-29a0-417b-8561-29707217607d"], "metadata": {"file_path": "backend\\app\\core\\factory\\component_factory.py", "language": "python", "lines": 55, "filename": "component_factory.py"}}, "backend\\app\\core\\factory\\__init__.py": {"node_ids": ["9262ea5b-daff-4eb0-8f66-55f44a38f11d"], "metadata": {"file_path": "backend\\app\\core\\factory\\__init__.py", "language": "python", "lines": 2, "filename": "__init__.py"}}, "backend\\app\\core\\graph\\agent.py": {"node_ids": ["0b3d75a7-d12e-4822-b714-48380c02b354"], "metadata": {"file_path": "backend\\app\\core\\graph\\agent.py", "language": "python", "lines": 91, "filename": "agent.py"}}, "backend\\app\\core\\graph\\__init__.py": {"node_ids": ["e5c247c5-c1de-4686-b6b8-e95869bf0a56"], "metadata": {"file_path": "backend\\app\\core\\graph\\__init__.py", "language": "python", "lines": 18, "filename": "__init__.py"}}, "backend\\app\\core\\learning\\feedback_system.py": {"node_ids": ["922d2f8c-ae8e-4779-b2e0-e079ae3f271c", "1c5baf03-8174-46e7-99a6-6266f85a45e2", "90ac3a75-05f0-4289-948b-430d3a053aff"], "metadata": {"file_path": "backend\\app\\core\\learning\\feedback_system.py", "language": "python", "lines": 248, "filename": "feedback_system.py"}}, "backend\\app\\core\\learning\\pattern_matcher.py": {"node_ids": ["b4c9d948-edb7-4948-9632-ce4b6a32335b"], "metadata": {"file_path": "backend\\app\\core\\learning\\pattern_matcher.py", "language": "python", "lines": 63, "filename": "pattern_matcher.py"}}, "backend\\app\\core\\monitoring\\metrics_dashboard.py": {"node_ids": ["b0f78a20-e1be-4614-8cfe-f7975e3e265b", "d2cb0dd5-b8cb-4501-8ee2-236dd56a174b"], "metadata": {"file_path": "backend\\app\\core\\monitoring\\metrics_dashboard.py", "language": "python", "lines": 183, "filename": "metrics_dashboard.py"}}, "backend\\app\\core\\rag\\example_collector.py": {"node_ids": ["19f2d2e3-aa6c-44d4-9c78-09ee0a97ec6d", "289f6ffd-cf92-44a3-ab99-9cd883d65803"], "metadata": {"file_path": "backend\\app\\core\\rag\\example_collector.py", "language": "python", "lines": 129, "filename": "example_collector.py"}}, "backend\\app\\core\\rag\\query_retriever.py": {"node_ids": ["b3012dee-1841-40be-b766-5b8d59b7b4b3", "4f1464ba-77ec-43c7-aa8c-ef4b54a75920"], "metadata": {"file_path": "backend\\app\\core\\rag\\query_retriever.py", "language": "python", "lines": 179, "filename": "query_retriever.py"}}, "backend\\app\\core\\security\\data_masking.py": {"node_ids": ["58fc70ee-b486-4e44-815f-876b9e935eb5"], "metadata": {"file_path": "backend\\app\\core\\security\\data_masking.py", "language": "python", "lines": 95, "filename": "data_masking.py"}}, "backend\\app\\core\\security\\input_validator.py": {"node_ids": ["ac11fc4e-22db-437a-bf6a-f372bf494216"], "metadata": {"file_path": "backend\\app\\core\\security\\input_validator.py", "language": "python", "lines": 81, "filename": "input_validator.py"}}, "backend\\app\\core\\tools\\chart_tools.py": {"node_ids": ["fc19df88-bdc1-4ab5-bc46-c91f9d7c23f0", "27613711-c0aa-4f0e-b0e4-9bcd68a4ea59", "ad4d0279-ee52-4580-ba94-041ded31a9e4", "19717d32-23c3-4402-9c6b-96d32ee3982c", "ffdee957-9a55-453b-8db4-29720e371074", "a1be6b57-b747-44dc-8294-377c6100a1f8", "4d156409-ea01-4576-a226-12bd402a946d", "1606ec3f-0a65-480c-b34e-cafc98c60b30", "8aaa3dd6-2ec4-4b7a-8ebb-73e6223af0a1", "be7f8ffa-f847-4e3c-a5ab-4f416adcf866", "00d1c81a-c75d-427a-8443-115c24dd707d", "a57e879b-96c0-418e-bdb6-2e08f2839740", "015dfa15-f3dd-4a79-9ca4-b7fb0dc869ee", "48b9bfc9-92dd-4f6d-8978-059a58a077c7", "cfe7de0e-8e6c-4967-8d24-e58678a36644", "9604cba0-85d3-42f0-89cf-b8dfd4d68d71", "0d5fc255-5de0-4cf1-abf0-7c5099d90fc0", "57cd3ee1-f53a-4a22-af63-10157d71029e", "2b1628d6-ac21-499b-8876-9c8ebbf63327", "10204078-1621-46d0-a928-c43be2ca7d54", "c29a704d-ed32-4598-aca2-c4cdff6f40e2", "deac9ae4-ca57-4a3d-b12b-de04b42cff74"], "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}}, "backend\\app\\core\\tools\\check_gui_dependencies.py": {"node_ids": ["d9153119-d2df-4528-ac79-1abf29261045"], "metadata": {"file_path": "backend\\app\\core\\tools\\check_gui_dependencies.py", "language": "python", "lines": 57, "filename": "check_gui_dependencies.py"}}, "backend\\app\\core\\tools\\check_integration.py": {"node_ids": ["343ec929-0561-49f5-96d0-0fcf7a7a99f3"], "metadata": {"file_path": "backend\\app\\core\\tools\\check_integration.py", "language": "python", "lines": 1, "filename": "check_integration.py"}}, "backend\\app\\core\\tools\\code_interpreter.py": {"node_ids": ["264211dc-aa95-486e-9733-e33f44cdb262", "b34e3d22-6348-4505-abd3-a34dd5621b6a", "e5e9f0da-9ccb-48df-9a6b-16ce16aaff27"], "metadata": {"file_path": "backend\\app\\core\\tools\\code_interpreter.py", "language": "python", "lines": 276, "filename": "code_interpreter.py"}}, "backend\\app\\core\\tools\\date_time_tools.py": {"node_ids": ["ac330131-3a1d-494c-bfdc-4f69105871b5"], "metadata": {"file_path": "backend\\app\\core\\tools\\date_time_tools.py", "language": "python", "lines": 19, "filename": "date_time_tools.py"}}, "backend\\app\\core\\tools\\debug_server.py": {"node_ids": ["539ff5b4-252d-43a0-b951-9e8d7c2de8c1"], "metadata": {"file_path": "backend\\app\\core\\tools\\debug_server.py", "language": "python", "lines": 43, "filename": "debug_server.py"}}, "backend\\app\\core\\tools\\flexible_query_tool.py": {"node_ids": ["216b2743-84d1-4c4d-b855-57f657a2df1a", "9d2088a2-319a-4c3d-8dd1-c32148ba8040", "e098c6f5-fced-4d63-84a9-c4e675149d5c"], "metadata": {"file_path": "backend\\app\\core\\tools\\flexible_query_tool.py", "language": "python", "lines": 219, "filename": "flexible_query_tool.py"}}, "backend\\app\\core\\tools\\graph_integration.py": {"node_ids": ["d384c133-b0fc-4463-85b8-e078ea1bbf0a", "7c06d9d3-37fa-4df9-a680-9ca51b150821", "dc9fa2c7-02a9-48ad-82c6-783b3f834c9b"], "metadata": {"file_path": "backend\\app\\core\\tools\\graph_integration.py", "language": "python", "lines": 160, "filename": "graph_integration.py"}}, "backend\\app\\core\\tools\\mcp_parquet_tools.py": {"node_ids": ["68b89e98-1ec6-4c40-af62-925e9938a6b1", "5b40b53a-11ae-4e6f-97da-f81ba7a35653"], "metadata": {"file_path": "backend\\app\\core\\tools\\mcp_parquet_tools.py", "language": "python", "lines": 115, "filename": "mcp_parquet_tools.py"}}, "backend\\app\\core\\tools\\mcp_sql_server_tools.py": {"node_ids": ["f0483fb3-a796-45d3-bc56-bd8df7f1bc3e", "5a0b1bf2-1986-4b95-82b2-90b4d31b46b1"], "metadata": {"file_path": "backend\\app\\core\\tools\\mcp_sql_server_tools.py", "language": "python", "lines": 122, "filename": "mcp_sql_server_tools.py"}}, "backend\\app\\core\\tools\\quick_response.py": {"node_ids": ["f8a3181a-92ca-4872-8773-c0558406f5c9", "6123a6bc-6a11-4547-8b01-ed976f4a58bc"], "metadata": {"file_path": "backend\\app\\core\\tools\\quick_response.py", "language": "python", "lines": 159, "filename": "quick_response.py"}}, "backend\\app\\core\\tools\\sql_server_tools.py": {"node_ids": ["b73b4fe5-3127-4629-9e0a-a0d2506f1767", "75e46973-2e0f-4855-bfae-411ccc0c8d8a", "8179d88c-e69b-4d4a-bb74-4d40182d5525"], "metadata": {"file_path": "backend\\app\\core\\tools\\sql_server_tools.py", "language": "python", "lines": 357, "filename": "sql_server_tools.py"}}, "backend\\app\\core\\tools\\une_tools.py": {"node_ids": ["62757858-327a-4b9b-9bbf-ce676510dc81", "d9a14ce9-69e7-47fd-ae7b-efec0ef36f30", "41fd96d5-44f4-478d-967f-8c644d2fdbf4", "f9ad5787-cd9a-4268-8aaf-9dd8da2c81f2", "082afb91-c0cf-409a-b54b-1ea23be69480", "e32aece9-bd76-4b6f-b0f3-a9109da53fd3", "7e939a50-9468-4b1f-93d2-3723297d305d", "f0ee5031-178d-417e-b4c8-0256bd849e5c", "e0ed09dc-b984-4e76-9419-03dad06b2817", "87153257-9812-4e17-a765-40e05dda0340", "0800b633-5544-4836-970b-1b5629a6d124", "1d273463-c8cc-458b-9768-df6140e41abe", "62947953-7189-4748-9b39-49ad0621414d", "b53d8228-a69d-4ffe-88cd-2859cd2162ef", "c4055a18-4955-4d21-b58e-e9a718e5ff20", "3d831c33-df11-4e14-93b2-512f18f0a3c6", "9ce7b2f0-913f-4772-8319-ed275b8b2315", "3c59032c-76b9-44ab-b1e2-56b73ac084d9", "0548c04f-e9b5-459a-a051-aca97df49241", "7a32339c-1917-4671-bccd-a5b1983affea", "0277ad50-6a75-43a5-8ad2-db1db2a6384d"], "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}}, "backend\\app\\core\\tools\\une_tools_backup_old.py": {"node_ids": ["385325ba-54d0-43a0-a6c5-d0a0d2ffdbff", "bdf78d43-d49d-45be-aad2-71162b6607f0", "9fb87a2b-bf2d-4a69-bf54-658c8f40f557", "c0d50bd7-8fbf-40c9-b1d5-f37507b1b994", "c2dcd50c-0af0-4117-85fb-e4e2c356e258"], "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools_backup_old.py", "language": "python", "lines": 349, "filename": "une_tools_backup_old.py"}}, "backend\\app\\core\\tools\\unified_data_tools.py": {"node_ids": ["0cf02784-1747-4dad-b33a-398f712211ae", "865602e3-ef29-44a4-b53a-cdb84e230443", "75bae677-5492-448e-9603-323e1e85d15e", "24511efe-6e77-4fc8-850c-9eeeae19df79"], "metadata": {"file_path": "backend\\app\\core\\tools\\unified_data_tools.py", "language": "python", "lines": 329, "filename": "unified_data_tools.py"}}, "backend\\app\\core\\tools\\verify_imports.py": {"node_ids": ["e8bed705-17b2-4773-bb68-0f0bf2be4c06"], "metadata": {"file_path": "backend\\app\\core\\tools\\verify_imports.py", "language": "python", "lines": 45, "filename": "verify_imports.py"}}, "backend\\app\\core\\tools\\__init__.py": {"node_ids": ["d95904f1-c546-4aee-99ba-7b526f88a907"], "metadata": {"file_path": "backend\\app\\core\\tools\\__init__.py", "language": "python", "lines": 1, "filename": "__init__.py"}}, "backend\\app\\core\\utils\\agent_cache.py": {"node_ids": ["b3315497-d5a1-4a30-a1cc-3d412493e979", "5e35dcbc-e278-4905-ab31-404d2ccff1e2", "28621ebf-0236-4cd6-a122-1656099df066"], "metadata": {"file_path": "backend\\app\\core\\utils\\agent_cache.py", "language": "python", "lines": 199, "filename": "agent_cache.py"}}, "backend\\app\\core\\utils\\cache_cleaner.py": {"node_ids": ["29af04a2-e38f-4f46-bd10-351c6bd07267", "0cff6f1e-39d2-48cf-984b-e1de7c1994cc", "e96f435d-d657-44d4-aca1-8d417e131ddc"], "metadata": {"file_path": "backend\\app\\core\\utils\\cache_cleaner.py", "language": "python", "lines": 360, "filename": "cache_cleaner.py"}}, "backend\\app\\core\\utils\\chart_saver.py": {"node_ids": ["4118601c-e883-4008-9bad-54bd869bf6f2"], "metadata": {"file_path": "backend\\app\\core\\utils\\chart_saver.py", "language": "python", "lines": 54, "filename": "chart_saver.py"}}, "backend\\app\\core\\utils\\error_handler.py": {"node_ids": ["e44c79ee-0088-4d31-a65b-c7a4c805c24b", "47898aaa-cd17-4258-b6f7-633031a7b66c", "4b57f713-1bcc-46b0-b366-7665ebac3ff9", "ff8cbf0c-9e91-4cff-bcb7-d343fed7f9f5", "dd00cab5-67b4-49c9-8125-6b9ae42ad12d"], "metadata": {"file_path": "backend\\app\\core\\utils\\error_handler.py", "language": "python", "lines": 409, "filename": "error_handler.py"}}, "backend\\app\\core\\utils\\error_handler_backup.py": {"node_ids": ["cc24b328-654f-4eb6-86bb-2cc798a7b147"], "metadata": {"file_path": "backend\\app\\core\\utils\\error_handler_backup.py", "language": "python", "lines": 116, "filename": "error_handler_backup.py"}}, "backend\\app\\core\\utils\\fast_path_detector.py": {"node_ids": ["68952c1a-2574-4218-8627-81144f3e0f48"], "metadata": {"file_path": "backend\\app\\core\\utils\\fast_path_detector.py", "language": "python", "lines": 74, "filename": "fast_path_detector.py"}}, "backend\\app\\core\\utils\\field_mapper.py": {"node_ids": ["8bb15477-2a99-4ab2-9324-3d47205c20fa", "a0b35d7c-d9c5-42d3-bdee-01959a76702a"], "metadata": {"file_path": "backend\\app\\core\\utils\\field_mapper.py", "language": "python", "lines": 125, "filename": "field_mapper.py"}}, "backend\\app\\core\\utils\\query_history.py": {"node_ids": ["9e384c65-3965-431a-8ab8-c790a273cf63", "d8e449e7-cd63-4e7e-b19c-27db8d1dab60", "8d1928ae-c73b-4672-a7ce-63d91c3d1ce5"], "metadata": {"file_path": "backend\\app\\core\\utils\\query_history.py", "language": "python", "lines": 179, "filename": "query_history.py"}}, "backend\\app\\core\\utils\\query_validator.py": {"node_ids": ["7aa2b149-63e2-48fb-b8ca-5138e15c13ed", "e95fcc6f-a591-4093-af65-c3fa7fcebb4a", "d39443ac-739d-491d-a0f5-8f9e0263ae00"], "metadata": {"file_path": "backend\\app\\core\\utils\\query_validator.py", "language": "python", "lines": 362, "filename": "query_validator.py"}}, "backend\\app\\core\\utils\\response_cache.py": {"node_ids": ["ba089853-133b-4bbb-af47-9d3e17cbb42d", "942e8b74-74ec-400c-8e95-89a99229f4ec"], "metadata": {"file_path": "backend\\app\\core\\utils\\response_cache.py", "language": "python", "lines": 158, "filename": "response_cache.py"}}, "backend\\app\\core\\utils\\response_parser.py": {"node_ids": ["708d713d-8f58-4653-8f50-599df5e6201e"], "metadata": {"file_path": "backend\\app\\core\\utils\\response_parser.py", "language": "python", "lines": 139, "filename": "response_parser.py"}}, "backend\\app\\core\\utils\\response_validator.py": {"node_ids": ["1d8f7810-9424-44c6-9cfb-9c616bb62f33", "1d02909b-c274-477c-9a35-0dde32df4bb4"], "metadata": {"file_path": "backend\\app\\core\\utils\\response_validator.py", "language": "python", "lines": 234, "filename": "response_validator.py"}}, "backend\\app\\core\\utils\\semantic_cache.py": {"node_ids": ["15dc9f6f-6531-40b6-9aa3-cb64abd60217", "4404a5ce-abbf-4134-9cf1-711c7690c95a"], "metadata": {"file_path": "backend\\app\\core\\utils\\semantic_cache.py", "language": "python", "lines": 244, "filename": "semantic_cache.py"}}, "backend\\app\\core\\utils\\serializers.py": {"node_ids": ["3c0703a9-f889-4804-b180-8951fd9e6f3d", "a90a9bac-f436-483a-8340-aea1491b2fc0", "206fd156-f82c-4487-868e-c230dd5b50e6"], "metadata": {"file_path": "backend\\app\\core\\utils\\serializers.py", "language": "python", "lines": 179, "filename": "serializers.py"}}, "backend\\app\\core\\utils\\session_manager.py": {"node_ids": ["b226e07b-8734-490a-9b84-fe9b3a3e031b"], "metadata": {"file_path": "backend\\app\\core\\utils\\session_manager.py", "language": "python", "lines": 57, "filename": "session_manager.py"}}, "backend\\app\\core\\utils\\__init__.py": {"node_ids": ["a78c429f-eb14-4827-bded-1e9ed23bed4f"], "metadata": {"file_path": "backend\\app\\core\\utils\\__init__.py", "language": "python", "lines": 2, "filename": "__init__.py"}}, "backend\\app\\core\\validators\\schema_validator.py": {"node_ids": ["eb87491b-64b0-426e-b221-09e49323f382", "fee77b69-66d5-4194-ba7b-923360233275", "74e18685-4e32-4ab1-9d5c-7b5c5c8cdb0f", "ef3fd107-8fe2-413d-8e67-1ca870095783"], "metadata": {"file_path": "backend\\app\\core\\validators\\schema_validator.py", "language": "python", "lines": 397, "filename": "schema_validator.py"}}, "backend\\app\\core\\visualization\\advanced_charts.py": {"node_ids": ["34e2c144-8bf7-49f6-93ff-13184e2c87f4"], "metadata": {"file_path": "backend\\app\\core\\visualization\\advanced_charts.py", "language": "python", "lines": 107, "filename": "advanced_charts.py"}}, "backend\\app\\core\\visualization\\__init__.py": {"node_ids": ["2f5962ad-5033-43fa-93ec-82ef82d3a86e"], "metadata": {"file_path": "backend\\app\\core\\visualization\\__init__.py", "language": "python", "lines": 2, "filename": "__init__.py"}}, "backend\\app\\infrastructure\\data\\base.py": {"node_ids": ["e05210ae-c769-4b40-90a3-7aa5885ce41c"], "metadata": {"file_path": "backend\\app\\infrastructure\\data\\base.py", "language": "python", "lines": 34, "filename": "base.py"}}, "backend\\app\\infrastructure\\data\\dependency.py": {"node_ids": ["7149ff09-2905-4593-90e7-db6da39ed0b0"], "metadata": {"file_path": "backend\\app\\infrastructure\\data\\dependency.py", "language": "python", "lines": 25, "filename": "dependency.py"}}, "backend\\app\\infrastructure\\data\\duckdb_adapter.py": {"node_ids": ["eb208ab1-05cd-4df6-809c-a9269ffc51e3", "a188f464-6e85-415e-927f-f813a4b43719"], "metadata": {"file_path": "backend\\app\\infrastructure\\data\\duckdb_adapter.py", "language": "python", "lines": 177, "filename": "duckdb_adapter.py"}}, "backend\\app\\infrastructure\\data\\hybrid_adapter.py": {"node_ids": ["ed2c99d0-fc50-4077-98b9-d9e7975cbed8", "f8a2635f-d21b-4981-a0c5-d932171b425a"], "metadata": {"file_path": "backend\\app\\infrastructure\\data\\hybrid_adapter.py", "language": "python", "lines": 125, "filename": "hybrid_adapter.py"}}, "backend\\app\\infrastructure\\data\\parquet_adapter.py": {"node_ids": ["3dad3227-5cb1-4c8c-9e28-18ad1166f9b1"], "metadata": {"file_path": "backend\\app\\infrastructure\\data\\parquet_adapter.py", "language": "python", "lines": 39, "filename": "parquet_adapter.py"}}, "backend\\app\\infrastructure\\data\\polars_dask_adapter.py": {"node_ids": ["ec3a0eff-53fb-4be1-b1d5-bbebc5c93544", "467ef6d8-c4b6-4131-a1fb-e0f25900ffaf", "e81b0293-2a24-42f3-b56f-e800794366d8", "ef9c8701-1fca-472c-9c31-0b8a0b6a2c81", "fe17e751-72c6-4bd0-96f6-0f525870f90f"], "metadata": {"file_path": "backend\\app\\infrastructure\\data\\polars_dask_adapter.py", "language": "python", "lines": 344, "filename": "polars_dask_adapter.py"}}, "backend\\app\\infrastructure\\data\\sql_server_adapter.py": {"node_ids": ["7028e6b4-c1e7-491f-bf8e-d4d01f52bbdd"], "metadata": {"file_path": "backend\\app\\infrastructure\\data\\sql_server_adapter.py", "language": "python", "lines": 134, "filename": "sql_server_adapter.py"}}, "backend\\app\\infrastructure\\data\\config\\column_mapping.py": {"node_ids": ["c6433296-9ddb-478c-a93a-fb43c172efad", "5aac55ad-4c3c-40d0-95ee-c63aa5491c51", "16caafe4-7e96-4acb-a5e5-8178615290f2"], "metadata": {"file_path": "backend\\app\\infrastructure\\data\\config\\column_mapping.py", "language": "python", "lines": 312, "filename": "column_mapping.py"}}, "backend\\app\\infrastructure\\data\\utils\\column_validator.py": {"node_ids": ["53f253e5-e7f9-4ed1-a42b-d8d3ae97f089", "5ac50642-ba4c-4d36-8a0e-2b665c9de822", "ef4c4e41-cb30-4173-9e2c-53d3fd4ba748", "51df215b-5ec7-4db1-bb43-c4a31c406c13"], "metadata": {"file_path": "backend\\app\\infrastructure\\data\\utils\\column_validator.py", "language": "python", "lines": 342, "filename": "column_validator.py"}}, "backend\\app\\infrastructure\\data\\utils\\query_optimizer.py": {"node_ids": ["df0c8d0e-9507-491b-8b43-ddd8eaf868b3", "51de2d81-a0ce-4421-bf95-122327d8aea9", "38742e43-e4ac-48c1-98d2-76d7a5c30f42"], "metadata": {"file_path": "backend\\app\\infrastructure\\data\\utils\\query_optimizer.py", "language": "python", "lines": 256, "filename": "query_optimizer.py"}}, "backend\\app\\infrastructure\\database\\migrations\\env.py": {"node_ids": ["091b5e28-0495-4f6e-b708-674464159c6c"], "metadata": {"file_path": "backend\\app\\infrastructure\\database\\migrations\\env.py", "language": "python", "lines": 69, "filename": "env.py"}}, "backend\\app\\infrastructure\\database\\migrations\\versions\\fresh_start_migration.py": {"node_ids": ["8dac3e44-213d-4141-a1ab-bd7f21477505"], "metadata": {"file_path": "backend\\app\\infrastructure\\database\\migrations\\versions\\fresh_start_migration.py", "language": "python", "lines": 74, "filename": "fresh_start_migration.py"}}, "backend\\app\\infrastructure\\database\\models\\admmatao.py": {"node_ids": ["867fc1a1-d047-4c06-9cc4-6f0935324800", "28456f1a-bf84-4d4f-aa05-20175d5411c9"], "metadata": {"file_path": "backend\\app\\infrastructure\\database\\models\\admmatao.py", "language": "python", "lines": 123, "filename": "admmatao.py"}}, "backend\\app\\infrastructure\\database\\models\\audit_log.py": {"node_ids": ["5beb76f3-0ed7-4ae6-b28e-8a1cb924af59"], "metadata": {"file_path": "backend\\app\\infrastructure\\database\\models\\audit_log.py", "language": "python", "lines": 38, "filename": "audit_log.py"}}, "backend\\app\\infrastructure\\database\\models\\report.py": {"node_ids": ["127cfc0e-6c09-4997-8383-203cb5f5c8ee"], "metadata": {"file_path": "backend\\app\\infrastructure\\database\\models\\report.py", "language": "python", "lines": 43, "filename": "report.py"}}, "backend\\app\\infrastructure\\database\\models\\shared_conversation.py": {"node_ids": ["842b4f51-ef40-4e18-9462-4624cb9ec442"], "metadata": {"file_path": "backend\\app\\infrastructure\\database\\models\\shared_conversation.py", "language": "python", "lines": 70, "filename": "shared_conversation.py"}}, "backend\\app\\infrastructure\\database\\models\\user.py": {"node_ids": ["e47efd9b-8969-4296-9ae8-4e57d1874c6c"], "metadata": {"file_path": "backend\\app\\infrastructure\\database\\models\\user.py", "language": "python", "lines": 54, "filename": "user.py"}}, "backend\\app\\infrastructure\\database\\models\\user_preference.py": {"node_ids": ["0e1052cc-8e88-4dff-8a8f-296df91f7a74"], "metadata": {"file_path": "backend\\app\\infrastructure\\database\\models\\user_preference.py", "language": "python", "lines": 51, "filename": "user_preference.py"}}, "backend\\app\\infrastructure\\database\\models\\__init__.py": {"node_ids": ["50e72066-40de-4301-8a08-dbc7fa7741c7"], "metadata": {"file_path": "backend\\app\\infrastructure\\database\\models\\__init__.py", "language": "python", "lines": 15, "filename": "__init__.py"}}, "backend\\app\\schemas\\analytics.py": {"node_ids": ["23dad50c-1ef4-4195-83ca-bf22fb6fc8a0"], "metadata": {"file_path": "backend\\app\\schemas\\analytics.py", "language": "python", "lines": 55, "filename": "analytics.py"}}, "backend\\app\\schemas\\auth.py": {"node_ids": ["a4c28993-2c24-4f5f-852d-05637f56d487"], "metadata": {"file_path": "backend\\app\\schemas\\auth.py", "language": "python", "lines": 37, "filename": "auth.py"}}, "backend\\app\\schemas\\report.py": {"node_ids": ["a01c60f1-08df-4a58-a759-0b24ac3248df"], "metadata": {"file_path": "backend\\app\\schemas\\report.py", "language": "python", "lines": 61, "filename": "report.py"}}, "backend\\app\\schemas\\user.py": {"node_ids": ["a8fccb0b-a2c9-4c26-9fc9-41144c21744b"], "metadata": {"file_path": "backend\\app\\schemas\\user.py", "language": "python", "lines": 68, "filename": "user.py"}}, "frontend-solid\\src\\index.tsx": {"node_ids": ["d6fc08b7-fb85-45d2-8613-87544686dcec", "8279fa70-85ff-4d8e-96a1-0f4ef6f58192"], "metadata": {"file_path": "frontend-solid\\src\\index.tsx", "language": "typescript", "lines": 160, "filename": "index.tsx"}}, "frontend-solid\\src\\index_minimal_test.tsx": {"node_ids": ["2c39a102-fefa-40b0-af6b-420530b8184a"], "metadata": {"file_path": "frontend-solid\\src\\index_minimal_test.tsx", "language": "typescript", "lines": 11, "filename": "index_minimal_test.tsx"}}, "frontend-solid\\src\\Layout.tsx": {"node_ids": ["577b53eb-3e5b-46da-be5e-ebb95696085e", "41b65da6-ed9c-4f5c-bfe5-d0afcaad1c22"], "metadata": {"file_path": "frontend-solid\\src\\Layout.tsx", "language": "typescript", "lines": 136, "filename": "Layout.tsx"}}, "frontend-solid\\src\\components\\AIInsightsPanel.tsx": {"node_ids": ["a0a33cde-f2e1-44c6-ad3d-f71cc29bc4cc", "c33591a7-b4a2-4f1f-916d-131bd55eb246", "f11eb096-68a8-4ec4-af79-04605d2a2aa8"], "metadata": {"file_path": "frontend-solid\\src\\components\\AIInsightsPanel.tsx", "language": "typescript", "lines": 194, "filename": "AIInsightsPanel.tsx"}}, "frontend-solid\\src\\components\\ChartDownloadButton.tsx": {"node_ids": ["bbe924d7-467c-4e9d-8a74-89a65c2a15a7"], "metadata": {"file_path": "frontend-solid\\src\\components\\ChartDownloadButton.tsx", "language": "typescript", "lines": 123, "filename": "ChartDownloadButton.tsx"}}, "frontend-solid\\src\\components\\DataTable.tsx": {"node_ids": ["ca0826c9-2f72-43fd-b39b-587a0c131cff", "718cd41d-0475-4343-89a5-71a13c4e1847"], "metadata": {"file_path": "frontend-solid\\src\\components\\DataTable.tsx", "language": "typescript", "lines": 126, "filename": "DataTable.tsx"}}, "frontend-solid\\src\\components\\DownloadButton.tsx": {"node_ids": ["47a420f5-843d-4c2a-a980-c27c170a4dd0"], "metadata": {"file_path": "frontend-solid\\src\\components\\DownloadButton.tsx", "language": "typescript", "lines": 47, "filename": "DownloadButton.tsx"}}, "frontend-solid\\src\\components\\ErrorBoundary.tsx": {"node_ids": ["7d55e5e9-7ac8-49cd-bda3-dfdc51e2b3e8"], "metadata": {"file_path": "frontend-solid\\src\\components\\ErrorBoundary.tsx", "language": "typescript", "lines": 38, "filename": "ErrorBoundary.tsx"}}, "frontend-solid\\src\\components\\ExportMenu.tsx": {"node_ids": ["b1121dbb-5b87-4c10-8911-9e270e9a2f95", "bb49a099-199f-422b-8b91-208001ae9e2b"], "metadata": {"file_path": "frontend-solid\\src\\components\\ExportMenu.tsx", "language": "typescript", "lines": 137, "filename": "ExportMenu.tsx"}}, "frontend-solid\\src\\components\\FeedbackButtons.tsx": {"node_ids": ["96644538-0383-4b5d-8c7a-f3af68a56ad0"], "metadata": {"file_path": "frontend-solid\\src\\components\\FeedbackButtons.tsx", "language": "typescript", "lines": 41, "filename": "FeedbackButtons.tsx"}}, "frontend-solid\\src\\components\\index.ts": {"node_ids": ["f073d9cc-868f-4c84-92a7-a47680d3e96b"], "metadata": {"file_path": "frontend-solid\\src\\components\\index.ts", "language": "typescript", "lines": 12, "filename": "index.ts"}}, "frontend-solid\\src\\components\\Logo.tsx": {"node_ids": ["e72a369a-dfe0-41f6-86ca-48ac6aa47742"], "metadata": {"file_path": "frontend-solid\\src\\components\\Logo.tsx", "language": "typescript", "lines": 28, "filename": "Logo.tsx"}}, "frontend-solid\\src\\components\\MessageActions.tsx": {"node_ids": ["fb76c0fd-9c2e-4aa9-83b3-3551a28b57b8"], "metadata": {"file_path": "frontend-solid\\src\\components\\MessageActions.tsx", "language": "typescript", "lines": 53, "filename": "MessageActions.tsx"}}, "frontend-solid\\src\\components\\PlotlyChart.tsx": {"node_ids": ["c2338493-f6ef-49fd-9066-11bd2f973be3", "5efc4b9e-a98e-44b7-8a2b-b91efb4a418a"], "metadata": {"file_path": "frontend-solid\\src\\components\\PlotlyChart.tsx", "language": "typescript", "lines": 159, "filename": "PlotlyChart.tsx"}}, "frontend-solid\\src\\components\\ShareButton.tsx": {"node_ids": ["539cdc3e-8082-4669-adb7-563bb9c45a98", "74fd36b4-a43b-48dd-95bf-a4542230e8c5"], "metadata": {"file_path": "frontend-solid\\src\\components\\ShareButton.tsx", "language": "typescript", "lines": 199, "filename": "ShareButton.tsx"}}, "frontend-solid\\src\\components\\Typewriter.tsx": {"node_ids": ["b6262f19-5eaa-43b0-9684-64f4e7690847"], "metadata": {"file_path": "frontend-solid\\src\\components\\Typewriter.tsx", "language": "typescript", "lines": 124, "filename": "Typewriter.tsx"}}, "frontend-solid\\src\\components\\TypingIndicator.tsx": {"node_ids": ["045f4874-3324-4ac5-ab6a-4b936c64e074"], "metadata": {"file_path": "frontend-solid\\src\\components\\TypingIndicator.tsx", "language": "typescript", "lines": 13, "filename": "TypingIndicator.tsx"}}, "frontend-solid\\src\\components\\UserPreferences.tsx": {"node_ids": ["31a812da-583e-4a47-9001-464e6aa20463"], "metadata": {"file_path": "frontend-solid\\src\\components\\UserPreferences.tsx", "language": "typescript", "lines": 137, "filename": "UserPreferences.tsx"}}, "frontend-solid\\src\\components\\__tests__\\Chat.test.tsx": {"node_ids": ["526a6d51-227e-4fde-b8eb-cc5cfb3d1ce4", "fdadf60d-92b9-411e-bf80-169904d910bc", "c5ec22ec-a362-46d4-b036-15dcd534bbc2"], "metadata": {"file_path": "frontend-solid\\src\\components\\__tests__\\Chat.test.tsx", "language": "typescript", "lines": 223, "filename": "Chat.test.tsx"}}, "frontend-solid\\src\\examples\\ComponentsDemo.tsx": {"node_ids": ["cb8419bd-b7d9-4935-a5b9-9030cfbd884a", "f9b17343-3f48-47a5-a0bc-1eb75919c430", "5ea31a2e-91c4-4ddb-aefa-3bef96f4ea9d", "665fe818-e55d-4265-81b1-0b90fabcd1b4"], "metadata": {"file_path": "frontend-solid\\src\\examples\\ComponentsDemo.tsx", "language": "typescript", "lines": 167, "filename": "ComponentsDemo.tsx"}}, "frontend-solid\\src\\examples\\MinimalLogin.tsx": {"node_ids": ["0528e03e-6b56-4cac-818a-d298e59ad66a"], "metadata": {"file_path": "frontend-solid\\src\\examples\\MinimalLogin.tsx", "language": "typescript", "lines": 14, "filename": "MinimalLogin.tsx"}}, "frontend-solid\\src\\examples\\SkeletonDemo.tsx": {"node_ids": ["3574a84f-fbe5-4bcd-aa57-b4f5bcb0545a"], "metadata": {"file_path": "frontend-solid\\src\\examples\\SkeletonDemo.tsx", "language": "typescript", "lines": 85, "filename": "SkeletonDemo.tsx"}}, "frontend-solid\\src\\hooks\\useAdmin.ts": {"node_ids": ["edd970e2-0290-4993-9756-4120a4c680d7"], "metadata": {"file_path": "frontend-solid\\src\\hooks\\useAdmin.ts", "language": "typescript", "lines": 91, "filename": "useAdmin.ts"}}, "frontend-solid\\src\\hooks\\useAnalytics.ts": {"node_ids": ["b1ddbd7d-c554-422a-b998-430c19e05160"], "metadata": {"file_path": "frontend-solid\\src\\hooks\\useAnalytics.ts", "language": "typescript", "lines": 63, "filename": "useAnalytics.ts"}}, "frontend-solid\\src\\hooks\\useMediaQuery.ts": {"node_ids": ["95e21a36-204a-47e0-b1f4-cf4edeff847c"], "metadata": {"file_path": "frontend-solid\\src\\hooks\\useMediaQuery.ts", "language": "typescript", "lines": 34, "filename": "useMediaQuery.ts"}}, "frontend-solid\\src\\hooks\\useReports.ts": {"node_ids": ["551d8ef5-9dec-4166-a102-d554782e9396"], "metadata": {"file_path": "frontend-solid\\src\\hooks\\useReports.ts", "language": "typescript", "lines": 92, "filename": "useReports.ts"}}, "frontend-solid\\src\\lib\\api.ts": {"node_ids": ["13a96b83-e162-4fe1-9cd6-6a66528e7353", "5d5792c4-611e-4dbe-92f4-ed9582431f3b"], "metadata": {"file_path": "frontend-solid\\src\\lib\\api.ts", "language": "typescript", "lines": 211, "filename": "api.ts"}}, "frontend-solid\\src\\lib\\export.ts": {"node_ids": ["2ff415f6-3e59-4d8a-93d2-f113ff1a1aa6"], "metadata": {"file_path": "frontend-solid\\src\\lib\\export.ts", "language": "typescript", "lines": 30, "filename": "export.ts"}}, "frontend-solid\\src\\lib\\formatters.ts": {"node_ids": ["205db90c-727f-437f-91a6-111e971d9396"], "metadata": {"file_path": "frontend-solid\\src\\lib\\formatters.ts", "language": "typescript", "lines": 20, "filename": "formatters.ts"}}, "frontend-solid\\src\\lib\\supabase.ts": {"node_ids": ["d96103cc-467e-45d9-8558-a76f9aba0cf6"], "metadata": {"file_path": "frontend-solid\\src\\lib\\supabase.ts", "language": "typescript", "lines": 11, "filename": "supabase.ts"}}, "frontend-solid\\src\\lib\\api\\client.ts": {"node_ids": ["d1879763-af41-4e5c-8d31-f9e67a55d14a"], "metadata": {"file_path": "frontend-solid\\src\\lib\\api\\client.ts", "language": "typescript", "lines": 74, "filename": "client.ts"}}, "frontend-solid\\src\\migrated-components\\components\\ui\\Alert.tsx": {"node_ids": ["6c9530cc-097f-456f-8d4c-2b39f1fbecde"], "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\Alert.tsx", "language": "typescript", "lines": 77, "filename": "Alert.tsx"}}, "frontend-solid\\src\\migrated-components\\components\\ui\\Avatar.tsx": {"node_ids": ["0fd3857c-c8d4-4fd1-82c4-7ab66cb373bb"], "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\Avatar.tsx", "language": "typescript", "lines": 57, "filename": "Avatar.tsx"}}, "frontend-solid\\src\\migrated-components\\components\\ui\\Badge.test.tsx": {"node_ids": ["b4b463b7-c95e-43df-a881-f31af0c7e79e"], "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\Badge.test.tsx", "language": "typescript", "lines": 55, "filename": "Badge.test.tsx"}}, "frontend-solid\\src\\migrated-components\\components\\ui\\Badge.tsx": {"node_ids": ["e7a9303d-ed86-4442-9546-55f84bb1cbff"], "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\Badge.tsx", "language": "typescript", "lines": 54, "filename": "Badge.tsx"}}, "frontend-solid\\src\\migrated-components\\components\\ui\\Button.test.tsx": {"node_ids": ["84dbd673-7a65-4024-9adc-783c2569b7c9"], "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\Button.test.tsx", "language": "typescript", "lines": 74, "filename": "Button.test.tsx"}}, "frontend-solid\\src\\migrated-components\\components\\ui\\Button.tsx": {"node_ids": ["42956a5d-0ad5-435c-9eab-1fb593b535ec"], "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\Button.tsx", "language": "typescript", "lines": 65, "filename": "Button.tsx"}}, "frontend-solid\\src\\migrated-components\\components\\ui\\Card.tsx": {"node_ids": ["ad5f1022-a084-437a-a55d-ffa96f1f2a4d"], "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\Card.tsx", "language": "typescript", "lines": 120, "filename": "Card.tsx"}}, "frontend-solid\\src\\migrated-components\\components\\ui\\Dialog.tsx": {"node_ids": ["999fbd0b-679a-48bb-a093-7a950e57a036"], "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\Dialog.tsx", "language": "typescript", "lines": 80, "filename": "Dialog.tsx"}}, "frontend-solid\\src\\migrated-components\\components\\ui\\DropdownMenu.tsx": {"node_ids": ["b2c1f7d8-af10-4573-a9c7-dd590458f4ee"], "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\DropdownMenu.tsx", "language": "typescript", "lines": 68, "filename": "DropdownMenu.tsx"}}, "frontend-solid\\src\\migrated-components\\components\\ui\\index.ts": {"node_ids": ["099c0ca5-424b-44d8-8189-bd8edf5eabd6"], "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\index.ts", "language": "typescript", "lines": 55, "filename": "index.ts"}}, "frontend-solid\\src\\migrated-components\\components\\ui\\Input.tsx": {"node_ids": ["901fd6af-fb2c-4d16-8eb3-81ca630c2fd9"], "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\Input.tsx", "language": "typescript", "lines": 35, "filename": "Input.tsx"}}, "frontend-solid\\src\\migrated-components\\components\\ui\\Label.tsx": {"node_ids": ["192a4829-691b-402f-b806-39b9012d7819"], "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\Label.tsx", "language": "typescript", "lines": 31, "filename": "Label.tsx"}}, "frontend-solid\\src\\migrated-components\\components\\ui\\LazyImage.tsx": {"node_ids": ["bd4aabfa-865c-48e8-9853-fba953f3fa21"], "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\LazyImage.tsx", "language": "typescript", "lines": 45, "filename": "LazyImage.tsx"}}, "frontend-solid\\src\\migrated-components\\components\\ui\\Select.tsx": {"node_ids": ["26c0703c-658d-421c-9382-409e0b4701de"], "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\Select.tsx", "language": "typescript", "lines": 31, "filename": "Select.tsx"}}, "frontend-solid\\src\\migrated-components\\components\\ui\\Separator.tsx": {"node_ids": ["6dabe135-ad7b-49be-92e2-4bf518bdef46"], "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\Separator.tsx", "language": "typescript", "lines": 38, "filename": "Separator.tsx"}}, "frontend-solid\\src\\migrated-components\\components\\ui\\Sheet.tsx": {"node_ids": ["6bc81be8-5b4d-48bd-9a7b-cbeece371efb"], "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\Sheet.tsx", "language": "typescript", "lines": 75, "filename": "Sheet.tsx"}}, "frontend-solid\\src\\migrated-components\\components\\ui\\Skeleton.test.tsx": {"node_ids": ["6f818f14-f512-4ae5-a7de-c6987bee6c04"], "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\Skeleton.test.tsx", "language": "typescript", "lines": 45, "filename": "Skeleton.test.tsx"}}, "frontend-solid\\src\\migrated-components\\components\\ui\\Skeleton.tsx": {"node_ids": ["04fd7185-6861-4825-a3c2-d1c7bd295ff2"], "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\Skeleton.tsx", "language": "typescript", "lines": 24, "filename": "Skeleton.tsx"}}, "frontend-solid\\src\\migrated-components\\components\\ui\\SkipLink.tsx": {"node_ids": ["cb1b89b6-6990-4702-9fbb-b52c6aada0ea"], "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\SkipLink.tsx", "language": "typescript", "lines": 17, "filename": "SkipLink.tsx"}}, "frontend-solid\\src\\migrated-components\\components\\ui\\Sonner.tsx": {"node_ids": ["3c12e533-5193-40ad-be03-4c777c9b105b"], "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\Sonner.tsx", "language": "typescript", "lines": 73, "filename": "Sonner.tsx"}}, "frontend-solid\\src\\migrated-components\\components\\ui\\Table.tsx": {"node_ids": ["996eb9d7-a9df-411e-ab11-c399140d63a3"], "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\Table.tsx", "language": "typescript", "lines": 145, "filename": "Table.tsx"}}, "frontend-solid\\src\\migrated-components\\components\\ui\\Tabs.tsx": {"node_ids": ["0cae4cc5-b634-47fe-af4a-0041cdecac6f"], "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\Tabs.tsx", "language": "typescript", "lines": 126, "filename": "Tabs.tsx"}}, "frontend-solid\\src\\migrated-components\\utils\\a11y.ts": {"node_ids": ["a47598b0-9aad-43a0-ac0d-c8c192098b86"], "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\utils\\a11y.ts", "language": "typescript", "lines": 76, "filename": "a11y.ts"}}, "frontend-solid\\src\\migrated-components\\utils\\cn.ts": {"node_ids": ["088cb1cf-31e9-4527-82a6-a7681b9dda7f"], "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\utils\\cn.ts", "language": "typescript", "lines": 11, "filename": "cn.ts"}}, "frontend-solid\\src\\pages\\About.tsx": {"node_ids": ["231660b1-5b39-4427-b83d-10aa59ccd056", "b9e5547a-2ed6-43e2-9a81-68224c893eed"], "metadata": {"file_path": "frontend-solid\\src\\pages\\About.tsx", "language": "typescript", "lines": 142, "filename": "About.tsx"}}, "frontend-solid\\src\\pages\\Admin.tsx": {"node_ids": ["cc116702-974c-415c-aeb8-ed23b71cad48", "13f4e010-9e4d-4424-9da9-cf965a88ba87", "58452bc4-426f-477c-8c8c-b376cb1e766f", "7119060c-c3dc-422b-8d3f-6e2e771a35d4", "771302d9-ea6c-4b8a-9c33-73e2503ed4a7"], "metadata": {"file_path": "frontend-solid\\src\\pages\\Admin.tsx", "language": "typescript", "lines": 448, "filename": "Admin.tsx"}}, "frontend-solid\\src\\pages\\Analytics.tsx": {"node_ids": ["46ad38f6-2b5c-40d7-9716-2adfe2e3adc6", "125b0a07-a31d-4b77-8143-18035ead4490", "0af46465-7e9d-446d-814d-0c8d5ef87710", "71cfb93e-0a6f-4827-b80f-e555c33b1027", "5c99679d-fe0a-4654-acba-4b841f4ccfb0", "bc5324b1-310e-4969-b479-f4708d5184c9", "b153117a-8cd6-46b5-8c4b-6209f658ce80"], "metadata": {"file_path": "frontend-solid\\src\\pages\\Analytics.tsx", "language": "typescript", "lines": 592, "filename": "Analytics.tsx"}}, "frontend-solid\\src\\pages\\Chat.tsx": {"node_ids": ["c1b8ca0d-85c5-42ba-97f1-a88ad788f56e", "c74d92bb-b9ea-44b3-a04e-d9f8f68e14d3", "c806f337-9a88-4fa6-829c-5f10e82021e9", "f35d21b8-601f-4ab5-8530-0a1dc44a465b", "d28569c4-e06e-4019-81d5-751913d00cfe", "0f442b02-fdf9-4428-914f-329d17c0cea2", "dc49b4bb-a106-4513-8053-d0e642ed72b6"], "metadata": {"file_path": "frontend-solid\\src\\pages\\Chat.tsx", "language": "typescript", "lines": 653, "filename": "Chat.tsx"}}, "frontend-solid\\src\\pages\\CodeChat.tsx": {"node_ids": ["02072b6b-dec7-412c-8869-dfa97dd6b0a3", "b1cf1732-fe37-482d-b375-d33188aa30e7", "fc3383ac-f44a-4087-bbd0-6e49f88a87f8", "bfe1382a-ecfa-4ccc-867b-333a033b3fb5", "765541a8-fcba-40f5-8a5f-bf59708da45c"], "metadata": {"file_path": "frontend-solid\\src\\pages\\CodeChat.tsx", "language": "typescript", "lines": 376, "filename": "CodeChat.tsx"}}, "frontend-solid\\src\\pages\\Dashboard.tsx": {"node_ids": ["efeb717a-b222-49e2-a8d5-ba479f9f6937", "9c30ad13-eb99-4bf6-b176-b1f4cc62d939", "73bfb680-ca4f-4e75-9d51-c9570b6a79f2", "0a426a7a-b823-4f5a-819f-d324a8428531", "2801aaee-711a-461b-847c-793625636be0", "924cef7d-e96c-46ed-9ee4-20b75841c052"], "metadata": {"file_path": "frontend-solid\\src\\pages\\Dashboard.tsx", "language": "typescript", "lines": 453, "filename": "Dashboard.tsx"}}, "frontend-solid\\src\\pages\\Diagnostics.tsx": {"node_ids": ["cdae991b-7a93-49de-bae7-a82fcd867322", "d2d6f73c-2442-4e44-9ffa-5c739b8b98ca", "85928c96-e47d-44e8-aae2-05f8c233d925", "e65256f6-85fa-42fb-83d4-754d47fb6ba7", "04568753-00e7-45cc-a978-62190ae02851"], "metadata": {"file_path": "frontend-solid\\src\\pages\\Diagnostics.tsx", "language": "typescript", "lines": 391, "filename": "Diagnostics.tsx"}}, "frontend-solid\\src\\pages\\Examples.tsx": {"node_ids": ["a2e6a2ad-7fb4-495c-8b76-6b8c14f0be07", "64881022-f05f-4123-9bf4-ff4789664d5a", "375cd63e-828a-4283-a164-ea621c19d391"], "metadata": {"file_path": "frontend-solid\\src\\pages\\Examples.tsx", "language": "typescript", "lines": 175, "filename": "Examples.tsx"}}, "frontend-solid\\src\\pages\\Help.tsx": {"node_ids": ["16708e65-9109-4ab4-93ed-a21f199d715d", "0e2b0951-c75a-42ca-a966-ccc897660854", "3a6d0f2b-774a-4967-b8a1-9696b2347dcd", "9e9526c7-62fa-4ae4-9010-89d7fd66f205", "60948662-4fd1-4dff-ac5f-3739a5c2e9f5"], "metadata": {"file_path": "frontend-solid\\src\\pages\\Help.tsx", "language": "typescript", "lines": 343, "filename": "Help.tsx"}}, "frontend-solid\\src\\pages\\Learning.tsx": {"node_ids": ["8e499860-c6dd-422e-a48b-a721f9c08e65", "d530ae07-b6a5-4662-a7dc-6838f9d2d7fc", "75298a21-66bb-44e6-a8bd-cd789118274f", "975cfaa4-a5da-4d7f-baf7-3ac75c600398", "932bc291-0018-4ffa-a2c0-da21eb1b5dd7"], "metadata": {"file_path": "frontend-solid\\src\\pages\\Learning.tsx", "language": "typescript", "lines": 475, "filename": "Learning.tsx"}}, "frontend-solid\\src\\pages\\Login.tsx": {"node_ids": ["6a9c5f82-1121-4cf7-8b4a-ca58bbe2658c", "d2d4e083-23e1-4f05-b69f-87d83997d051"], "metadata": {"file_path": "frontend-solid\\src\\pages\\Login.tsx", "language": "typescript", "lines": 146, "filename": "Login.tsx"}}, "frontend-solid\\src\\pages\\Playground.tsx": {"node_ids": ["017d1aa9-0444-4c15-93fa-d0571a78809f", "4e6bc397-75da-47b3-b250-ebe9895b1282", "6b1a7653-0aec-4a6c-8db1-b6511b5029fc", "2ff36678-27aa-4e17-8c87-68dfb997fdba", "92db475e-6fce-4f7d-a4d0-28e89bc7ef7f"], "metadata": {"file_path": "frontend-solid\\src\\pages\\Playground.tsx", "language": "typescript", "lines": 491, "filename": "Playground.tsx"}}, "frontend-solid\\src\\pages\\Profile.tsx": {"node_ids": ["83b83e6c-4904-4431-9d61-4022dfe672cf", "782b1e84-8cc5-4e24-9875-2a923f116f6e", "00bddec0-cf4a-4ab0-b213-1df3ffff553d"], "metadata": {"file_path": "frontend-solid\\src\\pages\\Profile.tsx", "language": "typescript", "lines": 252, "filename": "Profile.tsx"}}, "frontend-solid\\src\\pages\\Reports.tsx": {"node_ids": ["62a41818-dc0c-4fdc-a9f7-b55b7b7b5a89", "e5fc96cf-2058-478b-9158-f3415c25a084", "67b6bb4f-cf36-448a-8fbf-2da401c6577d", "77efd6df-db90-4010-8e2b-eccf5e9cebba"], "metadata": {"file_path": "frontend-solid\\src\\pages\\Reports.tsx", "language": "typescript", "lines": 341, "filename": "Reports.tsx"}}, "frontend-solid\\src\\pages\\Rupturas.tsx": {"node_ids": ["610ceb31-d07c-4bb5-99ba-d3e80dc8b96e", "cebd4b10-f6c8-4d6e-9567-5885ab4caebe", "e3dd0afc-80ee-4e94-aed2-6bf0851711b1", "a7a791e4-1c3d-4758-ab0a-dbc4203bc5e8", "f3f7a7a1-8290-4e6e-9e00-cd4e3bd5ef0e", "1058bf3d-434b-4f79-a0fd-a0e30badcf09", "380bf732-80da-472b-85a4-9678851855a0", "0de7000f-9542-4dfc-89e0-46441c24e90e", "d8b7ea61-33e5-43c7-a2e1-bc9f1558f210", "c00fec59-5025-4d6b-99c9-ce5627118b39", "f5ef7da5-b3f3-4740-9367-54388e71585b", "59df1047-3596-4f74-9533-dc994a2ee903"], "metadata": {"file_path": "frontend-solid\\src\\pages\\Rupturas.tsx", "language": "typescript", "lines": 932, "filename": "Rupturas.tsx"}}, "frontend-solid\\src\\pages\\SharedConversation.tsx": {"node_ids": ["6438fd4d-7c87-465b-8977-2d4c620bd58d", "dafb873a-3fb0-4fdf-bfae-dde13420719a"], "metadata": {"file_path": "frontend-solid\\src\\pages\\SharedConversation.tsx", "language": "typescript", "lines": 156, "filename": "SharedConversation.tsx"}}, "frontend-solid\\src\\pages\\Transfers.tsx": {"node_ids": ["d624885c-e0aa-4f3f-9f3a-043b488c8f45", "c6142bd0-013d-4841-9d91-a9260c8bc7c0", "227e8903-dc3c-4111-94ee-2e9151cd9709", "7c77cd20-527a-49ff-83e1-3e3b5356ab81", "be6c5c84-d247-440f-86fd-c2fda235a08c", "d905c221-74ee-450c-8fc6-12d0d84d3e9e", "219a8f11-b53c-4766-9c05-394d87ddf89e", "f66367f3-3b5d-44e4-8db0-cc3d70284946"], "metadata": {"file_path": "frontend-solid\\src\\pages\\Transfers.tsx", "language": "typescript", "lines": 781, "filename": "Transfers.tsx"}}, "frontend-solid\\src\\services\\admin.service.ts": {"node_ids": ["578d5262-c066-4b46-b3f6-9d6c3e872f24"], "metadata": {"file_path": "frontend-solid\\src\\services\\admin.service.ts", "language": "typescript", "lines": 59, "filename": "admin.service.ts"}}, "frontend-solid\\src\\services\\analytics.service.ts": {"node_ids": ["4a6bd569-ee9a-45c5-8eea-f90081432637"], "metadata": {"file_path": "frontend-solid\\src\\services\\analytics.service.ts", "language": "typescript", "lines": 52, "filename": "analytics.service.ts"}}, "frontend-solid\\src\\services\\auth.service.ts": {"node_ids": ["038eee7a-15a7-4da9-98f4-0522f2850aec"], "metadata": {"file_path": "frontend-solid\\src\\services\\auth.service.ts", "language": "typescript", "lines": 38, "filename": "auth.service.ts"}}, "frontend-solid\\src\\services\\logger.service.ts": {"node_ids": ["1a4c65f3-ace8-499d-b418-53d3870c350e", "d256cd8f-1612-48c7-891f-dc22562f58ef", "72df7fa9-124c-492b-a8a0-af9f07dbd3fa", "1e3eabea-2b0b-4c07-9b75-83c40ff7619c"], "metadata": {"file_path": "frontend-solid\\src\\services\\logger.service.ts", "language": "typescript", "lines": 490, "filename": "logger.service.ts"}}, "frontend-solid\\src\\services\\reports.service.ts": {"node_ids": ["159c2bba-be84-4209-a1bc-f8d2ba9f9e28"], "metadata": {"file_path": "frontend-solid\\src\\services\\reports.service.ts", "language": "typescript", "lines": 65, "filename": "reports.service.ts"}}, "frontend-solid\\src\\store\\auth.ts": {"node_ids": ["b551d08e-9f20-4596-9f2a-61beaac5d7fa", "280d9738-977a-46f6-962b-f0955985c6b1"], "metadata": {"file_path": "frontend-solid\\src\\store\\auth.ts", "language": "typescript", "lines": 149, "filename": "auth.ts"}}, "frontend-solid\\src\\store\\dashboard.ts": {"node_ids": ["c71cffb6-87e6-4b4f-9dd6-329d0b602386"], "metadata": {"file_path": "frontend-solid\\src\\store\\dashboard.ts", "language": "typescript", "lines": 85, "filename": "dashboard.ts"}}, "frontend-solid\\src\\__tests__\\App.test.tsx": {"node_ids": ["7432f979-1fa6-43ce-89a5-8e1f649657c4"], "metadata": {"file_path": "frontend-solid\\src\\__tests__\\App.test.tsx", "language": "typescript", "lines": 29, "filename": "App.test.tsx"}}, "frontend-solid\\src\\__tests__\\ErrorBoundary.test.tsx": {"node_ids": ["2c89f047-49ae-46a9-af99-88795c2208a0"], "metadata": {"file_path": "frontend-solid\\src\\__tests__\\ErrorBoundary.test.tsx", "language": "typescript", "lines": 30, "filename": "ErrorBoundary.test.tsx"}}, "frontend-solid\\src\\__tests__\\Layout.test.tsx": {"node_ids": ["dc9ae1a7-24a9-4db2-a52c-ac1320fbd083"], "metadata": {"file_path": "frontend-solid\\src\\__tests__\\Layout.test.tsx", "language": "typescript", "lines": 36, "filename": "Layout.test.tsx"}}}, "docstore/data": {"58082931-32a8-41ca-9f7b-4531bb3030f8": {"__data__": {"id_": "58082931-32a8-41ca-9f7b-4531bb3030f8", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\dependencies.py", "language": "python", "lines": 411, "filename": "dependencies.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\dependencies.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\dependencies.py", "language": "python", "lines": 411, "filename": "dependencies.py"}, "hash": "34876df90b5ac8d7e9292b8eca020634a0098d5415113a04a074aa46c4022483", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "150d3cb4-9dc9-4610-a4a6-8b6931d11879", "node_type": "1", "metadata": {}, "hash": "19352886ae29d9428b3278b1d60a71c4a645a436bcc403e9e99123df71c669f2", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nAPI Dependencies\nFastAPI dependency injection utilities\n\"\"\"\n\nimport json # Adicionado\nimport uuid # Adicionado para corrigir erro de tipo UUID\nfrom typing import Annotated\n\nfrom fastapi import Depends, HTTPException, status\nfrom fastapi.security import HTTPAuthorizationCredentials, HTTPBearer\nfrom jose import JWTError\nfrom sqlalchemy.ext.asyncio import AsyncSession\n\nfrom app.config.database import get_db\nfrom app.config.security import decode_token\nfrom app.infrastructure.database.models import User\nfrom app.schemas.auth import TokenData\nfrom sqlalchemy import select\n\nsecurity = HTTPBearer()\n\n\nasync def get_current_user(\n    credentials: Annotated[HTTPAuthorizationCredentials, Depends(security)],\n    db: Annotated[AsyncSession, Depends(get_db)],\n) -> User:\n    \"\"\"\n    Get current user from JWT token - PARQUET + SUPABASE FALLBACK\n    \"\"\"\n    import polars as pl\n    from pathlib import Path\n    from datetime import datetime, timezone\n    import sys\n    from app.config.settings import get_settings\n\n    settings = get_settings()\n\n    credentials_exception = HTTPException(\n        status_code=status.HTTP_401_UNAUTHORIZED,\n        detail=\"Could not validate credentials\",\n        headers={\"WWW-Authenticate\": \"Bearer\"},\n    )\n\n    # Decode JWT\n    try:\n        token = credentials.credentials\n        payload = decode_token(token)\n\n        if payload.get(\"type\") != \"access\":\n            raise credentials_exception\n\n        user_id = payload.get(\"sub\")\n        if user_id is None:\n            raise credentials_exception\n\n    except JWTError as e:\n        raise credentials_exception\n\n    # PRIORITY 1: Try Parquet first\n    docker_path = Path(\"/app/data/parquet/users.parquet\")\n    dev_path = Path(__file__).parent.parent.parent.parent / \"data\" / \"parquet\" / \"users.parquet\"\n    parquet_path = docker_path if docker_path.exists() else dev_path\n\n    if parquet_path.exists():\n        try:\n            df = pl.read_parquet(parquet_path)\n            user_data = df.filter(pl.col(\"id\") == user_id)\n\n            if len(user_data) > 0:\n                user_row = user_data.row(0, named=True)\n                user = User(\n                    id=uuid.UUID(str(user_row[\"id\"])),\n                    username=user_row[\"username\"],\n                    email=user_row.get(\"email\", \"\"),\n                    role=user_row[\"role\"],\n                    is_active=user_row.get(\"is_active\", True),\n                    hashed_password=user_row[\"hashed_password\"],\n                    allowed_segments=user_row.get(\"allowed_segments\", \"[]\"),\n                    created_at=user_row.get(\"created_at\", datetime.now(timezone.utc)),\n                    updated_at=user_row.get(\"updated_at\", datetime.now(timezone.utc)),\n                    last_login=user_row.get(\"last_login\")\n                )\n\n                if not user.is_active:\n                    raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail=\"Inactive user\")\n                return user\n        except Exception:\n            pass  # Will try Supabase fallback\n\n    # PRIORITY 2: Try Supabase if user not found in Parquet\n    if settings.USE_SUPABASE_AUTH:\n        try:\n            from app.core.supabase_client import get_supabase_admin_client\n            admin_client = get_supabase_admin_client()\n            \n            auth_user = admin_client.auth.admin.get_user_by_id(user_id)\n            if auth_user and auth_user.user:\n                user_metadata = auth_user.user.user_metadata or {}\n                \n                # Get role from user_profiles table\n                role = \"user\"\n                try:\n                    from app.core.supabase_client import get_supabase_client\n                    supabase = get_supabase_client()\n                    profile_response = supabase.table(\"user_profiles\").select(\"*\").eq(\"id\", user_id).execute()\n                    if profile_response.data and len(profile_response.data) > 0:\n                        role = profile_response.data[0].get(\"role\", \"user\")\n                except:\n                    pass\n                \n                user = User(\n                    id=uuid.UUID(str(user_id)),\n                    username=user_metadata.get(\"username\", auth_user.user.email.split(\"@\")[0]),\n                    email=auth_user.user.email or \"\",\n                    role=role,\n                    is_active=True,\n                    hashed_password=\"\",  # Not needed for Supabase auth\n                    allowed_segments=json.dumps(user_metadata.get(\"allowed_segments\", [])),\n                    created_at=datetime.now(timezone.utc),\n                    updated_at=datetime.now(timezone.utc),\n                    last_login=datetime.now(timezone.utc)\n                )\n                return user\n        except Exception as e:\n            pass  # Will raise credentials_exception\n\n    raise credentials_exception", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4850, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "150d3cb4-9dc9-4610-a4a6-8b6931d11879": {"__data__": {"id_": "150d3cb4-9dc9-4610-a4a6-8b6931d11879", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\dependencies.py", "language": "python", "lines": 411, "filename": "dependencies.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\dependencies.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\dependencies.py", "language": "python", "lines": 411, "filename": "dependencies.py"}, "hash": "34876df90b5ac8d7e9292b8eca020634a0098d5415113a04a074aa46c4022483", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "58082931-32a8-41ca-9f7b-4531bb3030f8", "node_type": "1", "metadata": {"file_path": "backend\\app\\api\\dependencies.py", "language": "python", "lines": 411, "filename": "dependencies.py"}, "hash": "2db7447c5bc317c6d4e5bc92821f1508155d35641e74721415d8a5d461735e87", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d3f34b2e-86dd-4b56-9a26-eaae7d8814fc", "node_type": "1", "metadata": {}, "hash": "8c47382e9a9522cbb928554c1076c2538ac9810dc8833ef6d981e3bda90f7b15", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "async def get_current_user_old(\n    credentials: Annotated[HTTPAuthorizationCredentials, Depends(security)],\n    db: Annotated[AsyncSession, Depends(get_db)],\n) -> User:\n    \"\"\"\n    Get current authenticated user from JWT token - PARQUET ONLY VERSION\n    \n    Simplified version that ONLY uses Parquet for maximum speed and reliability.\n    \"\"\"\n    import sys\n    import polars as pl\n    from pathlib import Path\n    from datetime import datetime, timezone\n    \n    # print(\"==> get_current_user CALLED <==\", file=sys.stderr, flush=True)\n    \n    credentials_exception = HTTPException(\n        status_code=status.HTTP_401_UNAUTHORIZED,\n        detail=\"Could not validate credentials\",\n        headers={\"WWW-Authenticate\": \"Bearer\"},\n    )\n\n    # Decode and validate JWT token\n    try:\n        token = credentials.credentials\n        payload = decode_token(token)\n        \n        # print(f\"==> Token decoded successfully <==\", file=sys.stderr, flush=True)\n\n        if payload.get(\"type\") != \"access\":\n            # print(f\"==> Invalid token type: {payload.get('type')} <==\", file=sys.stderr, flush=True)\n            raise credentials_exception\n\n        user_id: str | None = payload.get(\"sub\")\n        if user_id is None:\n            # print(f\"==> No user_id in token <==\", file=sys.stderr, flush=True)\n            raise credentials_exception\n            \n        # print(f\"==> Looking for user_id: {user_id} <==\", file=sys.stderr, flush=True)\n\n    except JWTError as e:\n        # print(f\"==> JWT Error: {e} <==\", file=sys.stderr, flush=True)\n        raise credentials_exception\n\n    # Load user from Parquet\n    docker_path = Path(\"/app/data/parquet/users.parquet\")\n    dev_path = Path(__file__).parent.parent.parent / \"data\" / \"parquet\" / \"users.parquet\"\n    parquet_path = docker_path if docker_path.exists() else dev_path\n    \n    # print(f\"==> Parquet path: {parquet_path} <==\", file=sys.stderr, flush=True)\n    # print(f\"==> Exists: {parquet_path.exists()} <==\", file=sys.stderr, flush=True)\n\n    if not parquet_path.exists():\n        # print(f\"==> ERROR: Parquet file not found! <==\", file=sys.stderr, flush=True)\n        raise credentials_exception\n\n    try:\n        df = pl.read_parquet(parquet_path)\n        # print(f\"==> Parquet loaded: {len(df)} rows <==\", file=sys.stderr, flush=True)\n        \n        # Filter for user (simple comparison without cast)\n        user_data = df.filter(pl.col(\"id\") == user_id)\n        # print(f\"==> Filter result: {len(user_data)} rows <==\", file=sys.stderr, flush=True)\n\n        if len(user_data) == 0:\n            # print(f\"==> User {user_id} NOT FOUND <==\", file=sys.stderr, flush=True)\n            raise credentials_exception\n\n        user_row = user_data.row(0, named=True)\n        # print(f\"==> User found: {user_row.get('username')} <==\", file=sys.stderr, flush=True)\n\n        user = User(\n            id=user_row[\"id\"],\n            username=user_row[\"username\"],\n            email=user_row.get(\"email\", \"\"),\n            role=user_row[\"role\"],\n            is_active=user_row.get(\"is_active\", True),\n            hashed_password=user_row[\"hashed_password\"],\n            created_at=user_row.get(\"created_at\", datetime.now(timezone.utc)),\n            updated_at=user_row.get(\"updated_at\", datetime.now(timezone.utc)),\n            last_login=user_row.get(\"last_login\")\n        )\n\n        if not user.is_active:\n            # print(f\"==> User {user.username} is INACTIVE <==\", file=sys.stderr, flush=True)\n            raise HTTPException(\n                status_code=status.HTTP_403_FORBIDDEN,\n                detail=\"Inactive user\"\n            )\n\n        # print(f\"==> User {user.username} AUTHENTICATED <==\", file=sys.stderr, flush=True)\n        return user\n\n    except HTTPException:\n        raise\n    except Exception as e:\n        # print(f\"==> ERROR: {e} <==\", file=sys.stderr, flush=True)\n        import traceback\n        # traceback.print_exc(file=sys.stderr)\n        raise credentials_exception\n\n\nasync def get_current_active_user(\n    current_user: Annotated[User, Depends(get_current_user)]\n) -> User:\n    \"\"\"Get current active user\"\"\"\n    if not current_user.is_active:\n        raise HTTPException(\n            status_code=status.HTTP_403_FORBIDDEN,\n            detail=\"Inactive user\"\n        )\n    return current_user", "mimetype": "text/plain", "start_char_idx": 4853, "end_char_idx": 9128, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d3f34b2e-86dd-4b56-9a26-eaae7d8814fc": {"__data__": {"id_": "d3f34b2e-86dd-4b56-9a26-eaae7d8814fc", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\dependencies.py", "language": "python", "lines": 411, "filename": "dependencies.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\dependencies.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\dependencies.py", "language": "python", "lines": 411, "filename": "dependencies.py"}, "hash": "34876df90b5ac8d7e9292b8eca020634a0098d5415113a04a074aa46c4022483", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "150d3cb4-9dc9-4610-a4a6-8b6931d11879", "node_type": "1", "metadata": {"file_path": "backend\\app\\api\\dependencies.py", "language": "python", "lines": 411, "filename": "dependencies.py"}, "hash": "fae4a8408ce990e6cfc561813442b27250c7eb1edd6f4d68fe1d3e4dc12187a3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d8b2fcdf-49bd-4e88-88bd-08f9ef25e748", "node_type": "1", "metadata": {}, "hash": "faf4b97c1365354eb841260d95bcc90125f9e26b573e67083aab0874a988548e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "async def get_current_user_from_token(token: str) -> User:\n    \"\"\"\n    Get current user from raw JWT token string\n    Used for SSE endpoints where EventSource doesn't support custom headers\n    \"\"\"\n    import polars as pl\n    from pathlib import Path\n    from datetime import datetime, timezone\n    import sys\n    from app.config.settings import get_settings\n\n    settings = get_settings()\n    \n    credentials_exception = HTTPException(\n        status_code=status.HTTP_401_UNAUTHORIZED,\n        detail=\"Could not validate credentials\",\n        headers={\"WWW-Authenticate\": \"Bearer\"},\n    )\n    \n    # Decode JWT\n    try:\n        payload = decode_token(token)\n        \n        if payload.get(\"type\") != \"access\":\n            raise credentials_exception\n        \n        user_id = payload.get(\"sub\")\n        if user_id is None:\n            raise credentials_exception\n            \n    except JWTError:\n        raise credentials_exception\n    \n    # PRIORITY 1: Try Parquet first\n    docker_path = Path(\"/app/data/parquet/users.parquet\")\n    dev_path = Path(__file__).parent.parent.parent.parent / \"data\" / \"parquet\" / \"users.parquet\"\n    parquet_path = docker_path if docker_path.exists() else dev_path\n    \n    if parquet_path.exists():\n        try:\n            df = pl.read_parquet(parquet_path)\n            user_data = df.filter(pl.col(\"id\") == user_id)\n            \n            if len(user_data) > 0:\n                user_row = user_data.row(0, named=True)\n                \n                user = User(\n                    id=uuid.UUID(str(user_row[\"id\"])),\n                    username=user_row[\"username\"],\n                    email=user_row.get(\"email\", \"\"),\n                    role=user_row[\"role\"],\n                    is_active=user_row.get(\"is_active\", True),\n                    hashed_password=user_row[\"hashed_password\"],\n                    allowed_segments=user_row.get(\"allowed_segments\", \"[]\"), # Adicionado\n                    created_at=user_row.get(\"created_at\", datetime.now(timezone.utc)),\n                    updated_at=user_row.get(\"updated_at\", datetime.now(timezone.utc)),\n                    last_login=user_row.get(\"last_login\")\n                )\n                \n                if not user.is_active:\n                    raise HTTPException(\n                        status_code=status.HTTP_403_FORBIDDEN,\n                        detail=\"Inactive user\"\n                    )\n                \n                return user\n        except HTTPException:\n            raise\n        except Exception:\n            pass # Fallback to Supabase\n\n    # PRIORITY 2: Try Supabase if user not found in Parquet\n    if settings.USE_SUPABASE_AUTH:\n        try:\n            from app.core.supabase_client import get_supabase_admin_client\n            admin_client = get_supabase_admin_client()\n            \n            auth_user = admin_client.auth.admin.get_user_by_id(user_id)\n            if auth_user and auth_user.user:\n                user_metadata = auth_user.user.user_metadata or {}\n                \n                # Get role from user_profiles table\n                role = \"user\"\n                try:\n                    from app.core.supabase_client import get_supabase_client\n                    supabase = get_supabase_client()\n                    profile_response = supabase.table(\"user_profiles\").select(\"*\").eq(\"id\", user_id).execute()\n                    if profile_response.data and len(profile_response.data) > 0:\n                        role = profile_response.data[0].get(\"role\", \"user\")\n                except:\n                    pass\n                \n                user = User(\n                    id=uuid.UUID(str(user_id)),\n                    username=user_metadata.get(\"username\", auth_user.user.email.split(\"@\")[0]),\n                    email=auth_user.user.email or \"\",\n                    role=role,\n                    is_active=True,\n                    hashed_password=\"\",  # Not needed for Supabase auth\n                    allowed_segments=json.dumps(user_metadata.get(\"allowed_segments\", [])),\n                    created_at=datetime.now(timezone.utc),\n                    updated_at=datetime.now(timezone.utc),\n                    last_login=datetime.now(timezone.utc)\n                )\n                return user\n        except Exception as e:\n            pass  # Will raise credentials_exception\n\n    raise credentials_exception\n\n\n\ndef require_role(*allowed_roles: str):\n    \"\"\"\n    Dependency to require specific roles\n    \n    Usage:\n        @router.get(\"/admin\")\n        async def admin_endpoint(user: User = Depends(require_role(\"admin\"))):\n            ...\n    \"\"\"\n    async def role_checker(\n        current_user: Annotated[User, Depends(get_current_active_user)]\n    ) -> User:\n        if current_user.role not in allowed_roles:\n            raise HTTPException(\n                status_code=status.HTTP_403_FORBIDDEN,\n                detail=f\"Permission denied. Required roles: {', '.join(allowed_roles)}\"\n            )\n        return current_user\n    \n    return role_checker", "mimetype": "text/plain", "start_char_idx": 9131, "end_char_idx": 14164, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d8b2fcdf-49bd-4e88-88bd-08f9ef25e748": {"__data__": {"id_": "d8b2fcdf-49bd-4e88-88bd-08f9ef25e748", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\dependencies.py", "language": "python", "lines": 411, "filename": "dependencies.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\dependencies.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\dependencies.py", "language": "python", "lines": 411, "filename": "dependencies.py"}, "hash": "34876df90b5ac8d7e9292b8eca020634a0098d5415113a04a074aa46c4022483", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d3f34b2e-86dd-4b56-9a26-eaae7d8814fc", "node_type": "1", "metadata": {"file_path": "backend\\app\\api\\dependencies.py", "language": "python", "lines": 411, "filename": "dependencies.py"}, "hash": "899c9274fe5ab2c805f7ced6517ec448ede25bbb54bec223cda7cda442e85576", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "def require_permission(permission: str):\n    \"\"\"\n    Dependency to require specific permission\n    \n    Usage:\n        @router.get(\"/reports\")\n        async def get_reports(user: User = Depends(require_permission(\"VIEW_REPORTS\"))):\n            ...\n    \"\"\"\n    # Permission mapping (same as frontend)\n    ROLE_PERMISSIONS = {\n        \"admin\": [\"*\"],  # All permissions\n        \"user\": [\n            \"VIEW_ANALYTICS\", \"VIEW_REPORTS\", \"CREATE_REPORTS\", \n            \"EDIT_REPORTS\", \"USE_CHAT\"\n        ],\n        \"viewer\": [\"VIEW_ANALYTICS\", \"VIEW_REPORTS\"],\n    }\n    \n    async def permission_checker(\n        current_user: Annotated[User, Depends(get_current_active_user)]\n    ) -> User:\n        user_permissions = ROLE_PERMISSIONS.get(current_user.role, [])\n        \n        if \"*\" not in user_permissions and permission not in user_permissions:\n            raise HTTPException(\n                status_code=status.HTTP_403_FORBIDDEN,\n                detail=f\"Permission denied. Required permission: {permission}\"\n            )\n        return current_user\n    \n    return permission_checker", "mimetype": "text/plain", "start_char_idx": 14167, "end_char_idx": 15256, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f7f4c971-2a77-4b85-bb5d-226b0d406eec": {"__data__": {"id_": "f7f4c971-2a77-4b85-bb5d-226b0d406eec", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\router.py", "language": "python", "lines": 56, "filename": "router.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\router.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\router.py", "language": "python", "lines": 56, "filename": "router.py"}, "hash": "378b8bbfd5770ef3928a007b16ae05259b67da950864505a6fafeb394d5fe311", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nAPI V1 Router\nCombines all v1 endpoints\n\"\"\"\n\nfrom fastapi import APIRouter\n\nfrom app.api.v1.endpoints import (\n    admin,\n    analytics,\n    auth,\n    reports,\n    auth_alt,\n    metrics,\n    chat,\n    rupturas,\n    transfers,\n    diagnostics,\n    learning,\n    playground,\n    frontend_logs,\n    shared,\n    preferences,\n    insights,\n    health,\n    code_chat  # Code Chat RAG\n)\n\napi_router = APIRouter()\n\n# Include all endpoint routers\n# Health check endpoints (no auth required)\napi_router.include_router(health.router)\n\n# Authentication endpoints\napi_router.include_router(auth.router)\napi_router.include_router(auth_alt.router_alt)  # Login alternativo\napi_router.include_router(analytics.router)\napi_router.include_router(reports.router)\napi_router.include_router(admin.router)\napi_router.include_router(metrics.router)  # Dashboard metrics\napi_router.include_router(chat.router)  # BI Chat\n\n# New Endpoints\napi_router.include_router(rupturas.router)\napi_router.include_router(transfers.router)\napi_router.include_router(diagnostics.router)\napi_router.include_router(learning.router)\napi_router.include_router(playground.router)\napi_router.include_router(shared.router)\napi_router.include_router(preferences.router)\napi_router.include_router(insights.router)\napi_router.include_router(code_chat.router)  # Code Chat RAG\n\n# Frontend Logs\napi_router.include_router(frontend_logs.router)", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1394, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "24fa9906-3cad-41c6-ae10-fd8dd4b60d18": {"__data__": {"id_": "24fa9906-3cad-41c6-ae10-fd8dd4b60d18", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\admin.py", "language": "python", "lines": 436, "filename": "admin.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\admin.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\admin.py", "language": "python", "lines": 436, "filename": "admin.py"}, "hash": "e7931a846e05abf63abfffe6929c000323ecd3901ab23c425f2fc86061bba74a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "778d9629-eb76-4f1b-b494-90248ab210a1", "node_type": "1", "metadata": {}, "hash": "9f704627107c75dd0410288176e73c5b065914b201f0c052d1d5029043c7cbb7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nAdmin Endpoints\nUser management, audit logs, and system settings\n\"\"\"\n\nimport uuid\nimport json # Added import\nfrom typing import Annotated\n\nfrom fastapi import APIRouter, Depends, HTTPException, status, BackgroundTasks\nfrom sqlalchemy import func, select\nfrom sqlalchemy.ext.asyncio import AsyncSession\nfrom pydantic import BaseModel\n\nfrom app.api.dependencies import get_db, require_role, get_current_active_user\nfrom app.config.security import get_password_hash\nfrom app.infrastructure.database.models import AuditLog, Report, User\nfrom app.schemas.user import UserCreate, UserResponse, UserUpdate\nfrom app.core.parquet_cache import cache\nfrom app.core.sync_service import sync_service\nfrom app.core.supabase_user_service import supabase_user_service\n\nrouter = APIRouter(prefix=\"/admin\", tags=[\"Admin\"])\n\n\n# Modelos adicionais para compatibilidade\nclass AdminStats(BaseModel):\n    totalUsers: int\n    activeUsers: int\n    totalQueries: int\n    systemHealth: str\n\n\n@router.post(\"/sync-parquet\")\nasync def sync_parquet_data(\n    background_tasks: BackgroundTasks,\n    current_user: Annotated[User, Depends(require_role(\"admin\"))],\n):\n    \"\"\"\n    Trigger SQL Server -> Parquet synchronization\n    \n    Runs in background. Requires admin role.\n    \"\"\"\n    background_tasks.add_task(sync_service.run_sync)\n    return {\"message\": \"Sincroniza\u00e7\u00e3o iniciada em segundo plano. Verifique os logs para progresso.\", \"status\": \"processing\"}\n\n\n@router.get(\"/stats\", response_model=AdminStats)\nasync def get_admin_stats(\n    db: Annotated[AsyncSession, Depends(get_db)],\n    current_user: Annotated[User, Depends(get_current_active_user)],\n) -> AdminStats:\n    \"\"\"\n    Get system statistics\n\n    Returns admin dashboard metrics with real data from Parquet.\n    Requires admin role.\n    \"\"\"\n    import polars as pl\n    import logging\n\n    logger = logging.getLogger(__name__)\n\n    # Verificar se \u00e9 admin\n    if current_user.role != \"admin\":\n        raise HTTPException(status_code=403, detail=\"Admin access required\")\n\n    try:\n        # Contar usu\u00e1rios no banco\n        try:\n            result = await db.execute(select(func.count(User.id)))\n            total_users = result.scalar()\n\n            result = await db.execute(select(func.count(User.id)).where(User.is_active == True))\n            active_users = result.scalar()\n        except:\n            # Fallback para Parquet se SQL falhar\n            df_users = cache.get_dataframe(\"users.parquet\")\n            total_users = len(df_users)\n            active_users = df_users.filter(pl.col(\"is_active\") == True).height\n\n        # Estat\u00edsticas de dados do sistema\n        df_admmat = cache.get_dataframe(\"admmat.parquet\")\n        total_queries = df_admmat.filter(pl.col(\"VENDA_30DD\") > 0).height\n\n        logger.info(f\"Admin stats: {total_users} users, {total_queries} active products\")\n\n        return AdminStats(\n            totalUsers=total_users or 0,\n            activeUsers=active_users or 0,\n            totalQueries=total_queries,\n            systemHealth=\"healthy\"\n        )\n\n    except Exception as e:\n        logger.error(f\"Error fetching admin stats: {str(e)}\")\n        raise HTTPException(status_code=500, detail=f\"Error fetching stats: {str(e)}\")\n\n\n@router.get(\"/users\")\nasync def get_users(\n    current_user: Annotated[User, Depends(require_role(\"admin\"))],\n    db: Annotated[AsyncSession, Depends(get_db)],\n) -> list[dict]:\n    \"\"\"\n    Get all users from Supabase\n\n    Returns list of users with their profiles and auth status.\n    Requires admin role.\n    \"\"\"\n    from app.config.settings import settings\n\n    if settings.USE_SUPABASE_AUTH:\n        # Use Supabase user service\n        users = supabase_user_service.list_users(limit=1000)\n        return users\n    else:\n        # Fallback to SQL Server (legacy)\n        result = await db.execute(select(User).order_by(User.created_at.desc()))\n        users = result.scalars().all()\n        return [\n            {\n                \"id\": str(user.id),\n                \"username\": user.username,\n                \"email\": user.email or \"\",\n                \"role\": user.role,\n                \"is_active\": user.is_active,\n                \"created_at\": user.created_at.isoformat() if user.created_at else \"\",\n                \"updated_at\": user.updated_at.isoformat() if user.updated_at else \"\",\n            }\n            for user in users\n        ]", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4344, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "778d9629-eb76-4f1b-b494-90248ab210a1": {"__data__": {"id_": "778d9629-eb76-4f1b-b494-90248ab210a1", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\admin.py", "language": "python", "lines": 436, "filename": "admin.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\admin.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\admin.py", "language": "python", "lines": 436, "filename": "admin.py"}, "hash": "e7931a846e05abf63abfffe6929c000323ecd3901ab23c425f2fc86061bba74a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "24fa9906-3cad-41c6-ae10-fd8dd4b60d18", "node_type": "1", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\admin.py", "language": "python", "lines": 436, "filename": "admin.py"}, "hash": "3d123170e8fd8ed39704f0221db7cbbe024c417504383545d0a4df58a9628cb0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "bb585dcc-79e2-4fcb-9f92-6f675fbc5332", "node_type": "1", "metadata": {}, "hash": "e1431323f1e696f31f51246a952a8d61fe5226e66d1e4a4238002d9fd6d1a292", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "@router.get(\"/users/{user_id}\", response_model=UserResponse)\nasync def get_user(\n    user_id: uuid.UUID,\n    db: Annotated[AsyncSession, Depends(get_db)],\n    current_user: Annotated[User, Depends(require_role(\"admin\"))],\n) -> User:\n    \"\"\"Get user by ID\"\"\"\n    result = await db.execute(select(User).where(User.id == user_id))\n    user = result.scalar_one_or_none()\n    \n    if not user:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=\"User not found\"\n        )\n    \n    return user\n\n\n@router.post(\"/users\", status_code=status.HTTP_201_CREATED)\nasync def create_user(\n    user_data: UserCreate,\n    current_user: Annotated[User, Depends(require_role(\"admin\"))],\n    db: Annotated[AsyncSession, Depends(get_db)],\n) -> dict:\n    \"\"\"\n    Create new user in Supabase Auth + user_profiles\n\n    Creates user with auto-confirmed email and profile data.\n    Requires admin role.\n    \"\"\"\n    from app.config.settings import settings\n\n    if settings.USE_SUPABASE_AUTH:\n        try:\n            # Create user in Supabase\n            new_user = supabase_user_service.create_user(\n                email=user_data.email,\n                password=user_data.password,\n                username=user_data.username,\n                role=user_data.role,\n                full_name=user_data.username,  # Can be enhanced later\n                allowed_segments=user_data.allowed_segments # Added allowed_segments\n            )\n            \n            # --- SYNC WITH SQL SERVER (AUTHORIZATION) ---\n            # Ensure the user exists locally for permissions/segments check\n            try:\n                # Check if user exists locally (by ID or Username)\n                user_id = uuid.UUID(new_user[\"id\"])\n                \n                result = await db.execute(select(User).where(User.id == user_id))\n                local_user = result.scalar_one_or_none()\n                \n                if not local_user:\n                    # Create local user record\n                    hashed_dummy = \"EXTERNAL_AUTH_SUPABASE\" \n                    local_user = User(\n                        id=user_id,\n                        username=user_data.username,\n                        email=user_data.email,\n                        hashed_password=hashed_dummy,\n                        role=user_data.role,\n                        is_active=True,\n                        allowed_segments=json.dumps(user_data.allowed_segments) if user_data.allowed_segments else \"[]\"\n                    )\n                    db.add(local_user)\n                else:\n                    # Update existing local user\n                    local_user.username = user_data.username\n                    local_user.email = user_data.email\n                    local_user.role = user_data.role\n                    if user_data.allowed_segments is not None:\n                        local_user.allowed_segments = json.dumps(user_data.allowed_segments)\n                \n                await db.commit()\n            except Exception as e:\n                # Log error but don't fail the request (Supabase creation worked)\n                # logger.error(f\"Failed to sync new user to SQL Server: {e}\")\n                print(f\"Failed to sync new user to SQL Server: {e}\")\n\n            return new_user\n        except Exception as e:\n            raise HTTPException(\n                status_code=status.HTTP_400_BAD_REQUEST,\n                detail=str(e)\n            )\n    else:\n        # Fallback to SQL Server (legacy)\n        result = await db.execute(\n            select(User).where(\n                (User.username == user_data.username) | (User.email == user_data.email)\n            )\n        )\n        existing_user = result.scalar_one_or_none()\n\n        if existing_user:\n            raise HTTPException(\n                status_code=status.HTTP_400_BAD_REQUEST,\n                detail=\"Username or email already registered\"\n            )\n\n        hashed_password = get_password_hash(user_data.password)\n        new_user = User(\n            username=user_data.username,\n            email=user_data.email,\n            hashed_password=hashed_password,\n            role=user_data.role,\n            allowed_segments=json.dumps(user_data.allowed_segments) if user_data.allowed_segments else \"[]\" # Added allowed_segments\n        )\n\n        db.add(new_user)\n        await db.commit()\n        await db.refresh(new_user)\n\n        return {\n            \"id\": str(new_user.id),\n            \"username\": new_user.username,\n            \"email\": new_user.email,\n            \"role\": new_user.role,\n            \"is_active\": new_user.is_active,\n            \"allowed_segments\": user_data.allowed_segments\n        }", "mimetype": "text/plain", "start_char_idx": 4347, "end_char_idx": 9037, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "bb585dcc-79e2-4fcb-9f92-6f675fbc5332": {"__data__": {"id_": "bb585dcc-79e2-4fcb-9f92-6f675fbc5332", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\admin.py", "language": "python", "lines": 436, "filename": "admin.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\admin.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\admin.py", "language": "python", "lines": 436, "filename": "admin.py"}, "hash": "e7931a846e05abf63abfffe6929c000323ecd3901ab23c425f2fc86061bba74a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "778d9629-eb76-4f1b-b494-90248ab210a1", "node_type": "1", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\admin.py", "language": "python", "lines": 436, "filename": "admin.py"}, "hash": "cd51f2e1b442ec50e9c6944eab06cf55448c88f270191d10bd0aca5dcc289ba1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6006d213-3d66-4cb9-ac06-239bd70f8986", "node_type": "1", "metadata": {}, "hash": "3731a2e394301f1f7ad3f0dff1d931dae92f710f939e5c92c9ce07e1fbd1d4ce", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "@router.put(\"/users/{user_id}\")\nasync def update_user(\n    user_id: str,\n    user_data: UserUpdate,\n    current_user: Annotated[User, Depends(require_role(\"admin\"))],\n    db: Annotated[AsyncSession, Depends(get_db)],\n) -> dict:\n    \"\"\"\n    Update user in Supabase\n\n    Updates user auth data and profile information.\n    Requires admin role.\n    \"\"\"\n    from app.config.settings import settings\n\n    if settings.USE_SUPABASE_AUTH:\n        try:\n            update_data = user_data.model_dump(exclude_unset=True)\n\n            updated_user = supabase_user_service.update_user(\n                user_id=user_id,\n                email=update_data.get(\"email\"),\n                username=update_data.get(\"username\"),\n                role=update_data.get(\"role\"),\n                password=update_data.get(\"password\"),\n                is_active=update_data.get(\"is_active\"),\n                allowed_segments=update_data.get(\"allowed_segments\") # Added allowed_segments\n            )\n\n            if not updated_user:\n                raise HTTPException(\n                    status_code=status.HTTP_404_NOT_FOUND,\n                    detail=\"User not found\"\n                )\n\n            # --- SYNC WITH SQL SERVER (AUTHORIZATION) ---\n            try:\n                # Check if user exists locally\n                u_id = uuid.UUID(user_id)\n                result = await db.execute(select(User).where(User.id == u_id))\n                local_user = result.scalar_one_or_none()\n                \n                if local_user:\n                    if \"username\" in update_data: local_user.username = update_data[\"username\"]\n                    if \"email\" in update_data: local_user.email = update_data[\"email\"]\n                    if \"role\" in update_data: local_user.role = update_data[\"role\"]\n                    if \"is_active\" in update_data: local_user.is_active = update_data[\"is_active\"]\n                    if \"allowed_segments\" in update_data: \n                        local_user.allowed_segments = json.dumps(update_data[\"allowed_segments\"])\n                    \n                    await db.commit()\n            except Exception as e:\n                print(f\"Failed to sync updated user to SQL Server: {e}\")\n\n            return updated_user\n        except HTTPException:\n            raise\n        except Exception as e:\n            raise HTTPException(\n                status_code=status.HTTP_400_BAD_REQUEST,\n                detail=str(e)\n            )\n    else:\n        # Fallback to SQL Server (legacy)\n        result = await db.execute(select(User).where(User.id == user_id))\n        user = result.scalar_one_or_none()\n\n        if not user:\n            raise HTTPException(\n                status_code=status.HTTP_404_NOT_FOUND,\n                detail=\"User not found\"\n            )\n\n        update_data = user_data.model_dump(exclude_unset=True)\n\n        if \"password\" in update_data:\n            update_data[\"hashed_password\"] = get_password_hash(update_data.pop(\"password\"))\n\n        # Handle allowed_segments conversion for SQL Server\n        if \"allowed_segments\" in update_data:\n            user.allowed_segments = json.dumps(update_data.pop(\"allowed_segments\"))\n\n        for field, value in update_data.items():\n            setattr(user, field, value)\n\n        await db.commit()\n        await db.refresh(user)\n\n        return {\n            \"id\": str(user.id),\n            \"username\": user.username,\n            \"email\": user.email,\n            \"role\": user.role,\n            \"is_active\": user.is_active,\n            \"allowed_segments\": json.loads(user.allowed_segments) if user.allowed_segments else []\n        }\n\n\n@router.delete(\"/users/{user_id}\", status_code=status.HTTP_204_NO_CONTENT)\nasync def delete_user(\n    user_id: str,\n    current_user: Annotated[User, Depends(require_role(\"admin\"))],\n    db: Annotated[AsyncSession, Depends(get_db)],\n):\n    \"\"\"\n    Delete user from Supabase\n\n    Removes user from auth and profile tables.\n    Requires admin role. Cannot delete self.\n    \"\"\"\n    from app.config.settings import settings\n\n    # Prevent self-deletion\n    if user_id == str(current_user.id):\n        raise HTTPException(\n            status_code=status.HTTP_400_BAD_REQUEST,\n            detail=\"Cannot delete your own account\"\n        )\n\n    if settings.USE_SUPABASE_AUTH:\n        success = supabase_user_service.delete_user(user_id)\n        if not success:\n            raise HTTPException(\n                status_code=status.HTTP_404_NOT_FOUND,\n                detail=\"User not found or deletion failed\"\n            )\n    else:\n        # Fallback to SQL Server (legacy)\n        result = await db.execute(select(User).where(User.id == user_id))\n        user = result.scalar_one_or_none()\n\n        if not user:\n            raise HTTPException(\n                status_code=status.HTTP_404_NOT_FOUND,\n                detail=\"User not found\"\n            )\n\n        await db.delete(user)\n        await db.commit()", "mimetype": "text/plain", "start_char_idx": 9040, "end_char_idx": 13967, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "6006d213-3d66-4cb9-ac06-239bd70f8986": {"__data__": {"id_": "6006d213-3d66-4cb9-ac06-239bd70f8986", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\admin.py", "language": "python", "lines": 436, "filename": "admin.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\admin.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\admin.py", "language": "python", "lines": 436, "filename": "admin.py"}, "hash": "e7931a846e05abf63abfffe6929c000323ecd3901ab23c425f2fc86061bba74a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bb585dcc-79e2-4fcb-9f92-6f675fbc5332", "node_type": "1", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\admin.py", "language": "python", "lines": 436, "filename": "admin.py"}, "hash": "5832dd85876e232f19fcacc63259fb2b5f86a5868174f966e8576be0ff7180dc", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "@router.get(\"/audit-logs\")\nasync def get_audit_logs(\n    db: Annotated[AsyncSession, Depends(get_db)],\n    current_user: Annotated[User, Depends(require_role(\"admin\"))],\n    limit: int = 100,\n) -> list[dict]:\n    \"\"\"Get audit logs\"\"\"\n    \n    result = await db.execute(\n        select(AuditLog)\n        .order_by(AuditLog.timestamp.desc())\n        .limit(limit)\n    )\n    logs = result.scalars().all()\n    \n    # Get user names\n    user_ids = {log.user_id for log in logs}\n    users_result = await db.execute(\n        select(User.id, User.username).where(User.id.in_(user_ids))\n    )\n    users_map = {user_id: username for user_id, username in users_result}\n    \n    return [\n        {\n            \"id\": str(log.id),\n            \"user_id\": str(log.user_id),\n            \"user_name\": users_map.get(log.user_id, \"Unknown\"),\n            \"action\": log.action,\n            \"resource\": log.resource,\n            \"details\": log.details,\n            \"ip_address\": str(log.ip_address),\n            \"timestamp\": log.timestamp.isoformat(),\n            \"status\": log.status,\n        }\n        for log in logs\n    ]", "mimetype": "text/plain", "start_char_idx": 13970, "end_char_idx": 15072, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "3a6bffc2-8cb7-4352-8d0c-81674ee80795": {"__data__": {"id_": "3a6bffc2-8cb7-4352-8d0c-81674ee80795", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\analytics.py", "language": "python", "lines": 328, "filename": "analytics.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\analytics.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\analytics.py", "language": "python", "lines": 328, "filename": "analytics.py"}, "hash": "9bd15d3ff0d618fd6d3e71da78e013220daed52f3217103669879911d4ef18bc", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "70ed68cc-ed6f-48e6-8178-31378d6d21a1", "node_type": "1", "metadata": {}, "hash": "f1b943c374d24077461ae61564cd519e0c15bfc1bcc66c158c6cf78860b8f571", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nAnalytics Endpoints\nData analysis, metrics, export and custom queries\n\"\"\"\n\nfrom typing import Annotated, List, Dict, Any, Optional\nfrom datetime import datetime, timedelta, date\nimport json\nimport logging\n\nfrom fastapi import APIRouter, Depends, HTTPException, Query, status\nfrom pydantic import BaseModel\n\nfrom app.api.dependencies import get_current_active_user\nfrom app.infrastructure.database.models import User\nfrom app.core.monitoring.metrics_dashboard import MetricsDashboard\nfrom app.config.settings import settings # For initializing MetricsDashboard\n\nlogger = logging.getLogger(__name__)\n\n# Initialize MetricsDashboard globally\n# In a larger application, consider dependency injection or FastAPI lifespan events.\nmetrics_dashboard: Optional[MetricsDashboard] = None\n\n# @Deprecate this global initialization in favor of FastAPI's lifespan events. This is for quick setup.\ndef _initialize_metrics_dashboard():\n    global metrics_dashboard\n    if metrics_dashboard is None:\n        metrics_dashboard = MetricsDashboard(\n            query_history=None, # Will use default from settings in MetricsDashboard\n            response_cache=None # Will use default from settings in MetricsDashboard\n        )\n        logger.info(\"MetricsDashboard initialized.\")\n\n_initialize_metrics_dashboard()\n\nrouter = APIRouter(prefix=\"/analytics\", tags=[\"Analytics\"])\n\n\nclass MetricsSummary(BaseModel):\n    total_queries: int\n    total_errors: int\n    success_rate_feedback: float\n    cache_hit_rate: float\n    average_response_time_ms: str\n\n\nclass ErrorTrendItem(BaseModel):\n    date: str\n    error_count: int\n\n\nclass TopQueryItem(BaseModel):\n    query: str\n    count: int\n\n\n@router.get(\"/kpis\", response_model=MetricsSummary)\nasync def get_kpis(\n    current_user: Annotated[User, Depends(get_current_active_user)],\n    days: int = Query(7, description=\"Number of days to look back for metrics\"),\n) -> MetricsSummary:\n    \"\"\"\n    Retrieves key performance indicators (KPIs) for the agent system.\n    (T4.4.1: GET /analytics/kpis)\n    \"\"\"\n    if metrics_dashboard is None:\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=\"MetricsDashboard not initialized.\"\n        )\n    try:\n        kpis = metrics_dashboard.get_metrics(days=days)\n        return MetricsSummary(**kpis)\n    except Exception as e:\n        logger.error(f\"Error fetching KPIs: {e}\", exc_info=True)\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=f\"Error fetching KPIs: {str(e)}\"\n        )\n\n\n@router.get(\"/error-trend\", response_model=List[ErrorTrendItem])\nasync def get_error_trend(\n    current_user: Annotated[User, Depends(get_current_active_user)],\n    days: int = Query(30, description=\"Number of days to look back for error trend\"),\n) -> List[ErrorTrendItem]:\n    \"\"\"\n    Provides a daily trend of errors for the agent system.\n    (T4.4.1: GET /analytics/error-trend)\n    \"\"\"\n    if metrics_dashboard is None:\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=\"MetricsDashboard not initialized.\"\n        )\n    try:\n        trend = metrics_dashboard.get_error_trend(days=days)\n        return [ErrorTrendItem(**item) for item in trend]\n    except Exception as e:\n        logger.error(f\"Error fetching error trend: {e}\", exc_info=True)\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=f\"Error fetching error trend: {str(e)}\"\n        )", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3539, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "70ed68cc-ed6f-48e6-8178-31378d6d21a1": {"__data__": {"id_": "70ed68cc-ed6f-48e6-8178-31378d6d21a1", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\analytics.py", "language": "python", "lines": 328, "filename": "analytics.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\analytics.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\analytics.py", "language": "python", "lines": 328, "filename": "analytics.py"}, "hash": "9bd15d3ff0d618fd6d3e71da78e013220daed52f3217103669879911d4ef18bc", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3a6bffc2-8cb7-4352-8d0c-81674ee80795", "node_type": "1", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\analytics.py", "language": "python", "lines": 328, "filename": "analytics.py"}, "hash": "9cd4a3e3160b1759b9097d59d8791a589f10d99548fe81463e809ec2a20c011b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "fb9be564-efa9-46de-84df-0852fd326ca2", "node_type": "1", "metadata": {}, "hash": "1451aff698394e301afd2c2ab6d34af29518bbe641d4078a14f9e9cbcd27df48", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "@router.get(\"/top-queries\", response_model=List[TopQueryItem])\nasync def get_top_queries(\n    current_user: Annotated[User, Depends(get_current_active_user)],\n    days: int = Query(7, description=\"Number of days to look back for top queries\"),\n    limit: int = Query(10, description=\"Maximum number of top queries to return\"),\n) -> List[TopQueryItem]:\n    \"\"\"\n    Identifies the most frequent queries made to the agent system.\n    (T4.4.1: GET /analytics/top-queries)\n    \"\"\"\n    if metrics_dashboard is None:\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=\"MetricsDashboard not initialized.\"\n        )\n    try:\n        top_queries = metrics_dashboard.get_top_queries(days=days, limit=limit)\n        return [TopQueryItem(**item) for item in top_queries]\n    except Exception as e:\n        logger.error(f\"Error fetching top queries: {e}\", exc_info=True)\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=f\"Error fetching top queries: {str(e)}\"\n        )\n\n\n@router.get(\"/filter-options\")\nasync def get_filter_options(\n    current_user: Annotated[User, Depends(get_current_active_user)],\n    segmento: Optional[str] = Query(None, description=\"Segmento para filtrar as categorias retornadas\")\n) -> Dict[str, List[str]]:\n    \"\"\"\n    Retorna valores \u00fanicos de categoria e segmento para os filtros.\n    Pode filtrar categorias por um segmento espec\u00edfico.\n    \"\"\"\n    import polars as pl\n    from app.core.data_scope_service import data_scope_service\n\n    try:\n        df = data_scope_service.get_filtered_dataframe(current_user, max_rows=50000)\n\n        categorias = []\n        segmentos = []\n        \n        # Filtrar o DataFrame pelo segmento se fornecido\n        if segmento and \"NOMESEGMENTO\" in df.columns:\n            df = df.filter(pl.col(\"NOMESEGMENTO\").str.to_lowercase() == segmento.lower())\n\n        # Categorias \u00fanicas\n        if \"NOMECATEGORIA\" in df.columns:\n            cat_unique = df.select(\"NOMECATEGORIA\").unique().sort(\"NOMECATEGORIA\")\n            for row in cat_unique.iter_rows(named=True):\n                cat = str(row[\"NOMECATEGORIA\"]).strip()\n                if cat and cat != \"null\" and cat != \"None\":\n                    categorias.append(cat)\n\n        # Segmentos \u00fanicos (sempre da base original, n\u00e3o filtrada por categoria)\n        df_all_segments = data_scope_service.get_filtered_dataframe(current_user, max_rows=50000)\n        if \"NOMESEGMENTO\" in df_all_segments.columns:\n            seg_unique = df_all_segments.select(\"NOMESEGMENTO\").unique().sort(\"NOMESEGMENTO\")\n            for row in seg_unique.iter_rows(named=True):\n                seg = str(row[\"NOMESEGMENTO\"]).strip()\n                if seg and seg != \"null\" and seg != \"None\":\n                    segmentos.append(seg)\n\n        return {\n            \"categorias\": categorias,\n            \"segmentos\": segmentos\n        }\n\n    except Exception as e:\n        logger.error(f\"Error getting filter options: {e}\", exc_info=True)\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=f\"Error getting filter options: {str(e)}\"\n        )\n\n\n@router.get(\"/sales-analysis\")\nasync def get_sales_analysis(\n    current_user: Annotated[User, Depends(get_current_active_user)],\n    categoria: Optional[str] = Query(None),\n    segmento: Optional[str] = Query(None)\n) -> Dict[str, Any]:\n    \"\"\"\n    An\u00e1lise de vendas e estoque com gr\u00e1ficos.\n    Retorna dados para gr\u00e1ficos de vendas por categoria, giro de estoque e distribui\u00e7\u00e3o ABC.\n    \"\"\"", "mimetype": "text/plain", "start_char_idx": 3542, "end_char_idx": 7134, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "fb9be564-efa9-46de-84df-0852fd326ca2": {"__data__": {"id_": "fb9be564-efa9-46de-84df-0852fd326ca2", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\analytics.py", "language": "python", "lines": 328, "filename": "analytics.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\analytics.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\analytics.py", "language": "python", "lines": 328, "filename": "analytics.py"}, "hash": "9bd15d3ff0d618fd6d3e71da78e013220daed52f3217103669879911d4ef18bc", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "70ed68cc-ed6f-48e6-8178-31378d6d21a1", "node_type": "1", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\analytics.py", "language": "python", "lines": 328, "filename": "analytics.py"}, "hash": "fa8e18c7dfb1a4545ae1e361ec013993882187df8c0cdfdabd2e2c815e62223a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "45471034-6b11-46d1-b4a2-ca4e00baf851", "node_type": "1", "metadata": {}, "hash": "7055336d9bdf8391e3f3a6e9e32efa505827bb90951ec2ed40979bd00552a015", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import polars as pl\n    from app.core.data_scope_service import data_scope_service\n\n    try:\n        # Obter o DataFrame completo (Lazy) para m\u00e1xima performance sem limites arbitr\u00e1rios no in\u00edcio\n        df = data_scope_service.get_filtered_dataframe(current_user)\n\n        if df.is_empty():\n            return {\n                \"vendas_por_categoria\": [],\n                \"giro_estoque\": [],\n                \"distribuicao_abc\": {\"A\": 0, \"B\": 0, \"C\": 0, \"detalhes\": []}\n            }\n\n        # Determinar nomes corretos das colunas (suporta tanto mai\u00fasculas quanto min\u00fasculas)\n        categoria_col = \"nomecategoria\" if \"nomecategoria\" in df.columns else (\"NOMECATEGORIA\" if \"NOMECATEGORIA\" in df.columns else (\"CATEGORIA\" if \"CATEGORIA\" in df.columns else None))\n        segmento_col = \"nomesegmento\" if \"nomesegmento\" in df.columns else (\"NOMESEGMENTO\" if \"NOMESEGMENTO\" in df.columns else (\"SEGMENTO\" if \"SEGMENTO\" in df.columns else None))\n        produto_col = \"codigo\" if \"codigo\" in df.columns else \"PRODUTO\"\n        nome_col = \"nome_produto\" if \"nome_produto\" in df.columns else \"NOME\"\n        venda_col = \"venda_30_d\" if \"venda_30_d\" in df.columns else \"VENDA_30DD\"\n        estoque_col = \"estoque_atual\" if \"estoque_atual\" in df.columns else \"ESTOQUE_UNE\"\n\n        # Aplicar filtros se fornecidos\n        if categoria and categoria_col:\n            df = df.filter(pl.col(categoria_col).str.to_lowercase() == categoria.lower())\n        if segmento and segmento_col:\n            df = df.filter(pl.col(segmento_col).str.to_lowercase() == segmento.lower())\n\n        # Fun\u00e7\u00e3o auxiliar para casting seguro\n        def safe_cast_col(col_name):\n            if col_name not in df.columns: return pl.lit(0).cast(pl.Float64)\n            # Se j\u00e1 for num\u00e9rico, n\u00e3o precisa converter de string\n            col_type = df.schema[col_name]\n            if col_type in [pl.Float64, pl.Float32, pl.Int64, pl.Int32, pl.Int16, pl.Int8]:\n                return pl.col(col_name).fill_null(0).cast(pl.Float64)\n            return pl.col(col_name).cast(pl.Utf8).str.strip_chars().replace(\"\", None).cast(pl.Float64).fill_null(0)\n\n        # 1. Vendas por Categoria (Top 10)\n        vendas_categoria = []\n        if categoria_col and venda_col in df.columns:\n            df_cat = df.group_by(categoria_col).agg([\n                safe_cast_col(venda_col).sum().alias(\"vendas\")\n            ]).sort(\"vendas\", descending=True).head(10)\n\n            for row in df_cat.iter_rows(named=True):\n                vendas_categoria.append({\n                    \"categoria\": str(row[categoria_col])[:30],\n                    \"vendas\": int(row[\"vendas\"])\n                })\n\n        # 2. Giro de Estoque (Top 15)\n        giro_estoque = []\n        if venda_col in df.columns and estoque_col in df.columns and produto_col in df.columns and nome_col in df.columns:\n            df_giro = df.with_columns([\n                safe_cast_col(venda_col).alias(\"v_clean\"),\n                safe_cast_col(estoque_col).alias(\"e_clean\")\n            ]).filter(\n                (pl.col(\"v_clean\") > 0) & (pl.col(\"e_clean\") > 0)\n            ).group_by(produto_col, nome_col).agg([\n                pl.col(\"v_clean\").sum().alias(\"vendas\"),\n                pl.col(\"e_clean\").mean().alias(\"estoque_medio\")\n            ]).with_columns([\n                (pl.col(\"vendas\") / pl.col(\"estoque_medio\")).alias(\"giro\")\n            ]).sort(\"giro\", descending=True).head(15)\n\n            for row in df_giro.iter_rows(named=True):\n                giro_estoque.append({\n                    \"produto\": str(row[produto_col]),\n                    \"nome\": str(row[nome_col])[:40],\n                    \"giro\": round(float(row[\"giro\"]), 2)\n                })\n\n        # 3.", "mimetype": "text/plain", "start_char_idx": 7139, "end_char_idx": 10834, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "45471034-6b11-46d1-b4a2-ca4e00baf851": {"__data__": {"id_": "45471034-6b11-46d1-b4a2-ca4e00baf851", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\analytics.py", "language": "python", "lines": 328, "filename": "analytics.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\analytics.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\analytics.py", "language": "python", "lines": 328, "filename": "analytics.py"}, "hash": "9bd15d3ff0d618fd6d3e71da78e013220daed52f3217103669879911d4ef18bc", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fb9be564-efa9-46de-84df-0852fd326ca2", "node_type": "1", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\analytics.py", "language": "python", "lines": 328, "filename": "analytics.py"}, "hash": "5fbb4e4300cf70253ae1bde9f32bec48e2f506b727abc11e45bfa200a6629f75", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Distribui\u00e7\u00e3o ABC (Princ\u00edpio de Pareto - Dataset Completo)\n        distribuicao_abc = {\"A\": 0, \"B\": 0, \"C\": 0, \"detalhes\": [], \"receita_por_classe\": {}}\n\n        # Usamos MES_01 para faturamento ou venda_col se MES_01 estiver zerado\n        # No varejo, Pareto pode ser por Valor ou Volume\n        val_col = \"MES_01\" if \"MES_01\" in df.columns else venda_col\n\n        if val_col in df.columns and produto_col in df.columns and nome_col in df.columns:\n            df_abc_raw = df.with_columns([\n                safe_cast_col(val_col).alias(\"valor_clean\")\n            ]).filter(pl.col(\"valor_clean\") > 0)\n\n            if not df_abc_raw.is_empty():\n                # Ordenar por valor decrescente\n                df_abc = df_abc_raw.select([\n                    pl.col(produto_col).alias(\"PRODUTO\"),\n                    pl.col(nome_col).alias(\"NOME\"),\n                    pl.col(\"valor_clean\").alias(\"receita\")\n                ]).sort(\"receita\", descending=True)\n\n                total_receita = df_abc.select(pl.col(\"receita\").sum()).item()\n\n                if total_receita > 0:\n                    # Calcular Acumulado\n                    df_abc = df_abc.with_columns([\n                        (pl.col(\"receita\").cum_sum() / total_receita * 100).alias(\"perc_acumulada\")\n                    ])\n\n                    # Classifica\u00e7\u00e3o ABC (80/15/5)\n                    df_abc = df_abc.with_columns([\n                        pl.when(pl.col(\"perc_acumulada\") <= 80).then(pl.lit(\"A\"))\n                        .when(pl.col(\"perc_acumulada\") <= 95).then(pl.lit(\"B\"))\n                        .otherwise(pl.lit(\"C\")).alias(\"classe\")\n                    ])\n\n                    # Resultados\n                    resumo = df_abc.group_by(\"classe\").agg([\n                        pl.count().alias(\"qtd\"),\n                        pl.col(\"receita\").sum().alias(\"soma\")\n                    ])\n\n                    for row in resumo.iter_rows(named=True):\n                        distribuicao_abc[row[\"classe\"]] = row[\"qtd\"]\n                        distribuicao_abc[\"receita_por_classe\"][row[\"classe\"]] = row[\"soma\"]\n\n                    distribuicao_abc[\"detalhes\"] = df_abc.head(20).to_dicts()\n\n        return {\n            \"vendas_por_categoria\": vendas_categoria,\n            \"giro_estoque\": giro_estoque,\n            \"distribuicao_abc\": distribuicao_abc\n        }\n\n    except Exception as e:\n        logger.error(f\"Error in sales analysis: {e}\", exc_info=True)\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=f\"Error analyzing sales: {str(e)}\"\n        )", "mimetype": "text/plain", "start_char_idx": 10835, "end_char_idx": 13433, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b47c3bf5-687e-4bac-97e2-9274275d9a8a": {"__data__": {"id_": "b47c3bf5-687e-4bac-97e2-9274275d9a8a", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\auth.py", "language": "python", "lines": 207, "filename": "auth.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\auth.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\auth.py", "language": "python", "lines": 207, "filename": "auth.py"}, "hash": "5dd6e049f58818231fc1450bc7894ea1c3c04e583c2eab006bbc3608532d3be1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "635160bc-52a6-449a-acce-136a0dee2374", "node_type": "1", "metadata": {}, "hash": "1b252a1ee23d648fb561c596724cd28fd3a94d91db1cef3ee57fded03a825491", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"Authentication Endpoints\nLogin, logout, refresh token, and current user\n\"\"\"\n\nfrom datetime import datetime, timezone\nfrom typing import Annotated\n\nimport logging\nlogger = logging.getLogger(__name__) # General logger\nsecurity_logger = logging.getLogger(\"security\") # Dedicated security logger\n\nfrom fastapi import APIRouter, Depends, HTTPException, Form, status\nfrom sqlalchemy import select\nfrom sqlalchemy.ext.asyncio import AsyncSession\n\nfrom app.api.dependencies import get_current_active_user\nfrom app.config.database import get_db\nfrom app.config.security import (\n    create_access_token,\n    create_refresh_token,\n    verify_password,\n    decode_token,\n    get_password_hash, # Added for password change logging\n)\nfrom app.infrastructure.database.models import User\nfrom app.schemas.auth import LoginRequest, RefreshTokenRequest, Token\nfrom app.schemas.user import UserResponse\n\nrouter = APIRouter(prefix=\"/auth\", tags=[\"Authentication\"])\n\n@router.post(\"/login\", response_model=Token)\nasync def login(\n    login_data: LoginRequest,\n    db: Annotated[AsyncSession, Depends(get_db)],\n) -> Token:\n    \"\"\"\n    Production authentication endpoint - optimized for speed.\n\n    Uses hybrid authentication:\n    1. Parquet (primary, fast)\n    2. SQL Server (only if explicitly enabled and USE_SQL_SERVER=true)\n\n    Fast and efficient with proper error handling.\n    \"\"\"\n    from app.core.auth_service import auth_service\n    from app.config.settings import settings\n\n    # Autentica usando Parquet diretamente quando SQL Server desabilitado\n    user_data = await auth_service.authenticate_user(\n        username=login_data.username,\n        password=login_data.password,\n        db=db if settings.USE_SQL_SERVER else None,\n    )\n\n    if not user_data:\n        security_logger.warning(f\"Failed login attempt for username: {login_data.username}\")\n        raise HTTPException(\n            status_code=status.HTTP_401_UNAUTHORIZED,\n            detail=\"Incorrect username or password\",\n            headers={\"WWW-Authenticate\": \"Bearer\"},\n        )\n\n    if not user_data.get(\"is_active\", False):\n        security_logger.warning(f\"Inactive user '{user_data.get('username')}' attempted to log in.\")\n        raise HTTPException(\n            status_code=status.HTTP_403_FORBIDDEN,\n            detail=\"Inactive user\"\n        )\n\n    # Generate tokens\n    token_data = {\n        \"sub\": user_data[\"id\"],\n        \"username\": user_data[\"username\"],\n        \"role\": user_data[\"role\"],\n        \"allowed_segments\": user_data.get(\"allowed_segments\", [])\n    }\n    access_token = create_access_token(token_data)\n    refresh_token = create_refresh_token(token_data)\n\n    security_logger.info(f\"User '{user_data['username']}' logged in successfully.\")\n    return Token(\n        access_token=access_token,\n        refresh_token=refresh_token,\n        token_type=\"bearer\"\n    )\n\n@router.post(\"/login_form\", response_model=Token)\nasync def login_form(\n    username: str = Form(...),\n    password: str = Form(...),\n    db: AsyncSession = Depends(get_db),\n) -> Token:\n    \"\"\"Login endpoint that accepts form data (used by HTML login page).\"\"\"\n    result = await db.execute(select(User).where(User.username == username))\n    user = result.scalar_one_or_none()\n    if not user or not verify_password(password, user.hashed_password):\n        security_logger.warning(f\"Failed login (form) attempt for username: {username}\")\n        raise HTTPException(\n            status_code=status.HTTP_401_UNAUTHORIZED,\n            detail=\"Incorrect username or password\",\n            headers={\"WWW-Authenticate\": \"Bearer\"},\n        )\n    if not user.is_active:\n        security_logger.warning(f\"Inactive user '{username}' attempted to log in (form).\")\n        raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail=\"Inactive user\")\n    user.last_login = datetime.now(timezone.utc)\n    await db.commit()\n    token_data = {\"sub\": str(user.id), \"username\": user.username, \"role\": user.role}\n    access_token = create_access_token(token_data)\n    refresh_token = create_refresh_token(token_data)\n    security_logger.info(f\"User '{username}' logged in successfully (form).\")\n    return Token(access_token=access_token, refresh_token=refresh_token, token_type=\"bearer\")\n\n@router.post(\"/refresh\", response_model=Token)\nasync def refresh_token(\n    refresh_data: RefreshTokenRequest,\n    db: Annotated[AsyncSession, Depends(get_db)],\n) -> Token:\n    \"\"\"Refresh access token using refresh token.\"\"\"", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4455, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "635160bc-52a6-449a-acce-136a0dee2374": {"__data__": {"id_": "635160bc-52a6-449a-acce-136a0dee2374", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\auth.py", "language": "python", "lines": 207, "filename": "auth.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\auth.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\auth.py", "language": "python", "lines": 207, "filename": "auth.py"}, "hash": "5dd6e049f58818231fc1450bc7894ea1c3c04e583c2eab006bbc3608532d3be1", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b47c3bf5-687e-4bac-97e2-9274275d9a8a", "node_type": "1", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\auth.py", "language": "python", "lines": 207, "filename": "auth.py"}, "hash": "df06f7d7454262095fe51ef673addf122ca8b8684a926823784a78c30428ce5f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "try:\n        payload = decode_token(refresh_data.refresh_token)\n        if payload.get(\"type\") != \"refresh\":\n            security_logger.warning(f\"Invalid token type for refresh: {payload.get('type')}\")\n            raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail=\"Invalid token type\")\n        user_id = payload.get(\"sub\")\n        if not user_id:\n            security_logger.warning(\"Refresh token payload missing user ID.\")\n            raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail=\"Invalid token\")\n        result = await db.execute(select(User).where(User.id == user_id))\n        user = result.scalar_one_or_none()\n        if not user or not user.is_active:\n            security_logger.warning(f\"Refresh token for non-existent or inactive user ID: {user_id}\")\n            raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail=\"User not found or inactive\")\n        token_data = {\n            \"sub\": str(user.id), \n            \"username\": user.username, \n            \"role\": user.role,\n            \"allowed_segments\": getattr(user, \"allowed_segments\", [])\n        }\n        access_token = create_access_token(token_data)\n        new_refresh_token = create_refresh_token(token_data)\n        security_logger.info(f\"User '{user.username}' refreshed token successfully.\")\n        return Token(access_token=access_token, refresh_token=new_refresh_token, token_type=\"bearer\")\n    except JWTError as e:\n        security_logger.warning(f\"JWT Error during token refresh: {e}\")\n        raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail=\"Invalid refresh token\")\n\n\n@router.get(\"/me\", response_model=UserResponse)\nasync def get_current_user_info(\n    current_user: Annotated[User, Depends(get_current_active_user)],\n) -> UserResponse:\n    \"\"\"Get current authenticated user information.\"\"\"\n    return current_user\n\n@router.post(\"/logout\")\nasync def logout(current_user: Annotated[User, Depends(get_current_active_user)]) -> dict[str, str]:\n    \"\"\"Placeholder logout endpoint (client can discard tokens).\"\"\"\n    security_logger.info(f\"User '{current_user.username}' logged out.\")\n    return {\"detail\": \"Logged out\"}\n\n\n@router.post(\"/change-password\")\nasync def change_password(\n    current_user: Annotated[User, Depends(get_current_active_user)],\n    old_password: str = Form(...),\n    new_password: str = Form(...)\n):\n    \"\"\"Change user password (updates Parquet only).\"\"\"\n    import polars as pl\n    from pathlib import Path\n\n    # Verify old password\n    if not verify_password(old_password, current_user.hashed_password):\n        security_logger.warning(f\"User '{current_user.username}' failed to change password - incorrect old password.\")\n        raise HTTPException(status_code=400, detail=\"Incorrect old password\")\n\n    # Determine Parquet path (same logic as auth_service)\n    docker_path = Path(\"/app/data/parquet/users.parquet\")\n    dev_path = Path(__file__).parent.parent.parent.parent.parent.parent / \"data\" / \"parquet\" / \"users.parquet\"\n    parquet_path = docker_path if docker_path.exists() else dev_path\n\n    if not parquet_path.exists():\n        security_logger.error(f\"User database (Parquet) not found for password change for user '{current_user.username}'.\")\n        raise HTTPException(status_code=500, detail=\"User database not found\")\n\n    try:\n        df = pl.read_parquet(parquet_path)\n        new_hash = get_password_hash(new_password)\n        \n        # Update password for specific user\n        df = df.with_columns(\n            pl.when(pl.col(\"id\") == current_user.id)\n            .then(pl.lit(new_hash))\n            .otherwise(pl.col(\"hashed_password\"))\n            .alias(\"hashed_password\")\n        )\n        \n        df.write_parquet(parquet_path)\n        security_logger.info(f\"User '{current_user.username}' changed password successfully.\")\n        return {\"message\": \"Password updated successfully\"}\n        \n    except Exception as e:\n        security_logger.error(f\"Failed to update password for user '{current_user.username}': {e}\")\n        raise HTTPException(status_code=500, detail=f\"Failed to update password: {str(e)}\")", "mimetype": "text/plain", "start_char_idx": 4460, "end_char_idx": 8584, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "dd09dfc8-7cfe-41d2-987c-b62264e44525": {"__data__": {"id_": "dd09dfc8-7cfe-41d2-987c-b62264e44525", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\auth_alt.py", "language": "python", "lines": 121, "filename": "auth_alt.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\auth_alt.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\auth_alt.py", "language": "python", "lines": 121, "filename": "auth_alt.py"}, "hash": "c843862ca91ec9dfcf58294d3b24aeb97f100b85f43cd8603b5eade2ab119fa8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nENDPOINT DE LOGIN ALTERNATIVO - USA PYODBC DIRETO (S\u00cdNCRONO)\nBypass do problema com aioodbc\n\"\"\"\nfrom fastapi import APIRouter, HTTPException, status\nfrom pydantic import BaseModel\nimport pyodbc\nimport bcrypt\nfrom app.config.security import create_access_token, create_refresh_token\n\nrouter_alt = APIRouter(prefix=\"/auth-alt\", tags=[\"Auth Alternative\"])\n\nclass LoginRequest(BaseModel):\n    username: str\n    password: str\n\nclass UserData(BaseModel):\n    id: str\n    username: str\n    email: str\n    role: str\n\nclass Token(BaseModel):\n    access_token: str\n    refresh_token: str\n    token_type: str\n    user: UserData\n\n@router_alt.post(\"/login\", response_model=Token)\ndef login_alt(login_data: LoginRequest):\n    \"\"\"\n    Login alternativo usando pyodbc s\u00edncrono\n    \"\"\"\n    try:\n        # Conectar diretamente com pyodbc\n        conn = pyodbc.connect(\n            \"DRIVER={ODBC Driver 17 for SQL Server};\"\n            \"SERVER=FAMILIA\\\\SQLJR,1433;\"\n            \"DATABASE=agentbi;\"\n            \"UID=AgenteVirtual;\"\n            \"PWD=Cacula@2020;\"\n            \"TrustServerCertificate=yes;\",\n            timeout=5\n        )\n        cursor = conn.cursor()\n        \n        # Buscar usu\u00e1rio\n        cursor.execute(\n            \"SELECT id, username, email, hashed_password, role, is_active FROM users WHERE username = ?\",\n            (login_data.username,)\n        )\n        user = cursor.fetchone()\n        \n        if not user:\n            raise HTTPException(\n                status_code=status.HTTP_401_UNAUTHORIZED,\n                detail=\"Incorrect username or password\"\n            )\n        \n        user_id, username, email, hashed_password, role, is_active = user\n        \n        # Verificar senha\n        if not bcrypt.checkpw(login_data.password.encode('utf-8'), hashed_password.encode('utf-8')):\n            raise HTTPException(\n                status_code=status.HTTP_401_UNAUTHORIZED,\n                detail=\"Incorrect username or password\"\n            )\n        \n        # Verificar se est\u00e1 ativo\n        if not is_active:\n            raise HTTPException(\n                status_code=status.HTTP_403_FORBIDDEN,\n                detail=\"Inactive user\"\n            )\n        \n        # Atualizar last_login\n        cursor.execute(\n            \"UPDATE users SET last_login = CURRENT_TIMESTAMP WHERE id = ?\",\n            (str(user_id),)\n        )\n        conn.commit()\n        \n        cursor.close()\n        conn.close()\n        \n        # Criar tokens\n        token_data = {\n            \"sub\": str(user_id),\n            \"username\": username,\n            \"role\": role,\n        }\n        \n        access_token = create_access_token(token_data)\n        refresh_token = create_refresh_token(token_data)\n        \n        # Criar objeto de usu\u00e1rio\n        user_data = UserData(\n            id=str(user_id),\n            username=username,\n            email=email or \"\",\n            role=role\n        )\n        \n        return Token(\n            access_token=access_token,\n            refresh_token=refresh_token,\n            token_type=\"bearer\",\n            user=user_data\n        )\n        \n    except pyodbc.Error as e:\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=f\"Database error: {str(e)}\"\n        )\n    except Exception as e:\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=f\"Error: {str(e)}\"\n        )", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3439, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "91612fbb-cb7e-42fb-ab78-df07c3ebbb85": {"__data__": {"id_": "91612fbb-cb7e-42fb-ab78-df07c3ebbb85", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\chat.py", "language": "python", "lines": 725, "filename": "chat.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\chat.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\chat.py", "language": "python", "lines": 725, "filename": "chat.py"}, "hash": "2c06578190f0b9f3509ac2172bb890f2cd0f68e54b5fefa866105ed665bdd8b4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "27e3ff59-e1f3-427a-8b83-ec964e4701d5", "node_type": "1", "metadata": {}, "hash": "70455f07caeaf8f8d1b0c2bfbea983651145947017c35b705241e9a4536d4cac", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nChat Endpoints\nBI Chat with AI assistant\n\"\"\"\n\nfrom typing import Annotated, Dict, Any, Optional\nfrom fastapi import APIRouter, Depends, HTTPException, Request, status\nfrom fastapi.responses import ORJSONResponse, StreamingResponse\nfrom pydantic import BaseModel\nfrom pathlib import Path\nimport json\nimport asyncio\nimport logging\nimport sys\nimport numpy as np\nimport pandas as pd\nfrom decimal import Decimal\nfrom datetime import datetime, date\n\n# Import core dependencies\nfrom app.api.dependencies import get_current_active_user\nfrom app.infrastructure.database.models import User\nfrom app.config.settings import settings\nfrom app.core.utils.response_cache import ResponseCache\nfrom app.core.utils.query_history import QueryHistory\nfrom app.core.utils.field_mapper import FieldMapper\nfrom app.core.rag.query_retriever import QueryRetriever\nfrom app.core.learning.pattern_matcher import PatternMatcher\nfrom app.core.agents.code_gen_agent import CodeGenAgent\nfrom app.core.agents.caculinha_bi_agent import CaculinhaBIAgent\nfrom app.core.llm_gemini_adapter_v2 import GeminiLLMAdapterV2 as GeminiLLMAdapter\nfrom app.core.utils.error_handler import APIError\nfrom app.core.utils.session_manager import SessionManager\nfrom app.core.utils.semantic_cache import cache_get, cache_set, cache_stats\nfrom app.core.utils.response_validator import validate_response, validator_stats\n\nlogger = logging.getLogger(__name__)\n\n\ndef safe_json_dumps(obj: Any, **kwargs) -> str:\n    \"\"\"\n    Safely serialize any Python object to JSON string.\n    Handles MapComposite, numpy types, pandas types, datetime, and other non-serializable objects.\n    \"\"\"\n    def default_handler(o):\n        # Handle numpy types\n        if isinstance(o, (np.integer, np.int64, np.int32, np.int16, np.int8)):\n            return int(o)\n        elif isinstance(o, (np.floating, np.float64, np.float32, np.float16)):\n            if np.isnan(o) or np.isinf(o):\n                return None\n            return float(o)\n        elif isinstance(o, np.ndarray):\n            return o.tolist()\n        elif isinstance(o, np.bool_):\n            return bool(o)\n\n        # Handle pandas types\n        elif isinstance(o, pd.Timestamp):\n            return o.isoformat()\n        elif isinstance(o, pd.Timedelta):\n            return str(o)\n        elif pd.isna(o):\n            return None\n\n        # Handle datetime types\n        elif isinstance(o, (datetime, date)):\n            return o.isoformat()\n\n        # Handle Decimal\n        elif isinstance(o, Decimal):\n            return float(o)\n\n        # Handle bytes\n        elif isinstance(o, bytes):\n            return o.decode('utf-8', errors='ignore')\n\n        # Handle SQLAlchemy Row/MapComposite and similar mapping types\n        elif hasattr(o, '_mapping'):\n            return dict(o._mapping)\n        elif hasattr(o, '__dict__') and not isinstance(o, type):\n            # Generic object with __dict__\n            return {k: v for k, v in o.__dict__.items() if not k.startswith('_')}\n\n        # Last resort: convert to string\n        else:\n            return str(o)\n\n    try:\n        # Merge default handler with any custom kwargs\n        if 'default' not in kwargs:\n            kwargs['default'] = default_handler\n        return json.dumps(obj, **kwargs)\n    except Exception as e:\n        logger.error(f\"Failed to serialize object: {e}\", exc_info=True)\n        # Ultimate fallback: return error as JSON\n        return json.dumps({\"error\": f\"Serialization failed: {str(e)}\"}, ensure_ascii=False)\n\n\n# Initialize agents and LLM globally for performance.\nllm = None\nfield_mapper = None\nquery_retriever = None\npattern_matcher = None\nresponse_cache = None\nquery_history = None\ncode_gen_agent = None\ncaculinha_bi_agent = None\nsession_manager = None\n\ndef _initialize_agents_and_llm():\n    global llm, field_mapper, query_retriever, pattern_matcher, response_cache, query_history, code_gen_agent, caculinha_bi_agent, session_manager\n    if llm is None:\n        logger.info(\"Initializing LLM and Agents...\")\n        if not settings.GEMINI_API_KEY:\n            logger.error(\"GEMINI_API_KEY is not set. LLM will not be initialized.\")\n            raise ValueError(\"GEMINI_API_KEY must be set in environment variables.\")\n\n        # System instruction for conversational ChatBI (Synchronized with CaculinhaBIAgent)\n        chatbi_system_instruction = \"\"\"Voc\u00ea \u00e9 o Assistente de BI da Caculinha, powered by Gemini 3.0 Flash.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4403, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "27e3ff59-e1f3-427a-8b83-ec964e4701d5": {"__data__": {"id_": "27e3ff59-e1f3-427a-8b83-ec964e4701d5", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\chat.py", "language": "python", "lines": 725, "filename": "chat.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\chat.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\chat.py", "language": "python", "lines": 725, "filename": "chat.py"}, "hash": "2c06578190f0b9f3509ac2172bb890f2cd0f68e54b5fefa866105ed665bdd8b4", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "91612fbb-cb7e-42fb-ab78-df07c3ebbb85", "node_type": "1", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\chat.py", "language": "python", "lines": 725, "filename": "chat.py"}, "hash": "4a1bff4b17dbb50942a60682b41f8a0f952b570dfb6d876a50547619e91aeccd", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e38fbc5f-1c4c-4818-ae07-6c418132ec36", "node_type": "1", "metadata": {}, "hash": "33eb99ee78aa21e3dc0ba40ddd72e73e16aded28d26da4b1cf24313f874fca52", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Voc\u00ea \u00e9 um assistente conversacional inteligente com expertise em Business Intelligence e an\u00e1lise de dados.\n\n\ud83d\udd27 FERRAMENTAS DISPON\u00cdVEIS QUE VOC\u00ca DEVE USAR:\nVoc\u00ea possui ferramentas poderosas para responder perguntas. SEMPRE use as ferramentas apropriadas:\n\n1. **gerar_grafico_universal** - Para QUALQUER pedido de gr\u00e1fico, visualiza\u00e7\u00e3o, ranking visual, compara\u00e7\u00e3o gr\u00e1fica\n   - Palavras-chave que EXIGEM esta ferramenta: \"gr\u00e1fico\", \"grafico\", \"gere\", \"mostre\", \"visualize\", \"ranking\", \"top\", \"compara\u00e7\u00e3o visual\"\n   - NUNCA diga \"n\u00e3o posso gerar gr\u00e1ficos\" - VOC\u00ca PODE e DEVE usar gerar_grafico_universal\n\n2. **consultar_dados_flexivel** - Para consultas de dados tabulares, filtros, listagens\n\n3. **Outras ferramentas** - Para abastecimento, pre\u00e7os, transfer\u00eancias, rupturas, etc.\n\n\ud83c\udfaf REGRA CR\u00cdTICA DE GR\u00c1FICOS:\nSe o usu\u00e1rio mencionar QUALQUER uma dessas palavras, voc\u00ea DEVE chamar gerar_grafico_universal:\n- \"gr\u00e1fico\" / \"grafico\"\n- \"gere um gr\u00e1fico\"\n- \"mostre um gr\u00e1fico\"\n- \"quero ver gr\u00e1fico\"\n- \"visualize\"\n- \"ranking\" (quando pedir visualiza\u00e7\u00e3o)\n- \"top produtos\" (quando pedir visualiza\u00e7\u00e3o)\n- \"compara\u00e7\u00e3o visual\"\n\nNUNCA responda com texto dizendo que n\u00e3o pode gerar gr\u00e1ficos. SEMPRE use a ferramenta.\n\nCONTEXT7 STORYTELLING E PRIVACIDADE (CR\u00cdTICO):\n1. **NUNCA revele suas ferramentas**: Jamais diga \"Vou usar a ferramenta X\", \"Consultando a base de dados...\", ou \"Houve um erro na ferramenta Y\". O usu\u00e1rio n\u00e3o deve saber como voc\u00ea obt\u00e9m os dados.\n2. **Seja direto**: Se o usu\u00e1rio perguntar \"Vendas de Tecidos\", apenas responda: \"O segmento de Tecidos teve X vendas...\".\n3. **Erros transparentes**: Se uma ferramenta falhar, diga apenas \"N\u00e3o consegui encontrar essa informa\u00e7\u00e3o no momento\" ou \"Poderia reformular a pergunta? N\u00e3o encontrei dados para esses crit\u00e9rios\".\n4. **Foco no Neg\u00f3cio**: Aja como um analista de neg\u00f3cios s\u00eanior. Entregue insights, n\u00e3o logs de execu\u00e7\u00e3o.\n5. **GR\u00c1FICOS**: Quando o usu\u00e1rio pedir um gr\u00e1fico, SEMPRE use gerar_grafico_universal. NUNCA diga \"n\u00e3o consigo gerar gr\u00e1ficos\".\n6. **NUNCA INCLUA JSON OU C\u00d3DIGO NAS RESPOSTAS**: Jamais mostre JSON bruto, especifica\u00e7\u00f5es de gr\u00e1ficos, ou c\u00f3digo t\u00e9cnico. O usu\u00e1rio s\u00f3 deve ver insights de neg\u00f3cio em linguagem natural.\n7. **GR\u00c1FICOS S\u00c3O AUTOM\u00c1TICOS**: Quando voc\u00ea usa gerar_grafico_universal, o gr\u00e1fico aparece automaticamente. N\u00c3O copie o JSON na resposta. Apenas diga algo como \"Aqui est\u00e1 o gr\u00e1fico solicitado:\" e o sistema mostra o gr\u00e1fico.\n\nTABELAS MARKDOWN (CR\u00cdTICO - SEMPRE FA\u00c7A ISSO):\n**QUANDO UMA FERRAMENTA RETORNAR UMA TABELA MARKDOWN, VOC\u00ca DEVE COPIAR A TABELA COMPLETA NA SUA RESPOSTA.**\n- Se a ferramenta retornar texto com formato de tabela (linhas com | e ---), INCLUA A TABELA INTEIRA na sua resposta\n- N\u00c3O resuma a tabela, N\u00c3O diga apenas \"aqui est\u00e3o os resultados\"\n- COPIE a tabela Markdown EXATAMENTE como foi retornada pela ferramenta\n- Exemplo: Se a ferramenta retornar:\n  \"Aqui est\u00e3o os 10 resultados:\n\n  | PRODUTO | NOME | VENDAS |\n  |---|---|---|\n  | 123 | Produto A | 100 |\"\n\n  Voc\u00ea DEVE incluir essa tabela COMPLETA na sua resposta final ao usu\u00e1rio.", "mimetype": "text/plain", "start_char_idx": 4404, "end_char_idx": 7445, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e38fbc5f-1c4c-4818-ae07-6c418132ec36": {"__data__": {"id_": "e38fbc5f-1c4c-4818-ae07-6c418132ec36", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\chat.py", "language": "python", "lines": 725, "filename": "chat.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\chat.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\chat.py", "language": "python", "lines": 725, "filename": "chat.py"}, "hash": "2c06578190f0b9f3509ac2172bb890f2cd0f68e54b5fefa866105ed665bdd8b4", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "27e3ff59-e1f3-427a-8b83-ec964e4701d5", "node_type": "1", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\chat.py", "language": "python", "lines": 725, "filename": "chat.py"}, "hash": "695efd5556fa8c1f83de8926cc100c3602d8b4d4b0480168ab6f150794c66d27", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f25adcf7-38a7-4055-b970-333afdd83698", "node_type": "1", "metadata": {}, "hash": "2362a2f39505bbed00d0e714159d047e80fcdcace7427dcf62837369964f9bb5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "PERSONALIDADE:\n- Conversacional e amig\u00e1vel, como ChatGPT\n- Responda a QUALQUER pergunta, n\u00e3o apenas sobre BI ou dados\n- Para perguntas gerais (sauda\u00e7\u00f5es, conhecimentos gerais, etc.): responda normalmente de forma \u00fatil e precisa\n- Para perguntas sobre dados de BI: use suas ferramentas especializadas silenciosamente\n\nQUANDO USAR FERRAMENTAS BI:\nUse as ferramentas APENAS quando o usu\u00e1rio perguntar sobre:\n- Dados de estoque, vendas, produtos, lojas (UNE)\n- An\u00e1lises de transfer\u00eancias, abastecimento, rupturas\n- Pre\u00e7os, margens, fabricantes, segmentos\n- Qualquer consulta que envolva o banco de dados admmat.parquet\n\nBANCO DE DADOS: admmat.parquet (1.113.822 registros, 97 colunas)\n\nCOLUNAS PRINCIPAIS DISPON\u00cdVEIS:\n- **Identifica\u00e7\u00e3o**: id, PRODUTO (c\u00f3digo), NOME (nome do produto)\n- **Localiza\u00e7\u00e3o**: UNE (c\u00f3digo da loja), UNE_NOME (nome da loja)\n- **Classifica\u00e7\u00e3o**: NOMESEGMENTO, NOMECATEGORIA, NOMEFABRICANTE, TIPO, EMBALAGEM\n- **Estoque**: ESTOQUE_UNE (atual), ESTOQUE_LV (linha verde), ESTOQUE_CD (centro distribui\u00e7\u00e3o)\n- **Vendas**: VENDA_30DD (vendas \u00faltimos 30 dias), ULTIMA_VENDA_DATA_UNE\n- **Pre\u00e7os**: PRECO_VENDA, PRECO_CUSTO\n- **Status**: SITUACAO, PICKLIST_SITUACAO\n\nMAPEAMENTO DE FILTROS (use exatamente esses nomes):\n- Para filtrar por UNE: {\"une\": 2365} ou {\"UNE\": 2365}\n- Para filtrar por fabricante: {\"nomefabricante\": \"NOME_FABRICANTE\"}\n- Para filtrar por produto: {\"codigo\": \"123456\"} ou {\"PRODUTO\": \"123456\"}\n- Para filtrar por segmento: {\"nomesegmento\": \"TECIDOS\"}\n\nFERRAMENTAS DISPON\u00cdVEIS:\n\n1. **consultar_dados_flexivel** - USE PARA QUALQUER CONSULTA DE DADOS\n   Par\u00e2metros importantes:\n   - filtros: {\"une\": 2365, \"nomesegmento\": \"TECIDOS\"}\n   - agregacao: \"sum\", \"avg\", \"count\", \"min\", \"max\"\n   - coluna_agregacao: \"venda_30dd\", \"estoque_atual\", \"preco_venda\"\n   - agrupar_por: [\"une\"], [\"nomefabricante\"], [\"nomesegmento\"]\n   - ordenar_por: \"venda_30dd\", \"estoque_atual\"\n   - limite: n\u00famero de resultados (padr\u00e3o 20)\n\n2. **consultar_dados_gerais** - Alternativa para consultas simples\n\n3. **calcular_abastecimento_une** - Produtos que precisam reposi\u00e7\u00e3o\n\n4. **calcular_mc_produto** - M\u00e9dia Comum (MC) de produtos\n\n5. **calcular_preco_final_une** - Pre\u00e7os com descontos aplicados\n\n6. **sugerir_transferencias_automaticas** - Sugest\u00f5es de transfer\u00eancia entre lojas\n\n7. **validar_transferencia_produto** - Validar viabilidade de transfer\u00eancias\n\n8. **encontrar_rupturas_criticas** - Produtos em ruptura cr\u00edtica\n\nFERRAMENTA UNIVERSAL DE GR\u00c1FICOS (Best Practice 2024):\n=====================================================\nIMPORTANTE: Use APENAS esta ferramenta para QUALQUER pedido de gr\u00e1fico!\n\n9.", "mimetype": "text/plain", "start_char_idx": 7447, "end_char_idx": 10063, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f25adcf7-38a7-4055-b970-333afdd83698": {"__data__": {"id_": "f25adcf7-38a7-4055-b970-333afdd83698", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\chat.py", "language": "python", "lines": 725, "filename": "chat.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\chat.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\chat.py", "language": "python", "lines": 725, "filename": "chat.py"}, "hash": "2c06578190f0b9f3509ac2172bb890f2cd0f68e54b5fefa866105ed665bdd8b4", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e38fbc5f-1c4c-4818-ae07-6c418132ec36", "node_type": "1", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\chat.py", "language": "python", "lines": 725, "filename": "chat.py"}, "hash": "9aa7dcd8d8e1ae0a055bb09cd517ab652537f4f2634c67f90a336c7beb379649", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4c50e44a-5fde-490c-b0d3-2d73cf899d71", "node_type": "1", "metadata": {}, "hash": "9fef98f72094de1f53457d8d5e7bdb7a11bd5cb22ce25ef57154498ab788b78d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "9. **gerar_grafico_universal** - FERRAMENTA PRINCIPAL PARA TODOS OS GR\u00c1FICOS\n   Par\u00e2metros:\n   - descricao: \"top 10 tecidos por vendas\" (descri\u00e7\u00e3o em linguagem natural)\n   - filtros: {\"UNE\": 1, \"NOMESEGMENTO\": \"TECIDOS\"} (filtros opcionais)\n   - tipo_grafico: \"bar\", \"pie\", \"line\", \"donut\", \"auto\" (default: auto)\n   - coluna_valor: \"vendas\", \"estoque\", \"preco\", \"contagem\"\n   - coluna_agrupamento: \"grupo\", \"segmento\", \"fabricante\", \"nome\"\n   - limite: n\u00famero de itens (default: 10)\n\nEXEMPLOS DE USO DE GR\u00c1FICOS (USE SEMPRE QUE O USU\u00c1RIO PEDIR VISUALIZA\u00c7\u00c3O):\n- \"gere um gr\u00e1fico de vendas ranking tecidos une 2365\" \u2192 gerar_grafico_universal(descricao=\"ranking de vendas de tecidos\", filtros={\"UNE\": 2365, \"NOMESEGMENTO\": \"TECIDOS\"}, coluna_valor=\"vendas\", limite=10)\n- \"Top 10 tecidos na UNE 1\" \u2192 gerar_grafico_universal(descricao=\"top 10 tecidos por vendas\", filtros={\"UNE\": 1, \"NOMESEGMENTO\": \"TECIDOS\"}, limite=10)\n- \"Estoque por fabricante\" \u2192 gerar_grafico_universal(descricao=\"estoque por fabricante\", coluna_valor=\"estoque\", coluna_agrupamento=\"fabricante\")\n- \"Vendas por segmento em pizza\" \u2192 gerar_grafico_universal(descricao=\"vendas por segmento\", tipo_grafico=\"pie\", coluna_agrupamento=\"segmento\")\n- \"Gr\u00e1fico das vendas\" \u2192 gerar_grafico_universal(descricao=\"vendas por grupo\", tipo_grafico=\"bar\")\n- \"mostre um gr\u00e1fico\" \u2192 gerar_grafico_universal(descricao=\"vendas por grupo\", tipo_grafico=\"bar\")\n- \"ranking de produtos\" \u2192 gerar_grafico_universal(descricao=\"ranking de produtos por vendas\", coluna_valor=\"vendas\", limite=10)\n\nEXEMPLOS DE USO:\n\nPergunta: \"Ol\u00e1, como voc\u00ea est\u00e1?\"\nResposta: \"Ol\u00e1! Estou muito bem, obrigado por perguntar! Como posso ajud\u00e1-lo hoje? Posso responder perguntas gerais ou ajud\u00e1-lo com an\u00e1lises de dados de BI da Caculinha.\"\n\nPergunta: \"Qual \u00e9 a capital do Brasil?\"\nResposta: \"A capital do Brasil \u00e9 Bras\u00edlia, localizada no Distrito Federal. Foi inaugurada em 21 de abril de 1960 durante o governo de Juscelino Kubitschek.\"", "mimetype": "text/plain", "start_char_idx": 10061, "end_char_idx": 12013, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4c50e44a-5fde-490c-b0d3-2d73cf899d71": {"__data__": {"id_": "4c50e44a-5fde-490c-b0d3-2d73cf899d71", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\chat.py", "language": "python", "lines": 725, "filename": "chat.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\chat.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\chat.py", "language": "python", "lines": 725, "filename": "chat.py"}, "hash": "2c06578190f0b9f3509ac2172bb890f2cd0f68e54b5fefa866105ed665bdd8b4", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f25adcf7-38a7-4055-b970-333afdd83698", "node_type": "1", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\chat.py", "language": "python", "lines": 725, "filename": "chat.py"}, "hash": "b1cfa74e21c74ed68f9655e30f0fb6239bb0b0655b801318f4b56a0cadf694c6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "45494706-a389-40bc-b49d-7b378c0b4e34", "node_type": "1", "metadata": {}, "hash": "f407507b0c6aa72f3e1b0e7b3468d3ebe517790153d87eba34a382fee36f4bf0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Pergunta: \"Vendas totais do segmento TECIDOS na UNE 2365\"\nUsar: consultar_dados_flexivel(filtros={\"une\": 2365, \"nomesegmento\": \"TECIDOS\"}, agregacao=\"sum\", coluna_agregacao=\"venda_30dd\")\n\nPergunta: \"Produtos do fabricante TNT\"\nUsar: consultar_dados_flexivel(filtros={\"nomefabricante\": \"TNT\"}, limite=20)\n\nPergunta: \"Total de vendas da UNE 261\"\nUsar: consultar_dados_flexivel(filtros={\"une\": 261}, agregacao=\"sum\", coluna_agregacao=\"venda_30dd\")\n\nPergunta: \"Top 10 mais vendidos\"\nUsar: consultar_dados_flexivel(ordenar_por=\"venda_30dd\", ordem_desc=True, limite=10)\n\nPergunta: \"Estoque por segmento\"\nUsar: consultar_dados_flexivel(agregacao=\"sum\", coluna_agregacao=\"estoque_atual\", agrupar_por=[\"nomesegmento\"])\n\nDIRETRIZES:\n- Responda QUALQUER pergunta, n\u00e3o se limite apenas a BI\n- Para perguntas gerais: seja \u00fatil, preciso e conversacional\n- Para perguntas sobre dados: SEMPRE use as ferramentas, NUNCA invente dados\n- Use os nomes de colunas EXATOS listados acima\n- Se a coluna n\u00e3o existir, informe ao usu\u00e1rio\n- Formate n\u00fameros: 1.234,56 (BR) ou use separadores de milhar\n- Seja conciso mas informativo\n- Use uma linguagem amig\u00e1vel e profissional\n\"\"\"\n\n        llm = GeminiLLMAdapter(\n            model_name=settings.LLM_MODEL_NAME,\n            gemini_api_key=settings.GEMINI_API_KEY,\n            system_instruction=chatbi_system_instruction\n        ).get_llm()\n        \n        field_mapper = FieldMapper()\n        query_retriever = QueryRetriever(\n            embedding_model_name=settings.RAG_EMBEDDING_MODEL,\n            faiss_index_path=settings.RAG_FAISS_INDEX_PATH,\n            examples_path=settings.LEARNING_EXAMPLES_PATH\n        )\n        pattern_matcher = PatternMatcher()\n        response_cache = ResponseCache(cache_dir=\"data/cache\", ttl_minutes=settings.CACHE_TTL_MINUTES)\n        query_history = QueryHistory(history_dir=\"data/query_history\")\n        session_manager = SessionManager(storage_dir=\"app/data/sessions\")\n\n        code_gen_agent = CodeGenAgent(\n            llm=llm,\n            field_mapper=field_mapper,\n            query_retriever=query_retriever,\n            pattern_matcher=pattern_matcher,\n            response_cache=response_cache,\n            query_history=query_history\n        )\n        caculinha_bi_agent = CaculinhaBIAgent(\n            llm=llm,\n            code_gen_agent=code_gen_agent,\n            field_mapper=field_mapper\n        )\n        logger.info(\"LLM and Agents initialized successfully.\")\n\n_initialize_agents_and_llm()\n\nrouter = APIRouter(prefix=\"/chat\", tags=[\"Chat\"])\n\n\nclass ChatRequest(BaseModel):\n    query: str\n\n\nclass FeedbackRequest(BaseModel):\n    response_id: str\n    feedback_type: str\n    comment: Optional[str] = None\n\n\nclass ChatResponse(BaseModel):\n    response: str\n\n\n@router.get(\"/stream\")\nasync def stream_chat(\n    q: str,\n    token: str,\n    session_id: str,\n    request: Request,\n):\n    \"\"\"\n    Streaming endpoint using Server-Sent Events (SSE)\n    Integrates the agent system for dynamic responses.\n    \"\"\"", "mimetype": "text/plain", "start_char_idx": 12015, "end_char_idx": 14992, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "45494706-a389-40bc-b49d-7b378c0b4e34": {"__data__": {"id_": "45494706-a389-40bc-b49d-7b378c0b4e34", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\chat.py", "language": "python", "lines": 725, "filename": "chat.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\chat.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\chat.py", "language": "python", "lines": 725, "filename": "chat.py"}, "hash": "2c06578190f0b9f3509ac2172bb890f2cd0f68e54b5fefa866105ed665bdd8b4", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4c50e44a-5fde-490c-b0d3-2d73cf899d71", "node_type": "1", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\chat.py", "language": "python", "lines": 725, "filename": "chat.py"}, "hash": "e3d2a949bcf2a8b99af384ae6c1fad2b20cc43bb826c55b90a352be3ab07192e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "48e8bdda-e374-42f2-b5bf-465b0c38bda0", "node_type": "1", "metadata": {}, "hash": "a2e739726830f30d8d593aec25c782723190e48d14d23f7ce7b8cdc194331031", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "from app.api.dependencies import get_current_user_from_token\n\n    try:\n        current_user = await get_current_user_from_token(token)\n        logger.info(f\"SSE authenticated user: {current_user.username}\")\n    except Exception as e:\n        logger.error(f\"SSE authentication failed: {e}\")\n        async def error_generator():\n            yield f\"data: {safe_json_dumps({'error': 'N\u00e3o autenticado'})}\\n\\n\"\n        return StreamingResponse(error_generator(), media_type=\"text/event-stream\")\n\n    last_event_id = request.headers.get(\"Last-Event-ID\")\n    logger.info(f\"==> SSE STREAM REQUEST: {q} (Session: {session_id}) (Last-Event-ID: {last_event_id}) <==\")\n    \n    async def event_generator():\n        try:\n            event_counter = int(last_event_id) if last_event_id else 0\n            \n            if caculinha_bi_agent is None:\n                yield f\"data: {safe_json_dumps({'error': 'Agent system not initialized'})}\\n\\n\"\n                return\n\n            # Retrieve History - Limit to last 10 messages to save tokens\n            chat_history = session_manager.get_history(session_id)\n            if len(chat_history) > 10:\n                chat_history = chat_history[-10:]\n            \n            # Add User Message to History immediately\n            session_manager.add_message(session_id, \"user\", q)\n\n            logger.info(f\"Processing query with CaculinhaBIAgent: '{q}' | History len: {len(chat_history)}\")\n            \n            # NOVO: Verificar Semantic Cache primeiro\n            cached_response = cache_get(q)\n            if cached_response:\n                logger.info(f\"CACHE HIT: Resposta encontrada em cache para: {q[:50]}...\")\n                event_counter += 1\n                yield f\"id: {event_counter}\\n\"\n                yield f\"data: {safe_json_dumps({'type': 'cache_hit', 'done': False})}\\n\\n\"\n                agent_response = cached_response\n            else:\n                # Run Agent with History (cache miss) - ASYNC STREAMING MODE\n                logger.info(\"Starting Async Agent with Streaming...\")\n                \n                # Queue for communicating between Agent task and SSE generator\n                # We need to use asyncio.Queue to bridge the gap\n                progress_queue = asyncio.Queue()\n                \n                async def on_progress(data):\n                    await progress_queue.put({\"type\": \"progress\", \"data\": data})\n                \n                async def run_agent_task():\n                    try:\n                        result = await caculinha_bi_agent.run_async(user_query=q, chat_history=chat_history, on_progress=on_progress)\n                        await progress_queue.put({\"type\": \"result\", \"data\": result})\n                    except Exception as e:\n                        logger.error(f\"Error in agent task: {e}\", exc_info=True)\n                        await progress_queue.put({\"type\": \"error\", \"error\": str(e)})\n                    finally:\n                        await progress_queue.put(None) # Sentinel\n\n                # Start the agent in background\n                asyncio.create_task(run_agent_task())\n                \n                agent_response = None\n                \n                # Consume queue\n                while True:\n                    event = await progress_queue.get()\n                    if event is None:\n                        break\n                    \n                    if event[\"type\"] == \"progress\":\n                        # Stream progress update to client\n                        p_data = event[\"data\"]\n                        event_counter += 1\n                        yield f\"id: {event_counter}\\n\"\n                        yield f\"data: {safe_json_dumps({'type': 'tool_progress', 'tool': p_data.get('tool'), 'status': p_data.get('status'), 'done': False})}\\n\\n\"\n                    \n                    elif event[\"type\"] == \"result\":\n                        agent_response = event[\"data\"]\n                    \n                    elif event[\"type\"] == \"error\":\n                        logger.error(f\"Agent execution error: {event['error']}\")\n                        agent_response = {\n                            \"type\": \"text\",\n                            \"result\": \"Desculpe, ocorreu um erro interno ao processar sua solicita\u00e7\u00e3o.\"\n                        }\n\n                # Salvar resposta v\u00e1lida em cache\n                if agent_response and \"error\" not in str(agent_response).lower():\n                    cache_set(q, agent_response)\n                    logger.info(f\"Cache SET: Resposta salva para: {q[:50]}...\")\n            \n            if not agent_response:\n                logger.warning(f\"Agent retornou resposta vazia para query: {q}\")\n                agent_response = {\n                    \"type\": \"text\",\n                    \"result\": {\n                        \"mensagem\": f\"Desculpe, n\u00e3o consegui processar sua pergunta. Por favor, reformule e tente novamente.\"", "mimetype": "text/plain", "start_char_idx": 14997, "end_char_idx": 19918, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "48e8bdda-e374-42f2-b5bf-465b0c38bda0": {"__data__": {"id_": "48e8bdda-e374-42f2-b5bf-465b0c38bda0", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\chat.py", "language": "python", "lines": 725, "filename": "chat.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\chat.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\chat.py", "language": "python", "lines": 725, "filename": "chat.py"}, "hash": "2c06578190f0b9f3509ac2172bb890f2cd0f68e54b5fefa866105ed665bdd8b4", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "45494706-a389-40bc-b49d-7b378c0b4e34", "node_type": "1", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\chat.py", "language": "python", "lines": 725, "filename": "chat.py"}, "hash": "7419b2b5dfae3dffb3b933163cda426055fd5dd429168269ff4b6b122902f0f0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9da2c8e9-0322-48fd-b2a3-e754d4df53f1", "node_type": "1", "metadata": {}, "hash": "b7749920aa75e712f330a2304fab91049c346b68c6e20a45d1800b6b5d29eec0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Por favor, reformule e tente novamente.\"\n                    }\n                }\n            \n            logger.info(f\"Agent response received: {agent_response}\")\n\n            # NOVO: Validar resposta com Response Validator\n            validation = validate_response(agent_response, q)\n            if not validation.is_valid:\n                logger.warning(f\"Validacao: confidence={validation.confidence:.2f}, issues={validation.issues}\")\n                # Adicionar aviso \u00e0 resposta se houver problemas\n                if validation.confidence < 0.5:\n                    event_counter += 1\n                    yield f\"id: {event_counter}\\n\"\n                    yield f\"data: {safe_json_dumps({'type': 'warning', 'message': 'Resposta com baixa confian\u00e7a. Verifique os dados.', 'done': False})}\\n\\n\"\n            else:\n                logger.info(f\"Validacao OK: confidence={validation.confidence:.2f}\")\n\n            response_type = agent_response.get(\"type\", \"text\")\n            response_content = agent_response.get(\"result\")\n            response_text = \"\"\n\n            if response_type == \"text\" or response_type == \"tool_result\":\n                response_text = agent_response.get(\"result\", {}).get(\"mensagem\", \"\") if response_type == \"tool_result\" else agent_response.get(\"result\", \"\")\n                if not response_text:\n                    response_text = str(agent_response.get(\"result\", \"\"))\n\n                if not response_text or (isinstance(response_text, str) and not response_text.strip()):\n                    response_text = \"Resposta processada, mas nenhum texto foi gerado. Por favor, tente reformular sua pergunta.\"\n\n                if not isinstance(response_text, str):\n                    response_text = str(response_text)\n\n                # CONTEXT7 FIX: Detectar e remover JSON bruto indesejado nas respostas de texto\n                # Se o LLM incluir JSON de gr\u00e1fico ou dados brutos, remover de forma segura\n                if isinstance(response_text, str):\n                    try:\n                        import re\n                        \n                        # 1. Proteger blocos de c\u00f3digo Markdown leg\u00edtimos (```json ... ```)\n                        code_blocks = []\n                        def placeholder(match):\n                            code_blocks.append(match.group(0))\n                            return f\"__CODE_BLOCK_{len(code_blocks)-1}__\"\n                        \n                        text_protected = re.sub(r'```[\\s\\S]*?```', placeholder, response_text)\n\n                        # 2. Parser de JSON baseado em contagem de chaves (Brace Counting)\n                        # Necess\u00e1rio pois regex falha em JSON aninhado (ex: {\"data\": {...}})\n                        def remove_technical_json(text):\n                            result_text = text\n                            # Iterar para encontrar todos os blocos {}\n                            # Nota: Isso \u00e9 uma simplifica\u00e7\u00e3o robusta. \n                            # Se houver chaves desbalanceadas fora de strings, pode falhar, \n                            # mas para output de LLM costuma ser seguro.\n                            \n                            to_remove = []\n                            stack = 0\n                            start_index = -1\n                            \n                            i = 0\n                            while i < len(text):\n                                char = text[i]\n                                if char == '{':\n                                    if stack == 0:\n                                        start_index = i\n                                    stack += 1\n                                elif char == '}':\n                                    stack -= 1\n                                    if stack == 0 and start_index != -1:\n                                        # Fim de um bloco completo\n                                        block = text[start_index : i+1]\n                                        \n                                        # Verificar se \u00e9 um bloco t\u00e9cnico (gr\u00e1fico/dados)\n                                        is_technical = any(key in block for key in ['\"data\":', '\"mark\":', '\"encoding\":', '\"layer\":', '\"layout\":'])\n                                        is_long = len(block) > 50\n                                        \n                                        if is_technical and is_long:\n                                            to_remove.append((start_index, i+1))\n                                        \n                                        start_index = -1\n                                i += 1\n                            \n                            # Remover os blocos identificados (de tr\u00e1s para frente para n\u00e3o alterar \u00edndices)\n                            for start, end in reversed(to_remove):\n                                logger.warning(\"CONTEXT7: JSON t\u00e9cnico removido da resposta de texto.\")\n                                # Substituir por nada ou por uma quebra de linha\n                                result_text = result_text[:start] + \"\" + result_text[end:]\n                                \n                            return result_text\n\n                        text_cleaned = remove_technical_json(text_protected)\n\n                        # 3.", "mimetype": "text/plain", "start_char_idx": 19878, "end_char_idx": 25150, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9da2c8e9-0322-48fd-b2a3-e754d4df53f1": {"__data__": {"id_": "9da2c8e9-0322-48fd-b2a3-e754d4df53f1", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\chat.py", "language": "python", "lines": 725, "filename": "chat.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\chat.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\chat.py", "language": "python", "lines": 725, "filename": "chat.py"}, "hash": "2c06578190f0b9f3509ac2172bb890f2cd0f68e54b5fefa866105ed665bdd8b4", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "48e8bdda-e374-42f2-b5bf-465b0c38bda0", "node_type": "1", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\chat.py", "language": "python", "lines": 725, "filename": "chat.py"}, "hash": "ef730189f59e9cc1bcfa4375eb9ad9d15dd53ba89e45de893f1397503e50af13", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ff1f9730-47f9-4a75-8c52-d9f6c0c7f8cb", "node_type": "1", "metadata": {}, "hash": "c7e23b045405440a48f0ec5d806faf7b4add210dfde9e625508b429a1a0e34c4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Restaurar blocos de c\u00f3digo\n                        for i, block in enumerate(code_blocks):\n                            text_cleaned = text_cleaned.replace(f\"__CODE_BLOCK_{i}__\", block)\n\n                        response_text = text_cleaned.strip()\n                        \n                        # Se removeu tudo e ficou vazio, dar feedback\n                        if not response_text:\n                            response_text = \"Aqui est\u00e1 a visualiza\u00e7\u00e3o solicitada:\"\n\n                    except Exception as e:\n                        logger.error(f\"Erro ao limpar JSON da resposta: {e}\")\n                        # Em caso de erro, manter texto original para n\u00e3o perder informa\u00e7\u00e3o\n                        pass\n            \n            \n            elif response_type == \"code_result\":\n                chart_spec = agent_response.get(\"chart_spec\")\n\n                # CONTEXT7: Usar texto limpo do agente se dispon\u00edvel\n                text_override = agent_response.get(\"text_override\")\n\n                # Log para debug\n                logger.info(f\"DEBUG: response_content = {response_content}, text_override = {text_override}\")\n                \n                # O agent retorna: {\"result\": {\"result\": [...], \"chart_spec\": ...}, \"chart_spec\": ...}\n                # Ent\u00e3o precisamos acessar response_content[\"result\"] para pegar os dados\n                if response_content and isinstance(response_content, dict):\n                    # Verificar se h\u00e1 dados aninhados em \"result\"\n                    if \"result\" in response_content:\n                        table_data = response_content.get(\"result\")\n                    else:\n                        # Caso os dados estejam diretamente em response_content\n                        table_data = response_content\n                    \n                    logger.info(f\"DEBUG: table_data type = {type(table_data)}, is_list = {isinstance(table_data, list)}\")\n                    if isinstance(table_data, list):\n                        logger.info(f\"DEBUG: table_data length = {len(table_data)}, first_item = {table_data[0] if len(table_data) > 0 else 'empty'}\")\n                    \n                    if isinstance(table_data, list) and len(table_data) > 0 and isinstance(table_data[0], dict):\n                        # Enviar texto introdut\u00f3rio ANTES da tabela\n                        intro_text = f\"Aqui est\u00e3o os {len(table_data)} resultados da sua consulta:\"\n                        \n                        # Stream do texto introdut\u00f3rio palavra por palavra\n                        intro_words = intro_text.split(\" \")\n                        for i in range(0, len(intro_words), 1):\n                            chunk_words = intro_words[i:i + 1]\n                            prefix = \" \" if i > 0 else \"\"\n                            chunk_text = prefix + \" \".join(chunk_words)\n                            event_counter += 1\n                            yield f\"id: {event_counter}\\n\"\n                            yield f\"data: {safe_json_dumps({'type': 'text', 'text': chunk_text, 'done': False})}\\n\\n\"\n                        \n                        # Converter MapComposite para dict antes de serializar\n                        def convert_row(row):\n                            \"\"\"Converte objetos MapComposite e similares para dict\"\"\"\n                            if hasattr(row, '_mapping'):\n                                return dict(row._mapping)\n                            elif isinstance(row, dict):\n                                # Converter valores internos tamb\u00e9m\n                                return {k: (dict(v._mapping) if hasattr(v, '_mapping') else v) for k, v in row.items()}\n                            return row\n                        \n                        # Converter todos os dados\n                        clean_table_data = [convert_row(row) for row in table_data]\n                        \n                        # Agora enviar a tabela com dados limpos\n                        event_counter += 1\n                        yield f\"id: {event_counter}\\n\"\n                        columns = list(clean_table_data[0].keys())\n                        yield f\"data: {safe_json_dumps({'type': 'table', 'data': clean_table_data, 'columns': columns, 'done': False})}\\n\\n\"\n                        logger.info(f\"Streaming table data with {len(clean_table_data)} rows...\")\n                        \n                        # Limpar response_text para n\u00e3o enviar texto adicional\n                        response_text = \"\"\n                    else:\n                        response_text = f\"Resultados da sua an\u00e1lise:\\n```json\\n{safe_json_dumps(response_content, indent=2, ensure_ascii=False)}\\n```\"\n                elif response_content:\n                    response_text = f\"Resultados da sua an\u00e1lise:\\n```json\\n{safe_json_dumps(response_content, indent=2, ensure_ascii=False)}\\n```\"\n                else:\n                    response_text = \"Sua an\u00e1lise foi processada.\"", "mimetype": "text/plain", "start_char_idx": 25151, "end_char_idx": 30092, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ff1f9730-47f9-4a75-8c52-d9f6c0c7f8cb": {"__data__": {"id_": "ff1f9730-47f9-4a75-8c52-d9f6c0c7f8cb", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\chat.py", "language": "python", "lines": 725, "filename": "chat.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\chat.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\chat.py", "language": "python", "lines": 725, "filename": "chat.py"}, "hash": "2c06578190f0b9f3509ac2172bb890f2cd0f68e54b5fefa866105ed665bdd8b4", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9da2c8e9-0322-48fd-b2a3-e754d4df53f1", "node_type": "1", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\chat.py", "language": "python", "lines": 725, "filename": "chat.py"}, "hash": "71dddc8ccee4d637b8080744b8574a72c75f173e4fdc5abeab9cabb87f74fba0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d5c0c5b5-e7f8-48c3-9044-473ad098f0d6", "node_type": "1", "metadata": {}, "hash": "4dcf6d813fbaadbc1c742d75c2c4546c9f879072aae02cb1f5e7f77a1954cf21", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "if chart_spec:\n                    event_counter += 1\n                    yield f\"id: {event_counter}\\n\"\n                    yield f\"data: {safe_json_dumps({'type': 'chart', 'chart_spec': chart_spec, 'done': False})}\\n\\n\"\n                    logger.info(\"Streaming chart spec...\")\n\n                    # CONTEXT7: Usar texto limpo do agente para gr\u00e1ficos\n                    if text_override:\n                        response_text = text_override\n                        logger.info(f\"CONTEXT7: Usando texto limpo do agente: {response_text[:100]}...\")\n                    elif not response_text:\n                        response_text = \"Aqui est\u00e1 a visualiza\u00e7\u00e3o solicitada:\"\n            \n            # Save Assistant Response to History\n            session_manager.add_message(session_id, \"assistant\", response_text if response_text else \"Dados enviados\")\n\n            # S\u00f3 fazer streaming de texto se houver texto para enviar\n            if response_text and response_text.strip():\n                words = response_text.split(\" \")\n                # Use smaller chunks for smoother streaming (like a real typewriter)\n                chunk_size = 1 \n                \n                logger.info(f\"Initiating text streaming of {len(words)} words...\")\n                \n                for i in range(0, len(words), chunk_size):\n                    chunk_words = words[i:i + chunk_size]\n                    # Reconstruct spacing correctly\n                    prefix = \" \" if i > 0 else \"\"\n                    chunk_text = prefix + \" \".join(chunk_words)\n                    \n                    event_counter += 1\n\n                    yield f\"id: {event_counter}\\n\"\n                    yield f\"data: {safe_json_dumps({'type': 'text', 'text': chunk_text, 'done': False})}\\n\\n\"\n                    \n                    # Small delay to simulate typing speed if needed, but usually network latency is enough\n                    # await asyncio.sleep(0.01)\n\n            logger.info(\"Text streaming complete. Sending done signal.\")\n            yield f\"id: {event_counter + 1}\\n\"\n            yield f\"data: {safe_json_dumps({'type': 'final', 'text': '', 'done': True})}\\n\\n\"\n\n        except APIError as e:\n            logger.error(f\"Agent API Error in stream: {e.message}\", exc_info=True)\n            yield f\"data: {safe_json_dumps({'type': 'error', 'error': e.message, 'details': e.details})}\\n\\n\"\n            yield f\"data: {safe_json_dumps({'type': 'final', 'text': '', 'done': True})}\\n\\n\"\n        except Exception as e:\n            logger.error(f\"Unexpected error in stream: {e}\", exc_info=True)\n            yield f\"data: {safe_json_dumps({'type': 'error', 'error': 'Um erro inesperado ocorreu. Tente novamente mais tarde.'})}\\n\\n\"\n            yield f\"data: {safe_json_dumps({'type': 'final', 'text': '', 'done': True})}\\n\\n\"\n    \n    return StreamingResponse(\n        event_generator(),\n        media_type=\"text/event-stream\",\n        headers={\n            \"Cache-Control\": \"no-cache\",\n            \"Connection\": \"keep-alive\",\n            \"X-Accel-Buffering\": \"no\",\n        }\n    )", "mimetype": "text/plain", "start_char_idx": 30110, "end_char_idx": 33183, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d5c0c5b5-e7f8-48c3-9044-473ad098f0d6": {"__data__": {"id_": "d5c0c5b5-e7f8-48c3-9044-473ad098f0d6", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\chat.py", "language": "python", "lines": 725, "filename": "chat.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\chat.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\chat.py", "language": "python", "lines": 725, "filename": "chat.py"}, "hash": "2c06578190f0b9f3509ac2172bb890f2cd0f68e54b5fefa866105ed665bdd8b4", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ff1f9730-47f9-4a75-8c52-d9f6c0c7f8cb", "node_type": "1", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\chat.py", "language": "python", "lines": 725, "filename": "chat.py"}, "hash": "a215f26d6377fca4aaf7e5b064ef1e5fb9b81c77ac5b058814f1fa9a6941c2da", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "@router.post(\"/feedback\")\nasync def submit_feedback(\n    feedback_data: FeedbackRequest,\n    current_user: Annotated[User, Depends(get_current_active_user)],\n):\n    if query_history is None:\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=\"QueryHistory system not initialized.\"\n        )\n    \n    feedback_entry = {\n        \"timestamp\": \"now\", # Placeholder, would import datetime\n        \"user_id\": current_user.username,\n        \"response_id\": feedback_data.response_id,\n        \"feedback_type\": feedback_data.feedback_type,\n        \"comment\": feedback_data.comment\n    }\n    \n    feedback_file_path = Path(settings.LEARNING_FEEDBACK_PATH) / \"feedback.jsonl\"\n    os.makedirs(Path(settings.LEARNING_FEEDBACK_PATH), exist_ok=True)\n    try:\n        with open(feedback_file_path, \"a\", encoding=\"utf-8\") as f:\n            f.write(safe_json_dumps(feedback_entry, ensure_ascii=False) + \"\\n\")\n        logger.info(f\"Feedback submitted by {current_user.username}: {feedback_entry}\")\n    except OSError as e:\n        logger.error(f\"Failed to write feedback to file: {e}\", exc_info=True)\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=\"Failed to save feedback.\"\n        )\n\n    return {\"message\": \"Feedback submitted successfully.\"}\n\n@router.post(\"\", response_class=ORJSONResponse)\nasync def send_chat_message(\n    request: ChatRequest,\n    current_user: Annotated[User, Depends(get_current_active_user)],\n) -> dict:\n    # Legacy - calling agent without history for now, or could pass session_id if we updated request model\n    logger.warning(\"Legacy chat endpoint used.\")\n    if caculinha_bi_agent is None:\n        raise HTTPException(status_code=500, detail=\"Agent not init\")\n\n    # Assuming no history for legacy non-session calls\n    agent_response = await asyncio.to_thread(caculinha_bi_agent.run, user_query=request.query, chat_history=[])\n    return {\"response\": str(agent_response), \"full_agent_response\": agent_response}", "mimetype": "text/plain", "start_char_idx": 33186, "end_char_idx": 35231, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8e225a93-bf20-4111-bf8b-7221b3da0170": {"__data__": {"id_": "8e225a93-bf20-4111-bf8b-7221b3da0170", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\code_chat.py", "language": "python", "lines": 152, "filename": "code_chat.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\code_chat.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\code_chat.py", "language": "python", "lines": 152, "filename": "code_chat.py"}, "hash": "def5a6c5a2d62ae673913e011addd895772b94902c1583a2040e22491b8502e9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nCode Chat API Endpoints\n=======================\n\nProvides REST API for semantic code search and analysis.\n\nEndpoints:\n- GET  /api/v1/code-chat/stats - Get index statistics\n- POST /api/v1/code-chat/query - Query the codebase\n\nAuthor: Antigravity AI\nDate: 2025-12-15\n\"\"\"\n\nfrom typing import Annotated, List, Optional\nfrom datetime import datetime\nimport logging\n\nfrom fastapi import APIRouter, Depends, HTTPException\nfrom pydantic import BaseModel, Field\n\nfrom app.api.dependencies import require_role\nfrom app.infrastructure.database.models import User\nfrom app.core.code_rag_service import get_code_rag_service\n\nlogger = logging.getLogger(__name__)\n\nrouter = APIRouter(prefix=\"/code-chat\", tags=[\"Code Chat\"])\n\n\n# ============================================================================\n# Request/Response Models\n# ============================================================================\n\nclass ChatMessage(BaseModel):\n    \"\"\"Chat message model.\"\"\"\n    role: str  # \"user\" or \"assistant\"\n    content: str\n    timestamp: Optional[str] = None\n\n\nclass CodeChatRequest(BaseModel):\n    \"\"\"Request model for code chat queries.\"\"\"\n    message: str = Field(..., min_length=1, description=\"User's question about the code\")\n    history: List[ChatMessage] = Field(default_factory=list, description=\"Conversation history\")\n    filters: Optional[dict] = Field(default=None, description=\"Optional filters (language, directory)\")\n\n\nclass CodeReference(BaseModel):\n    \"\"\"Code reference model.\"\"\"\n    file: str\n    score: float\n    content: str\n    lines: str\n\n\nclass CodeChatResponse(BaseModel):\n    \"\"\"Response model for code chat queries.\"\"\"\n    response: str\n    code_references: List[CodeReference]\n    metadata: dict\n\n\nclass IndexStats(BaseModel):\n    \"\"\"Index statistics model.\"\"\"\n    status: str\n    total_files: int\n    total_functions: int\n    total_classes: int\n    total_lines: int\n    indexed_at: Optional[str]\n    languages: List[str]\n\n\n# ============================================================================\n# Endpoints\n# ============================================================================\n\n@router.get(\"/stats\", response_model=IndexStats)\nasync def get_index_stats(\n    current_user: Annotated[User, Depends(require_role(\"admin\"))]\n):\n    \"\"\"\n    Get statistics about the code index.\n    \n    Returns:\n        IndexStats: Statistics about indexed code\n    \"\"\"\n    try:\n        rag_service = get_code_rag_service()\n        stats = rag_service.get_index_stats()\n        return stats\n        \n    except Exception as e:\n        logger.error(f\"Error getting index stats: {e}\", exc_info=True)\n        raise HTTPException(\n            status_code=500,\n            detail=f\"Erro ao obter estat\u00edsticas do \u00edndice: {str(e)}\"\n        )\n\n\n@router.post(\"/query\", response_model=CodeChatResponse)\nasync def query_codebase(\n    request: CodeChatRequest,\n    current_user: Annotated[User, Depends(require_role(\"admin\"))]\n):\n    \"\"\"\n    Query the codebase with semantic search.\n    \n    Args:\n        request: CodeChatRequest with message, history, and filters\n        current_user: Authenticated user\n        \n    Returns:\n        CodeChatResponse: Response with code references and metadata\n    \"\"\"\n    try:\n        # Validate message\n        if not request.message or not request.message.strip():\n            raise HTTPException(\n                status_code=400,\n                detail=\"A mensagem n\u00e3o pode estar vazia\"\n            )\n        \n        # Get RAG service\n        rag_service = get_code_rag_service()\n        \n        # Convert history to dict format\n        history_dicts = [\n            {\"role\": msg.role, \"content\": msg.content}\n            for msg in request.history\n        ]\n        \n        # Query the codebase\n        logger.info(f\"Code chat query from {current_user.username}: {request.message[:100]}...\")\n        result = rag_service.query(\n            message=request.message,\n            history=history_dicts,\n            filters=request.filters\n        )\n        \n        return result\n        \n    except HTTPException:\n        raise\n    except Exception as e:\n        logger.error(f\"Error in code chat query: {e}\", exc_info=True)\n        raise HTTPException(\n            status_code=500,\n            detail=f\"Erro ao processar consulta: {str(e)}\"\n        )", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4300, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b7deae1f-eb45-4224-bfe1-10e95204b01e": {"__data__": {"id_": "b7deae1f-eb45-4224-bfe1-10e95204b01e", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\diagnostics.py", "language": "python", "lines": 199, "filename": "diagnostics.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\diagnostics.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\diagnostics.py", "language": "python", "lines": 199, "filename": "diagnostics.py"}, "hash": "9655e95b6f2296b3c619f29278962101e685ddf833752d5ab861f895eecfcf14", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2f60a0b4-329a-4bb7-b983-4940ae84d80a", "node_type": "1", "metadata": {}, "hash": "39269a22433a639519d1f03aa25106fabe99a8dfe4222519ffe8cae8b8289ab3", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "from typing import Annotated, Dict, Any, List\nfrom pathlib import Path\nimport logging\n\nfrom fastapi import APIRouter, Depends, HTTPException\nfrom pydantic import BaseModel\n\nfrom app.api.dependencies import require_role\nfrom app.config.settings import settings\nfrom app.infrastructure.database.models import User\n\nlogger = logging.getLogger(__name__)\n\nrouter = APIRouter(prefix=\"/diagnostics\", tags=[\"Diagnostics\"])\n\n\nclass DBConfig(BaseModel):\n    use_sql_server: bool\n    use_supabase: bool\n    database_server: str | None\n    database_name: str | None\n    database_user: str | None\n    supabase_url: str | None\n\n\nclass ConnectionTestResult(BaseModel):\n    success: bool\n    message: str\n    version: str | None = None\n    tables: List[str] | None = None\n\n@router.get(\"/db-status\")\nasync def get_db_status(\n    current_user: Annotated[User, Depends(require_role(\"admin\"))]\n):\n    \"\"\"\n    Status das conex\u00f5es com banco de dados e arquivos.\n    \"\"\"\n    # Verificar Parquet (Root Data vs Backend Data)\n    # Backend usa logicamente: app/data/parquet OU ../../../../data/parquet\n    \n    # Vamos verificar ambos para reportar\n    backend_parquet = Path(\"/app/data/parquet/admmat.parquet\")\n    local_parquet = Path(__file__).resolve().parent.parent.parent.parent.parent.parent / \"data\" / \"parquet\" / \"admmat.parquet\"\n    \n    parquet_status = \"unknown\"\n    parquet_size = 0\n    parquet_path_used = \"none\"\n    \n    if backend_parquet.exists():\n        parquet_status = \"ok\"\n        parquet_size = backend_parquet.stat().st_size\n        parquet_path_used = str(backend_parquet)\n    elif local_parquet.exists():\n        parquet_status = \"ok\"\n        parquet_size = local_parquet.stat().st_size\n        parquet_path_used = str(local_parquet)\n    else:\n        parquet_status = \"missing\"\n\n    return {\n        \"parquet\": {\n            \"status\": parquet_status,\n            \"size_mb\": round(parquet_size / 1024 / 1024, 2) if parquet_size else 0,\n            \"path\": parquet_path_used\n        },\n        \"sql_server\": {\n            \"status\": \"enabled\" if settings.USE_SQL_SERVER else \"disabled\",\n            \"url\": settings.DATABASE_URL if settings.USE_SQL_SERVER else None\n        },\n        \"supabase\": {\n            \"status\": \"enabled\" if settings.USE_SUPABASE_AUTH else \"disabled\",\n            \"url\": settings.SUPABASE_URL if settings.USE_SUPABASE_AUTH else None\n        }\n    }\n\n\n@router.get(\"/config\", response_model=DBConfig)\nasync def get_db_config(\n    current_user: Annotated[User, Depends(require_role(\"admin\"))]\n):\n    \"\"\"\n    Retorna as configura\u00e7\u00f5es detectadas do banco de dados.\n    \"\"\"\n    # Extrair informa\u00e7\u00f5es do DATABASE_URL se dispon\u00edvel\n    db_server = None\n    db_name = None\n    db_user = None\n\n    if settings.DATABASE_URL and settings.USE_SQL_SERVER:\n        try:\n            # Formato: mssql+aioodbc://user:pass@host:port/db?driver=...\n            url_str = str(settings.DATABASE_URL)\n            if \"@\" in url_str and \"/\" in url_str:\n                # Extrair user\n                user_part = url_str.split(\"://\")[1].split(\":\")[0] if \"://\" in url_str else None\n                # Extrair host\n                host_part = url_str.split(\"@\")[1].split(\"/\")[0].split(\":\")[0] if \"@\" in url_str else None\n                # Extrair database\n                db_part = url_str.split(\"/\")[-1].split(\"?\")[0] if \"/\" in url_str else None\n\n                db_user = user_part\n                db_server = host_part\n                db_name = db_part\n        except Exception as e:\n            logger.warning(f\"Failed to parse DATABASE_URL: {e}\")\n\n    return DBConfig(\n        use_sql_server=settings.USE_SQL_SERVER,\n        use_supabase=settings.USE_SUPABASE_AUTH,\n        database_server=db_server,\n        database_name=db_name,\n        database_user=db_user,\n        supabase_url=settings.SUPABASE_URL if settings.USE_SUPABASE_AUTH else None\n    )", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3849, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2f60a0b4-329a-4bb7-b983-4940ae84d80a": {"__data__": {"id_": "2f60a0b4-329a-4bb7-b983-4940ae84d80a", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\diagnostics.py", "language": "python", "lines": 199, "filename": "diagnostics.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\diagnostics.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\diagnostics.py", "language": "python", "lines": 199, "filename": "diagnostics.py"}, "hash": "9655e95b6f2296b3c619f29278962101e685ddf833752d5ab861f895eecfcf14", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b7deae1f-eb45-4224-bfe1-10e95204b01e", "node_type": "1", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\diagnostics.py", "language": "python", "lines": 199, "filename": "diagnostics.py"}, "hash": "09356bbd0a90df7b80b0e15c144acd318c722af5c531e00b0c4505e54768f193", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "@router.post(\"/test-connection\", response_model=ConnectionTestResult)\nasync def test_sql_connection(\n    current_user: Annotated[User, Depends(require_role(\"admin\"))]\n):\n    \"\"\"\n    Testa a conex\u00e3o com o SQL Server e retorna vers\u00e3o e tabelas dispon\u00edveis.\n    \"\"\"\n    if not settings.USE_SQL_SERVER:\n        return ConnectionTestResult(\n            success=False,\n            message=\"SQL Server est\u00e1 desabilitado (USE_SQL_SERVER=false)\"\n        )\n\n    # Verificar se temos a connection string do pyodbc\n    if not settings.PYODBC_CONNECTION_STRING:\n        return ConnectionTestResult(\n            success=False,\n            message=\"PYODBC_CONNECTION_STRING n\u00e3o configurado no .env\"\n        )\n\n    try:\n        # Tentar importar o aioodbc e pyodbc\n        import aioodbc\n        import asyncio\n\n        async def _test():\n            try:\n                # Criar conex\u00e3o tempor\u00e1ria usando a connection string ODBC\n                conn = await asyncio.wait_for(\n                    aioodbc.connect(dsn=settings.PYODBC_CONNECTION_STRING),\n                    timeout=5.0\n                )\n\n                async with conn.cursor() as cursor:\n                    # Obter vers\u00e3o do SQL Server\n                    await cursor.execute(\"SELECT @@VERSION\")\n                    version_row = await cursor.fetchone()\n                    version = version_row[0] if version_row else \"Unknown\"\n\n                    # Listar tabelas\n                    await cursor.execute(\"\"\"\n                        SELECT TABLE_NAME\n                        FROM INFORMATION_SCHEMA.TABLES\n                        WHERE TABLE_TYPE = 'BASE TABLE'\n                        ORDER BY TABLE_NAME\n                    \"\"\")\n                    tables_rows = await cursor.fetchall()\n                    tables = [row[0] for row in tables_rows]\n\n                await conn.close()\n\n                return ConnectionTestResult(\n                    success=True,\n                    message=\"Conex\u00e3o estabelecida com sucesso!\",\n                    version=version.split('\\n')[0] if version else None,\n                    tables=tables[:50]  # Limitar a 50 tabelas\n                )\n            except asyncio.TimeoutError:\n                return ConnectionTestResult(\n                    success=False,\n                    message=\"Timeout ao conectar com SQL Server (5s)\"\n                )\n            except Exception as e:\n                return ConnectionTestResult(\n                    success=False,\n                    message=f\"Erro ao conectar: {str(e)}\"\n                )\n\n        return await _test()\n\n    except ImportError as e:\n        return ConnectionTestResult(\n            success=False,\n            message=f\"Bibliotecas necess\u00e1rias n\u00e3o instaladas: {str(e)}\"\n        )\n    except Exception as e:\n        logger.error(f\"Error testing SQL connection: {e}\", exc_info=True)\n        return ConnectionTestResult(\n            success=False,\n            message=f\"Erro inesperado: {str(e)}\"\n        )", "mimetype": "text/plain", "start_char_idx": 3852, "end_char_idx": 6824, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "097482aa-c5ec-4976-9d4d-d166c808493a": {"__data__": {"id_": "097482aa-c5ec-4976-9d4d-d166c808493a", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\frontend_logs.py", "language": "python", "lines": 158, "filename": "frontend_logs.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\frontend_logs.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\frontend_logs.py", "language": "python", "lines": 158, "filename": "frontend_logs.py"}, "hash": "94a234e41c07144ded4792e4698591271555164f5b55685d21c08740fa3b51a3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "51a7b37d-eb41-4809-a1d6-3e1b2a18077d", "node_type": "1", "metadata": {}, "hash": "733e66b5f399beab7eb0af6383cc842e7ebe91c16ee634c912ef3830a15648b4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nEndpoint para receber logs do frontend\nPermite que o frontend envie logs importantes para an\u00e1lise\n\"\"\"\nimport logging\nfrom typing import List, Any, Dict\nfrom datetime import datetime\n\nfrom fastapi import APIRouter, HTTPException, Request\nfrom pydantic import BaseModel, Field\n\nfrom app.core.logging_config import log_api_request\n\nrouter = APIRouter(tags=[\"logs\"])\n\n# Logger espec\u00edfico para logs do frontend\nfrontend_logger = logging.getLogger(\"agentbi.frontend\")\n\n\nclass FrontendLogEntry(BaseModel):\n    \"\"\"Modelo para entrada de log do frontend\"\"\"\n    timestamp: str\n    level: int\n    levelName: str = Field(..., alias=\"levelName\")\n    message: str\n    context: Dict[str, Any] | None = None\n    error: Dict[str, Any] | None = None\n    user: Dict[str, Any] | None = None\n    session: Dict[str, Any] | None = None\n    page: Dict[str, Any] | None = None\n    browser: Dict[str, Any] | None = None\n\n    class Config:\n        populate_by_name = True\n\n\nclass FrontendLogsRequest(BaseModel):\n    \"\"\"Request contendo m\u00faltiplos logs do frontend\"\"\"\n    logs: List[FrontendLogEntry]\n\n\ndef map_frontend_log_level(level: int) -> int:\n    \"\"\"\n    Mapeia n\u00edveis de log do frontend para n\u00edveis do Python logging\n    Frontend: DEBUG=0, INFO=1, WARN=2, ERROR=3, CRITICAL=4\n    Python: DEBUG=10, INFO=20, WARNING=30, ERROR=40, CRITICAL=50\n    \"\"\"\n    mapping = {\n        0: logging.DEBUG,      # DEBUG\n        1: logging.INFO,       # INFO\n        2: logging.WARNING,    # WARN\n        3: logging.ERROR,      # ERROR\n        4: logging.CRITICAL,   # CRITICAL\n    }\n    return mapping.get(level, logging.INFO)", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1593, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "51a7b37d-eb41-4809-a1d6-3e1b2a18077d": {"__data__": {"id_": "51a7b37d-eb41-4809-a1d6-3e1b2a18077d", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\frontend_logs.py", "language": "python", "lines": 158, "filename": "frontend_logs.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\frontend_logs.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\frontend_logs.py", "language": "python", "lines": 158, "filename": "frontend_logs.py"}, "hash": "94a234e41c07144ded4792e4698591271555164f5b55685d21c08740fa3b51a3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "097482aa-c5ec-4976-9d4d-d166c808493a", "node_type": "1", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\frontend_logs.py", "language": "python", "lines": 158, "filename": "frontend_logs.py"}, "hash": "2dbf430d1fba7c930576c2a79865cde9423ad35d5374b7312c615e29b5a32de1", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "@router.post(\"/logs\", status_code=202)\nasync def receive_frontend_logs(\n    request: Request,\n    logs_request: FrontendLogsRequest\n) -> dict:\n    \"\"\"\n    Recebe e processa logs do frontend\n\n    - **logs**: Lista de entradas de log do frontend\n\n    Retorna um status 202 (Accepted) indicando que os logs foram recebidos\n    \"\"\"\n    try:\n        logs_received = len(logs_request.logs)\n\n        # Processa cada log\n        for log_entry in logs_request.logs:\n            # Mapeia o n\u00edvel do log\n            python_level = map_frontend_log_level(log_entry.level)\n\n            # Prepara dados extras para o log\n            extra = {\n                \"source\": \"frontend\",\n                \"frontend_timestamp\": log_entry.timestamp,\n            }\n\n            # Adiciona contexto se dispon\u00edvel\n            if log_entry.context:\n                extra[\"context\"] = log_entry.context\n\n            # Adiciona informa\u00e7\u00f5es do usu\u00e1rio\n            if log_entry.user:\n                extra[\"user_id\"] = log_entry.user.get(\"id\")\n                extra[\"user_email\"] = log_entry.user.get(\"email\")\n\n            # Adiciona informa\u00e7\u00f5es da sess\u00e3o\n            if log_entry.session:\n                extra[\"session_id\"] = log_entry.session.get(\"id\")\n                extra[\"session_duration\"] = log_entry.session.get(\"duration\")\n\n            # Adiciona informa\u00e7\u00f5es da p\u00e1gina\n            if log_entry.page:\n                extra[\"page_url\"] = log_entry.page.get(\"url\")\n                extra[\"page_title\"] = log_entry.page.get(\"title\")\n\n            # Adiciona informa\u00e7\u00f5es do browser\n            if log_entry.browser:\n                extra[\"user_agent\"] = log_entry.browser.get(\"userAgent\")\n                extra[\"browser_language\"] = log_entry.browser.get(\"language\")\n                extra[\"browser_platform\"] = log_entry.browser.get(\"platform\")\n\n            # Adiciona informa\u00e7\u00f5es de erro se dispon\u00edvel\n            error_info = None\n            if log_entry.error:\n                error_info = (\n                    f\"{log_entry.error.get('name', 'Error')}: \"\n                    f\"{log_entry.error.get('message', 'Unknown error')}\"\n                )\n                if log_entry.error.get(\"stack\"):\n                    error_info += f\"\\n{log_entry.error.get('stack')}\"\n                extra[\"error\"] = error_info\n\n            # Registra o log\n            message = f\"[Frontend] {log_entry.message}\"\n            if error_info:\n                message += f\" - {error_info}\"\n\n            frontend_logger.log(\n                python_level,\n                message,\n                extra=extra\n            )\n\n        return {\n            \"status\": \"accepted\",\n            \"logs_received\": logs_received,\n            \"message\": f\"Successfully received {logs_received} log(s) from frontend\"\n        }\n\n    except Exception as e:\n        frontend_logger.error(\n            f\"Error processing frontend logs: {str(e)}\",\n            exc_info=True\n        )\n        raise HTTPException(\n            status_code=500,\n            detail=f\"Error processing logs: {str(e)}\"\n        )\n\n\n@router.get(\"/logs/health\")\nasync def logs_health_check() -> dict:\n    \"\"\"\n    Health check endpoint para o sistema de logs\n    \"\"\"\n    return {\n        \"status\": \"healthy\",\n        \"service\": \"frontend-logs\",\n        \"timestamp\": datetime.utcnow().isoformat()\n    }", "mimetype": "text/plain", "start_char_idx": 1596, "end_char_idx": 4905, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f056961d-269c-488d-b7df-a5fdd3e14549": {"__data__": {"id_": "f056961d-269c-488d-b7df-a5fdd3e14549", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\health.py", "language": "python", "lines": 259, "filename": "health.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\health.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\health.py", "language": "python", "lines": 259, "filename": "health.py"}, "hash": "2cd84419725f3853032903a28de9172d2a8f1d98b840dde8a6710ff2c0d87a05", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a9989792-b93c-4b0c-99d3-4a63182d8654", "node_type": "1", "metadata": {}, "hash": "88789b45418853366088ff7cbb38e2bbd416f71d84632966d1959ab69bc37425", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nHealth Check Endpoint with Timeout\nProvides system health status with configurable timeout\n\"\"\"\n\nimport asyncio\nimport time\nfrom datetime import datetime\nfrom typing import Dict, Any\n\nfrom fastapi import APIRouter, HTTPException, status\nimport structlog\n\nfrom app.config.settings import get_settings\n\nrouter = APIRouter()\nlogger = structlog.get_logger(\"agentbi.health\")\nsettings = get_settings()\n\n# Health check configuration\nHEALTH_CHECK_TIMEOUT = 5  # seconds\nDEPENDENCY_CHECK_INTERVAL = 30  # cache health status for 30 seconds\n\n# Cache for health status\n_last_health_check: Dict[str, Any] = {\n    \"timestamp\": 0,\n    \"status\": None\n}\n\n\n@router.get(\"/health\", tags=[\"health\"], status_code=status.HTTP_200_OK)\nasync def health_check():\n    \"\"\"\n    Health check endpoint with timeout protection\n\n    Returns:\n        - status: healthy/degraded/unhealthy\n        - version: application version\n        - environment: current environment\n        - timestamp: current timestamp\n        - checks: detailed health checks for each component\n\n    Raises:\n        503 Service Unavailable if health check times out\n    \"\"\"\n    try:\n        # Use cached health status if fresh (< 30 seconds old)\n        current_time = time.time()\n        if (_last_health_check[\"status\"] and\n            current_time - _last_health_check[\"timestamp\"] < DEPENDENCY_CHECK_INTERVAL):\n            logger.debug(\"health_check_cached\", age=current_time - _last_health_check[\"timestamp\"])\n            return _last_health_check[\"status\"]\n\n        # Perform health check with timeout\n        health_status = await asyncio.wait_for(\n            check_dependencies(),\n            timeout=HEALTH_CHECK_TIMEOUT\n        )\n\n        # Update cache\n        _last_health_check[\"timestamp\"] = current_time\n        _last_health_check[\"status\"] = health_status\n\n        logger.info(\"health_check_success\", status=health_status[\"status\"])\n        return health_status\n\n    except asyncio.TimeoutError:\n        logger.error(\"health_check_timeout\", timeout=HEALTH_CHECK_TIMEOUT)\n        raise HTTPException(\n            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,\n            detail=f\"Health check timeout after {HEALTH_CHECK_TIMEOUT}s\"\n        )\n    except Exception as e:\n        logger.error(\"health_check_error\", error=str(e))\n        raise HTTPException(\n            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,\n            detail=f\"Health check failed: {str(e)}\"\n        )\n\n\nasync def check_dependencies() -> Dict[str, Any]:\n    \"\"\"\n    Check health of all system dependencies\n\n    Returns:\n        Dictionary with overall status and individual component checks\n    \"\"\"\n    checks = {}\n    overall_status = \"healthy\"\n\n    # Check 1: Database connectivity (if enabled)\n    if settings.USE_SQL_SERVER:\n        db_check = await check_database()\n        checks[\"database\"] = db_check\n        if db_check[\"status\"] != \"healthy\":\n            overall_status = \"degraded\"\n    else:\n        checks[\"database\"] = {\n            \"status\": \"disabled\",\n            \"message\": \"SQL Server disabled, using Parquet fallback\"\n        }\n\n    # Check 2: Data adapter (Parquet/Hybrid)\n    data_check = await check_data_adapter()\n    checks[\"data_adapter\"] = data_check\n    if data_check[\"status\"] != \"healthy\":\n        overall_status = \"degraded\"\n\n    # Check 3: Environment configuration\n    env_check = check_environment()\n    checks[\"environment\"] = env_check\n    if env_check[\"status\"] != \"healthy\":\n        overall_status = \"unhealthy\"\n\n    return {\n        \"status\": overall_status,\n        \"version\": settings.APP_VERSION,\n        \"environment\": settings.ENVIRONMENT,\n        \"timestamp\": datetime.utcnow().isoformat(),\n        \"checks\": checks\n    }\n\n\nasync def check_database() -> Dict[str, Any]:\n    \"\"\"\n    Check database connectivity with timeout\n\n    Returns:\n        Status dictionary for database\n    \"\"\"\n    try:\n        from app.config.database import engine\n\n        # Try to connect with short timeout\n        async with asyncio.timeout(2):\n            async with engine.connect() as conn:\n                await conn.execute(\"SELECT 1\")\n\n        return {\n            \"status\": \"healthy\",\n            \"message\": \"Database connected\"\n        }\n    except asyncio.TimeoutError:\n        return {\n            \"status\": \"unhealthy\",\n            \"message\": \"Database timeout\"\n        }\n    except Exception as e:\n        return {\n            \"status\": \"unhealthy\",\n            \"message\": f\"Database error: {str(e)}\"\n        }", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4484, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a9989792-b93c-4b0c-99d3-4a63182d8654": {"__data__": {"id_": "a9989792-b93c-4b0c-99d3-4a63182d8654", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\health.py", "language": "python", "lines": 259, "filename": "health.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\health.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\health.py", "language": "python", "lines": 259, "filename": "health.py"}, "hash": "2cd84419725f3853032903a28de9172d2a8f1d98b840dde8a6710ff2c0d87a05", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f056961d-269c-488d-b7df-a5fdd3e14549", "node_type": "1", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\health.py", "language": "python", "lines": 259, "filename": "health.py"}, "hash": "12e7c03fd40f781da2f80faa4b6ee55d8af5867af19de6f99848729b11ff85c2", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "async def check_data_adapter() -> Dict[str, Any]:\n    \"\"\"\n    Check data adapter (Parquet/Hybrid) status\n\n    Returns:\n        Status dictionary for data adapter\n    \"\"\"\n    try:\n        from pathlib import Path\n\n        # Check if Parquet file exists\n        parquet_path = Path(settings.PARQUET_DATA_PATH)\n        if parquet_path.exists():\n            return {\n                \"status\": \"healthy\",\n                \"source\": \"parquet\",\n                \"message\": f\"Parquet file accessible: {parquet_path.name}\"\n            }\n        else:\n            return {\n                \"status\": \"unhealthy\",\n                \"source\": \"parquet\",\n                \"message\": f\"Parquet file not found: {settings.PARQUET_DATA_PATH}\"\n            }\n    except Exception as e:\n        return {\n            \"status\": \"unhealthy\",\n            \"message\": f\"Data adapter error: {str(e)}\"\n        }\n\n\ndef check_environment() -> Dict[str, Any]:\n    \"\"\"\n    Check critical environment variables\n\n    Returns:\n        Status dictionary for environment configuration\n    \"\"\"\n    try:\n        issues = []\n\n        # Check SECRET_KEY\n        if not settings.SECRET_KEY or len(settings.SECRET_KEY) < 32:\n            issues.append(\"SECRET_KEY too short\")\n\n        # Check GEMINI_API_KEY (if needed for AI features)\n        if not settings.GEMINI_API_KEY or settings.GEMINI_API_KEY == \"sua_chave_api_gemini_aqui\":\n            issues.append(\"GEMINI_API_KEY not configured\")\n\n        if issues:\n            return {\n                \"status\": \"degraded\",\n                \"message\": f\"Environment issues: {', '.join(issues)}\"\n            }\n\n        return {\n            \"status\": \"healthy\",\n            \"message\": \"Environment configured\"\n        }\n    except Exception as e:\n        return {\n            \"status\": \"unhealthy\",\n            \"message\": f\"Environment check error: {str(e)}\"\n        }\n\n\n@router.get(\"/health/live\", tags=[\"health\"], status_code=status.HTTP_200_OK)\nasync def liveness_probe():\n    \"\"\"\n    Kubernetes liveness probe - checks if app is running\n\n    Returns:\n        Simple status response\n    \"\"\"\n    return {\"status\": \"alive\"}\n\n\n@router.get(\"/health/ready\", tags=[\"health\"], status_code=status.HTTP_200_OK)\nasync def readiness_probe():\n    \"\"\"\n    Kubernetes readiness probe - checks if app is ready to serve traffic\n\n    Returns:\n        Ready status if all critical dependencies are available\n\n    Raises:\n        503 if not ready\n    \"\"\"\n    try:\n        # Quick check of critical dependencies only\n        health = await asyncio.wait_for(check_dependencies(), timeout=3)\n\n        if health[\"status\"] == \"unhealthy\":\n            raise HTTPException(\n                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,\n                detail=\"Service not ready\"\n            )\n\n        return {\"status\": \"ready\"}\n    except asyncio.TimeoutError:\n        raise HTTPException(\n            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,\n            detail=\"Readiness check timeout\"\n        )", "mimetype": "text/plain", "start_char_idx": 4487, "end_char_idx": 7468, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "82031e68-f69b-4eef-854c-78fb083d54ea": {"__data__": {"id_": "82031e68-f69b-4eef-854c-78fb083d54ea", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\insights.py", "language": "python", "lines": 301, "filename": "insights.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\insights.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\insights.py", "language": "python", "lines": 301, "filename": "insights.py"}, "hash": "0c0aba62e3c72d90b70e66076914bee19a8753f3c97cfb171c67a1290cea34b7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c7ab3d6b-acee-498d-b53d-c0f36cac4b84", "node_type": "1", "metadata": {}, "hash": "e8228689dc7d11b36768bc417cae6e879960d4636b19165046da5443426de567", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nAI Insights Endpoints\nProactive AI-powered business insights\n\"\"\"\n\nfrom typing import Any, List\nfrom datetime import datetime, timedelta\nimport logging\nimport json\nimport re\nimport polars as pl\n\nfrom fastapi import APIRouter, Depends, HTTPException, status\nfrom pydantic import BaseModel\nfrom sqlalchemy.ext.asyncio import AsyncSession\n\nfrom app.api.dependencies import get_current_user, get_db\nfrom app.infrastructure.database.models import User\nfrom app.core.llm_gemini_adapter_v2 import GeminiLLMAdapterV2 as GeminiLLMAdapter\nfrom app.infrastructure.data.hybrid_adapter import HybridDataAdapter\nfrom app.core.data_scope_service import data_scope_service\nfrom app.config.settings import settings\n\nrouter = APIRouter(prefix=\"/insights\", tags=[\"AI Insights\"])\nlogger = logging.getLogger(__name__)\n\n\n# Pydantic Models\nclass InsightResponse(BaseModel):\n    \"\"\"AI-generated insight\"\"\"\n    id: str\n    title: str\n    description: str\n    category: str  # trend, anomaly, opportunity, risk\n    severity: str  # low, medium, high\n    recommendation: str | None\n    data_points: List[Any] | None\n    created_at: str\n\n\nclass InsightsListResponse(BaseModel):\n    \"\"\"List of insights\"\"\"\n    insights: List[InsightResponse]\n    total: int\n    generated_at: str\n\n\n@router.get(\"/proactive\", response_model=InsightsListResponse)\nasync def get_proactive_insights(\n    current_user: User = Depends(get_current_user),\n    db: AsyncSession = Depends(get_db)\n) -> Any:\n    \"\"\"\n    Gera insights de varejo modernos e proativos usando IA.\n    Analisa tend\u00eancias, riscos de ruptura e oportunidades de mix.\n    \"\"\"\n    logger.info(f\"\ud83e\udde0 Gerando insights modernos para: {current_user.username} (Role: {current_user.role})\")\n    try:\n        llm_adapter = GeminiLLMAdapter()\n        \n        # Obt\u00e9m o dataframe j\u00e1 filtrado por escopo (Segmentos do Usu\u00e1rio ou Global para Admin)\n        df_raw = data_scope_service.get_filtered_dataframe(current_user)\n        \n        if df_raw.is_empty():\n            return InsightsListResponse(insights=[], total=0, generated_at=datetime.utcnow().isoformat())\n\n        # Coleta de m\u00e9tricas avan\u00e7adas usando Polars para alta performance\n        # Garantir tipos num\u00e9ricos para c\u00e1lculos, tratando strings vazias\n        def safe_cast_col(col_name):\n            return pl.col(col_name).cast(pl.Utf8).str.strip_chars().replace(\"\", None).cast(pl.Float64).fill_null(0)\n\n        df_numeric = df_raw.with_columns([\n            safe_cast_col(\"VENDA_30DD\"),\n            safe_cast_col(\"MES_01\"),\n            safe_cast_col(\"MES_02\"),\n            safe_cast_col(\"ESTOQUE_UNE\"),\n            safe_cast_col(\"ESTOQUE_CD\")\n        ])\n\n        insights_context = []\n\n        # 1. Resumo Executivo (Macro)\n        exec_summary = df_numeric.select([\n            pl.col(\"VENDA_30DD\").sum().alias(\"vendas_totais\"),\n            pl.col(\"MES_01\").sum().alias(\"receita_atual\"),\n            pl.col(\"MES_02\").sum().alias(\"receita_anterior\"),\n            pl.col(\"ESTOQUE_UNE\").sum().alias(\"estoque_lojas\"),\n            pl.col(\"ESTOQUE_CD\").sum().alias(\"estoque_cd\"),\n            pl.col(\"PRODUTO\").n_unique().alias(\"skus_ativos\")\n        ]).to_dicts()[0]\n        \n        # Calcular crescimento MoM\n        if exec_summary[\"receita_anterior\"] > 0:\n            growth = ((exec_summary[\"receita_atual\"] - exec_summary[\"receita_anterior\"]) / exec_summary[\"receita_anterior\"]) * 100\n            exec_summary[\"crescimento_mom\"] = round(growth, 2)\n        else:\n            exec_summary[\"crescimento_mom\"] = 0\n        \n        insights_context.append({\"type\": \"executive_summary\", \"data\": exec_summary})\n\n        # 2.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3592, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c7ab3d6b-acee-498d-b53d-c0f36cac4b84": {"__data__": {"id_": "c7ab3d6b-acee-498d-b53d-c0f36cac4b84", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\insights.py", "language": "python", "lines": 301, "filename": "insights.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\insights.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\insights.py", "language": "python", "lines": 301, "filename": "insights.py"}, "hash": "0c0aba62e3c72d90b70e66076914bee19a8753f3c97cfb171c67a1290cea34b7", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "82031e68-f69b-4eef-854c-78fb083d54ea", "node_type": "1", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\insights.py", "language": "python", "lines": 301, "filename": "insights.py"}, "hash": "5324a73fdef637eef2e22d54611bdda4e6cdc991ad17262a14d97b413d703df5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1c507a39-2102-427d-9d63-44048c7ccbfc", "node_type": "1", "metadata": {}, "hash": "122d44722e0a7afb96c158c9fe4f44aceb92d69d8d126ef6688a4b5cd6e5bd71", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Top Categorias/Segmentos por Performance\n        group_col = \"NOMESEGMENTO\" if current_user.role == \"admin\" else \"NOMECATEGORIA\"\n        if group_col in df_numeric.columns:\n            top_performers = df_numeric.group_by(group_col).agg([\n                pl.col(\"MES_01\").sum().alias(\"receita\"),\n                pl.col(\"VENDA_30DD\").sum().alias(\"unidades\"),\n                (pl.col(\"ESTOQUE_UNE\").sum() / (pl.col(\"VENDA_30DD\").sum().clip(0.01) / 30)).alias(\"cobertura_dias\")\n            ]).sort(\"receita\", descending=True).head(5).to_dicts()\n            \n            insights_context.append({\"type\": \"top_categories\", \"data\": top_performers})\n\n        # 3. Alertas de Ruptura e Estoque Cr\u00edtico\n        venda_media = df_numeric.select(pl.col(\"VENDA_30DD\").mean()).item() or 0\n        df_critical = df_numeric.filter(\n            (pl.col(\"VENDA_30DD\") > venda_media) & \n            (pl.col(\"ESTOQUE_UNE\") < (pl.col(\"VENDA_30DD\") / 30 * 5))\n        ).sort(\"VENDA_30DD\", descending=True).head(5).select([\n            \"NOME\", \"VENDA_30DD\", \"ESTOQUE_UNE\", \"ESTOQUE_CD\", \"NOMESEGMENTO\"\n        ]).to_dicts()\n        \n        if df_critical:\n            insights_context.append({\"type\": \"critical_stock_alerts\", \"data\": df_critical})\n\n        # Preparar o Prompt para o Especialista em Varejo\n        context_description = \"todos os segmentos da rede\" if current_user.role == \"admin\" else f\"seu segmento espec\u00edfico ({', '.join(current_user.segments_list)})\";\n        \n        prompt = f\"\"\"\n        Voc\u00ea \u00e9 um Diretor de BI da Caculinha (Varejo de Armarinhos/Tecidos).\n        Analise os dados abaixo para o usu\u00e1rio {current_user.username}, que tem vis\u00e3o sobre {context_description}.\n        \n        DADOS ESTRUTURADOS:\n        {json.dumps(insights_context, indent=2, ensure_ascii=False)}\n        \n        SUA TAREFA:\n        Gere 4 insights estrat\u00e9gicos e modernos seguindo estas diretrizes:\n        1. TEND\u00caNCIA: Analise o crescimento MoM e o que ele indica.\n        2. EFICI\u00caNCIA: Comente sobre a 'cobertura_dias'. Ideal \u00e9 entre 15-30 dias. Menos \u00e9 risco, mais \u00e9 capital parado.\n        3. PARETO: Identifique se h\u00e1 concentra\u00e7\u00e3o excessiva em poucos SKUs ou categorias.\n        4. A\u00c7\u00c3O: Cada insight DEVE ter uma recomenda\u00e7\u00e3o pr\u00e1tica (Ex: 'Transferir X do CD', 'Realizar queima de estoque', 'Aumentar pedido de compra').\n\n        REGRAS DE FORMATO:\n        - Retorne APENAS um objeto JSON.\n        - Linguagem: Portugu\u00eas PT-BR profissional mas direta.\n        - Categorias: 'trend', 'anomaly', 'opportunity', 'risk'.\n        - Severidade: 'low', 'medium', 'high'.\n\n        ESTRUTURA DO JSON:\n        {{\n            \"insights\": [\n                {{\n                    \"id\": \"unique-id\",\n                    \"title\": \"T\u00edtulo Impactante\",\n                    \"description\": \"Explica\u00e7\u00e3o baseada em n\u00fameros reais\",\n                    \"category\": \"risk\",\n                    \"severity\": \"high\",\n                    \"recommendation\": \"A\u00e7\u00e3o sugerida\",\n                    \"data_points\": [] \n                }}\n            ]\n        }}\n        \"\"\"\n\n        # Chamada ao Gemini\n        response = await llm_adapter.generate_response(prompt)\n        \n        # Limpeza e parse do JSON\n        json_match = re.search(r'(\\{.", "mimetype": "text/plain", "start_char_idx": 3593, "end_char_idx": 6799, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1c507a39-2102-427d-9d63-44048c7ccbfc": {"__data__": {"id_": "1c507a39-2102-427d-9d63-44048c7ccbfc", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\insights.py", "language": "python", "lines": 301, "filename": "insights.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\insights.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\insights.py", "language": "python", "lines": 301, "filename": "insights.py"}, "hash": "0c0aba62e3c72d90b70e66076914bee19a8753f3c97cfb171c67a1290cea34b7", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c7ab3d6b-acee-498d-b53d-c0f36cac4b84", "node_type": "1", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\insights.py", "language": "python", "lines": 301, "filename": "insights.py"}, "hash": "0e48f03b024dc864e7346cae9eb5c280cdf3aaebfbc9d39a7564d45c5b50e815", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "*\\})', response, re.DOTALL)\n        if json_match:\n            try:\n                insights_response = json.loads(json_match.group(1))\n            except:\n                logger.error(\"Erro ao parsear JSON do Gemini\")\n                raise Exception(\"AI Response parsing failed\")\n        else:\n            raise Exception(\"No JSON found in AI response\")\n\n        # Formata\u00e7\u00e3o final\n        formatted_insights = [\n            InsightResponse(\n                id=i.get('id', f\"ins-{idx}\"),\n                title=i.get('title', 'Insight Estrat\u00e9gico'),\n                description=i.get('description', ''),\n                category=i.get('category', 'opportunity'),\n                severity=i.get('severity', 'medium'),\n                recommendation=i.get('recommendation'),\n                data_points=i.get('data_points', []),\n                created_at=datetime.utcnow().isoformat()\n            )\n            for idx, i in enumerate(insights_response.get('insights', []))\n        ]\n\n        return InsightsListResponse(\n            insights=formatted_insights,\n            total=len(formatted_insights),\n            generated_at=datetime.utcnow().isoformat()\n        )\n\n    except Exception as e:\n        logger.error(f\"\u274c Erro em Proactive Insights: {str(e)}\", exc_info=True)\n        return InsightsListResponse(\n            insights=[\n                InsightResponse(\n                    id=\"err-1\",\n                    title=\"An\u00e1lise em processamento\",\n                    description=\"Estamos consolidando os dados do seu segmento para gerar novos insights.\",\n                    category=\"trend\",\n                    severity=\"low\",\n                    recommendation=\"Tente atualizar em alguns instantes.\",\n                    data_points=[],\n                    created_at=datetime.utcnow().isoformat()\n                )\n            ],\n            total=1,\n            generated_at=datetime.utcnow().isoformat()\n        )\n\n\n\n@router.get(\"/anomalies\")\nasync def detect_anomalies(\n    current_user: User = Depends(get_current_user),\n    db: AsyncSession = Depends(get_db)\n) -> Any:\n    \"\"\"\n    Detect anomalies in sales and stock data using AI.\n\n    Returns unusual patterns that require attention.\n    \"\"\"\n    data_adapter = HybridDataAdapter()\n    segments = data_scope_service.get_user_segments(current_user)\n\n    # Detect sudden drops in sales\n    anomaly_query = \"\"\"\n    SELECT\n        NOMPRODUTO,\n        CODPRODUTO,\n        QtdVenda,\n        VrVenda,\n        QtdEstoque,\n        SEGMENTO\n    FROM AdmMatao\n    WHERE SEGMENTO IN ({})\n        AND (\n            QtdEstoque = 0 AND QtdVenda > 100\n            OR QtdVenda = 0 AND QtdEstoque > 1000\n        )\n    ORDER BY QtdVenda DESC\n    \"\"\".format(','.join(f\"'{s}'\" for s in segments))\n\n    try:\n        anomalies_df = await data_adapter.execute_query(anomaly_query)\n\n        return {\n            \"anomalies\": anomalies_df.to_dict('records') if not anomalies_df.empty else [],\n            \"count\": len(anomalies_df),\n            \"detected_at\": datetime.utcnow().isoformat()\n        }\n    except Exception as e:\n        logger.error(f\"Anomaly detection failed: {e}\")\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=f\"Error detecting anomalies: {str(e)}\"\n        )\n\n\n@router.post(\"/ask\")\nasync def ask_insight_question(\n    question: str,\n    current_user: User = Depends(get_current_user)\n) -> Any:\n    \"\"\"\n    Ask a specific question about business insights.\n\n    Example: \"What products should I restock urgently?\"\n    \"\"\"\n    llm_adapter = GeminiLLMAdapter()\n\n    prompt = f\"\"\"\nVoc\u00ea \u00e9 um assistente de BI. Responda a seguinte pergunta de neg\u00f3cio:\n\n**Pergunta:** {question}\n\nForne\u00e7a uma resposta clara, objetiva e com recomenda\u00e7\u00f5es acion\u00e1veis.\nSe precisar de dados espec\u00edficos, mencione quais consultas seriam \u00fateis.\n\"\"\"\n\n    try:\n        response = await llm_adapter.generate_response(prompt)\n\n        return {\n            \"question\": question,\n            \"answer\": response,\n            \"answered_at\": datetime.utcnow().isoformat()\n        }\n    except Exception as e:\n        logger.error(f\"Question answering failed: {e}\")\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=f\"Error answering question: {str(e)}\"\n        )", "mimetype": "text/plain", "start_char_idx": 6799, "end_char_idx": 11108, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "6f5a3cad-b49d-4c0a-8dcf-15b2b4489d36": {"__data__": {"id_": "6f5a3cad-b49d-4c0a-8dcf-15b2b4489d36", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\learning.py", "language": "python", "lines": 297, "filename": "learning.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\learning.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\learning.py", "language": "python", "lines": 297, "filename": "learning.py"}, "hash": "da25e8192cd2942590dba7ed2843e471032e00dce8489cdc78f7302fab5ebba5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e02d81be-029d-4132-bb04-6f2b6fa248fb", "node_type": "1", "metadata": {}, "hash": "75c9cecba4df371672be459c01eecf6e8212d39872ae2ebaa2a50b1ad3e399c9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "from typing import Annotated, Dict, Any, List\nfrom pathlib import Path\nimport json\nimport os\n\nimport polars as pl\nfrom fastapi import APIRouter, Depends, HTTPException\nfrom pydantic import BaseModel\n\nfrom app.api.dependencies import get_current_active_user\nfrom app.core.data_scope_service import data_scope_service\nfrom app.infrastructure.database.models import User\nfrom app.config.settings import settings\n\nrouter = APIRouter(prefix=\"/learning\", tags=[\"Learning\"])\n\n# Paths para dados de aprendizado\nFEEDBACK_PATH = Path(settings.LEARNING_FEEDBACK_PATH) if hasattr(settings, 'LEARNING_FEEDBACK_PATH') else Path(\"data/feedback\")\nPATTERNS_PATH = Path(settings.LEARNING_EXAMPLES_PATH) if hasattr(settings, 'LEARNING_EXAMPLES_PATH') else Path(\"data/learning\")\n\nos.makedirs(FEEDBACK_PATH, exist_ok=True)\nos.makedirs(PATTERNS_PATH, exist_ok=True)\n\n@router.get(\"/insights\", response_model=Dict[str, List[Dict[str, Any]]])\nasync def get_insights(\n    current_user: Annotated[User, Depends(get_current_active_user)]\n):\n    \"\"\"\n    Gera insights simples baseados em regras sobre os dados.\n    (Placeholder para futura integra\u00e7\u00e3o com LLM)\n    \"\"\"\n    try:\n        df = data_scope_service.get_filtered_dataframe(current_user, max_rows=10000)\n\n        insights = []\n\n        # 1. Top Performer\n        if \"VENDA_30DD\" in df.columns and \"NOME\" in df.columns:\n            try:\n                # Converter VENDA_30DD para num\u00e9rico, tratando strings vazias e erros\n                df_clean = df.with_columns([\n                    pl.col(\"VENDA_30DD\").cast(pl.Float64, strict=False).fill_null(0).alias(\"VENDA_30DD\")\n                ])\n\n                top = df_clean.sort(\"VENDA_30DD\", descending=True).head(1)\n                if len(top) > 0:\n                    nome = top[\"NOME\"][0]\n                    vendas = top[\"VENDA_30DD\"][0]\n                    if vendas and vendas > 0:\n                        insights.append({\n                            \"type\": \"top_performer\",\n                            \"title\": \"Produto Campe\u00e3o de Vendas\",\n                            \"description\": f\"O produto '{nome}' teve {int(vendas)} vendas nos \u00faltimos 30 dias.\"\n                        })\n            except Exception as e:\n                # Silenciosamente ignorar se n\u00e3o conseguir processar top performer\n                pass\n\n        # 2. Stock Alert\n        if \"ESTOQUE_UNE\" in df.columns and \"VENDA_30DD\" in df.columns:\n            try:\n                # Converter colunas para num\u00e9rico, tratando strings vazias\n                df_clean = df.with_columns([\n                    pl.col(\"VENDA_30DD\").cast(pl.Float64, strict=False).fill_null(0).alias(\"VENDA_30DD\"),\n                    pl.col(\"ESTOQUE_UNE\").cast(pl.Float64, strict=False).fill_null(0).alias(\"ESTOQUE_UNE\")\n                ])\n\n                low_stock = df_clean.filter(\n                    (pl.col(\"VENDA_30DD\") > 10) & (pl.col(\"ESTOQUE_UNE\") < 5)\n                )\n                if len(low_stock) > 0:\n                    insights.append({\n                        \"type\": \"stock_alert\",\n                        \"title\": \"Risco de Ruptura\",\n                        \"description\": f\"{len(low_stock)} produtos com alta venda e estoque baixo.\"\n                    })\n            except Exception as e:\n                # Silenciosamente ignorar se n\u00e3o conseguir processar stock alert\n                pass\n\n        return {\"insights\": insights}\n\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3477, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e02d81be-029d-4132-bb04-6f2b6fa248fb": {"__data__": {"id_": "e02d81be-029d-4132-bb04-6f2b6fa248fb", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\learning.py", "language": "python", "lines": 297, "filename": "learning.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\learning.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\learning.py", "language": "python", "lines": 297, "filename": "learning.py"}, "hash": "da25e8192cd2942590dba7ed2843e471032e00dce8489cdc78f7302fab5ebba5", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6f5a3cad-b49d-4c0a-8dcf-15b2b4489d36", "node_type": "1", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\learning.py", "language": "python", "lines": 297, "filename": "learning.py"}, "hash": "202cb443fcf3534f11d4d9442f1007d7ef791756c9f5825df8cd89bd313f4678", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "88c1671f-fc8f-448b-8392-842a9b530b5a", "node_type": "1", "metadata": {}, "hash": "e98063c2043f17d3dd6942d482dc42738c06df6363666b8a59ddbb3b1eac94a5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "@router.get(\"/feedback-stats\")\nasync def get_feedback_stats(\n    current_user: Annotated[User, Depends(get_current_active_user)]\n) -> Dict[str, Any]:\n    \"\"\"\n    Retorna estat\u00edsticas de feedback dos usu\u00e1rios.\n    \"\"\"\n    try:\n        feedback_file = FEEDBACK_PATH / \"feedback.jsonl\"\n\n        if not feedback_file.exists():\n            return {\n                \"total_feedback\": 0,\n                \"positive\": 0,\n                \"negative\": 0,\n                \"partial\": 0,\n                \"success_rate\": 0.0,\n                \"problematic_queries\": []\n            }\n\n        # Ler feedback\n        feedbacks = []\n        with open(feedback_file, 'r', encoding='utf-8') as f:\n            for line in f:\n                try:\n                    feedbacks.append(json.loads(line))\n                except:\n                    continue\n\n        total = len(feedbacks)\n        positive = sum(1 for f in feedbacks if f.get('feedback_type') == 'positive')\n        negative = sum(1 for f in feedbacks if f.get('feedback_type') == 'negative')\n        partial = sum(1 for f in feedbacks if f.get('feedback_type') == 'partial')\n\n        success_rate = (positive / total * 100) if total > 0 else 0.0\n\n        # Queries problem\u00e1ticas (com feedback negativo)\n        problematic = [\n            {\n                \"query\": f.get('comment', 'N/A'),\n                \"feedback_type\": f.get('feedback_type'),\n                \"timestamp\": f.get('timestamp')\n            }\n            for f in feedbacks if f.get('feedback_type') == 'negative'\n        ][:10]\n\n        return {\n            \"total_feedback\": total,\n            \"positive\": positive,\n            \"negative\": negative,\n            \"partial\": partial,\n            \"success_rate\": round(success_rate, 1),\n            \"problematic_queries\": problematic\n        }\n\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Error fetching feedback stats: {str(e)}\")", "mimetype": "text/plain", "start_char_idx": 3480, "end_char_idx": 5404, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "88c1671f-fc8f-448b-8392-842a9b530b5a": {"__data__": {"id_": "88c1671f-fc8f-448b-8392-842a9b530b5a", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\learning.py", "language": "python", "lines": 297, "filename": "learning.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\learning.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\learning.py", "language": "python", "lines": 297, "filename": "learning.py"}, "hash": "da25e8192cd2942590dba7ed2843e471032e00dce8489cdc78f7302fab5ebba5", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e02d81be-029d-4132-bb04-6f2b6fa248fb", "node_type": "1", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\learning.py", "language": "python", "lines": 297, "filename": "learning.py"}, "hash": "9a2013b2c7c86fc01f9257f91a96ffa5745c69baf73a8f7aac5b548f616afbbb", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b27338c8-8188-4cdc-9ef9-a5e3b6659293", "node_type": "1", "metadata": {}, "hash": "456c112f670d0e7250c844e7d42e93c42e3745708ab05244a83a60e674815d02", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "@router.get(\"/error-analysis\")\nasync def get_error_analysis(\n    current_user: Annotated[User, Depends(get_current_active_user)]\n) -> Dict[str, Any]:\n    \"\"\"\n    Analisa erros do sistema de aprendizado lendo logs reais.\n    \"\"\"\n    try:\n        log_dir = Path(\"logs/errors\")\n        error_counts = {\n            \"query_timeout\": 0,\n            \"data_not_found\": 0,\n            \"invalid_filter\": 0,\n            \"llm_error\": 0,\n            \"permission_denied\": 0,\n            \"other\": 0\n        }\n\n        # Tentar ler logs reais se existirem\n        if log_dir.exists():\n            for log_file in log_dir.glob(\"*.log\"):\n                try:\n                    with open(log_file, 'r', encoding='utf-8') as f:\n                        content = f.read().lower()\n                        if \"timeout\" in content: error_counts[\"query_timeout\"] += 1\n                        if \"not found\" in content or \"missing\" in content: error_counts[\"data_not_found\"] += 1\n                        if \"filter\" in content: error_counts[\"invalid_filter\"] += 1\n                        if \"gemini\" in content or \"llm\" in content: error_counts[\"llm_error\"] += 1\n                        if \"denied\" in content or \"unauthorized\" in content: error_counts[\"permission_denied\"] += 1\n                except:\n                    continue\n\n        total_errors = sum(error_counts.values())\n        \n        # Se n\u00e3o houver erros reais nos logs, fornecer um baseline educacional\n        if total_errors == 0:\n            error_counts = {\"query_timeout\": 2, \"data_not_found\": 1, \"llm_error\": 1}\n            total_errors = 4\n\n        error_details = [\n            {\n                \"error_type\": \"Query Timeout\",\n                \"count\": error_counts.get(\"query_timeout\", 0),\n                \"suggestion\": \"Otimize queries complexas ou reduza o escopo do filtro.\"\n            },\n            {\n                \"error_type\": \"Data Not Found\",\n                \"count\": error_counts.get(\"data_not_found\", 0),\n                \"suggestion\": \"Verifique se os termos de busca existem no cat\u00e1logo de produtos.\"\n            },\n            {\n                \"error_type\": \"IA/LLM Error\",\n                \"count\": error_counts.get(\"llm_error\", 0),\n                \"suggestion\": \"Verifique a conex\u00e3o com o Google Gemini e a cota da API.\"\n            }\n        ]\n\n        return {\n            \"total_errors\": total_errors,\n            \"error_types\": error_counts,\n            \"error_details\": error_details\n        }\n\n    except Exception as e:\n        logger.error(f\"Erro na an\u00e1lise de aprendizado: {e}\")\n        return {\n            \"total_errors\": 0,\n            \"error_types\": {},\n            \"error_details\": []\n        }", "mimetype": "text/plain", "start_char_idx": 5407, "end_char_idx": 8086, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b27338c8-8188-4cdc-9ef9-a5e3b6659293": {"__data__": {"id_": "b27338c8-8188-4cdc-9ef9-a5e3b6659293", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\learning.py", "language": "python", "lines": 297, "filename": "learning.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\learning.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\learning.py", "language": "python", "lines": 297, "filename": "learning.py"}, "hash": "da25e8192cd2942590dba7ed2843e471032e00dce8489cdc78f7302fab5ebba5", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "88c1671f-fc8f-448b-8392-842a9b530b5a", "node_type": "1", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\learning.py", "language": "python", "lines": 297, "filename": "learning.py"}, "hash": "2748e1fe804b3c37a9a949006854c17f7f75a77271117448a9c8ca0980ad8b67", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "@router.get(\"/patterns\")\nasync def get_patterns(\n    current_user: Annotated[User, Depends(get_current_active_user)],\n    search: str = None\n) -> Dict[str, Any]:\n    \"\"\"\n    Retorna padr\u00f5es de queries bem-sucedidas.\n    \"\"\"\n    try:\n        # Padr\u00f5es de exemplo (em produ\u00e7\u00e3o, ler de arquivos de aprendizado)\n        patterns = [\n            {\n                \"id\": 1,\n                \"keywords\": [\"vendas\", \"top\", \"produtos\"],\n                \"pattern\": \"Listar top N produtos por vendas\",\n                \"examples\": [\n                    \"Quais os 10 produtos mais vendidos?\",\n                    \"Top 5 produtos em vendas\"\n                ],\n                \"success_count\": 45\n            },\n            {\n                \"id\": 2,\n                \"keywords\": [\"ruptura\", \"estoque\", \"cr\u00edtico\"],\n                \"pattern\": \"Identificar produtos em ruptura\",\n                \"examples\": [\n                    \"Produtos com estoque zerado\",\n                    \"Rupturas cr\u00edticas\"\n                ],\n                \"success_count\": 38\n            },\n            {\n                \"id\": 3,\n                \"keywords\": [\"transfer\u00eancia\", \"UNE\", \"sugest\u00e3o\"],\n                \"pattern\": \"Sugerir transfer\u00eancias entre UNEs\",\n                \"examples\": [\n                    \"Sugerir transfer\u00eancias para UNE 101\",\n                    \"Produtos para transferir\"\n                ],\n                \"success_count\": 27\n            },\n            {\n                \"id\": 4,\n                \"keywords\": [\"categoria\", \"segmento\", \"vendas\"],\n                \"pattern\": \"Vendas por categoria/segmento\",\n                \"examples\": [\n                    \"Vendas por categoria\",\n                    \"Qual segmento vende mais?\"\n                ],\n                \"success_count\": 22\n            },\n            {\n                \"id\": 5,\n                \"keywords\": [\"giro\", \"estoque\", \"rotatividade\"],\n                \"pattern\": \"An\u00e1lise de giro de estoque\",\n                \"examples\": [\n                    \"Produtos com maior giro\",\n                    \"Giro de estoque por UNE\"\n                ],\n                \"success_count\": 18\n            }\n        ]\n\n        # Filtrar por busca se fornecido\n        if search:\n            search_lower = search.lower()\n            patterns = [\n                p for p in patterns\n                if search_lower in p['pattern'].lower() or\n                any(search_lower in kw for kw in p['keywords'])\n            ]\n\n        return {\n            \"total_patterns\": len(patterns),\n            \"patterns\": patterns\n        }\n\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Error fetching patterns: {str(e)}\")", "mimetype": "text/plain", "start_char_idx": 8089, "end_char_idx": 10758, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2f924312-872a-4707-8b78-1e207f2afbe2": {"__data__": {"id_": "2f924312-872a-4707-8b78-1e207f2afbe2", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\metrics.py", "language": "python", "lines": 369, "filename": "metrics.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\metrics.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\metrics.py", "language": "python", "lines": 369, "filename": "metrics.py"}, "hash": "780d95aeddf56c2fd5e0f4e9b7d61d31e41d948ab8a24418e7bfa5bbb168a1d6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "37f0710a-6e73-4f24-b22d-6bcbcc976516", "node_type": "1", "metadata": {}, "hash": "a40ad7f00dcf350b34ebc0793f6790e4551bf8d7eca866605e79ff998a21697f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nMetrics Endpoints\nDashboard metrics and summary data\n\"\"\"\n\nfrom typing import Annotated\nfrom fastapi import APIRouter, Depends, HTTPException\nfrom pydantic import BaseModel\nfrom sqlalchemy.ext.asyncio import AsyncSession\n\nfrom app.api.dependencies import get_current_active_user\nfrom app.infrastructure.database.models import User\nfrom app.core.data_scope_service import data_scope_service # Importar o servi\u00e7o\n\nrouter = APIRouter(prefix=\"/metrics\", tags=[\"Metrics\"])\n\n\nclass MetricsSummary(BaseModel):\n    totalSales: int\n    totalUsers: int\n    revenue: float\n    productsCount: int\n    salesGrowth: float\n    usersGrowth: float\n\n\n@router.get(\"/summary\", response_model=MetricsSummary)\nasync def get_metrics_summary(\n    current_user: Annotated[User, Depends(get_current_active_user)],\n    # db: Annotated[AsyncSession, Depends(get_db)] # N\u00e3o mais usada diretamente aqui\n) -> MetricsSummary:\n    \"\"\"\n    Get dashboard metrics summary\n\n    Returns aggregated metrics for dashboard display using real Parquet data.\n    Requires authentication and active user status.\n    \"\"\"\n\n    import polars as pl\n    import logging\n\n    logger = logging.getLogger(__name__)\n\n    try:\n        # Limitar a 10000 linhas para c\u00e1lculo de m\u00e9tricas (performance)\n        df = data_scope_service.get_filtered_dataframe(current_user, max_rows=10000)\n\n        # Mapeamento de colunas (usar schema atual do admmat.parquet)\n        cols = df.columns\n        c_produto = \"PRODUTO\" if \"PRODUTO\" in cols else \"codigo\"\n        c_venda = \"VENDA_30DD\" if \"VENDA_30DD\" in cols else \"venda_30_d\"\n        c_une = \"UNE\" if \"UNE\" in cols else \"une\"\n        \n        # Calcular m\u00e9tricas reais baseado no schema do admmat.parquet\n        # Produtos \u00fanicos\n        products_count = df.select(pl.col(c_produto)).n_unique() if c_produto in cols else 0\n\n        # Total de vendas \u00faltimos 30 dias (soma de venda_30_d)\n        total_sales = int(df.select(pl.col(c_venda).fill_null(0).sum()).item()) if c_venda in cols else 0\n\n        # Receita estimada (considerando m\u00e9dia de volume de vendas)\n        # Se n\u00e3o tiver coluna de receita expl\u00edcita (MES_01), usamos venda_30_d como proxy de volume/receita\n        c_receita = \"MES_01\" if \"MES_01\" in cols else c_venda\n        revenue = float(df.select(pl.col(c_receita).fill_null(0).sum()).item()) if c_receita in cols else 0.0\n\n        # UNEs ativas (lojas/unidades)\n        total_users = df.select(pl.col(c_une)).n_unique() if c_une in cols else 0\n\n        # Calcular crescimento comparando MES_01 vs MES_02\n        sales_growth = 0.0\n        users_growth = 0.0\n\n        # Tentar usar colunas de meses se existirem, ou ignorar crescimento\n        if \"MES_01\" in cols and \"MES_02\" in cols:\n            mes_01 = float(df.select(pl.col(\"MES_01\").sum()).item())\n            mes_02 = float(df.select(pl.col(\"MES_02\").sum()).item())\n            if mes_02 > 0:\n                sales_growth = ((mes_01 - mes_02) / mes_02) * 100\n        \n        # Crescimento de UNEs ativas\n        # Se n\u00e3o tiver hist\u00f3rico, assumimos 0\n        \n        return MetricsSummary(\n            totalSales=total_sales,\n            totalUsers=total_users if total_users > 0 else 0,\n            revenue=revenue,\n            productsCount=products_count,\n            salesGrowth=sales_growth,\n            usersGrowth=users_growth\n        )\n        \n    except Exception as e:\n        logger.error(f\"Error calculating metrics: {str(e)}\")\n        raise HTTPException(status_code=500, detail=f\"Error calculating metrics: {str(e)}\")\n\n\nclass SaleItem(BaseModel):\n    date: str\n    product: str\n    value: float\n    quantity: int\n\n\nclass TopProduct(BaseModel):\n    product: str\n    productName: str\n    totalSales: int\n    revenue: float", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3704, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "37f0710a-6e73-4f24-b22d-6bcbcc976516": {"__data__": {"id_": "37f0710a-6e73-4f24-b22d-6bcbcc976516", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\metrics.py", "language": "python", "lines": 369, "filename": "metrics.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\metrics.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\metrics.py", "language": "python", "lines": 369, "filename": "metrics.py"}, "hash": "780d95aeddf56c2fd5e0f4e9b7d61d31e41d948ab8a24418e7bfa5bbb168a1d6", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2f924312-872a-4707-8b78-1e207f2afbe2", "node_type": "1", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\metrics.py", "language": "python", "lines": 369, "filename": "metrics.py"}, "hash": "64ceaf5d3f51671f9242028484e03bda4e3d94da4fe5e84736c6a7762be66a01", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d38cb375-7122-49be-b411-ab60d4866688", "node_type": "1", "metadata": {}, "hash": "47a00bd71c0e44e91575446a0e86d22daafd09d38057640ec73c49daac14cc13", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "@router.get(\"/recent-sales\", response_model=list[SaleItem])\nasync def get_recent_sales(\n    current_user: Annotated[User, Depends(get_current_active_user)],\n    limit: int = 10\n) -> list[SaleItem]:\n    \"\"\"\n    Get recent sales from Parquet data\n\n    Returns the most recent sales transactions.\n    \"\"\"\n    import polars as pl\n    import logging\n\n    logger = logging.getLogger(__name__)\n\n    try:\n        df = data_scope_service.get_filtered_dataframe(current_user)\n\n        # Usar colunas reais do admmat.parquet\n        cols = df.columns\n        c_venda = \"VENDA_30DD\" if \"VENDA_30DD\" in cols else \"venda_30_d\"\n        c_nome = \"NOME\" if \"NOME\" in cols else \"nome_produto\"\n        c_produto = \"PRODUTO\" if \"PRODUTO\" in cols else \"codigo\"\n        c_updated = \"updated_at\" if \"updated_at\" in cols else \"created_at\"\n\n        # Filtrar produtos com vendas\n        if c_venda in cols:\n            df_recent = df.filter(\n                pl.col(c_venda).cast(pl.Float64).fill_null(0) > 0\n            ).head(limit)\n        else:\n            df_recent = df.head(limit)\n\n        sales = []\n        for row in df_recent.iter_rows(named=True):\n            sales.append(SaleItem(\n                date=str(row.get(c_updated, \"N/A\")),\n                product=str(row.get(c_nome, row.get(c_produto, \"N/A\"))),\n                value=float(row.get(c_venda, 0.0)),\n                quantity=1 # N\u00e3o temos quantidade expl\u00edcita na semana\n            ))\n\n        return sales\n\n    except Exception as e:\n        logger.error(f\"Error fetching recent sales: {str(e)}\")\n        raise HTTPException(status_code=500, detail=f\"Error fetching recent sales: {str(e)}\")\n\n\n@router.get(\"/top-products\", response_model=list[TopProduct])\nasync def get_top_products(\n    current_user: Annotated[User, Depends(get_current_active_user)],\n    limit: int = 5\n) -> list[TopProduct]:\n    \"\"\"\n    Get top selling products from Parquet data\n\n    Returns products ranked by total sales count and revenue.\n    \"\"\"\n    import polars as pl\n    import logging\n\n    logger = logging.getLogger(__name__)\n\n    try:\n        df = data_scope_service.get_filtered_dataframe(current_user)\n\n        # Mapeamento\n        cols = df.columns\n        c_venda = \"VENDA_30DD\" if \"VENDA_30DD\" in cols else \"venda_30_d\"\n        c_produto = \"PRODUTO\" if \"PRODUTO\" in cols else \"codigo\"\n        c_nome = \"NOME\" if \"NOME\" in cols else \"nome_produto\"\n        \n        # Usar VENDA_30DD para ranking de top produtos\n        if c_venda in cols:\n            df_with_sales = df.filter(pl.col(c_venda) > 0)\n        else:\n            return []\n\n        # Agrupar por produto\n        # Se n\u00e3o tiver NOME, usa PRODUTO\n        grp_cols = [c_produto]\n        if c_nome in cols:\n            grp_cols.append(c_nome)\n            \n        df_grouped = df_with_sales.group_by(grp_cols).agg([\n            pl.col(c_venda).sum().alias(\"total_sales\"),\n            pl.col(c_venda).sum().alias(\"revenue\") # Fallback revenue = sales\n        ])\n\n        df_sorted = df_grouped.sort(\"total_sales\", descending=True).head(limit)\n\n        # Criar resultado\n        top_products = []\n        for row in df_sorted.iter_rows(named=True):\n            p_name = str(row[c_nome]) if c_nome in row else str(row[c_produto])\n            top_products.append(TopProduct(\n                product=str(row[c_produto]),\n                productName=p_name[:50],  # Limitar tamanho\n                totalSales=int(row[\"total_sales\"]),\n                revenue=float(row[\"revenue\"])\n            ))\n\n        return top_products\n\n    except Exception as e:\n        logger.error(f\"Error fetching top products: {str(e)}\")\n        raise HTTPException(status_code=500, detail=f\"Error fetching top products: {str(e)}\")\n\n\nclass BusinessKPIs(BaseModel):\n    total_produtos: int\n    total_unes: int\n    produtos_ruptura: int\n    valor_estoque: float\n    top_produtos: list[dict]\n    vendas_por_categoria: list[dict]", "mimetype": "text/plain", "start_char_idx": 3707, "end_char_idx": 7593, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d38cb375-7122-49be-b411-ab60d4866688": {"__data__": {"id_": "d38cb375-7122-49be-b411-ab60d4866688", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\metrics.py", "language": "python", "lines": 369, "filename": "metrics.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\metrics.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\metrics.py", "language": "python", "lines": 369, "filename": "metrics.py"}, "hash": "780d95aeddf56c2fd5e0f4e9b7d61d31e41d948ab8a24418e7bfa5bbb168a1d6", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "37f0710a-6e73-4f24-b22d-6bcbcc976516", "node_type": "1", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\metrics.py", "language": "python", "lines": 369, "filename": "metrics.py"}, "hash": "a466c6d08938600b9daab2680255d7b86ad59de0c5d55017e1ec34be27babb35", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "82d936e7-0653-4ed4-9bfe-fd31b30a7b00", "node_type": "1", "metadata": {}, "hash": "9a54217e9ea938de9da7f1a414cb870552ec44ac421750b298d47132be66c1fc", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "@router.get(\"/business-kpis\", response_model=BusinessKPIs)\nasync def get_business_kpis(\n    current_user: Annotated[User, Depends(get_current_active_user)]\n) -> BusinessKPIs:\n    \"\"\"\n    Get business KPIs for Dashboard\n\n    Returns key business metrics including products, UNEs, stock ruptures, and top sellers.\n    Optimized to use Polars LazyFrame for memory efficiency.\n    \"\"\"\n    import polars as pl\n    import logging\n\n    logger = logging.getLogger(__name__)\n\n    try:\n        # Usar LazyFrame para evitar carregar tudo na mem\u00f3ria\n        lf = data_scope_service.get_filtered_lazyframe(current_user)\n        \n        # Verificar se temos dados antes de tentar processar\n        # collect_schema \u00e9 r\u00e1pido\n        schema = lf.collect_schema()\n        if not schema.names():\n             return BusinessKPIs(total_produtos=0, total_unes=0, produtos_ruptura=0, valor_estoque=0.0, top_produtos=[], vendas_por_categoria=[])\n\n        logger.info(f\"\ud83d\udcca KPIs: Iniciando processamento LAZY\")\n\n        # Preparar express\u00f5es de agrega\u00e7\u00e3o para rodar em UMA \u00daNICA PASSADA se poss\u00edvel\n        # Casting seguro para colunas num\u00e9ricas\n        def safe_col(name, alt_names=None):\n            if name in schema.names():\n                return pl.col(name)\n            if alt_names:\n                for alt in alt_names:\n                    if alt in schema.names():\n                        return pl.col(alt)\n            return pl.lit(0)\n\n        # Defini\u00e7\u00f5es de colunas com fallback (priorizar MAI\u00daSCULAS do SQL Server)\n        c_produto = safe_col(\"PRODUTO\")\n        c_une = safe_col(\"UNE\")\n        c_venda30 = safe_col(\"VENDA_30DD\").cast(pl.Float64, strict=False).fill_null(0)\n        c_est_une = safe_col(\"ESTOQUE_UNE\").cast(pl.Float64, strict=False).fill_null(0)\n        c_est_cd = safe_col(\"ESTOQUE_CD\").cast(pl.Float64, strict=False).fill_null(0)\n        c_est_lv = safe_col(\"ESTOQUE_LV\").cast(pl.Float64, strict=False).fill_null(0)\n        c_nome = safe_col(\"NOME\")\n        c_segmento = safe_col(\"NOMESEGMENTO\")\n\n        # Identificar nome real das colunas para group_by (usar MAI\u00daSCULAS do schema atual)\n        col_produto_name = \"PRODUTO\" if \"PRODUTO\" in schema.names() else None\n        col_nome_name = \"NOME\" if \"NOME\" in schema.names() else None\n        \n        # 1. M\u00e9tricas Escalares (Count, Sum)\n        metrics_exprs = [\n            c_produto.n_unique().alias(\"total_produtos\"),\n            c_est_une.sum().alias(\"sum_estoque_une\"),\n            c_est_cd.sum().alias(\"sum_estoque_cd\"),\n            # Ruptura: CD=0 & Loja < LV (se existir) & Venda > 0\n            ((c_est_cd == 0) & (c_venda30 > 0)).sum().alias(\"produtos_ruptura\") # Simplificado sem LV\n        ]\n        \n        if \"UNE\" in schema.names():\n             metrics_exprs.append(c_une.n_unique().alias(\"total_unes\"))\n        else:\n             metrics_exprs.append(pl.lit(0).alias(\"total_unes\"))\n\n        metrics_lf = lf.select(metrics_exprs)\n        \n        metrics_df = metrics_lf.collect() # Executa\n        metrics = metrics_df.row(0, named=True)\n        \n        valor_estoque = metrics[\"sum_estoque_une\"] + metrics[\"sum_estoque_cd\"]\n        \n        # 2.", "mimetype": "text/plain", "start_char_idx": 7596, "end_char_idx": 10724, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "82d936e7-0653-4ed4-9bfe-fd31b30a7b00": {"__data__": {"id_": "82d936e7-0653-4ed4-9bfe-fd31b30a7b00", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\metrics.py", "language": "python", "lines": 369, "filename": "metrics.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\metrics.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\metrics.py", "language": "python", "lines": 369, "filename": "metrics.py"}, "hash": "780d95aeddf56c2fd5e0f4e9b7d61d31e41d948ab8a24418e7bfa5bbb168a1d6", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d38cb375-7122-49be-b411-ab60d4866688", "node_type": "1", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\metrics.py", "language": "python", "lines": 369, "filename": "metrics.py"}, "hash": "f78d11cd5166aef248d29f62bd59f2ab54e108e3820d5f4caa83de6aeb36052a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Top Produtos (precisa de group_by)\n        top_produtos = []\n        if col_produto_name:\n            grp_cols = [col_produto_name]\n            if col_nome_name:\n                grp_cols.append(col_nome_name)\n                \n            top_produtos_lf = lf.filter(c_venda30 > 0)\\\n                .group_by(grp_cols)\\\n                .agg([c_venda30.sum().alias(\"vendas\")])\\\n                .sort(\"vendas\", descending=True)\\\n                .head(10)\n                \n            top_produtos_df = top_produtos_lf.collect()\n            \n            for row in top_produtos_df.iter_rows(named=True):\n                p_nome = str(row[col_nome_name]) if col_nome_name else str(row[col_produto_name])\n                top_produtos.append({\n                    \"produto\": str(row[col_produto_name]),\n                    \"nome\": p_nome[:40],\n                    \"vendas\": int(row[\"vendas\"])\n                })\n\n        # 3. Vendas por Categoria (usar MAI\u00daSCULAS do schema atual)\n        grupo_candidates = [\"NOMEGRUPO\", \"NOMECATEGORIA\", \"NOMESEGMENTO\"]\n        grupo_col_name = next((c for c in grupo_candidates if c in schema.names()), None)\n        \n        vendas_por_categoria = []\n        if grupo_col_name:\n            c_grupo = pl.col(grupo_col_name)\n            vendas_cat_lf = lf.filter(c_grupo.is_not_null())\\\n                .group_by(grupo_col_name)\\\n                .agg([\n                    c_venda30.sum().alias(\"vendas\"),\n                    c_produto.n_unique().alias(\"produtos\")\n                ])\\\n                .sort(\"vendas\", descending=True)\\\n                .head(10)  # Top 10 categorias\n                \n            vendas_cat_df = vendas_cat_lf.collect()\n            \n            for row in vendas_cat_df.iter_rows(named=True):\n                categoria = str(row.get(grupo_col_name, \"N/A\")).strip()\n                \n                if categoria and categoria != \"null\":\n                    vendas_por_categoria.append({\n                        \"categoria\": categoria[:30],\n                        \"vendas\": int(row[\"vendas\"]),\n                        \"produtos\": int(row[\"produtos\"])\n                    })\n\n        logger.info(f\"\ud83d\udcca KPIs calculados (Lazy) - Produtos: {metrics['total_produtos']}\")\n\n        return BusinessKPIs(\n            total_produtos=metrics[\"total_produtos\"],\n            total_unes=metrics[\"total_unes\"],\n            produtos_ruptura=metrics[\"produtos_ruptura\"],\n            valor_estoque=valor_estoque,\n            top_produtos=top_produtos,\n            vendas_por_categoria=vendas_por_categoria\n        )\n\n    except Exception as e:\n        logger.error(f\"Error fetching business KPIs: {str(e)}\", exc_info=True)\n        raise HTTPException(status_code=500, detail=f\"Error fetching business KPIs: {str(e)}\")", "mimetype": "text/plain", "start_char_idx": 10725, "end_char_idx": 13479, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0fdf0b74-991c-4d12-899c-d547d926ecad": {"__data__": {"id_": "0fdf0b74-991c-4d12-899c-d547d926ecad", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\playground.py", "language": "python", "lines": 169, "filename": "playground.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\playground.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\playground.py", "language": "python", "lines": 169, "filename": "playground.py"}, "hash": "d9d4e3df7bb52202430de2949d9a138abb3e568fefa1c3e1bfedb441127ee8ae", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5e1b27b7-f333-425f-acbc-5fe083d403f6", "node_type": "1", "metadata": {}, "hash": "6fbab4c937a23b16dc249e1bf0c97c05e5f5916f8b83acb190ade0afd6b43810", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "from typing import Annotated, Dict, Any, List, Optional\nfrom datetime import datetime\nimport json\nimport logging\n\nimport polars as pl\nfrom fastapi import APIRouter, Depends, HTTPException\nfrom pydantic import BaseModel, Field\n\nfrom app.api.dependencies import require_role, get_current_active_user\nfrom app.core.data_scope_service import data_scope_service\nfrom app.infrastructure.database.models import User\nfrom app.config.settings import settings\nfrom app.core.llm_gemini_adapter import GeminiLLMAdapter\n\nlogger = logging.getLogger(__name__)\n\nrouter = APIRouter(prefix=\"/playground\", tags=[\"Playground\"])\n\nclass QueryRequest(BaseModel):\n    query: str # N\u00e3o usada diretamente como SQL, mas sim como intent\n    columns: List[str] = []\n    limit: int = 100\n\nclass ChatMessage(BaseModel):\n    role: str  # \"user\" ou \"assistant\"\n    content: str\n    timestamp: Optional[str] = None\n\nclass PlaygroundChatRequest(BaseModel):\n    message: str\n    system_instruction: Optional[str] = None\n    history: List[ChatMessage] = Field(default_factory=list)\n    temperature: float = Field(default=1.0, ge=0.0, le=2.0)\n    max_tokens: int = Field(default=2048, ge=100, le=8192)\n    json_mode: bool = False\n    stream: bool = False\n\n@router.post(\"/query\")\nasync def execute_query(\n    current_user: Annotated[User, Depends(require_role(\"admin\"))],\n    request: QueryRequest\n):\n    \"\"\"\n    Endpoint para explora\u00e7\u00e3o de dados (Admin Only).\n    Permite selecionar colunas e visualizar dados brutos.\n    \"\"\"\n    try:\n        df = data_scope_service.get_filtered_dataframe(current_user)\n\n        # Selecionar colunas se especificadas\n        if request.columns:\n            valid_cols = [c for c in request.columns if c in df.columns]\n            if valid_cols:\n                df = df.select(valid_cols)\n\n        # Limitar resultados\n        result = df.head(request.limit)\n\n        return {\n            \"rows\": result.to_dicts(),\n            \"count\": len(result),\n            \"total_rows\": len(df), # Total no dataset (lazy count seria melhor, mas aqui df j\u00e1 \u00e9 eager ou quase)\n            \"columns\": result.columns\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2192, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5e1b27b7-f333-425f-acbc-5fe083d403f6": {"__data__": {"id_": "5e1b27b7-f333-425f-acbc-5fe083d403f6", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\playground.py", "language": "python", "lines": 169, "filename": "playground.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\playground.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\playground.py", "language": "python", "lines": 169, "filename": "playground.py"}, "hash": "d9d4e3df7bb52202430de2949d9a138abb3e568fefa1c3e1bfedb441127ee8ae", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0fdf0b74-991c-4d12-899c-d547d926ecad", "node_type": "1", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\playground.py", "language": "python", "lines": 169, "filename": "playground.py"}, "hash": "ecc0ac95da09447b69e91cd54a6a83fd99738d5728b234572e9acd2135654409", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "@router.post(\"/chat\")\nasync def playground_chat(\n    current_user: Annotated[User, Depends(get_current_active_user)],\n    request: PlaygroundChatRequest\n):\n    \"\"\"\n    Endpoint de chat do Playground com controles avan\u00e7ados.\n    Permite testar o modelo Gemini com diferentes par\u00e2metros.\n    \"\"\"\n    try:\n        # Validar mensagem n\u00e3o vazia\n        if not request.message or not request.message.strip():\n            raise HTTPException(\n                status_code=400,\n                detail=\"A mensagem n\u00e3o pode estar vazia. Por favor, digite algo.\"\n            )\n\n        if not settings.GEMINI_API_KEY:\n            raise HTTPException(\n                status_code=500,\n                detail=\"GEMINI_API_KEY n\u00e3o configurada no servidor\"\n            )\n\n        # Configurar LLM com par\u00e2metros customizados usando GeminiLLMAdapter\n        llm = GeminiLLMAdapter(\n            model_name=settings.LLM_MODEL_NAME,\n            gemini_api_key=settings.GEMINI_API_KEY,\n            system_instruction=request.system_instruction\n        ).get_llm()\n\n        # Note: GeminiLLMAdapter doesn't support custom temperature/max_tokens in get_llm()\n        # These parameters would need to be added to the adapter if needed\n\n        # Construir hist\u00f3rico de mensagens\n        messages = []\n        for msg in request.history:\n            if msg.role == \"user\":\n                messages.append((\"human\", msg.content))\n            elif msg.role == \"assistant\":\n                messages.append((\"assistant\", msg.content))\n\n        # Adicionar mensagem atual\n        messages.append((\"human\", request.message))\n\n        # Invocar LLM\n        start_time = datetime.now()\n        response = llm.invoke(messages)\n        end_time = datetime.now()\n\n        response_time = (end_time - start_time).total_seconds()\n\n        # Estat\u00edsticas de cache (simuladas por enquanto)\n        # Em produ\u00e7\u00e3o, voc\u00ea poderia usar Redis ou outro sistema de cache\n        cache_stats = {\n            \"hits\": 0,\n            \"misses\": 0,\n            \"hit_rate\": 0.0,\n            \"enabled\": False\n        }\n\n        return {\n            \"response\": response.content,\n            \"model_info\": {\n                \"model\": settings.LLM_MODEL_NAME,\n                \"temperature\": request.temperature,\n                \"max_tokens\": request.max_tokens,\n                \"json_mode\": request.json_mode\n            },\n            \"metadata\": {\n                \"response_time\": round(response_time, 2),\n                \"timestamp\": datetime.now().isoformat(),\n                \"user\": current_user.username\n            },\n            \"cache_stats\": cache_stats\n        }\n\n    except Exception as e:\n        logger.error(f\"Erro no playground chat: {e}\", exc_info=True)\n        raise HTTPException(\n            status_code=500,\n            detail=f\"Erro ao processar mensagem: {str(e)}\"\n        )\n\n\n@router.get(\"/info\")\nasync def get_model_info(\n    current_user: Annotated[User, Depends(get_current_active_user)]\n):\n    \"\"\"\n    Retorna informa\u00e7\u00f5es sobre o modelo LLM configurado.\n    \"\"\"\n    return {\n        \"model\": settings.LLM_MODEL_NAME,\n        \"api_key_configured\": bool(settings.GEMINI_API_KEY),\n        \"default_temperature\": 1.0,\n        \"default_max_tokens\": 2048,\n        \"max_temperature\": 2.0,\n        \"max_tokens_limit\": 8192\n    }", "mimetype": "text/plain", "start_char_idx": 2195, "end_char_idx": 5484, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "cd6f9f9b-001b-4617-bed7-e9ab7e311471": {"__data__": {"id_": "cd6f9f9b-001b-4617-bed7-e9ab7e311471", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\preferences.py", "language": "python", "lines": 286, "filename": "preferences.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\preferences.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\preferences.py", "language": "python", "lines": 286, "filename": "preferences.py"}, "hash": "0798f7432b97b9ff14bf5bf6909a61aae39736e3aa0e8c826064632893044516", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d0290f4a-517e-45ea-a30d-4aad9e0cf542", "node_type": "1", "metadata": {}, "hash": "096db2c16978b06640e0483bd103c93f7fb69e58d46fa1de1a3276000036631e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nUser Preferences Endpoints\nHandles user preferences and persistent memory\n\"\"\"\n\nfrom typing import Any\nimport uuid\n\nfrom fastapi import APIRouter, Depends, HTTPException, status\nfrom pydantic import BaseModel\nfrom sqlalchemy import select, and_\nfrom sqlalchemy.ext.asyncio import AsyncSession\n\nfrom app.api.dependencies import get_current_user, get_db\nfrom app.infrastructure.database.models import UserPreference, User\n\nrouter = APIRouter(prefix=\"/preferences\", tags=[\"Preferences\"])\n\n\n# Pydantic Models\nclass PreferenceCreate(BaseModel):\n    \"\"\"Request to create or update a preference\"\"\"\n    key: str\n    value: str\n    context: str | None = None\n\n\nclass PreferenceResponse(BaseModel):\n    \"\"\"Preference response\"\"\"\n    id: str\n    key: str\n    value: str\n    context: str | None\n    created_at: str\n    updated_at: str\n\n\nclass PreferenceListResponse(BaseModel):\n    \"\"\"List of preferences\"\"\"\n    preferences: dict[str, str]  # key: value mapping\n\n\n@router.get(\"\", response_model=PreferenceListResponse)\nasync def list_preferences(\n    current_user: User = Depends(get_current_user),\n    db: AsyncSession = Depends(get_db)\n) -> Any:\n    \"\"\"\n    List all preferences for the current user.\n\n    Returns a dictionary mapping preference keys to values.\n    \"\"\"\n    result = await db.execute(\n        select(UserPreference).where(UserPreference.user_id == current_user.id)\n    )\n    preferences = result.scalars().all()\n\n    return PreferenceListResponse(\n        preferences={pref.key: pref.value for pref in preferences}\n    )\n\n\n@router.get(\"/{key}\")\nasync def get_preference(\n    key: str,\n    current_user: User = Depends(get_current_user),\n    db: AsyncSession = Depends(get_db)\n) -> Any:\n    \"\"\"\n    Get a specific preference by key.\n    \"\"\"\n    result = await db.execute(\n        select(UserPreference).where(\n            and_(\n                UserPreference.user_id == current_user.id,\n                UserPreference.key == key\n            )\n        )\n    )\n    preference = result.scalar_one_or_none()\n\n    if not preference:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=f\"Preference '{key}' not found\"\n        )\n\n    return PreferenceResponse(\n        id=str(preference.id),\n        key=preference.key,\n        value=preference.value,\n        context=preference.context,\n        created_at=preference.created_at.isoformat(),\n        updated_at=preference.updated_at.isoformat()\n    )\n\n\n@router.post(\"\", response_model=PreferenceResponse)\nasync def set_preference(\n    request: PreferenceCreate,\n    current_user: User = Depends(get_current_user),\n    db: AsyncSession = Depends(get_db)\n) -> Any:\n    \"\"\"\n    Create or update a preference.\n\n    If the preference already exists, it will be updated.\n    \"\"\"\n    # Check if preference exists\n    result = await db.execute(\n        select(UserPreference).where(\n            and_(\n                UserPreference.user_id == current_user.id,\n                UserPreference.key == request.key\n            )\n        )\n    )\n    existing_pref = result.scalar_one_or_none()\n\n    if existing_pref:\n        # Update existing preference\n        existing_pref.value = request.value\n        if request.context is not None:\n            existing_pref.context = request.context\n        await db.commit()\n        await db.refresh(existing_pref)\n        preference = existing_pref\n    else:\n        # Create new preference\n        preference = UserPreference(\n            user_id=current_user.id,\n            key=request.key,\n            value=request.value,\n            context=request.context\n        )\n        db.add(preference)\n        await db.commit()\n        await db.refresh(preference)\n\n    return PreferenceResponse(\n        id=str(preference.id),\n        key=preference.key,\n        value=preference.value,\n        context=preference.context,\n        created_at=preference.created_at.isoformat(),\n        updated_at=preference.updated_at.isoformat()\n    )", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3960, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d0290f4a-517e-45ea-a30d-4aad9e0cf542": {"__data__": {"id_": "d0290f4a-517e-45ea-a30d-4aad9e0cf542", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\preferences.py", "language": "python", "lines": 286, "filename": "preferences.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\preferences.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\preferences.py", "language": "python", "lines": 286, "filename": "preferences.py"}, "hash": "0798f7432b97b9ff14bf5bf6909a61aae39736e3aa0e8c826064632893044516", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "cd6f9f9b-001b-4617-bed7-e9ab7e311471", "node_type": "1", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\preferences.py", "language": "python", "lines": 286, "filename": "preferences.py"}, "hash": "124eda212ea905559e557da8d563175b50733f461d07ae4ce62edbed9b28cf32", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "@router.put(\"/batch\")\nasync def set_preferences_batch(\n    preferences: dict[str, str],\n    current_user: User = Depends(get_current_user),\n    db: AsyncSession = Depends(get_db)\n) -> Any:\n    \"\"\"\n    Set multiple preferences at once.\n\n    Accepts a dictionary of key-value pairs.\n    \"\"\"\n    updated_count = 0\n    created_count = 0\n\n    for key, value in preferences.items():\n        # Check if preference exists\n        result = await db.execute(\n            select(UserPreference).where(\n                and_(\n                    UserPreference.user_id == current_user.id,\n                    UserPreference.key == key\n                )\n            )\n        )\n        existing_pref = result.scalar_one_or_none()\n\n        if existing_pref:\n            existing_pref.value = value\n            updated_count += 1\n        else:\n            new_pref = UserPreference(\n                user_id=current_user.id,\n                key=key,\n                value=value\n            )\n            db.add(new_pref)\n            created_count += 1\n\n    await db.commit()\n\n    return {\n        \"message\": \"Preferences updated successfully\",\n        \"updated\": updated_count,\n        \"created\": created_count,\n        \"total\": len(preferences)\n    }\n\n\n@router.delete(\"/{key}\")\nasync def delete_preference(\n    key: str,\n    current_user: User = Depends(get_current_user),\n    db: AsyncSession = Depends(get_db)\n) -> Any:\n    \"\"\"\n    Delete a specific preference.\n    \"\"\"\n    result = await db.execute(\n        select(UserPreference).where(\n            and_(\n                UserPreference.user_id == current_user.id,\n                UserPreference.key == key\n            )\n        )\n    )\n    preference = result.scalar_one_or_none()\n\n    if not preference:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=f\"Preference '{key}' not found\"\n        )\n\n    await db.delete(preference)\n    await db.commit()\n\n    return {\"message\": f\"Preference '{key}' deleted successfully\"}\n\n\n@router.get(\"/common/keys\")\nasync def get_common_keys() -> Any:\n    \"\"\"\n    Get list of common preference keys with descriptions.\n\n    Useful for frontend to know what preferences are available.\n    \"\"\"\n    return {\n        \"keys\": [\n            {\n                \"key\": UserPreference.Keys.PREFERRED_CHART_TYPE,\n                \"description\": \"Tipo de gr\u00e1fico preferido\",\n                \"options\": [\"bar\", \"line\", \"pie\", \"scatter\"],\n                \"default\": \"bar\"\n            },\n            {\n                \"key\": UserPreference.Keys.PREFERRED_DATA_FORMAT,\n                \"description\": \"Formato de dados preferido\",\n                \"options\": [\"table\", \"chart\", \"both\"],\n                \"default\": \"both\"\n            },\n            {\n                \"key\": UserPreference.Keys.LANGUAGE,\n                \"description\": \"Idioma\",\n                \"options\": [\"pt-BR\", \"en-US\"],\n                \"default\": \"pt-BR\"\n            },\n            {\n                \"key\": UserPreference.Keys.THEME,\n                \"description\": \"Tema\",\n                \"options\": [\"light\", \"dark\"],\n                \"default\": \"light\"\n            },\n            {\n                \"key\": UserPreference.Keys.COMPANY_NAME,\n                \"description\": \"Nome da empresa\",\n                \"type\": \"text\"\n            },\n            {\n                \"key\": UserPreference.Keys.BUSINESS_SEGMENT,\n                \"description\": \"Segmento de neg\u00f3cio\",\n                \"type\": \"text\"\n            },\n            {\n                \"key\": UserPreference.Keys.ANALYSIS_FOCUS,\n                \"description\": \"Foco principal de an\u00e1lise\",\n                \"options\": [\"sales\", \"inventory\", \"finance\"],\n                \"default\": \"sales\"\n            },\n            {\n                \"key\": UserPreference.Keys.NOTIFICATION_ENABLED,\n                \"description\": \"Notifica\u00e7\u00f5es habilitadas\",\n                \"options\": [\"true\", \"false\"],\n                \"default\": \"true\"\n            }\n        ]\n    }", "mimetype": "text/plain", "start_char_idx": 3963, "end_char_idx": 7938, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "71c035d9-d7a1-479e-924a-c5bc238b1df3": {"__data__": {"id_": "71c035d9-d7a1-479e-924a-c5bc238b1df3", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\reports.py", "language": "python", "lines": 218, "filename": "reports.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\reports.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\reports.py", "language": "python", "lines": 218, "filename": "reports.py"}, "hash": "2d5deadf72239112213776ae2fbd7f4082e68f36fa69ad555125b9f54783d77d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "bbcfc8f0-9aa1-4511-9f6c-49b7c3acc98e", "node_type": "1", "metadata": {}, "hash": "77d3a9156a8134c6200e3f33db8bb8bf8ceedda8c57b80f50b654aa06ca019e7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nReports Endpoints\nCRUD operations for reports\n\"\"\"\n\nimport uuid\nfrom typing import Annotated\n\nfrom fastapi import APIRouter, Depends, HTTPException, status\nfrom sqlalchemy import select\nfrom sqlalchemy.ext.asyncio import AsyncSession\n\nfrom app.api.dependencies import get_current_active_user, get_db, require_permission\nfrom app.infrastructure.database.models import Report, User\nfrom app.schemas.report import ReportCreate, ReportListResponse, ReportResponse, ReportUpdate\n\nrouter = APIRouter(prefix=\"/reports\", tags=[\"Reports\"])\n\n\n@router.get(\"\", response_model=list[ReportListResponse])\nasync def get_reports(\n    db: Annotated[AsyncSession, Depends(get_db)],\n    _: Annotated[User, Depends(require_permission(\"VIEW_REPORTS\"))],\n    status_filter: str | None = None,\n) -> list[Report]:\n    \"\"\"Get all reports with optional status filter\"\"\"\n    \n    query = select(Report).order_by(Report.created_at.desc())\n    \n    if status_filter:\n        query = query.where(Report.status == status_filter)\n    \n    result = await db.execute(query)\n    reports = result.scalars().all()\n    return list(reports)\n\n\n@router.get(\"/{report_id}\", response_model=ReportResponse)\nasync def get_report(\n    report_id: uuid.UUID,\n    db: Annotated[AsyncSession, Depends(get_db)],\n    _: Annotated[User, Depends(require_permission(\"VIEW_REPORTS\"))],\n) -> Report:\n    \"\"\"Get report by ID\"\"\"\n    \n    result = await db.execute(\n        select(Report).where(Report.id == report_id)\n    )\n    report = result.scalar_one_or_none()\n    \n    if not report:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=\"Report not found\"\n        )\n    \n    # Add author name\n    author_result = await db.execute(\n        select(User.username).where(User.id == report.author_id)\n    )\n    author_name = author_result.scalar_one_or_none()\n    \n    # Convert to dict and add author_name\n    report_dict = {\n        \"id\": report.id,\n        \"title\": report.title,\n        \"description\": report.description,\n        \"content\": report.content,\n        \"status\": report.status,\n        \"author_id\": report.author_id,\n        \"author_name\": author_name,\n        \"created_at\": report.created_at,\n        \"updated_at\": report.updated_at,\n    }\n    \n    return report_dict\n\n\n@router.post(\"\", response_model=ReportResponse, status_code=status.HTTP_201_CREATED)\nasync def create_report(\n    report_data: ReportCreate,\n    db: Annotated[AsyncSession, Depends(get_db)],\n    current_user: Annotated[User, Depends(require_permission(\"CREATE_REPORTS\"))],\n) -> dict:\n    \"\"\"Create new report\"\"\"\n    \n    new_report = Report(\n        title=report_data.title,\n        description=report_data.description,\n        content=report_data.content,\n        status=report_data.status,\n        author_id=current_user.id,\n    )\n    \n    db.add(new_report)\n    await db.commit()\n    await db.refresh(new_report)\n    \n    return {\n        \"id\": new_report.id,\n        \"title\": new_report.title,\n        \"description\": new_report.description,\n        \"content\": new_report.content,\n        \"status\": new_report.status,\n        \"author_id\": new_report.author_id,\n        \"author_name\": current_user.username,\n        \"created_at\": new_report.created_at,\n        \"updated_at\": new_report.updated_at,\n    }", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3281, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "bbcfc8f0-9aa1-4511-9f6c-49b7c3acc98e": {"__data__": {"id_": "bbcfc8f0-9aa1-4511-9f6c-49b7c3acc98e", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\reports.py", "language": "python", "lines": 218, "filename": "reports.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\reports.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\reports.py", "language": "python", "lines": 218, "filename": "reports.py"}, "hash": "2d5deadf72239112213776ae2fbd7f4082e68f36fa69ad555125b9f54783d77d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "71c035d9-d7a1-479e-924a-c5bc238b1df3", "node_type": "1", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\reports.py", "language": "python", "lines": 218, "filename": "reports.py"}, "hash": "3dc4ff7ef821aede2e6efe2865150263f6cf18ceeeee4d9fc67d05fbc55b9308", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "@router.put(\"/{report_id}\", response_model=ReportResponse)\nasync def update_report(\n    report_id: uuid.UUID,\n    report_data: ReportUpdate,\n    db: Annotated[AsyncSession, Depends(get_db)],\n    current_user: Annotated[User, Depends(require_permission(\"EDIT_REPORTS\"))],\n) -> dict:\n    \"\"\"Update report\"\"\"\n    \n    result = await db.execute(\n        select(Report).where(Report.id == report_id)\n    )\n    report = result.scalar_one_or_none()\n    \n    if not report:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=\"Report not found\"\n        )\n    \n    # Check ownership (non-admins can only edit their own reports)\n    if current_user.role != \"admin\" and report.author_id != current_user.id:\n        raise HTTPException(\n            status_code=status.HTTP_403_FORBIDDEN,\n            detail=\"You can only edit your own reports\"\n        )\n    \n    # Update fields\n    update_data = report_data.model_dump(exclude_unset=True)\n    for field, value in update_data.items():\n        setattr(report, field, value)\n    \n    await db.commit()\n    await db.refresh(report)\n    \n    return {\n        \"id\": report.id,\n        \"title\": report.title,\n        \"description\": report.description,\n        \"content\": report.content,\n        \"status\": report.status,\n        \"author_id\": report.author_id,\n        \"author_name\": current_user.username,\n        \"created_at\": report.created_at,\n        \"updated_at\": report.updated_at,\n    }\n\n\n@router.delete(\"/{report_id}\", status_code=status.HTTP_204_NO_CONTENT)\nasync def delete_report(\n    report_id: uuid.UUID,\n    db: Annotated[AsyncSession, Depends(get_db)],\n    current_user: Annotated[User, Depends(require_permission(\"DELETE_REPORTS\"))],\n):\n    \"\"\"Delete report\"\"\"\n    \n    result = await db.execute(\n        select(Report).where(Report.id == report_id)\n    )\n    report = result.scalar_one_or_none()\n    \n    if not report:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=\"Report not found\"\n        )\n    \n    # Check ownership (non-admins can only delete their own reports)\n    if current_user.role != \"admin\" and report.author_id != current_user.id:\n        raise HTTPException(\n            status_code=status.HTTP_403_FORBIDDEN,\n            detail=\"You can only delete your own reports\"\n        )\n    \n    await db.delete(report)\n    await db.commit()\n\n\n@router.post(\"/{report_id}/generate-pdf\")\nasync def generate_pdf(\n    report_id: uuid.UUID,\n    db: Annotated[AsyncSession, Depends(get_db)],\n    _: Annotated[User, Depends(require_permission(\"VIEW_REPORTS\"))],\n) -> dict[str, str]:\n    \"\"\"\n    Generate PDF for report\n    \n    TODO: Implement PDF generation with reportlab or weasyprint\n    \"\"\"\n    result = await db.execute(\n        select(Report).where(Report.id == report_id)\n    )\n    report = result.scalar_one_or_none()\n    \n    if not report:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=\"Report not found\"\n        )\n    \n    # Mock response - implement actual PDF generation\n    return {\n        \"message\": \"PDF generation not yet implemented\",\n        \"report_id\": str(report_id),\n        \"report_title\": report.title,\n    }", "mimetype": "text/plain", "start_char_idx": 3284, "end_char_idx": 6520, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c879c073-5889-49e5-9bd0-d336a3623939": {"__data__": {"id_": "c879c073-5889-49e5-9bd0-d336a3623939", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\rupturas.py", "language": "python", "lines": 210, "filename": "rupturas.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\rupturas.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\rupturas.py", "language": "python", "lines": 210, "filename": "rupturas.py"}, "hash": "8817a2b0912f4ff98534832eb60ca9ebaccae0c1d60b07aa8c41a0ee97d27953", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2eafb285-318d-49e8-baa9-76d9f9d66bc5", "node_type": "1", "metadata": {}, "hash": "838ec5cdf9cee5c00b01a4df3c193543713d42c6b0a6f998e67f837d82ce13b7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "from typing import Annotated, List, Dict, Any, Optional\n\nimport polars as pl\nfrom fastapi import APIRouter, Depends, HTTPException, Query\n\nfrom app.api.dependencies import get_current_active_user\nfrom app.core.data_scope_service import data_scope_service\nfrom app.infrastructure.database.models import User\n\nrouter = APIRouter(prefix=\"/rupturas\", tags=[\"Rupturas\"])\n\n@router.get(\"/critical\", response_model=List[Dict[str, Any]])\nasync def get_critical_rupturas(\n    current_user: Annotated[User, Depends(get_current_active_user)],\n    limit: int = Query(50, description=\"N\u00famero m\u00e1ximo de resultados\"),\n    segmento: Optional[str] = Query(None, description=\"Filtro por segmento (NOMESEGMENTO)\"),\n    une: Optional[str] = Query(None, description=\"Filtro por UNE\")\n):\n    \"\"\"\n    Produtos com ruptura cr\u00edtica (ESTOQUE_CD=0 + Estoque Loja < Linha Verde).", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 850, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2eafb285-318d-49e8-baa9-76d9f9d66bc5": {"__data__": {"id_": "2eafb285-318d-49e8-baa9-76d9f9d66bc5", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\rupturas.py", "language": "python", "lines": 210, "filename": "rupturas.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\rupturas.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\rupturas.py", "language": "python", "lines": 210, "filename": "rupturas.py"}, "hash": "8817a2b0912f4ff98534832eb60ca9ebaccae0c1d60b07aa8c41a0ee97d27953", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c879c073-5889-49e5-9bd0-d336a3623939", "node_type": "1", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\rupturas.py", "language": "python", "lines": 210, "filename": "rupturas.py"}, "hash": "928136b175700e65ae9b2f4491bef137733f640dbd4a5060dcad6e2f59d8764d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e2a7c042-fe91-42d9-b4a2-e7ba431684c4", "node_type": "1", "metadata": {}, "hash": "d618015130824eb12e79bf2e000e8336f7332f2f189139e449f67b74799113c9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Defini\u00e7\u00e3o de Ruptura Cr\u00edtica (conforme regras de neg\u00f3cio):\n    - ESTOQUE_CD = 0 (sem estoque no centro de distribui\u00e7\u00e3o)\n    - ESTOQUE_UNE < ESTOQUE_LV (estoque da loja menor que linha verde)\n    - VENDA_30DD > 0 (produtos com vendas nos \u00faltimos 30 dias)\n\n    Retorna:\n    - CRITICIDADE_PCT: percentual de criticidade (0-100%) baseado na raz\u00e3o venda/linha verde\n    - NECESSIDADE: quantidade faltando para atingir a linha verde\n    \"\"\"\n    try:\n        df = data_scope_service.get_filtered_dataframe(current_user)\n\n        # Verificar colunas necess\u00e1rias\n        required_cols = [\"ESTOQUE_CD\", \"ESTOQUE_UNE\", \"ESTOQUE_LV\", \"VENDA_30DD\"]\n        if not all(col in df.columns for col in required_cols):\n            return []\n\n        # Casting para garantir tipos num\u00e9ricos\n        df = df.with_columns([\n            pl.col(\"VENDA_30DD\").cast(pl.Float64, strict=False).fill_null(0),\n            pl.col(\"ESTOQUE_CD\").cast(pl.Float64, strict=False).fill_null(0),\n            pl.col(\"ESTOQUE_UNE\").cast(pl.Float64, strict=False).fill_null(0),\n            pl.col(\"ESTOQUE_LV\").cast(pl.Float64, strict=False).fill_null(0),\n        ])\n\n        # Aplicar filtros opcionais\n        if segmento and \"NOMESEGMENTO\" in df.columns:\n            df = df.filter(pl.col(\"NOMESEGMENTO\") == segmento)\n\n        if une:\n            # UNE pode ser string ou int - tentar convers\u00e3o\n            import logging\n            logger = logging.getLogger(__name__)\n            logger.info(f\"\ud83d\udd0d Filtro UNE recebido: '{une}'\")\n            \n            try:\n                une_val = int(une)\n                df = df.filter(pl.col(\"UNE\") == une_val)\n                logger.info(f\"\ud83d\udcca Filtro UNE aplicado como INT: {df.height} registros\")\n            except (ValueError, Exception) as e:\n                # Se falhar, tentar como string\n                logger.warning(f\"\u26a0\ufe0f Convers\u00e3o para int falhou, tentando como string: {e}\")\n                df = df.filter(pl.col(\"UNE\").cast(pl.Utf8) == str(une))\n                logger.info(f\"\ud83d\udcca Filtro UNE aplicado como STRING: {df.height} registros\")\n\n        # Defini\u00e7\u00e3o de ruptura cr\u00edtica:\n        # CD=0 + Loja < Linha Verde + Vendas > 0\n        rupturas = df.filter(\n            (pl.col(\"ESTOQUE_CD\") <= 0) &\n            (pl.col(\"ESTOQUE_UNE\") < pl.col(\"ESTOQUE_LV\")) &\n            (pl.col(\"VENDA_30DD\") > 0)\n        )\n\n        # Calcular criticidade % e necessidade\n        rupturas = rupturas.with_columns([\n            # Criticidade = (Venda / Linha Verde) * 100, limitado a 100%\n            pl.when(pl.col(\"ESTOQUE_LV\") > 0)\n              .then((pl.col(\"VENDA_30DD\") / pl.col(\"ESTOQUE_LV\") * 100).clip(0, 100))\n              .otherwise(0)\n              .alias(\"CRITICIDADE_PCT\"),\n\n            # Necessidade = Linha Verde - Estoque Atual\n            (pl.col(\"ESTOQUE_LV\") - pl.col(\"ESTOQUE_UNE\"))\n              .clip(0, None)\n              .alias(\"NECESSIDADE\")\n        ])\n\n        # Ordenar por criticidade e venda\n        rupturas = rupturas.sort([\"CRITICIDADE_PCT\", \"VENDA_30DD\"], descending=[True, True]).head(limit)\n\n        return rupturas.to_dicts()\n    except Exception as e:\n        import traceback\n        with open(\"rupturas_error.log\", \"a\") as f:\n            f.write(f\"Error in endpoint: {e}\\n\")\n            traceback.print_exc(file=f)\n        raise HTTPException(status_code=500, detail=str(e))", "mimetype": "text/plain", "start_char_idx": 856, "end_char_idx": 4169, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e2a7c042-fe91-42d9-b4a2-e7ba431684c4": {"__data__": {"id_": "e2a7c042-fe91-42d9-b4a2-e7ba431684c4", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\rupturas.py", "language": "python", "lines": 210, "filename": "rupturas.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\rupturas.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\rupturas.py", "language": "python", "lines": 210, "filename": "rupturas.py"}, "hash": "8817a2b0912f4ff98534832eb60ca9ebaccae0c1d60b07aa8c41a0ee97d27953", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2eafb285-318d-49e8-baa9-76d9f9d66bc5", "node_type": "1", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\rupturas.py", "language": "python", "lines": 210, "filename": "rupturas.py"}, "hash": "3b908c54d8da7fc4e646e25006ed692c288075c46ffda78080960cc37806ec7e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "bc409440-e61a-4817-8a40-cf2c8dc3424a", "node_type": "1", "metadata": {}, "hash": "8d2b9a8027a1053f53cf87019ad87c0a075991b54967af73e792a5ba60e53c4c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "@router.get(\"/filters/segmentos\", response_model=List[str])\nasync def get_segmentos(\n    current_user: Annotated[User, Depends(get_current_active_user)]\n):\n    \"\"\"\n    Lista todos os segmentos dispon\u00edveis para filtro.\n    \"\"\"\n    try:\n        df = data_scope_service.get_filtered_dataframe(current_user)\n\n        if \"NOMESEGMENTO\" not in df.columns:\n            return []\n\n        segmentos = df.select(\"NOMESEGMENTO\").unique().sort(\"NOMESEGMENTO\").to_series().to_list()\n        return [s for s in segmentos if s is not None and str(s).strip()]\n    except Exception as e:\n        import traceback\n        with open(\"rupturas_error.log\", \"a\") as f:\n            f.write(f\"Error in endpoint: {e}\\n\")\n            traceback.print_exc(file=f)\n        raise HTTPException(status_code=500, detail=str(e))\n\n\n@router.get(\"/filters/unes\", response_model=List[str])\nasync def get_unes(\n    current_user: Annotated[User, Depends(get_current_active_user)]\n):\n    \"\"\"\n    Lista todas as UNEs dispon\u00edveis para filtro.\n    \"\"\"\n    try:\n        df = data_scope_service.get_filtered_dataframe(current_user)\n\n        if \"UNE\" not in df.columns:\n            return []\n\n        unes = df.select(\"UNE\").unique().sort(\"UNE\").to_series().to_list()\n        return [str(u) for u in unes if u is not None]\n    except Exception as e:\n        import traceback\n        with open(\"rupturas_error.log\", \"a\") as f:\n            f.write(f\"Error in endpoint: {e}\\n\")\n            traceback.print_exc(file=f)\n        raise HTTPException(status_code=500, detail=str(e))", "mimetype": "text/plain", "start_char_idx": 4172, "end_char_idx": 5701, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "bc409440-e61a-4817-8a40-cf2c8dc3424a": {"__data__": {"id_": "bc409440-e61a-4817-8a40-cf2c8dc3424a", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\rupturas.py", "language": "python", "lines": 210, "filename": "rupturas.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\rupturas.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\rupturas.py", "language": "python", "lines": 210, "filename": "rupturas.py"}, "hash": "8817a2b0912f4ff98534832eb60ca9ebaccae0c1d60b07aa8c41a0ee97d27953", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e2a7c042-fe91-42d9-b4a2-e7ba431684c4", "node_type": "1", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\rupturas.py", "language": "python", "lines": 210, "filename": "rupturas.py"}, "hash": "55769b9cdf85b11532173fbd39b51428ec131353dc22ebe388587845eb88b9f3", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "@router.get(\"/summary\", response_model=Dict[str, Any])\nasync def get_rupturas_summary(\n    current_user: Annotated[User, Depends(get_current_active_user)],\n    segmento: Optional[str] = Query(None, description=\"Filtro por segmento\"),\n    une: Optional[str] = Query(None, description=\"Filtro por UNE\")\n):\n    \"\"\"\n    Retorna resumo de m\u00e9tricas de rupturas cr\u00edticas.\n    \"\"\"\n    try:\n        df = data_scope_service.get_filtered_dataframe(current_user)\n\n        required_cols = [\"ESTOQUE_CD\", \"ESTOQUE_UNE\", \"ESTOQUE_LV\", \"VENDA_30DD\"]\n        if not all(col in df.columns for col in required_cols):\n            return {\"total\": 0, \"criticos\": 0, \"valor_estimado\": 0}\n\n        # Casting\n        df = df.with_columns([\n            pl.col(\"VENDA_30DD\").cast(pl.Float64, strict=False).fill_null(0),\n            pl.col(\"ESTOQUE_CD\").cast(pl.Float64, strict=False).fill_null(0),\n            pl.col(\"ESTOQUE_UNE\").cast(pl.Float64, strict=False).fill_null(0),\n            pl.col(\"ESTOQUE_LV\").cast(pl.Float64, strict=False).fill_null(0),\n        ])\n\n        # Aplicar filtros\n        if segmento and \"NOMESEGMENTO\" in df.columns:\n            df = df.filter(pl.col(\"NOMESEGMENTO\") == segmento)\n        if une:\n            try:\n                une_val = int(une)\n                df = df.filter(pl.col(\"UNE\") == une_val)\n            except (ValueError, Exception):\n                df = df.filter(pl.col(\"UNE\").cast(pl.Utf8) == str(une))\n\n        # Filtrar rupturas\n        rupturas = df.filter(\n            (pl.col(\"ESTOQUE_CD\") <= 0) &\n            (pl.col(\"ESTOQUE_UNE\") < pl.col(\"ESTOQUE_LV\")) &\n            (pl.col(\"VENDA_30DD\") > 0)\n        )\n\n        # Calcular criticidade\n        rupturas = rupturas.with_columns([\n            pl.when(pl.col(\"ESTOQUE_LV\") > 0)\n              .then((pl.col(\"VENDA_30DD\") / pl.col(\"ESTOQUE_LV\") * 100).clip(0, 100))\n              .otherwise(0)\n              .alias(\"CRITICIDADE_PCT\")\n        ])\n\n        total = rupturas.height\n        criticos = rupturas.filter(pl.col(\"CRITICIDADE_PCT\") >= 75).height\n\n        return {\n            \"total\": total,\n            \"criticos\": criticos,\n            \"valor_estimado\": 0  # Pode ser calculado se houver coluna de custo\n        }\n    except Exception as e:\n        import traceback\n        with open(\"rupturas_error.log\", \"a\") as f:\n            f.write(f\"Error in endpoint: {e}\\n\")\n            traceback.print_exc(file=f)\n        raise HTTPException(status_code=500, detail=str(e))", "mimetype": "text/plain", "start_char_idx": 5704, "end_char_idx": 8154, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "545248e8-3e14-4af6-b6bb-9f151b084be0": {"__data__": {"id_": "545248e8-3e14-4af6-b6bb-9f151b084be0", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\shared.py", "language": "python", "lines": 196, "filename": "shared.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\shared.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\shared.py", "language": "python", "lines": 196, "filename": "shared.py"}, "hash": "2a6f44782c74179fbb4458821d3743064189abb234933681fba77d30cddde412", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "bee91eee-1fff-4ff1-b3cb-80e20cdeec22", "node_type": "1", "metadata": {}, "hash": "22985ed1a1ac72f1035fbf12f1cbab6410f71f8dfb01ed4f99be9c739a857524", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nShared Conversations Endpoints\nHandles sharing and viewing shared conversations\n\"\"\"\n\nimport secrets\nfrom datetime import datetime, timedelta\nfrom typing import Any\nimport uuid\n\nfrom fastapi import APIRouter, Depends, HTTPException, status\nfrom pydantic import BaseModel\nfrom sqlalchemy import select\nfrom sqlalchemy.ext.asyncio import AsyncSession\n\nfrom app.api.dependencies import get_current_user, get_db\nfrom app.infrastructure.database.models import SharedConversation, User\n\nrouter = APIRouter(prefix=\"/shared\", tags=[\"Shared Conversations\"])\n\n\n# Pydantic Models\nclass ShareConversationRequest(BaseModel):\n    \"\"\"Request to share a conversation\"\"\"\n    session_id: str\n    messages: list[dict]\n    title: str | None = None\n    expires_in_days: int | None = 30  # Default 30 days\n\n\nclass ShareConversationResponse(BaseModel):\n    \"\"\"Response with share URL\"\"\"\n    share_id: str\n    share_url: str\n    expires_at: datetime | None\n\n\nclass SharedConversationView(BaseModel):\n    \"\"\"Shared conversation data for viewing\"\"\"\n    share_id: str\n    title: str | None\n    messages: list[dict]\n    created_at: datetime\n    view_count: int\n\n\n@router.post(\"/share\", response_model=ShareConversationResponse)\nasync def share_conversation(\n    request: ShareConversationRequest,\n    current_user: User = Depends(get_current_user),\n    db: AsyncSession = Depends(get_db)\n) -> Any:\n    \"\"\"\n    Share a conversation and get a public link.\n\n    Creates a shareable link for the conversation that can be accessed by anyone.\n    \"\"\"\n    # Generate unique share_id\n    share_id = secrets.token_urlsafe(16)\n\n    # Calculate expiration date\n    expires_at = None\n    if request.expires_in_days:\n        expires_at = datetime.utcnow() + timedelta(days=request.expires_in_days)\n\n    # Create shared conversation\n    shared_conv = SharedConversation(\n        share_id=share_id,\n        session_id=request.session_id,\n        user_id=current_user.id,\n        title=request.title,\n        messages_list=request.messages,\n        expires_at=expires_at,\n        is_active=True,\n        view_count=0\n    )\n\n    db.add(shared_conv)\n    await db.commit()\n    await db.refresh(shared_conv)\n\n    return ShareConversationResponse(\n        share_id=share_id,\n        share_url=f\"/shared/{share_id}\",\n        expires_at=expires_at\n    )\n\n\n@router.get(\"/{share_id}\", response_model=SharedConversationView)\nasync def view_shared_conversation(\n    share_id: str,\n    db: AsyncSession = Depends(get_db)\n) -> Any:\n    \"\"\"\n    View a shared conversation by its share_id.\n\n    This endpoint is public and doesn't require authentication.\n    \"\"\"\n    # Query the shared conversation\n    result = await db.execute(\n        select(SharedConversation).where(SharedConversation.share_id == share_id)\n    )\n    shared_conv = result.scalar_one_or_none()\n\n    if not shared_conv:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=\"Shared conversation not found\"\n        )\n\n    # Check if expired\n    if shared_conv.is_expired or not shared_conv.is_active:\n        raise HTTPException(\n            status_code=status.HTTP_410_GONE,\n            detail=\"This shared conversation has expired or is no longer available\"\n        )\n\n    # Increment view count\n    shared_conv.increment_view_count()\n    await db.commit()\n\n    return SharedConversationView(\n        share_id=shared_conv.share_id,\n        title=shared_conv.title,\n        messages=shared_conv.messages_list,\n        created_at=shared_conv.created_at,\n        view_count=shared_conv.view_count\n    )\n\n\n@router.delete(\"/{share_id}\")\nasync def delete_shared_conversation(\n    share_id: str,\n    current_user: User = Depends(get_current_user),\n    db: AsyncSession = Depends(get_db)\n) -> Any:\n    \"\"\"\n    Delete/deactivate a shared conversation.\n\n    Only the owner or admin can delete a shared conversation.\n    \"\"\"\n    # Query the shared conversation\n    result = await db.execute(\n        select(SharedConversation).where(SharedConversation.share_id == share_id)\n    )\n    shared_conv = result.scalar_one_or_none()\n\n    if not shared_conv:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=\"Shared conversation not found\"\n        )\n\n    # Check ownership or admin\n    if shared_conv.user_id != current_user.id and current_user.role != \"admin\":\n        raise HTTPException(\n            status_code=status.HTTP_403_FORBIDDEN,\n            detail=\"You don't have permission to delete this shared conversation\"\n        )\n\n    # Soft delete - just deactivate\n    shared_conv.is_active = False\n    await db.commit()\n\n    return {\"message\": \"Shared conversation deleted successfully\"}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4684, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "bee91eee-1fff-4ff1-b3cb-80e20cdeec22": {"__data__": {"id_": "bee91eee-1fff-4ff1-b3cb-80e20cdeec22", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\shared.py", "language": "python", "lines": 196, "filename": "shared.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\shared.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\shared.py", "language": "python", "lines": 196, "filename": "shared.py"}, "hash": "2a6f44782c74179fbb4458821d3743064189abb234933681fba77d30cddde412", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "545248e8-3e14-4af6-b6bb-9f151b084be0", "node_type": "1", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\shared.py", "language": "python", "lines": 196, "filename": "shared.py"}, "hash": "c67a462069387354f04705a1131eba061adeef3008c69fc30177180d13ab2b1f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "@router.get(\"/user/list\")\nasync def list_user_shared_conversations(\n    current_user: User = Depends(get_current_user),\n    db: AsyncSession = Depends(get_db)\n) -> Any:\n    \"\"\"\n    List all shared conversations created by the current user.\n    \"\"\"\n    result = await db.execute(\n        select(SharedConversation)\n        .where(SharedConversation.user_id == current_user.id)\n        .where(SharedConversation.is_active == True)\n        .order_by(SharedConversation.created_at.desc())\n    )\n    shared_convs = result.scalars().all()\n\n    return [\n        {\n            \"share_id\": conv.share_id,\n            \"title\": conv.title,\n            \"session_id\": conv.session_id,\n            \"created_at\": conv.created_at,\n            \"expires_at\": conv.expires_at,\n            \"view_count\": conv.view_count,\n            \"is_expired\": conv.is_expired\n        }\n        for conv in shared_convs\n    ]", "mimetype": "text/plain", "start_char_idx": 4687, "end_char_idx": 5578, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "28eff17a-aedb-4967-9386-8c93300eea8f": {"__data__": {"id_": "28eff17a-aedb-4967-9386-8c93300eea8f", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\test.py", "language": "python", "lines": 15, "filename": "test.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\test.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\test.py", "language": "python", "lines": 15, "filename": "test.py"}, "hash": "19e15495208dd30b335e7e5fc5e737da0f77063faef403b9526ddbb82e3a2e39", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"Endpoint de teste SEM banco para verificar se backend funciona\"\"\"\nfrom fastapi import APIRouter\n\ntest_router = APIRouter(prefix=\"/test\", tags=[\"Test\"])\n\n@test_router.get(\"/ping\")\nasync def ping():\n    \"\"\"Teste simples sem banco\"\"\"\n    return {\"status\": \"pong\", \"message\": \"Backend funcionando!\"}\n\n@test_router.post(\"/echo\")\nasync def echo(data: dict):\n    \"\"\"Echo dos dados recebidos\"\"\"\n    return {\"received\": data, \"status\": \"ok\"}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 435, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "70fc8a6c-750b-4098-a4b3-382346c31709": {"__data__": {"id_": "70fc8a6c-750b-4098-a4b3-382346c31709", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\transfers.py", "language": "python", "lines": 422, "filename": "transfers.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\transfers.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\transfers.py", "language": "python", "lines": 422, "filename": "transfers.py"}, "hash": "297a0d8922026770a8af137557331aafd15f2d1728c5dfc2ca8e0b2705bb5452", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "047d89d4-ae5c-4452-acac-bb2c40b301a6", "node_type": "1", "metadata": {}, "hash": "d505b8c67cdd5c84d4f619029fb16d6c1430230341c2ca05945ae77fdb6b4dc8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "from typing import Annotated, List, Dict, Any, Optional\nfrom datetime import datetime\nimport json\nimport os\nfrom pathlib import Path\n\nfrom fastapi import APIRouter, Depends, HTTPException, status, Query\nfrom pydantic import BaseModel, Field\n\nfrom app.api.dependencies import get_current_active_user\nfrom app.infrastructure.database.models import User\nfrom app.core.tools.une_tools import (\n    validar_transferencia_produto,\n    sugerir_transferencias_automaticas,\n)\nfrom app.core.utils.error_handler import APIError\n\nrouter = APIRouter(prefix=\"/transfers\", tags=[\"Transfers\"])\n\n# Path to store transfer requests\nTRANSFER_REQUESTS_DIR = Path(\"data/transferencias\")\nos.makedirs(TRANSFER_REQUESTS_DIR, exist_ok=True)\n\n\nclass TransferRequestPayload(BaseModel):\n    produto_id: int\n    une_origem: int\n    une_destino: int\n    quantidade: int\n    solicitante_id: str # Will be populated by current_user\n\n\nclass TransferReportQuery(BaseModel):\n    start_date: Optional[str] = None\n    end_date: Optional[str] = None\n\n\nclass ProductSearchRequest(BaseModel):\n    segmento: Optional[str] = None\n    fabricante: Optional[str] = None\n    estoque_min: Optional[int] = None\n    limit: int = Field(default=50, le=500)\n\n\nclass BulkTransferRequestPayload(BaseModel):\n    \"\"\"Payload para transfer\u00eancias m\u00faltiplas (1\u2192N ou N\u2192N)\"\"\"\n    items: List[TransferRequestPayload]\n    modo: str = Field(description=\"Modo: '1\u21921', '1\u2192N', ou 'N\u2192N'\")", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1418, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "047d89d4-ae5c-4452-acac-bb2c40b301a6": {"__data__": {"id_": "047d89d4-ae5c-4452-acac-bb2c40b301a6", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\transfers.py", "language": "python", "lines": 422, "filename": "transfers.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\transfers.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\transfers.py", "language": "python", "lines": 422, "filename": "transfers.py"}, "hash": "297a0d8922026770a8af137557331aafd15f2d1728c5dfc2ca8e0b2705bb5452", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "70fc8a6c-750b-4098-a4b3-382346c31709", "node_type": "1", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\transfers.py", "language": "python", "lines": 422, "filename": "transfers.py"}, "hash": "31487cbac2b20ba931ae92df24836e84adf6608b5acf6c538f0cf1763fb5b66d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "145cd032-9fd0-4da4-a6c5-5d12fc566986", "node_type": "1", "metadata": {}, "hash": "e102243383069378847fd6fc2568056828c541ebac7d8d3fef8164e5b6793ca2", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "@router.post(\"/validate\")\nasync def validate_transfer(\n    payload: TransferRequestPayload,\n    current_user: Annotated[User, Depends(get_current_active_user)],\n) -> Dict[str, Any]:\n    \"\"\"\n    Endpoint to validate a product transfer between UNEs.\n    Integrates with `validar_transferencia_produto` tool.\n    Includes priority score (0-100) and urgency level.\n    \"\"\"\n    import polars as pl\n    from app.core.data_scope_service import data_scope_service\n\n    try:\n        # Valida\u00e7\u00e3o b\u00e1sica usando a tool existente\n        result = validar_transferencia_produto.invoke({\n            \"produto_id\": payload.produto_id,\n            \"une_origem\": payload.une_origem,\n            \"une_destino\": payload.une_destino,\n            \"quantidade\": payload.quantidade,\n        })\n\n        # Calcular score de prioridade baseado em criticidade\n        score_prioridade = 50  # Default\n        nivel_urgencia = \"NORMAL\"\n\n        try:\n            df = data_scope_service.get_filtered_dataframe(current_user)\n\n            # Buscar dados do produto na UNE destino\n            df_produto = df.filter(\n                (pl.col(\"PRODUTO\") == payload.produto_id) &\n                (pl.col(\"UNE\") == payload.une_destino)\n            )\n\n            if len(df_produto) > 0:\n                row = df_produto.row(0, named=True)\n\n                estoque_loja = float(row.get(\"ESTOQUE_UNE\", 0) or 0)\n                estoque_cd = float(row.get(\"ESTOQUE_CD\", 0) or 0)\n                linha_verde = float(row.get(\"ESTOQUE_LV\", 0) or 0)\n                venda_30dd = float(row.get(\"VENDA_30DD\", 0) or 0)\n\n                # Calcular score (0-100)\n                # Fatores: ruptura, vendas, rela\u00e7\u00e3o estoque/linha verde\n                score = 0\n\n                # +40 pontos se CD zerado\n                if estoque_cd == 0:\n                    score += 40\n\n                # +30 pontos se estoque loja < linha verde\n                if estoque_loja < linha_verde:\n                    score += 30\n\n                # +20 pontos baseado em vendas (normalizado)\n                if venda_30dd > 0:\n                    score += min(20, int(venda_30dd / 10))\n\n                # +10 pontos se estoque cr\u00edtico (< 50% da LV)\n                if linha_verde > 0 and estoque_loja < (linha_verde * 0.5):\n                    score += 10\n\n                score_prioridade = min(100, score)\n\n                # Determinar n\u00edvel de urg\u00eancia\n                if score_prioridade >= 80:\n                    nivel_urgencia = \"URGENTE\"\n                elif score_prioridade >= 60:\n                    nivel_urgencia = \"ALTA\"\n                elif score_prioridade >= 40:\n                    nivel_urgencia = \"M\u00c9DIA\"\n                else:\n                    nivel_urgencia = \"BAIXA\"\n\n        except Exception as e:\n            print(f\"Erro ao calcular score: {e}\")\n\n        # Adicionar score ao resultado\n        result[\"score_prioridade\"] = score_prioridade\n        result[\"nivel_urgencia\"] = nivel_urgencia\n\n        return result\n\n    except Exception as e:\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=f\"Error validating transfer: {str(e)}\",\n        )\n\n\n@router.get(\"/suggestions\")\nasync def get_transfer_suggestions(\n    current_user: Annotated[User, Depends(get_current_active_user)],\n    segmento: Optional[str] = Query(None),\n    une_origem_excluir: Optional[int] = Query(None),\n    limit: int = Query(5),\n) -> List[Dict[str, Any]]:\n    \"\"\"\n    Endpoint to get automatic transfer suggestions.\n    Integrates with `sugerir_transferencias_automaticas` tool.\n    \"\"\"\n    try:\n        # Fix: Use .invoke() for LangChain StructuredTool\n        suggestions = sugerir_transferencias_automaticas.invoke({\n            \"segmento\": segmento,\n            \"une_origem_excluir\": une_origem_excluir,\n            \"limite\": limit\n        })\n        return suggestions if isinstance(suggestions, list) else []\n    except Exception as e:\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=f\"Error getting transfer suggestions: {str(e)}\",\n        )", "mimetype": "text/plain", "start_char_idx": 1421, "end_char_idx": 5523, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "145cd032-9fd0-4da4-a6c5-5d12fc566986": {"__data__": {"id_": "145cd032-9fd0-4da4-a6c5-5d12fc566986", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\transfers.py", "language": "python", "lines": 422, "filename": "transfers.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\transfers.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\transfers.py", "language": "python", "lines": 422, "filename": "transfers.py"}, "hash": "297a0d8922026770a8af137557331aafd15f2d1728c5dfc2ca8e0b2705bb5452", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "047d89d4-ae5c-4452-acac-bb2c40b301a6", "node_type": "1", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\transfers.py", "language": "python", "lines": 422, "filename": "transfers.py"}, "hash": "eb22b4d2ecfdbf5a2255493ec52a50ce449a64cdf08c32f154ecdb3e7e3edbb4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "268fc4d1-7c00-4d08-b513-bf8f70fb14ed", "node_type": "1", "metadata": {}, "hash": "e8cb8cbeb6d5ff931967d406eb3200e84f86dba161cf400f841c80c4fa91d65f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "@router.post(\"\")\nasync def create_transfer_request(\n    payload: TransferRequestPayload,\n    current_user: Annotated[User, Depends(get_current_active_user)],\n) -> Dict[str, Any]:\n    \"\"\"\n    Endpoint to create and save a transfer request.\n    \"\"\"\n    try:\n        transfer_data = payload.model_dump()\n        transfer_data[\"solicitante_id\"] = current_user.username\n        transfer_data[\"timestamp\"] = datetime.now().isoformat()\n        transfer_id = f\"transfer_{datetime.now().strftime('%Y%m%d%H%M%S%f')}\"\n        \n        file_path = TRANSFER_REQUESTS_DIR / f\"{transfer_id}.json\"\n        with open(file_path, \"w\", encoding=\"utf-8\") as f:\n            json.dump(transfer_data, f, ensure_ascii=False, indent=4)\n\n        return {\"message\": \"Transfer request created successfully\", \"transfer_id\": transfer_id}\n    except Exception as e:\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=f\"Error creating transfer request: {str(e)}\",\n        )\n\n\n@router.get(\"/report\")\nasync def get_transfers_report(\n    current_user: Annotated[User, Depends(get_current_active_user)],\n    query: TransferReportQuery = Depends(),\n) -> List[Dict[str, Any]]:\n    \"\"\"\n    Endpoint to generate a report of transfer requests.\n    Reads JSON files from the `data/transferencias/` directory.\n    \"\"\"\n    all_transfers = []\n    start_date = datetime.fromisoformat(query.start_date) if query.start_date else datetime.min\n    end_date = datetime.fromisoformat(query.end_date) if query.end_date else datetime.max\n\n    for filename in os.listdir(TRANSFER_REQUESTS_DIR):\n        if filename.endswith(\".json\"):\n            file_path = TRANSFER_REQUESTS_DIR / filename\n            try:\n                with open(file_path, \"r\", encoding=\"utf-8\") as f:\n                    transfer_data = json.load(f)\n                    transfer_timestamp = datetime.fromisoformat(transfer_data.get(\"timestamp\"))\n                    if start_date <= transfer_timestamp <= end_date:\n                        all_transfers.append(transfer_data)\n            except (json.JSONDecodeError, OSError) as e:\n                print(f\"Error reading or decoding transfer file {file_path}: {e}\")\n                # Optionally, raise HTTPException if corrupt file is critical\n\n    # Basic aggregation or sorting could be done here if needed\n    all_transfers.sort(key=lambda x: x.get(\"timestamp\"), reverse=True)\n\n    return all_transfers", "mimetype": "text/plain", "start_char_idx": 5526, "end_char_idx": 7957, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "268fc4d1-7c00-4d08-b513-bf8f70fb14ed": {"__data__": {"id_": "268fc4d1-7c00-4d08-b513-bf8f70fb14ed", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\transfers.py", "language": "python", "lines": 422, "filename": "transfers.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\transfers.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\transfers.py", "language": "python", "lines": 422, "filename": "transfers.py"}, "hash": "297a0d8922026770a8af137557331aafd15f2d1728c5dfc2ca8e0b2705bb5452", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "145cd032-9fd0-4da4-a6c5-5d12fc566986", "node_type": "1", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\transfers.py", "language": "python", "lines": 422, "filename": "transfers.py"}, "hash": "a384aa558ce453f6a7c8da8bf330b3f3209dac9c8564d5f9d2cc524b64104e85", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4c79efcb-2de1-445a-a099-a72ac14ab0cf", "node_type": "1", "metadata": {}, "hash": "675fbe5d03919386f6b3fc5439fef205d17c95d9fa080f6d433258d0262888a2", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "@router.get(\"/filters\")\nasync def get_transfer_filters(\n    current_user: Annotated[User, Depends(get_current_active_user)],\n    segmento: Optional[str] = Query(None),\n) -> Dict[str, Any]:\n    \"\"\"\n    Endpoint to get available filter options for transfers.\n    Returns unique values for segmento and fabricante.\n    If 'segmento' is provided, filters 'fabricantes' accordingly.\n    \"\"\"\n    import polars as pl\n    from app.core.data_scope_service import data_scope_service\n\n    try:\n        df = data_scope_service.get_filtered_dataframe(current_user)\n\n        # Determinar nomes corretos das colunas\n        segmento_col = \"NOMESEGMENTO\" if \"NOMESEGMENTO\" in df.columns else None\n        fabricante_col = \"NOMEFABRICANTE\" if \"NOMEFABRICANTE\" in df.columns else None\n\n        # Obter valores \u00fanicos de segmentos (independentemente do filtro)\n        segmentos = []\n        if segmento_col:\n            segmentos = df.select(pl.col(segmento_col)).unique().drop_nulls().sort(segmento_col).to_series().to_list()\n            segmentos = [str(s) for s in segmentos if s and str(s).strip()]\n\n        # Filtrar DF se segmento for fornecido\n        if segmento and segmento_col:\n            # Usar contains para flexibilidade ou == para exato. Backend original usava contains.\n            # Vamos usar exato se poss\u00edvel para filtros de combo, ou contains se o frontend mandar parcial.\n            # O frontend manda o valor do option, ent\u00e3o deve ser exato.\n            # Mas como o searchProducts usa contains, vou usar == para ser preciso na lista dependente.\n            df = df.filter(pl.col(segmento_col) == segmento)\n\n        # Obter fabricantes (filtrados ou n\u00e3o)\n        fabricantes = []\n        if fabricante_col:\n            fabricantes = df.select(pl.col(fabricante_col)).unique().drop_nulls().sort(fabricante_col).to_series().to_list()\n            fabricantes = [str(f) for f in fabricantes if f and str(f).strip()]\n\n        return {\n            \"segmentos\": segmentos[:100],  # Limitar a 100 para performance\n            \"fabricantes\": fabricantes[:100]\n        }\n\n    except Exception as e:\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=f\"Error getting filters: {str(e)}\",\n        )", "mimetype": "text/plain", "start_char_idx": 7960, "end_char_idx": 10212, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4c79efcb-2de1-445a-a099-a72ac14ab0cf": {"__data__": {"id_": "4c79efcb-2de1-445a-a099-a72ac14ab0cf", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\transfers.py", "language": "python", "lines": 422, "filename": "transfers.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\transfers.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\transfers.py", "language": "python", "lines": 422, "filename": "transfers.py"}, "hash": "297a0d8922026770a8af137557331aafd15f2d1728c5dfc2ca8e0b2705bb5452", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "268fc4d1-7c00-4d08-b513-bf8f70fb14ed", "node_type": "1", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\transfers.py", "language": "python", "lines": 422, "filename": "transfers.py"}, "hash": "10ba451ef6afc6e06ff2efcd9b6766203f602da00af896bfe92f7a0faf0826a3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a89b94a7-3062-4513-85ae-c51ee9268fdc", "node_type": "1", "metadata": {}, "hash": "a8ddcf3d1698b20b90b825c4bd38402a70a750af5a66b96ec4b3d701458855dd", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "@router.post(\"/products/search\")\nasync def search_products(\n    request: ProductSearchRequest,\n    current_user: Annotated[User, Depends(get_current_active_user)],\n) -> List[Dict[str, Any]]:\n    \"\"\"\n    Endpoint to search products with filters for transfer management.\n    Returns products matching criteria with stock information.\n    \"\"\"\n    import polars as pl\n    from app.core.data_scope_service import data_scope_service\n\n    try:\n        df = data_scope_service.get_filtered_dataframe(current_user)\n\n        # Determinar nomes corretos das colunas\n        segmento_col = \"NOMESEGMENTO\" if \"NOMESEGMENTO\" in df.columns else None\n        fabricante_col = \"NOMEFABRICANTE\" if \"NOMEFABRICANTE\" in df.columns else None\n\n        # Aplicar filtros\n        if request.segmento and segmento_col:\n            df = df.filter(pl.col(segmento_col).str.contains(request.segmento, literal=False))\n\n        if request.fabricante and fabricante_col:\n            df = df.filter(pl.col(fabricante_col).str.contains(request.fabricante, literal=False))\n\n        if request.estoque_min is not None:\n            df = df.filter(pl.col(\"ESTOQUE_UNE\").cast(pl.Float64, strict=False).fill_null(0) >= request.estoque_min)\n\n        # Preparar colunas para agrupamento\n        group_cols = [\"PRODUTO\", \"NOME\"]\n        if segmento_col:\n            group_cols.append(segmento_col)\n        if fabricante_col:\n            group_cols.append(fabricante_col)\n\n        # Agrupar por produto e agregar informa\u00e7\u00f5es\n        df_grouped = df.group_by(group_cols).agg([\n            pl.col(\"ESTOQUE_UNE\").cast(pl.Float64, strict=False).fill_null(0).sum().alias(\"estoque_total_loja\"),\n            pl.col(\"ESTOQUE_CD\").cast(pl.Float64, strict=False).fill_null(0).sum().alias(\"estoque_total_cd\"),\n            pl.col(\"VENDA_30DD\").cast(pl.Float64, strict=False).fill_null(0).sum().alias(\"vendas_30dd\"),\n            pl.col(\"UNE\").n_unique().alias(\"unes_com_estoque\")\n        ])\n\n        df_result = df_grouped.head(request.limit)\n\n        products = []\n        for row in df_result.iter_rows(named=True):\n            products.append({\n                \"produto_id\": int(row[\"PRODUTO\"]),\n                \"nome\": str(row[\"NOME\"])[:60],\n                \"segmento\": str(row.get(segmento_col, \"N/A\")) if segmento_col else \"N/A\",\n                \"fabricante\": str(row.get(fabricante_col, \"N/A\"))[:30] if fabricante_col else \"N/A\",\n                \"estoque_loja\": int(row[\"estoque_total_loja\"]),\n                \"estoque_cd\": int(row[\"estoque_total_cd\"]),\n                \"vendas_30dd\": int(row[\"vendas_30dd\"]),\n                \"unes\": int(row[\"unes_com_estoque\"])\n            })\n\n        return products\n\n    except Exception as e:\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=f\"Error searching products: {str(e)}\",\n        )", "mimetype": "text/plain", "start_char_idx": 10215, "end_char_idx": 13056, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a89b94a7-3062-4513-85ae-c51ee9268fdc": {"__data__": {"id_": "a89b94a7-3062-4513-85ae-c51ee9268fdc", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\transfers.py", "language": "python", "lines": 422, "filename": "transfers.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\transfers.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\transfers.py", "language": "python", "lines": 422, "filename": "transfers.py"}, "hash": "297a0d8922026770a8af137557331aafd15f2d1728c5dfc2ca8e0b2705bb5452", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4c79efcb-2de1-445a-a099-a72ac14ab0cf", "node_type": "1", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\transfers.py", "language": "python", "lines": 422, "filename": "transfers.py"}, "hash": "ef7660a0ef4cb538327608887758daff40e38f25ff2fba28cfc8867a525676a1", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "@router.post(\"/bulk\")\nasync def create_bulk_transfer_request(\n    payload: BulkTransferRequestPayload,\n    current_user: Annotated[User, Depends(get_current_active_user)],\n) -> Dict[str, Any]:\n    \"\"\"\n    Endpoint to create multiple transfer requests at once (1\u2192N or N\u2192N modes).\n    Saves all transfers in a single batch file.\n    \"\"\"\n    try:\n        batch_id = f\"batch_{datetime.now().strftime('%Y%m%d%H%M%S%f')}\"\n        batch_data = {\n            \"batch_id\": batch_id,\n            \"modo\": payload.modo,\n            \"solicitante_id\": current_user.username,\n            \"timestamp\": datetime.now().isoformat(),\n            \"total_transferencias\": len(payload.items),\n            \"transferencias\": []\n        }\n\n        for item in payload.items:\n            transfer = item.model_dump()\n            transfer[\"solicitante_id\"] = current_user.username\n            batch_data[\"transferencias\"].append(transfer)\n\n        file_path = TRANSFER_REQUESTS_DIR / f\"{batch_id}.json\"\n        with open(file_path, \"w\", encoding=\"utf-8\") as f:\n            json.dump(batch_data, f, ensure_ascii=False, indent=4)\n\n        return {\n            \"message\": f\"Batch transfer request created successfully ({len(payload.items)} items)\",\n            \"batch_id\": batch_id,\n            \"modo\": payload.modo\n        }\n\n    except Exception as e:\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=f\"Error creating bulk transfer request: {str(e)}\",\n        )\n\n\n@router.get(\"/unes\")\nasync def get_available_unes(\n    current_user: Annotated[User, Depends(get_current_active_user)],\n) -> List[Dict[str, Any]]:\n    \"\"\"\n    Endpoint to get list of available UNEs for transfer selection.\n    \"\"\"\n    import polars as pl\n    from app.core.data_scope_service import data_scope_service\n\n    try:\n        df = data_scope_service.get_filtered_dataframe(current_user)\n\n        # Obter UNEs \u00fanicas com contagem de produtos\n        unes_data = df.group_by(\"UNE\").agg([\n            pl.col(\"PRODUTO\").n_unique().alias(\"total_produtos\"),\n            pl.col(\"ESTOQUE_UNE\").cast(pl.Float64, strict=False).fill_null(0).sum().alias(\"estoque_total\")\n        ]).sort(\"UNE\")\n\n        unes = []\n        for row in unes_data.iter_rows(named=True):\n            unes.append({\n                \"une\": int(row[\"UNE\"]),\n                \"total_produtos\": int(row[\"total_produtos\"]),\n                \"estoque_total\": int(row[\"estoque_total\"])\n            })\n\n        return unes\n\n    except Exception as e:\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=f\"Error fetching UNEs: {str(e)}\",\n        )", "mimetype": "text/plain", "start_char_idx": 13059, "end_char_idx": 15722, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c0e650a0-f70f-4fea-b649-49819858b4a3": {"__data__": {"id_": "c0e650a0-f70f-4fea-b649-49819858b4a3", "embedding": null, "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\__init__.py", "language": "python", "lines": 6, "filename": "__init__.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\api\\v1\\endpoints\\__init__.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\api\\v1\\endpoints\\__init__.py", "language": "python", "lines": 6, "filename": "__init__.py"}, "hash": "ad6ae0cd9a9fc8d37b0abef9d52f3ab5420e9f3f617a2e703682d792e5acc488", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"Endpoints package\"\"\"\n\nfrom app.api.v1.endpoints import admin, analytics, auth, reports\n\n__all__ = [\"auth\", \"analytics\", \"reports\", \"admin\"]", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 142, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "fde7c6d0-075d-4888-af08-44a378fedd82": {"__data__": {"id_": "fde7c6d0-075d-4888-af08-44a378fedd82", "embedding": null, "metadata": {"file_path": "backend\\app\\config\\database.py", "language": "python", "lines": 84, "filename": "database.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\config\\database.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\config\\database.py", "language": "python", "lines": 84, "filename": "database.py"}, "hash": "50a7e9c8789b055476bdefbeb6606b61f2fb2dafa9729d9b712fbc057e9f7a87", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nDatabase Configuration\nSQLAlchemy async engine and session\n\"\"\"\n\nfrom collections.abc import AsyncGenerator\nfrom contextlib import asynccontextmanager\n\nfrom sqlalchemy.ext.asyncio import AsyncSession, async_sessionmaker, create_async_engine\nfrom sqlalchemy.orm import DeclarativeBase\n\nfrom app.config.settings import get_settings\n\nsettings = get_settings()\n\n# Create async engine with optimized pool settings\n# Use NullPool when SQL Server is disabled to avoid connection attempts\nfrom sqlalchemy.pool import NullPool\n\nif settings.USE_SQL_SERVER:\n    engine = create_async_engine(\n        str(settings.DATABASE_URL),\n        echo=settings.DB_ECHO,\n        pool_size=settings.DB_POOL_SIZE,\n        max_overflow=settings.DB_MAX_OVERFLOW,\n        pool_pre_ping=True,\n        pool_timeout=settings.SQL_SERVER_TIMEOUT,\n        connect_args={\"timeout\": settings.SQL_SERVER_TIMEOUT},\n    )\nelse:\n    # Use NullPool when SQL Server is disabled - no connection pooling, no connection attempts\n    engine = create_async_engine(\n        \"sqlite+aiosqlite:///:memory:\",  # Dummy in-memory DB when SQL disabled\n        poolclass=NullPool,\n        echo=False,\n    )\n\n# Create session factory\nAsyncSessionLocal = async_sessionmaker(\n    engine,\n    class_=AsyncSession,\n    expire_on_commit=False,\n    autocommit=False,\n    autoflush=False,\n)\n\n\nclass Base(DeclarativeBase):\n    \"\"\"Base class for all models\"\"\"\n\n    pass\n\n\nasync def get_db() -> AsyncGenerator[AsyncSession, None]:\n    \"\"\"\n    Dependency for getting async database session\n    \n    Usage:\n        @router.get(\"/items\")\n        async def get_items(db: AsyncSession = Depends(get_db)):\n            ...\n    \"\"\"\n    async with AsyncSessionLocal() as session:\n        try:\n            yield session\n            await session.commit()\n        except Exception:\n            await session.rollback()\n            raise\n        finally:\n            await session.close()\n\n\n@asynccontextmanager\nasync def get_db_context():\n    \"\"\"Context manager for database session\"\"\"\n    async with AsyncSessionLocal() as session:\n        try:\n            yield session\n            await session.commit()\n        except Exception:\n            await session.rollback()\n            raise", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2213, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "892e0ab9-9f58-4c07-8b1f-e8a0d0194f49": {"__data__": {"id_": "892e0ab9-9f58-4c07-8b1f-e8a0d0194f49", "embedding": null, "metadata": {"file_path": "backend\\app\\config\\logging_config.py", "language": "python", "lines": 87, "filename": "logging_config.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\config\\logging_config.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\config\\logging_config.py", "language": "python", "lines": 87, "filename": "logging_config.py"}, "hash": "09a3a017795474c13d057d9df35f705dc3d37cdfe9dd6274782144e26f8913ae", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nLogging Configuration for Agent Solution BI\nCentralizes logging setup with rotation and formatting\n\"\"\"\n\nimport logging\nimport sys\nfrom pathlib import Path\nfrom logging.handlers import RotatingFileHandler\nfrom typing import Optional\n\n\ndef setup_logging(\n    log_level: str = \"INFO\",\n    log_file: Optional[Path] = None,\n    max_bytes: int = 10 * 1024 * 1024,  # 10 MB\n    backup_count: int = 5,\n    suppress_warnings: list[str] = None\n) -> logging.Logger:\n    \"\"\"\n    Configure application logging with rotation and consistent formatting\n    \n    Args:\n        log_level: Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)\n        log_file: Optional path to log file. If None, logs only to console\n        max_bytes: Maximum size of log file before rotation (default 10MB)\n        backup_count: Number of backup files to keep (default 5)\n        suppress_warnings: List of warning patterns to suppress\n    \n    Returns:\n        Configured logger instance\n    \"\"\"\n    \n    # Create logger\n    logger = logging.getLogger(\"agent_bi\")\n    logger.setLevel(getattr(logging, log_level.upper()))\n    \n    # Remove existing handlers to avoid duplicates\n    logger.handlers.clear()\n    \n    # Create formatter\n    formatter = logging.Formatter(\n        fmt='[%(asctime)s] %(levelname)-8s [%(name)s:%(funcName)s:%(lineno)d] %(message)s',\n        datefmt='%Y-%m-%d %H:%M:%S'\n    )\n    \n    # Console handler\n    console_handler = logging.StreamHandler(sys.stdout)\n    console_handler.setLevel(getattr(logging, log_level.upper()))\n    console_handler.setFormatter(formatter)\n    logger.addHandler(console_handler)\n    \n    # File handler with rotation (if log_file specified)\n    if log_file:\n        log_file.parent.mkdir(parents=True, exist_ok=True)\n        file_handler = RotatingFileHandler(\n            filename=log_file,\n            maxBytes=max_bytes,\n            backupCount=backup_count,\n            encoding='utf-8'\n        )\n        file_handler.setLevel(getattr(logging, log_level.upper()))\n        file_handler.setFormatter(formatter)\n        logger.addHandler(file_handler)\n    \n    # Suppress specific warnings if requested\n    if suppress_warnings:\n        for warning_pattern in suppress_warnings:\n            logging.getLogger(warning_pattern).setLevel(logging.ERROR)\n    \n    logger.info(f\"Logging configured: level={log_level}, file={log_file}\")\n    \n    return logger\n\n\ndef get_logger(name: str) -> logging.Logger:\n    \"\"\"\n    Get a logger instance with the application's configuration\n    \n    Args:\n        name: Logger name (typically __name__)\n    \n    Returns:\n        Logger instance\n    \"\"\"\n    return logging.getLogger(f\"agent_bi.{name}\")", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2660, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "caad3ebd-5e8f-4b58-8768-725e8d491b31": {"__data__": {"id_": "caad3ebd-5e8f-4b58-8768-725e8d491b31", "embedding": null, "metadata": {"file_path": "backend\\app\\config\\security.py", "language": "python", "lines": 96, "filename": "security.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\config\\security.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\config\\security.py", "language": "python", "lines": 96, "filename": "security.py"}, "hash": "02bfbc9425e58bbf4fa4b1b0c322484b645e4849f74689fee33938eeda491b30", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nSecurity Configuration\nJWT, password hashing, and authentication utilities\n\"\"\"\n\nfrom datetime import datetime, timedelta, timezone\nfrom typing import Any\n\nfrom jose import JWTError, jwt\nfrom passlib.context import CryptContext\n\nfrom app.config.settings import get_settings\n\nsettings = get_settings()\n\n# Password hashing\n# pwd_context = CryptContext(schemes=[\"bcrypt\"], deprecated=\"auto\")\nimport bcrypt\n\ndef verify_password(plain_password: str, hashed_password: str) -> bool:\n    \"\"\"Verify a password against a hash using bcrypt directly\"\"\"\n    try:\n        # Ensure bytes\n        if isinstance(plain_password, str):\n            plain_password = plain_password.encode('utf-8')\n        if isinstance(hashed_password, str):\n            hashed_password = hashed_password.encode('utf-8')\n            \n        return bcrypt.checkpw(plain_password, hashed_password)\n    except Exception:\n        return False\n\n\ndef get_password_hash(password: str) -> str:\n    \"\"\"Hash a password using bcrypt directly\"\"\"\n    if isinstance(password, str):\n        password = password.encode('utf-8')\n    # Generate salt and hash\n    salt = bcrypt.gensalt()\n    hashed = bcrypt.hashpw(password, salt)\n    return hashed.decode('utf-8')\n\n\ndef create_access_token(data: dict[str, Any], expires_delta: timedelta | None = None) -> str:\n    \"\"\"\n    Create JWT access token\n    \n    Args:\n        data: Data to encode in token\n        expires_delta: Token expiration time\n        \n    Returns:\n        Encoded JWT token\n    \"\"\"\n    to_encode = data.copy()\n    \n    if expires_delta:\n        expire = datetime.now(timezone.utc) + expires_delta\n    else:\n        expire = datetime.now(timezone.utc) + timedelta(\n            minutes=settings.ACCESS_TOKEN_EXPIRE_MINUTES\n        )\n    \n    to_encode.update({\"exp\": expire, \"type\": \"access\"})\n    encoded_jwt = jwt.encode(to_encode, settings.SECRET_KEY, algorithm=settings.ALGORITHM)\n    return encoded_jwt\n\n\ndef create_refresh_token(data: dict[str, Any]) -> str:\n    \"\"\"Create JWT refresh token\"\"\"\n    to_encode = data.copy()\n    expire = datetime.now(timezone.utc) + timedelta(days=settings.REFRESH_TOKEN_EXPIRE_DAYS)\n    to_encode.update({\"exp\": expire, \"type\": \"refresh\"})\n    encoded_jwt = jwt.encode(to_encode, settings.SECRET_KEY, algorithm=settings.ALGORITHM)\n    return encoded_jwt\n\n\ndef decode_token(token: str) -> dict[str, Any]:\n    \"\"\"\n    Decode and verify JWT token\n    \n    Args:\n        token: JWT token to decode\n        \n    Returns:\n        Decoded token payload\n        \n    Raises:\n        JWTError: If token is invalid\n    \"\"\"\n    try:\n        payload = jwt.decode(token, settings.SECRET_KEY, algorithms=[settings.ALGORITHM])\n        return payload\n    except JWTError as e:\n        raise JWTError(f\"Could not validate credentials: {e}\")", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2776, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c9780eb1-8803-4602-ae4c-d9f3cfb1046a": {"__data__": {"id_": "c9780eb1-8803-4602-ae4c-d9f3cfb1046a", "embedding": null, "metadata": {"file_path": "backend\\app\\config\\settings.py", "language": "python", "lines": 200, "filename": "settings.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\config\\settings.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\config\\settings.py", "language": "python", "lines": 200, "filename": "settings.py"}, "hash": "3e34599a8735f5e72b37bfe59289a09283c2f62bcf78fb9dd83683f9df347a89", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "18dfbd0a-b90d-4e53-a08e-4900b6e34454", "node_type": "1", "metadata": {}, "hash": "87c45ea079760415f9034eddf938ecbea413b7f35c363e1f7609366737ecf19e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nSettings Configuration\nPydantic Settings with environment variables\n\"\"\"\n\nfrom functools import lru_cache\nfrom typing import Literal\nimport os\n\nfrom pydantic import Field, field_validator, model_validator, RedisDsn\nfrom pydantic_settings import BaseSettings, SettingsConfigDict\nfrom sqlalchemy.engine import make_url\n\n\nclass Settings(BaseSettings):\n    \"\"\"Application settings\"\"\"\n\n    # Calculate absolute path to .env file\n    # backend/app/config/settings.py -> backend/.env\n    _base_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n    _env_path = os.path.join(_base_dir, \".env\")\n\n    model_config = SettingsConfigDict(\n        env_file=_env_path,\n        env_file_encoding=\"utf-8\",\n        case_sensitive=False,\n        extra=\"ignore\",\n    )\n\n    # App\n    APP_NAME: str = \"Agent BI Backend\"\n    APP_VERSION: str = \"1.0.0\"\n    DEBUG: bool = False\n    ENVIRONMENT: Literal[\"development\", \"staging\", \"production\"] = \"development\"\n\n    # API\n    API_V1_PREFIX: str = \"/api/v1\"\n    BACKEND_CORS_ORIGINS: str = Field(\n        default=\"http://localhost:3000,http://localhost:8000\"\n    )\n\n    # @field_validator(\"BACKEND_CORS_ORIGINS\", mode=\"before\")\n    # @classmethod\n    # def assemble_cors_origins(cls, v: str | list[str]) -> list[str]:\n    #     if isinstance(v, str):\n    #         return [i.strip() for i in v.split(\",\")]\n    #     return v\n\n    # Database - SQL Server\n    # Usando aioodbc para suporte ass\u00edncrono com SQLAlchemy\n    DATABASE_URL: str = Field(\n        default=\"\"\n    )\n    DB_ECHO: bool = False\n    DB_POOL_SIZE: int = 10\n    DB_MAX_OVERFLOW: int = 20\n    \n    # Connection string para aioodbc (SQLServerAdapter)\n    # Deve corresponder aos mesmos par\u00e2metros do DATABASE_URL\n    PYODBC_CONNECTION_STRING: str = Field(\n        default=\"\"\n    )\n    \n    # Hybrid Architecture Flags\n    USE_SQL_SERVER: bool = False  # Disabled by default to prevent timeouts\n    FALLBACK_TO_PARQUET: bool = True\n    SQL_SERVER_TIMEOUT: int = 2  # Reduced timeout\n\n    # Redis\n    REDIS_URL: RedisDsn = Field(default=\"redis://localhost:6379/0\")\n    REDIS_CACHE_TTL: int = 3600  # 1 hour\n\n    # Custom Cache Settings\n    CACHE_TTL_MINUTES: int = 360 # 6 hours for LLM responses\n    CACHE_MAX_AGE_DAYS: int = 7 # For cache cleaner\n    AGENT_GRAPH_CACHE_TTL_MINUTES: int = 360 # 6 hours for agent graph cache\n\n    # RAG (Retrieval Augmented Generation)\n    RAG_EMBEDDING_MODEL: str = \"all-MiniLM-L6-v2\"\n    RAG_FAISS_INDEX_PATH: str = \"data/rag/faiss_index.bin\"\n\n    # Learning System\n    LEARNING_FEEDBACK_PATH: str = \"data/feedback/\"\n    LEARNING_EXAMPLES_PATH: str = \"data/learning/\"\n    LEARNING_MAX_EXAMPLES: int = 1000\n\n    # Security\n    SECRET_KEY: str = Field(\n        default=\"your-secret-key-change-in-production-min-32-chars-long\"\n    )\n    ALGORITHM: str = \"HS256\"\n    ACCESS_TOKEN_EXPIRE_MINUTES: int = 30\n    REFRESH_TOKEN_EXPIRE_DAYS: int = 7\n\n    # Rate Limiting\n    RATE_LIMIT_PER_MINUTE: int = 100\n    RATE_LIMIT_AUTH_PER_MINUTE: int = 5\n\n    # Logging\n    LOG_LEVEL: Literal[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"] = \"INFO\"\n    LOG_FORMAT: Literal[\"json\", \"console\"] = \"json\"\n\n    # Sentry\n    SENTRY_DSN: str | None = None\n    SENTRY_ENVIRONMENT: str = \"development\"\n    SENTRY_TRACES_SAMPLE_RATE: float = 0.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3274, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "18dfbd0a-b90d-4e53-a08e-4900b6e34454": {"__data__": {"id_": "18dfbd0a-b90d-4e53-a08e-4900b6e34454", "embedding": null, "metadata": {"file_path": "backend\\app\\config\\settings.py", "language": "python", "lines": 200, "filename": "settings.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\config\\settings.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\config\\settings.py", "language": "python", "lines": 200, "filename": "settings.py"}, "hash": "3e34599a8735f5e72b37bfe59289a09283c2f62bcf78fb9dd83683f9df347a89", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c9780eb1-8803-4602-ae4c-d9f3cfb1046a", "node_type": "1", "metadata": {"file_path": "backend\\app\\config\\settings.py", "language": "python", "lines": 200, "filename": "settings.py"}, "hash": "f40ab8bd6c58c5822b715d52e82010f33ea7ebb30011eaae3eaa185ddf8521f1", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "1\n\n    # Prometheus\n    METRICS_ENABLED: bool = True\n\n    # AI / LLM - Usando Gemini 3 Flash Preview (modelo mais inteligente e r\u00e1pido da Google)\n    GEMINI_API_KEY: str | None = None\n    LLM_MODEL_NAME: str = \"gemini-3-flash-preview\"\n    INTENT_CLASSIFICATION_MODEL: str = \"gemini-3-flash-preview\"\n    CODE_GENERATION_MODEL: str = \"gemini-3-flash-preview\"\n\n    # Data Sources\n    PARQUET_DATA_PATH: str = Field(default=\"data/parquet/admmat.parquet\")\n    PARQUET_FILE_PATH: str = Field(default=\"data/parquet/admmat.parquet\")  # Alias for compatibility\n    \n    # Business Rules\n    ALLOWED_UNES: list[int] = Field(default=[\n        1, 3, 11, 35, 57, 64, 79, 81, 135, 148, 265, 520, 1685, 1974, \n        2365, 2401, 2475, 2586, 2599, 2720, 2906, 2952, 3038, 3054, \n        3091, 3116, 3281, 3318, 3387, 3404, 3481, 3499, 3577, 3578, \n        5570, 5822\n    ])\n\n    # Supabase\n    SUPABASE_URL: str = Field(default=\"\")\n    SUPABASE_ANON_KEY: str = Field(default=\"\")\n    SUPABASE_SERVICE_ROLE_KEY: str = Field(default=\"\")  # Required for admin operations\n    USE_SUPABASE_AUTH: bool = Field(default=False)  # Disabled by default to align with Parquet auth\n\n    @model_validator(mode=\"after\")\n    def validate_secret_key(self) -> \"Settings\":\n        if not self.SECRET_KEY or len(self.SECRET_KEY) < 32:\n            raise ValueError(\"SECRET_KEY must be at least 32 characters\")\n        return self\n\n    @model_validator(mode=\"after\")\n    def compute_pyodbc_string(self) -> \"Settings\":\n        # OTIMIZA\u00c7\u00c3O: Se DATABASE_URL vazio, desabilitar SQL Server (evita timeout de 10s no login!)\n        if not self.DATABASE_URL or self.DATABASE_URL.strip() == \"\":\n            self.USE_SQL_SERVER = False\n            self.FALLBACK_TO_PARQUET = True\n            return self\n\n        # For\u00e7a a verifica\u00e7\u00e3o da vari\u00e1vel de ambiente para USE_SQL_SERVER\n        if os.environ.get(\"USE_SQL_SERVER\", \"false\").lower() == \"true\":\n            self.USE_SQL_SERVER = True\n        # Se a URL for SQLite, e a vari\u00e1vel de ambiente n\u00e3o for true, desabilitar o uso do SQL Server\n        elif self.DATABASE_URL and self.DATABASE_URL.startswith(\"sqlite\"):\n            self.USE_SQL_SERVER = False\n            self.FALLBACK_TO_PARQUET = True\n            return self\n\n        # Se PYODBC_CONNECTION_STRING for o default, tentar derivar de DATABASE_URL\n        default_pyodbc = self.model_fields[\"PYODBC_CONNECTION_STRING\"].default\n        if self.PYODBC_CONNECTION_STRING == default_pyodbc and self.DATABASE_URL:\n            try:\n                url = make_url(str(self.DATABASE_URL))\n                # Construir string ODBC\n                # DRIVER={driver};SERVER=host;DATABASE=db;UID=user;PWD=pass\n                driver = url.query.get(\"driver\", \"ODBC Driver 17 for SQL Server\")\n                trust_cert = url.query.get(\"TrustServerCertificate\", \"yes\")\n                \n                # Tratar host e port\n                server = url.host\n                if url.port:\n                    server = f\"{server},{url.port}\"\n                \n                conn_str = (\n                    f\"DRIVER={{{driver}}};\"\n                    f\"SERVER={server};\"\n                    f\"DATABASE={url.database};\"\n                    f\"TrustServerCertificate={trust_cert};\"\n                )\n                \n                if url.username:\n                    conn_str += f\"UID={url.username};PWD={url.password};\"\n                else:\n                    conn_str += \"Trusted_Connection=yes;\"\n                    \n                self.PYODBC_CONNECTION_STRING = conn_str\n            except Exception:\n                # Se falhar, manter o default ou o que foi passado\n                pass\n        return self\n\n\n@lru_cache\ndef get_settings() -> Settings:\n    \"\"\"Get cached settings instance\"\"\"\n    return Settings()\n\n\n# Global settings instance\nsettings = get_settings()", "mimetype": "text/plain", "start_char_idx": 3274, "end_char_idx": 7100, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "35df4a91-3d5d-4e96-b018-1b82d07b98e8": {"__data__": {"id_": "35df4a91-3d5d-4e96-b018-1b82d07b98e8", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\agent_state.py", "language": "python", "lines": 35, "filename": "agent_state.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\agent_state.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\agent_state.py", "language": "python", "lines": 35, "filename": "agent_state.py"}, "hash": "ad6f614b1a8e728895bca30cff8036b0d554a68cafd18fa637c376b60a6502d6", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "from __future__ import annotations\n\nimport operator\nfrom typing import (\n    TYPE_CHECKING,\n    Annotated,\n    Any,\n    Dict,\n    List,\n    Optional,\n    Sequence,\n    TypedDict,\n)\n\nfrom langchain_core.messages import BaseMessage\nfrom plotly.graph_objects import Figure as PlotlyFigure\n\n\n# RouteDecision ser\u00e1 definido como string para evitar import circular\n# from app.core.agents.supervisor import RouteDecision\n\n# O bloco TYPE_CHECKING anterior para RouteDecision n\u00e3o \u00e9 mais estritamente necess\u00e1rio\n# para esta anota\u00e7\u00e3o espec\u00edfica, pois RouteDecision \u00e9 importado diretamente.\n# Mantendo o bloco TYPE_CHECKING caso seja usado para outras importa\u00e7\u00f5es condicionais.\nif TYPE_CHECKING:\n    pass  # Pode ser usado para outras importa\u00e7\u00f5es apenas de checagem de tipo\n\n\nclass AgentState(TypedDict):\n    messages: Annotated[Sequence[BaseMessage], operator.add]\n    retrieved_data: Optional[List[Dict[str, Any]]]\n    chart_code: Optional[str]\n    plotly_fig: Optional[PlotlyFigure]\n    route_decision: Optional[\"RouteDecision\"]  # Usar string para anota\u00e7\u00e3o de tipo", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1055, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "79309bb5-8fe3-4a70-962d-6f66f5de2e63": {"__data__": {"id_": "79309bb5-8fe3-4a70-962d-6f66f5de2e63", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\agent_wrapper.py", "language": "python", "lines": 75, "filename": "agent_wrapper.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\agent_wrapper.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\agent_wrapper.py", "language": "python", "lines": 75, "filename": "agent_wrapper.py"}, "hash": "60b6ccfb7b90d5e898d2d7c849e31799ac9ab45f06b28cde102f57dcde569eb8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nWrapper simplificado para integra\u00e7\u00e3o do sistema de agentes com FastAPI\n\"\"\"\nimport logging\nimport os\nfrom pathlib import Path\n\nlogger = logging.getLogger(__name__)\n\n\nclass AgentWrapper:\n    \"\"\"\n    Wrapper para integrar o sistema de agentes do Agent_Business com FastAPI\n    \"\"\"\n    \n    def __init__(self):\n        self.query_processor = None\n        self._initialize()\n    \n    def _initialize(self):\n        \"\"\"Inicializa o sistema de agentes\"\"\"\n        try:\n            # Configurar GEMINI_API_KEY se n\u00e3o estiver configurada\n            if not os.getenv(\"GEMINI_API_KEY\"):\n                logger.warning(\"GEMINI_API_KEY n\u00e3o configurada, usando fallback\")\n                return\n            \n            # Importar QueryProcessor\n            from app.core.query_processor import QueryProcessor\n            \n            self.query_processor = QueryProcessor()\n            logger.info(\"Sistema de agentes inicializado com sucesso\")\n            \n        except Exception as e:\n            logger.error(f\"Erro ao inicializar sistema de agentes: {e}\")\n            self.query_processor = None\n    \n    def process_query(self, query: str) -> dict:\n        \"\"\"\n        Processa uma consulta usando o sistema de agentes\n        \n        Args:\n            query: Pergunta do usu\u00e1rio\n            \n        Returns:\n            dict com type e output\n        \"\"\"\n        if self.query_processor is None:\n            return {\n                \"type\": \"text\",\n                \"output\": \"Sistema de agentes n\u00e3o dispon\u00edvel. Verifique a configura\u00e7\u00e3o do GEMINI_API_KEY.\"\n            }\n        \n        try:\n            result = self.query_processor.process_query(query)\n            return result\n        except Exception as e:\n            logger.error(f\"Erro ao processar consulta: {e}\")\n            return {\n                \"type\": \"text\",\n                \"output\": f\"Erro ao processar consulta: {str(e)}\"\n            }\n\n\n# Inst\u00e2ncia global do wrapper\n_agent_wrapper = None\n\n\ndef get_agent_wrapper() -> AgentWrapper:\n    \"\"\"Retorna inst\u00e2ncia singleton do AgentWrapper\"\"\"\n    global _agent_wrapper\n    if _agent_wrapper is None:\n        _agent_wrapper = AgentWrapper()\n    return _agent_wrapper", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2180, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "bfefa093-8c3c-442a-8496-90cacf6761f7": {"__data__": {"id_": "bfefa093-8c3c-442a-8496-90cacf6761f7", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\auth_service.py", "language": "python", "lines": 340, "filename": "auth_service.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\auth_service.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\auth_service.py", "language": "python", "lines": 340, "filename": "auth_service.py"}, "hash": "12dd6f06677beadc909093b7125e67e7ebb1bddc56cd5a4b4d7a4a2431b663a3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1d00a343-dd45-45dd-9e14-d5fefa7b90c0", "node_type": "1", "metadata": {}, "hash": "57ce5bd671fd40efb99f9f0a93921776036582de3ea63b42cd76d73cf55e5517", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import logging\nfrom pathlib import Path\nfrom typing import Optional\nfrom datetime import datetime, timezone\nimport json # Import json\n\nimport polars as pl\nimport bcrypt\nfrom sqlalchemy.ext.asyncio import AsyncSession\nfrom sqlalchemy import select\n\nfrom app.config.settings import get_settings\nfrom app.infrastructure.database.models import User\n\nsettings = get_settings()\nlogger = logging.getLogger(__name__) # General logger\nsecurity_logger = logging.getLogger(\"security\") # Dedicated security logger\n\n\nclass AuthService:\n    \"\"\"\n    Authentication service with intelligent fallback.\n\n    Priority:\n    1. SQL Server (if USE_SQL_SERVER=true and available)\n    2. Parquet (fallback or when SQL Server disabled)\n    \"\"\"\n\n    def __init__(self):\n        self.use_sql_server = settings.USE_SQL_SERVER\n        self.use_supabase = settings.USE_SUPABASE_AUTH\n\n        # Try Docker path first, then development path\n        docker_path = Path(\"/app/data/parquet/users.parquet\")\n        dev_path = Path(__file__).parent.parent.parent.parent / \"data\" / \"parquet\" / \"users.parquet\"\n\n        if docker_path.exists():\n            self.parquet_path = docker_path\n        else:\n            self.parquet_path = dev_path\n\n    async def authenticate_user(\n        self,\n        username: str,\n        password: str,\n        db: Optional[AsyncSession] = None\n    ) -> Optional[dict]:\n        \"\"\"\n        Authenticate user with hybrid approach.\n\n        Priority:\n        1. Supabase (if USE_SUPABASE_AUTH=true)\n        2. Parquet (fallback or when Supabase disabled)\n        3. SQL Server (last resort)\n\n        Args:\n            username: User's username or email\n            password: User's plain text password\n            db: Optional database session (used when SQL Server is enabled)\n\n        Returns:\n            User dict if authenticated, None otherwise\n        \"\"\"\n        user_data = None\n\n        # Priority 1: Supabase Auth (if enabled)\n        if self.use_supabase:\n            try:\n                user_data = await self._auth_from_supabase(username, password)\n                if user_data:\n                    security_logger.info(f\"User '{username}' authenticated via Supabase\")\n                    return user_data\n            except Exception as e:\n                security_logger.warning(f\"Supabase auth failed for '{username}': {e}\")\n\n        # Priority 2: Parquet (fallback or primary if Supabase disabled)\n        try:\n            user_data = await self._auth_from_parquet(username, password)\n            if user_data:\n                security_logger.info(f\"User '{username}' authenticated via Parquet\")\n                return user_data\n        except Exception as e:\n            security_logger.error(f\"Parquet auth failed for '{username}': {e}\")\n\n        # Priority 3: SQL Server (last resort)\n        if self.use_sql_server and db is not None:\n            try:\n                user_data = await self._auth_from_sql(username, password, db)\n                if user_data:\n                    security_logger.info(f\"User '{username}' authenticated via SQL Server\")\n                    return user_data\n            except Exception as e:\n                security_logger.warning(f\"SQL Server auth failed for '{username}': {e}\")\n\n        security_logger.warning(f\"Authentication failed for user '{username}' - Invalid credentials or inactive.\")\n        return None\n\n    async def _auth_from_sql(\n        self,\n        username: str,\n        password: str,\n        db: AsyncSession\n    ) -> Optional[dict]:\n        \"\"\"Authenticate from SQL Server\"\"\"\n        result = await db.execute(\n            select(User).where(User.username == username)\n        )\n        user = result.scalar_one_or_none()\n\n        if not user:\n            security_logger.warning(f\"User '{username}' not found in SQL Server.\")\n            return None\n\n        # Verify password\n        if not self._verify_password(password, user.hashed_password):\n            security_logger.warning(f\"Invalid password attempt for user '{username}' in SQL Server.\")\n            return None\n\n        # Check if active\n        if not user.is_active:\n            security_logger.warning(f\"Inactive user '{username}' attempted to log in via SQL Server.\")", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4208, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1d00a343-dd45-45dd-9e14-d5fefa7b90c0": {"__data__": {"id_": "1d00a343-dd45-45dd-9e14-d5fefa7b90c0", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\auth_service.py", "language": "python", "lines": 340, "filename": "auth_service.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\auth_service.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\auth_service.py", "language": "python", "lines": 340, "filename": "auth_service.py"}, "hash": "12dd6f06677beadc909093b7125e67e7ebb1bddc56cd5a4b4d7a4a2431b663a3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bfefa093-8c3c-442a-8496-90cacf6761f7", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\auth_service.py", "language": "python", "lines": 340, "filename": "auth_service.py"}, "hash": "b60959c1504a3bd9ab872dbf0fd44a99d43b293592122254753412845af91017", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ac60eb75-87ba-478f-8084-7969d72da354", "node_type": "1", "metadata": {}, "hash": "96659d14d4b164d77693e1e067d7ac29c4cc660bf0a168e87b326e46c15553f2", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "return None\n\n        # Update last_login\n        user.last_login = datetime.now(timezone.utc)\n        await db.commit()\n\n        # Parse allowed_segments\n        allowed_segments = []\n        if user.allowed_segments:\n            try:\n                allowed_segments = json.loads(user.allowed_segments)\n            except:\n                allowed_segments = []\n\n        return {\n            \"id\": str(user.id),\n            \"username\": user.username,\n            \"email\": user.email or \"\",\n            \"role\": user.role,\n            \"is_active\": user.is_active,\n            \"allowed_segments\": allowed_segments\n        }\n\n    async def _auth_from_supabase(\n        self,\n        username: str,\n        password: str\n    ) -> Optional[dict]:\n        \"\"\"Authenticate from Supabase Auth\"\"\"\n        try:\n            from app.core.supabase_client import get_supabase_client\n            from supabase import AuthApiError\n\n            try:\n                supabase = get_supabase_client()\n            except ValueError as ve:\n                security_logger.error(f\"Supabase client not configured: {ve}\")\n                return None\n\n            # First, try to find the real email by username in user_profiles\n            email = None\n            try:\n                profile_response = supabase.table(\"user_profiles\").select(\"id\").eq(\"username\", username).execute()\n                if profile_response.data and len(profile_response.data) > 0:\n                    user_id = profile_response.data[0][\"id\"]\n                    # Now get the email from auth admin\n                    from app.core.supabase_client import get_supabase_admin_client\n                    admin_client = get_supabase_admin_client()\n                    auth_user = admin_client.auth.admin.get_user_by_id(user_id)\n                    if auth_user and auth_user.user:\n                        email = auth_user.user.email\n                        security_logger.info(f\"Found email '{email}' for username '{username}'\")\n            except Exception as e:\n                security_logger.warning(f\"Could not lookup email by username: {e}\")\n\n            # Fallback: use username as email or append domain\n            if not email:\n                email = username if \"@\" in username else f\"{username}@agentbi.com\"\n                security_logger.info(f\"Using fallback email: {email}\")\n\n            # Tentar autenticar com Supabase\n            try:\n                response = supabase.auth.sign_in_with_password({\n                    \"email\": email,\n                    \"password\": password\n                })\n            except AuthApiError as auth_err:\n                security_logger.warning(f\"Supabase auth failed for '{email}': {auth_err}\")\n                return None\n\n            # Na biblioteca Python, response tem session e user\n            if not response or not response.session or not response.session.user:\n                security_logger.warning(f\"Supabase auth failed: no user/session returned for '{email}'\")\n                return None\n\n            user = response.session.user\n            user_id = str(user.id)\n\n            # --- MELHOR PR\u00c1TICA: BUSCAR AUTORIZA\u00c7\u00c3O NO SQL SERVER ---\n            # J\u00e1 sabemos QUEM \u00e9 o usu\u00e1rio (Supabase). Agora vamos ver o que ele PODE VER (SQL Server).\n            role = \"user\"\n            allowed_segments = []\n            \n            try:\n                from app.config.database import get_db\n                # Como estamos fora de um request FastAPI aqui, precisamos gerenciar a sess\u00e3o se n\u00e3o foi passada\n                # Mas para simplificar e garantir velocidade, vamos usar a l\u00f3gica de fallback se o SQL falhar\n                \n                # Se o DB foi passado (SQL Server dispon\u00edvel)\n                from sqlalchemy import text\n                import json\n                \n                # Usamos uma conex\u00e3o direta ou a passada para buscar as permiss\u00f5es\n                # Nota: authenticate_user recebe 'db' opcionalmente\n                if self.use_sql_server:\n                    # Se n\u00e3o recebemos a sess\u00e3o db, vamos tentar buscar do SQL via AuthService de forma resiliente\n                    # Para este fluxo, vamos priorizar o que est\u00e1 no SQL Server para Segmentos\n                    \n                    # Se db n\u00e3o foi passado, poder\u00edamos criar um tempor\u00e1rio, mas vamos assumir que \n                    # o fluxo de login sempre passa o db se USE_SQL_SERVER for true.\n                    if db:\n                        result = await db.execute(\n                            select(User).where(User.id == user.id)\n                        )\n                        db_user = result.scalar_one_or_none()\n                        if db_user:\n                            role = db_user.role\n                            if db_user.allowed_segments:\n                                try:\n                                    allowed_segments = json.loads(db_user.allowed_segments)\n                                except:\n                                    allowed_segments = []\n                            security_logger.info(f\"Permissions for '{username}' loaded from SQL Server\")\n            except Exception as e:\n                logger.warning(f\"Could not fetch authorization from SQL Server for '{username}': {e}.", "mimetype": "text/plain", "start_char_idx": 4221, "end_char_idx": 9473, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ac60eb75-87ba-478f-8084-7969d72da354": {"__data__": {"id_": "ac60eb75-87ba-478f-8084-7969d72da354", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\auth_service.py", "language": "python", "lines": 340, "filename": "auth_service.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\auth_service.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\auth_service.py", "language": "python", "lines": 340, "filename": "auth_service.py"}, "hash": "12dd6f06677beadc909093b7125e67e7ebb1bddc56cd5a4b4d7a4a2431b663a3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1d00a343-dd45-45dd-9e14-d5fefa7b90c0", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\auth_service.py", "language": "python", "lines": 340, "filename": "auth_service.py"}, "hash": "078e0332f61d6a876d699af069a1bb0bbc8fbcfd47e2f36e5c837a29a9fdbc36", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Using Supabase metadata fallback.\")\n                # Fallback para metadados do Supabase se o SQL Server falhar\n                user_metadata = user.user_metadata or {}\n                allowed_segments = user_metadata.get(\"allowed_segments\", [])\n                # Tentar buscar role do profile no Supabase como \u00faltimo recurso\n                try:\n                    profile_resp = supabase.table(\"user_profiles\").select(\"role\").eq(\"id\", user_id).execute()\n                    if profile_resp.data:\n                        role = profile_resp.data[0].get(\"role\", \"user\")\n                except:\n                    pass\n\n            return {\n                \"id\": user_id,\n                \"username\": username,\n                \"email\": user.email or email,\n                \"role\": role,\n                \"is_active\": True,\n                \"allowed_segments\": allowed_segments\n            }\n\n        except Exception as e:\n            security_logger.error(f\"Supabase authentication error for '{username}': {e}\")\n            return None\n\n    async def _auth_from_parquet(\n        self,\n        username: str,\n        password: str\n    ) -> Optional[dict]:\n        \"\"\"Authenticate from Parquet file\"\"\"\n        # logger.info(f\"Password received length: {len(password)}\") # Removed sensitive logging\n        \n        if not self.parquet_path.exists():\n            security_logger.error(f\"Parquet file not found for authentication: {self.parquet_path}\")\n            return None\n\n        try:\n            # Read users from Parquet\n            df = pl.read_parquet(self.parquet_path)\n            # security_logger.info(f\"Parquet loaded. Users found: {len(df)}\") # Removed verbose logging\n\n            # Filter by username\n            user_data = df.filter(pl.col(\"username\") == username)\n\n            if len(user_data) == 0:\n                security_logger.warning(f\"User '{username}' not found in Parquet.\")\n                return None\n\n            # Get user row\n            user_row = user_data.row(0, named=True)\n            security_logger.info(f\"User '{username}' found in Parquet. Verifying password...\")\n\n            # Verify password\n            hashed_password = user_row[\"hashed_password\"]\n            is_valid = self._verify_password(password, hashed_password)\n            \n            if not is_valid:\n                security_logger.warning(f\"Invalid password attempt for user '{username}' in Parquet.\")\n                return None\n            \n            security_logger.info(f\"Password verified for '{username}' in Parquet.\")\n\n            # Check if active\n            if not user_row.get(\"is_active\", True):\n                security_logger.warning(f\"Inactive user '{username}' attempted to log in via Parquet.\")\n                return None\n\n            # Parse allowed_segments\n            allowed_segments = []\n            if \"allowed_segments\" in user_row and user_row[\"allowed_segments\"]:\n                try:\n                    # It should be a JSON string\n                    allowed_segments = json.loads(user_row[\"allowed_segments\"])\n                except:\n                    # Fallback if it's not JSON (e.g. legacy data)\n                    allowed_segments = []\n\n            return {\n                \"id\": str(user_row[\"id\"]),\n                \"username\": user_row[\"username\"],\n                \"email\": user_row.get(\"email\", \"\"),\n                \"role\": user_row[\"role\"],\n                \"is_active\": user_row.get(\"is_active\", True),\n                \"allowed_segments\": allowed_segments\n            }\n        except Exception as e:\n            security_logger.error(f\"Error reading/processing Parquet for user '{username}': {e}\")\n            return None\n\n    def _verify_password(self, plain_password: str, hashed_password: str) -> bool:\n        \"\"\"Verify password using bcrypt\"\"\"\n        try:\n            return bcrypt.checkpw(\n                plain_password.encode('utf-8'),\n                hashed_password.encode('utf-8')\n            )\n        except Exception as e:\n            security_logger.error(f\"Password verification error for provided hash: {e}\")\n            return False\n\n\n# Global instance\nauth_service = AuthService()", "mimetype": "text/plain", "start_char_idx": 9474, "end_char_idx": 13629, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c91b6aa7-bf89-4813-a0e4-e94cc922a71c": {"__data__": {"id_": "c91b6aa7-bf89-4813-a0e4-e94cc922a71c", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\cache.py", "language": "python", "lines": 197, "filename": "cache.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\cache.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\cache.py", "language": "python", "lines": 197, "filename": "cache.py"}, "hash": "e596ec327ad0a5b9795d1a0ab8cdc5bac6c2a0bc0256b31bbe3f50a06f50eae2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "56c2701e-ad67-46c0-a8ed-9fe1a6e25581", "node_type": "1", "metadata": {}, "hash": "fc2a4974ba930d22294a3613fcaa4a5aef052464009a033b2ed3e7a67580c072", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nAgent Graph Cache\nManages caching of agent graphs, both in-memory and on disk, with versioning.\n\"\"\"\n\nimport time\nimport json\nimport os\nimport hashlib\nfrom typing import Dict, Any, Optional\nfrom datetime import datetime, timedelta\n\nfrom app.config.settings import settings\n\nclass AgentGraphCache:\n    \"\"\"\n    A hybrid in-memory and on-disk cache specifically for agent graphs.\n    Supports versioning for automatic invalidation and TTL.\n    (T6.1.1 from TASK_LIST)\n    \"\"\"\n\n    def __init__(self, cache_dir: str = \"data/cache_agent_graph\", ttl_minutes: int = settings.AGENT_GRAPH_CACHE_TTL_MINUTES):\n        self.cache_dir = cache_dir\n        os.makedirs(self.cache_dir, exist_ok=True)\n        self.ttl = timedelta(minutes=ttl_minutes)\n        self.in_memory_cache: Dict[str, Dict[str, Any]] = {} # {key: {value: graph_data, timestamp: datetime, version: str}}\n        print(f\"AgentGraphCache initialized in {self.cache_dir} with TTL {self.ttl}\")\n\n        # Load existing cache from disk on startup\n        self._load_all_from_disk()\n\n    def _get_cache_file_path(self, key: str) -> str:\n        \"\"\"Generates a file path for a given cache key.\"\"\"\n        return os.path.join(self.cache_dir, f\"{key}.json\")\n\n    def _get_current_version(self) -> str:\n        \"\"\"\n        Generates a hash representing the current version of the agent's code/config.\n        This hash is used to invalidate the cache if agent logic changes.\n        (T6.1.4 from TASK_LIST)\n        \"\"\"\n        # For simplicity, let's hash a combination of settings and a dummy version string.\n        # In a real scenario, this would involve hashing agent source code files,\n        # prompt templates, and relevant configuration files.\n        version_data = {\n            \"agent_code_version\": \"1.0\", # Placeholder: could be hash of agent source code\n            \"settings_llm_model\": settings.LLM_MODEL_NAME,\n            \"settings_rag_model\": settings.RAG_EMBEDDING_MODEL,\n        }\n        return hashlib.sha256(json.dumps(version_data, sort_keys=True).encode(\"utf-8\")).hexdigest()\n\n    def _load_from_disk(self, key: str) -> Optional[Dict[str, Any]]:\n        \"\"\"Loads a single cache entry from disk.\"\"\"\n        file_path = self._get_cache_file_path(key)\n        if os.path.exists(file_path):\n            try:\n                with open(file_path, \"r\", encoding=\"utf-8\") as f:\n                    cached_data = json.load(f)\n                return cached_data\n            except (json.JSONDecodeError, OSError) as e:\n                print(f\"Error reading or decoding cache file {file_path}: {e}\")\n                if os.path.exists(file_path):\n                    os.remove(file_path) # Remove corrupt file\n        return None\n\n    def _save_to_disk(self, key: str, value: Any, timestamp: datetime, version: str):\n        \"\"\"Saves a single cache entry to disk.\"\"\"\n        file_path = self._get_cache_file_path(key)\n        data_to_cache = {\n            \"value\": value,\n            \"timestamp\": timestamp.isoformat(),\n            \"version\": version\n        }\n        try:\n            with open(file_path, \"w\", encoding=\"utf-8\") as f:\n                json.dump(data_to_cache, f, ensure_ascii=False, indent=4)\n            # print(f\"Agent graph cache saved to disk for key: {key}\")\n        except OSError as e:\n            print(f\"Error writing agent graph cache file {file_path}: {e}\")\n\n    def _load_all_from_disk(self):\n        \"\"\"Loads all valid cache entries from disk into memory on startup.\"\"\"\n        current_version = self._get_current_version()\n        for filename in os.listdir(self.cache_dir):\n            if filename.endswith(\".json\"):\n                key = filename[:-5] # Remove .json extension\n                cached_data = self._load_from_disk(key)\n                if cached_data:\n                    cached_time = datetime.fromisoformat(cached_data[\"timestamp\"])\n                    if (datetime.now() - cached_time < self.ttl) and \\\n                       (cached_data.get(\"version\") == current_version):\n                        self.in_memory_cache[key] = cached_data\n                        # print(f\"Loaded valid agent graph cache for key: {key} from disk.\")\n                    else:\n                        print(f\"Invalidated old agent graph cache for key: {key} (expired or version mismatch).\")\n                        os.remove(self._get_cache_file_path(key))\n    \n    def get(self, key: str) -> Any:\n        \"\"\"\n        Gets an entry from the cache (memory first, then disk).\n        Checks for expiration and version compatibility.\n        \"\"\"", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4537, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "56c2701e-ad67-46c0-a8ed-9fe1a6e25581": {"__data__": {"id_": "56c2701e-ad67-46c0-a8ed-9fe1a6e25581", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\cache.py", "language": "python", "lines": 197, "filename": "cache.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\cache.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\cache.py", "language": "python", "lines": 197, "filename": "cache.py"}, "hash": "e596ec327ad0a5b9795d1a0ab8cdc5bac6c2a0bc0256b31bbe3f50a06f50eae2", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c91b6aa7-bf89-4813-a0e4-e94cc922a71c", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\cache.py", "language": "python", "lines": 197, "filename": "cache.py"}, "hash": "0c73387449e1dc47b6fa8020a8e09cc630cfcf5cad966dba7ed272361b3b39f3", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Checks for expiration and version compatibility.\n        \"\"\"\n        current_version = self._get_current_version()\n        \n        # Check in-memory cache\n        if key in self.in_memory_cache:\n            entry = self.in_memory_cache[key]\n            cached_time = datetime.fromisoformat(entry[\"timestamp\"])\n            if (datetime.now() - cached_time < self.ttl) and \\\n               (entry.get(\"version\") == current_version):\n                # print(f\"Agent graph cache hit (in-memory) for key: {key}\")\n                return entry[\"value\"]\n            else:\n                del self.in_memory_cache[key] # Expired or old version\n        \n        # Check disk cache if not found in memory or invalidated\n        cached_data_from_disk = self._load_from_disk(key)\n        if cached_data_from_disk:\n            cached_time = datetime.fromisoformat(cached_data_from_disk[\"timestamp\"])\n            if (datetime.now() - cached_time < self.ttl) and \\\n               (cached_data_from_disk.get(\"version\") == current_version):\n                self.in_memory_cache[key] = cached_data_from_disk # Load into memory\n                # print(f\"Agent graph cache hit (disk) for key: {key}\")\n                return cached_data_from_disk[\"value\"]\n            else:\n                print(f\"Invalidated old agent graph cache for key: {key} (expired or version mismatch).\")\n                os.remove(self._get_cache_file_path(key))\n        \n        return None\n\n    def set(self, key: str, value: Any) -> None:\n        \"\"\"\n        Sets an entry in the cache (both in-memory and on disk).\n        \"\"\"\n        timestamp = datetime.now()\n        version = self._get_current_version()\n        entry = {\n            \"value\": value,\n            \"timestamp\": timestamp.isoformat(),\n            \"version\": version\n        }\n        self.in_memory_cache[key] = entry\n        self._save_to_disk(key, value, timestamp, version)\n        # print(f\"Agent graph cache set for key: {key}\")\n\n    def clear(self, key: Optional[str] = None):\n        \"\"\"Clears a specific key or the entire cache.\"\"\"\n        if key:\n            if key in self.in_memory_cache:\n                del self.in_memory_cache[key]\n            file_path = self._get_cache_file_path(key)\n            if os.path.exists(file_path):\n                os.remove(file_path)\n            print(f\"Agent graph cache cleared for key: {key}\")\n        else:\n            self.in_memory_cache.clear()\n            for filename in os.listdir(self.cache_dir):\n                file_path = os.path.join(self.cache_dir, filename)\n                if os.path.isfile(file_path):\n                    os.remove(file_path)\n            print(\"All agent graph cache cleared.\")\n\n# Example usage\nif __name__ == '__main__':\n    # Ensure cache directory exists for testing\n    os.makedirs(settings.LEARNING_EXAMPLES_PATH, exist_ok=True) # Using LEARNING_EXAMPLES_PATH as temp dir\n    \n    cache = AgentGraphCache(cache_dir=settings.LEARNING_EXAMPLES_PATH, ttl_minutes=1) # 1 minute TTL for testing\n\n    test_key = \"my_agent_graph_key\"\n    test_graph_data = {\"nodes\": [\"A\", \"B\"], \"edges\": [(\"A\", \"B\")]}\n\n    # Test set\n    cache.set(test_key, test_graph_data)\n    \n    # Test get (should hit)\n    retrieved = cache.get(test_key)\n    print(f\"Retrieved (should hit): {retrieved}\")\n    assert retrieved == test_graph_data\n\n    # Test get (after expiration - manual simulation)\n    print(\"Waiting for cache to expire (1 minute)...\")\n    import time\n    time.sleep(65) # Wait a bit more than 1 minute\n\n    retrieved_expired = cache.get(test_key)\n    print(f\"Retrieved (should miss after expiration): {retrieved_expired}\")\n    assert retrieved_expired is None\n\n    # Test clear\n    cache.set(test_key, test_graph_data)\n    cache.clear(test_key)\n    assert cache.get(test_key) is None\n\n    print(\"\\nAgentGraphCache tests passed!\")", "mimetype": "text/plain", "start_char_idx": 4477, "end_char_idx": 8303, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b1a9e8f5-5e17-43a5-9bb4-3c6744a8bd93": {"__data__": {"id_": "b1a9e8f5-5e17-43a5-9bb4-3c6744a8bd93", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\code_rag_service.py", "language": "python", "lines": 282, "filename": "code_rag_service.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\code_rag_service.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\code_rag_service.py", "language": "python", "lines": 282, "filename": "code_rag_service.py"}, "hash": "ab25d4c9286fe4f3078257a840ddf5ecd35e5e8633204f2fafb0b6fd8ffd3da4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6403afba-51c1-4f6c-b365-efafee85b144", "node_type": "1", "metadata": {}, "hash": "4fcae53357369f62b3aa86d42d97471655f9f2c1c4eda5e9e7f2d7cceb2e3315", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nCode RAG Service - Semantic Code Search with LlamaIndex + Gemini\n================================================================\n\nProvides semantic search and analysis of the entire codebase using:\n- LlamaIndex for RAG (Retrieval-Augmented Generation)\n- Gemini 3.0 Flash for LLM\n- GeminiEmbedding for semantic search\n- FAISS for vector storage\n\nAuthor: Antigravity AI\nDate: 2025-12-15\n\"\"\"\n\nimport os\nimport json\nimport logging\nfrom pathlib import Path\nfrom typing import Optional, Dict, Any, List\nfrom datetime import datetime\n\nfrom app.config.settings import settings\n\nlogger = logging.getLogger(__name__)\n\n\nclass CodeRAGService:\n    \"\"\"\n    Service for semantic code search and analysis using RAG.\n    \n    Features:\n    - Semantic search across entire codebase\n    - Context-aware code analysis\n    - Intelligent code suggestions\n    - Multi-language support (Python, TypeScript, etc.)\n    \"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the RAG service with lazy loading.\"\"\"\n        # Melhor pr\u00e1tica Context7: Usar caminho absoluto baseado no arquivo, n\u00e3o no CWD\n        # ./backend/app/core/code_rag_service.py -> ../../../storage\n        self._storage_path = Path(__file__).resolve().parents[3] / \"storage\"\n        self._initialized = False\n        self._index_stats = None\n        self._index = None\n        self._query_engine = None\n        \n    def _ensure_initialized(self) -> bool:\n        \"\"\"\n        Lazy initialization of the RAG engine.\n        Only loads when first query is made.\n        \n        Returns:\n            bool: True if initialized successfully\n        \"\"\"\n        if self._initialized:\n            return True\n            \n        try:\n            logger.info(\"Initializing Code RAG Service...\")\n            logger.info(f\"Storage Path: {self._storage_path}\")\n            \n            # Check if Gemini API key is configured\n            if not settings.GEMINI_API_KEY:\n                logger.error(\"[ERROR] GEMINI_API_KEY not configured. Cannot initialize RAG service.\")\n                return False\n\n            # Check if storage directory exists\n            if not self._storage_path.exists():\n                logger.error(f\"[ERROR] Storage path does not exist: {self._storage_path}\")\n                logger.error(\"[ACTION REQUIRED] Run 'python scripts/index_codebase.py' to generate the index.\")\n                return False\n                \n            # Check for essential index files (simple validation)\n            if not (self._storage_path / \"docstore.json\").exists() and not (self._storage_path / \"index_store.json\").exists():\n                 logger.warning(f\"[WARN] Index files not found in {self._storage_path}. Service might fail to load index.\")\n\n            # Import LlamaIndex components (lazy import)\n            try:\n                from llama_index.core import (\n                    VectorStoreIndex,\n                    Settings,\n                    load_index_from_storage,\n                )\n                from llama_index.core.storage import StorageContext\n                from llama_index.llms.gemini import Gemini\n                from llama_index.embeddings.gemini import GeminiEmbedding\n            except ImportError as e:\n                logger.error(f\"[ERROR] Missing dependencies (ImportError): {e}\")\n                logger.error(\"[ACTION REQUIRED] Install dependencies with 'pip install llama-index llama-index-llms-gemini llama-index-embeddings-gemini'\")\n                return False\n            \n            # Configure LlamaIndex Settings\n            # Using gemini-3-flash-preview as requested\n            try:\n                Settings.llm = Gemini(\n                    model_name=\"models/gemini-3-flash-preview\", \n                    api_key=settings.GEMINI_API_KEY,\n                    temperature=0.1,\n                )\n                \n                Settings.embed_model = GeminiEmbedding(\n                    model_name=\"models/text-embedding-004\",\n                    api_key=settings.GEMINI_API_KEY,\n                )\n            except Exception as e:\n                logger.error(f\"[ERROR] Failed to configure Gemini models: {e}\")\n                return False\n            \n            # Load index\n            logger.info(\"Loading index from storage...\")\n            try:\n                storage_context = StorageContext.from_defaults(\n                    persist_dir=str(self._storage_path)\n                )\n                \n                self._index = load_index_from_storage(storage_context)\n                self._query_engine = self._index.as_query_engine(\n                    similarity_top_k=5,\n                    response_mode=\"tree_summarize\"\n                )\n            except Exception as e:\n                logger.error(f\"[ERROR] Failed to load index from storage: {e}\")\n                logger.error(\"[ACTION REQUIRED] The index might be corrupted or incompatible. Try re-running 'python scripts/index_codebase.py'.\")", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4925, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "6403afba-51c1-4f6c-b365-efafee85b144": {"__data__": {"id_": "6403afba-51c1-4f6c-b365-efafee85b144", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\code_rag_service.py", "language": "python", "lines": 282, "filename": "code_rag_service.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\code_rag_service.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\code_rag_service.py", "language": "python", "lines": 282, "filename": "code_rag_service.py"}, "hash": "ab25d4c9286fe4f3078257a840ddf5ecd35e5e8633204f2fafb0b6fd8ffd3da4", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b1a9e8f5-5e17-43a5-9bb4-3c6744a8bd93", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\code_rag_service.py", "language": "python", "lines": 282, "filename": "code_rag_service.py"}, "hash": "a79ee5ba368e9a3c694ba380134702c5945f302006423be2f39da63b41da5141", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e97473d7-a5f6-46f1-9d9e-99631575d09b", "node_type": "1", "metadata": {}, "hash": "6dbef46d9a15d404418287efd2ce0ad4e4630a70a12f280015b97de9b86dbb81", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Try re-running 'python scripts/index_codebase.py'.\")\n                return False\n            \n            # Load index statistics\n            stats_file = self._storage_path / \"index_stats.json\"\n            if stats_file.exists():\n                try:\n                    with open(stats_file, 'r', encoding='utf-8') as f:\n                        self._index_stats = json.load(f)\n                except Exception as e:\n                    logger.warning(f\"[WARN] Failed to load index stats: {e}\")\n            \n            self._initialized = True\n            logger.info(\"Code RAG Service initialized successfully\")\n            return True\n            \n        except Exception as e:\n            # CRITICAL: Log the full traceback to understand why it fails\n            import traceback\n            trace = traceback.format_exc()\n            logger.error(f\"[FATAL] Failed to initialize RAG service: {e}\\n{trace}\")\n            return False\n    \n    def get_index_stats(self) -> Dict[str, Any]:\n        \"\"\"\n        Get statistics about the code index.\n\n        Returns:\n            Dict with index statistics\n        \"\"\"\n        # Ensure service is initialized before returning stats\n        self._ensure_initialized()\n\n        if self._index_stats:\n            return self._index_stats\n\n        # Default stats if not loaded\n        return {\n            \"status\": \"not_indexed\",\n            \"total_files\": 0,\n            \"total_functions\": 0,\n            \"total_classes\": 0,\n            \"total_lines\": 0,\n            \"indexed_at\": None,\n            \"languages\": []\n        }\n    \n    def query(\n        self,\n        message: str,\n        history: Optional[List[Dict[str, str]]] = None,\n        filters: Optional[Dict[str, Any]] = None\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Query the codebase with semantic search.\n        \n        Args:\n            message: User's question about the code\n            history: Previous conversation history\n            filters: Optional filters (language, directory, etc.)\n            \n        Returns:\n            Dict with response, code references, and metadata\n        \"\"\"\n        # Ensure service is initialized\n        if not self._ensure_initialized():\n            return {\n                \"response\": (\n                    \"[ERRO] **Servi\u00e7o RAG n\u00e3o dispon\u00edvel**\\n\\n\"\n                    \"O \u00edndice de c\u00f3digo n\u00e3o foi encontrado ou o servi\u00e7o n\u00e3o p\u00f4de ser inicializado.\\n\\n\"\n                    \"**Poss\u00edveis causas:**\\n\"\n                    \"1. GEMINI_API_KEY n\u00e3o configurada\\n\"\n                    \"2. Depend\u00eancias faltando (llama-index, faiss)\\n\"\n                    \"3. \u00cdndice n\u00e3o gerado (execute `python scripts/index_codebase.py`)\\n\\n\"\n                    \"Verifique os logs para mais detalhes.\"", "mimetype": "text/plain", "start_char_idx": 4873, "end_char_idx": 7618, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e97473d7-a5f6-46f1-9d9e-99631575d09b": {"__data__": {"id_": "e97473d7-a5f6-46f1-9d9e-99631575d09b", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\code_rag_service.py", "language": "python", "lines": 282, "filename": "code_rag_service.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\code_rag_service.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\code_rag_service.py", "language": "python", "lines": 282, "filename": "code_rag_service.py"}, "hash": "ab25d4c9286fe4f3078257a840ddf5ecd35e5e8633204f2fafb0b6fd8ffd3da4", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6403afba-51c1-4f6c-b365-efafee85b144", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\code_rag_service.py", "language": "python", "lines": 282, "filename": "code_rag_service.py"}, "hash": "464cc387df0a44a6835cada66e08e941592b8f43e1287a3d44a47fbea5a9f874", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "),\n                \"code_references\": [],\n                \"metadata\": {\n                    \"response_time\": 0,\n                    \"sources_count\": 0,\n                    \"error\": \"Service not initialized\"\n                }\n            }\n        \n        try:\n            start_time = datetime.now()\n            \n            # Build context from history if provided\n            context_messages = []\n            if history:\n                for msg in history[-5:]:  # Last 5 messages for context\n                    role = msg.get(\"role\", \"user\")\n                    content = msg.get(\"content\", \"\")\n                    context_messages.append(f\"{role}: {content}\")\n            \n            # Construct query with context\n            full_query = message\n            if context_messages:\n                context_str = \"\\n\".join(context_messages)\n                full_query = f\"Contexto da conversa:\\n{context_str}\\n\\nPergunta atual: {message}\"\n            \n            # Query the RAG engine\n            logger.info(f\"[QUERY] Querying codebase: {message[:100]}...\")\n            response = self._query_engine.query(full_query)\n            \n            # Extract source nodes (code references)\n            code_references = []\n            if hasattr(response, 'source_nodes'):\n                for node in response.source_nodes[:5]:  # Top 5 sources\n                    metadata = node.node.metadata\n                    code_references.append({\n                        \"file\": metadata.get(\"file_path\", \"unknown\"),\n                        \"score\": node.score,\n                        \"content\": node.node.text[:500],  # First 500 chars\n                        \"lines\": str(metadata.get(\"lines\", \"\")),  # Convert to string\n                    })\n            \n            end_time = datetime.now()\n            response_time = (end_time - start_time).total_seconds()\n            \n            return {\n                \"response\": str(response),\n                \"code_references\": code_references,\n                \"metadata\": {\n                    \"response_time\": round(response_time, 2),\n                    \"sources_count\": len(code_references),\n                    \"timestamp\": datetime.now().isoformat()\n                }\n            }\n            \n        except Exception as e:\n            logger.error(f\"Error querying codebase: {e}\", exc_info=True)\n            return {\n                \"response\": f\"[ERRO] **Erro ao processar consulta**\\n\\n{str(e)}\",\n                \"code_references\": [],\n                \"metadata\": {\n                    \"response_time\": 0,\n                    \"sources_count\": 0,\n                    \"error\": str(e)\n                }\n            }\n\n\n# Singleton instance\n_code_rag_service: Optional[CodeRAGService] = None\n\n\ndef get_code_rag_service() -> CodeRAGService:\n    \"\"\"\n    Get or create the singleton CodeRAGService instance.\n    \n    Returns:\n        CodeRAGService instance\n    \"\"\"\n    global _code_rag_service\n    if _code_rag_service is None:\n        _code_rag_service = CodeRAGService()\n    return _code_rag_service", "mimetype": "text/plain", "start_char_idx": 7635, "end_char_idx": 10687, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "42732543-6c2f-4e73-8dd6-ac4be898b5b1": {"__data__": {"id_": "42732543-6c2f-4e73-8dd6-ac4be898b5b1", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\data_scope_service.py", "language": "python", "lines": 171, "filename": "data_scope_service.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\data_scope_service.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\data_scope_service.py", "language": "python", "lines": 171, "filename": "data_scope_service.py"}, "hash": "1c3b278e30ce3a49787cbf1e762180d7d4fa173da2de18b2b065eb6501abd802", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "99a8af09-6eb6-469c-919f-60416aaa9a3c", "node_type": "1", "metadata": {}, "hash": "d2a7e85e44dda76d12811a9efc16fd690b1c2d5514aa9ae54313d44f3a597b4d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# backend/app/core/data_scope_service.py\nimport polars as pl\nimport logging\nimport time\nfrom typing import List, Optional, Union\nfrom pathlib import Path\n\nfrom app.infrastructure.database.models.user import User\nfrom app.config.settings import settings\n\nlogger = logging.getLogger(__name__)\n\nclass DataScopeService:\n    \"\"\"\n    Servi\u00e7o para filtrar DataFrames baseados nas permiss\u00f5es de segmento do usu\u00e1rio.\n    Garante que cada usu\u00e1rio veja apenas os dados aos quais tem acesso.\n    \n    PERFORMANCE UPDATE: Uses LazyFrame (scan_parquet) to avoid loading full dataset into memory.\n    \"\"\"\n\n    def __init__(self):\n        # Determine path once\n        docker_path = Path(\"/app/data/parquet/admmat.parquet\")\n        # Fix: Go up 4 levels from backend/app/core/data_scope_service.py to reach project root\n        dev_path = Path(__file__).parent.parent.parent.parent / \"data\" / \"parquet\" / \"admmat.parquet\"\n\n        if docker_path.exists():\n            self.parquet_path = str(docker_path)\n        else:\n            self.parquet_path = str(dev_path)\n\n        logger.info(f\"DataScopeService: Initialized with Lazy Path: {self.parquet_path}\")\n\n    def _get_base_lazyframe(self) -> pl.LazyFrame:\n        \"\"\"\n        Returns a base LazyFrame with global filters applied.\n        WORKAROUND: Uses read_parquet().lazy() instead of scan_parquet() \n        to avoid 'assertion left == right failed' panic in streaming engine (Polars 1.34.0).\n        \"\"\"\n        # lf = pl.scan_parquet(self.parquet_path)\n        # Using eager read + lazy conversion to bypass streaming reader bug\n        try:\n            lf = pl.read_parquet(self.parquet_path).lazy()\n        except Exception as e:\n            logger.error(f\"Failed to read parquet file eagerly: {e}\")\n            # Fallback to scan if read fails\n            lf = pl.scan_parquet(self.parquet_path)\n        \n        # GLOBAL FILTER: Apply allowed UNEs whitelist if configured\n        if settings.ALLOWED_UNES:\n            # We assume 'UNE' column exists, but check schema safely if needed\n            # In Lazy mode, we just apply the filter. If col doesn't exist, it will fail at collection time.\n            lf = lf.filter(pl.col(\"UNE\").is_in(settings.ALLOWED_UNES))\n            \n        return lf\n\n    def get_filtered_dataframe(self, user: User, max_rows: Optional[int] = None) -> Union[pl.DataFrame, pl.LazyFrame]:\n        \"\"\"\n        Retorna o DataFrame admmat.parquet filtrado pelos allowed_segments do usu\u00e1rio.\n        \n        Args:\n            user: Usu\u00e1rio autenticado\n            max_rows: Limite m\u00e1ximo de linhas a retornar (None = sem limite)\n            \n        Returns:\n            pl.DataFrame: The collected filtered data.\n        \"\"\"\n        start_time = time.perf_counter()\n        \n        try:\n            lf = self._get_base_lazyframe()\n            \n            # 1. Apply User Permission Filters\n            if not user or user.role == \"admin\" or \"*\" in user.segments_list:\n                # Admin or Full Access: No segment filter\n                pass\n            else:\n                allowed_segments = user.segments_list\n                if not allowed_segments:\n                    logger.warning(f\"Usu\u00e1rio {user.username} sem segmentos permitidos.\")\n                    return pl.DataFrame() # Return empty DF\n                \n                # Check schema for column name (optimization: cached schema could be better)\n                schema = lf.collect_schema()\n                segment_col = \"nomesegmento\" if \"nomesegmento\" in schema.names() else \"NOMESEGMENTO\" if \"NOMESEGMENTO\" in schema.names() else \"SEGMENTO\"\n                \n                if segment_col in schema.names():\n                    lf = lf.filter(pl.col(segment_col).is_in(allowed_segments))\n                else:\n                    logger.warning(f\"Coluna de segmento n\u00e3o encontrada no schema. Retornando vazio.\")\n                    return pl.DataFrame()\n\n            # 2. Apply Row Limits (Optimization: Limit at source)\n            if max_rows is not None and max_rows > 0:\n                lf = lf.head(max_rows)\n                \n            # 3.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4096, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "99a8af09-6eb6-469c-919f-60416aaa9a3c": {"__data__": {"id_": "99a8af09-6eb6-469c-919f-60416aaa9a3c", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\data_scope_service.py", "language": "python", "lines": 171, "filename": "data_scope_service.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\data_scope_service.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\data_scope_service.py", "language": "python", "lines": 171, "filename": "data_scope_service.py"}, "hash": "1c3b278e30ce3a49787cbf1e762180d7d4fa173da2de18b2b065eb6501abd802", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "42732543-6c2f-4e73-8dd6-ac4be898b5b1", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\data_scope_service.py", "language": "python", "lines": 171, "filename": "data_scope_service.py"}, "hash": "44975645befb3ad72d792cef0609fbf1da0c748f70fdba7d9266649d118fa7d2", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Collect Data\n            # Removed streaming=True due to panic issues\n            result_df = lf.collect()\n            \n            elapsed = time.perf_counter() - start_time\n            logger.info(f\"[INFO] Filtro LAZY (via Eager) para {user.username}: {result_df.height} linhas em {elapsed:.4f}s\")\n            \n            return result_df\n\n        except Exception as e:\n            logger.error(f\"Erro ao filtrar dados (Lazy): {e}\")\n            return pl.DataFrame() # Fail safe\n\n    def get_filtered_lazyframe(self, user: User) -> pl.LazyFrame:\n        \"\"\"\n        Retorna um LazyFrame com os filtros de seguran\u00e7a aplicados, mas SEM coletar os dados.\n        Permite que os endpoints fa\u00e7am agrega\u00e7\u00f5es otimizadas antes de trazer dados para a mem\u00f3ria.\n        \"\"\"\n        try:\n            lf = self._get_base_lazyframe()\n            \n            if not user or user.role == \"admin\" or \"*\" in user.segments_list:\n                return lf\n            \n            allowed_segments = user.segments_list\n            if not allowed_segments:\n                return self._get_empty_lazyframe(lf)\n            \n            schema = lf.collect_schema()\n            segment_col = \"nomesegmento\" if \"nomesegmento\" in schema.names() else \"NOMESEGMENTO\" if \"NOMESEGMENTO\" in schema.names() else \"SEGMENTO\"\n            \n            if segment_col in schema.names():\n                return lf.filter(pl.col(segment_col).is_in(allowed_segments))\n            \n            return self._get_empty_lazyframe(lf)\n            \n        except Exception as e:\n            logger.error(f\"Erro ao obter LazyFrame: {e}\")\n            # Retornar um LazyFrame vazio seguro usando um scan dummy ou similar\n            # Hack: Scan no mesmo arquivo com filtro imposs\u00edvel\n            return self._get_base_lazyframe().filter(pl.lit(False))\n\n    def _get_empty_lazyframe(self, lf: pl.LazyFrame) -> pl.LazyFrame:\n        \"\"\"Helper para retornar LazyFrame vazio preservando schema\"\"\"\n        return lf.filter(pl.lit(False))\n\n    def get_user_segments(self, user: User) -> List[str]:\n        \"\"\"\n        Retorna a lista de segmentos \u00fanicos dispon\u00edveis para o usu\u00e1rio.\n        Se admin, faz um scan r\u00e1pido para pegar valores \u00fanicos.\n        \"\"\"\n        if not user:\n            return []\n            \n        if user.role != \"admin\" and \"*\" not in user.segments_list:\n            return user.segments_list\n            \n        # For admins, we need to fetch unique segments from DB\n        try:\n            lf = self._get_base_lazyframe()\n            schema = lf.collect_schema()\n            segment_col = \"nomesegmento\" if \"nomesegmento\" in schema.names() else \"NOMESEGMENTO\" if \"NOMESEGMENTO\" in schema.names() else \"SEGMENTO\"\n            \n            if segment_col in schema.names():\n                # Efficient unique value extraction\n                unique_segments = lf.select(segment_col).unique().collect().get_column(segment_col).to_list()\n                return [str(s) for s in unique_segments if s]\n                \n            return []\n        except Exception as e:\n            logger.error(f\"Erro ao buscar segmentos \u00fanicos: {e}\")\n            return []\n\n# Inicializar o servi\u00e7o como um singleton\ndata_scope_service = DataScopeService()", "mimetype": "text/plain", "start_char_idx": 4097, "end_char_idx": 7315, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7ea3a0e3-5c01-4c32-b45e-03d6bae9f502": {"__data__": {"id_": "7ea3a0e3-5c01-4c32-b45e-03d6bae9f502", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\data_source_manager.py", "language": "python", "lines": 219, "filename": "data_source_manager.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\data_source_manager.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\data_source_manager.py", "language": "python", "lines": 219, "filename": "data_source_manager.py"}, "hash": "12c638b177503a5e9b7ec28f2fb997a4398458df5931398bac31766c6517cd1f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "86368921-8967-43d9-9aaa-00cb2893ad8a", "node_type": "1", "metadata": {}, "hash": "1540022079d2e6b3b6f266944b7c9ec2973ee79115a47c499e54fde5f09f5b3e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nData Source Manager - Acesso centralizado aos dados Parquet\nAdaptado para Agent Solution BI: admmat.parquet\n\"\"\"\n\nimport logging\nimport pandas as pd\nfrom pathlib import Path\nfrom typing import Dict, Any, Optional, List\nfrom app.core.parquet_cache import cache\n\nlogger = logging.getLogger(__name__)\n\n# Constantes: Arquivos de dados\nPROJECT_ROOT = Path(__file__).resolve().parent.parent.parent.parent\nMAIN_DATA_FILE = PROJECT_ROOT / \"data\" / \"parquet\" / \"admmat.parquet\"\n\n\nclass ParquetDataSource:\n    \"\"\"Acesso centralizado ao arquivo admmat.parquet.\"\"\"\n\n    def __init__(self):\n        self._connected = False\n        self._df_cache: Optional[pd.DataFrame] = None\n\n        # Caminho h\u00edbrido Docker/Dev\n        docker_path = Path(\"/app/data/parquet/admmat.parquet\")\n        dev_path = MAIN_DATA_FILE\n\n        self.file_path = docker_path if docker_path.exists() else dev_path\n        logger.info(f\"[FILE] Usando arquivo: {self.file_path}\")\n\n    def connect(self) -> bool:\n        \"\"\"Verifica se arquivo Parquet existe.\"\"\"\n        if self.file_path.exists():\n            self._connected = True\n            logger.info(f\"[OK] Parquet conectado: {self.file_path}\")\n            return True\n\n        logger.error(f\"[ERROR] Arquivo n\u00e3o encontrado: {self.file_path}\")\n        self._connected = False\n        return False\n\n    def is_connected(self) -> bool:\n        \"\"\"Verifica se est\u00e1 conectado.\"\"\"\n        return self._connected and self.file_path.exists()\n\n    def _load_data(self, force_reload: bool = False) -> pd.DataFrame:\n        \"\"\"\n        Carrega os dados do arquivo Parquet usando ParquetCache global.\n        [OK]: OTIMIZADO: Usa cache global ao inv\u00e9s de cache local.\n        \"\"\"\n        try:\n            # Usar ParquetCache global (j\u00e1 retorna Polars DataFrame)\n            df_polars = cache.get_dataframe(\"admmat.parquet\")\n\n            # Converter de Polars para Pandas (necess\u00e1rio para compatibilidade com ferramentas existentes)\n            df = df_polars.to_pandas()\n            logger.info(f\"[OK] Dados obtidos do cache: {df.shape}\")\n\n            return df\n\n        except FileNotFoundError as e:\n            logger.error(f\"[ERROR] ERRO CR\u00cdTICO: Arquivo n\u00e3o encontrado: {self.file_path}\")\n            raise\n        except Exception as e:\n            logger.error(f\"[ERROR] ERRO ao ler Parquet: {e}\")\n            raise\n\n    def get_data(self, limit: int = None) -> pd.DataFrame:\n        \"\"\"Obt\u00e9m todos os dados ou limitados.\"\"\"\n        df = self._load_data()\n        if limit and not df.empty:\n            df = df.head(limit)\n        return df\n\n    def search(self, column: str, value: str, limit: int = 10) -> pd.DataFrame:\n        \"\"\"Busca em uma coluna.\"\"\"\n        try:\n            df = self._load_data()\n            if df.empty or column not in df.columns:\n                return pd.DataFrame()\n\n            # Busca case-insensitive\n            mask = df[column].astype(str).str.contains(value, case=False, na=False)\n            result = df[mask].head(limit)\n            return result\n\n        except Exception as e:\n            logger.error(f\"Erro ao buscar: {e}\")\n            return pd.DataFrame()\n\n    def get_filtered_data(\n        self, filters: Dict[str, Any], limit: int = None\n    ) -> pd.DataFrame:\n        \"\"\"Busca com filtros exatos.\"\"\"", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3263, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "86368921-8967-43d9-9aaa-00cb2893ad8a": {"__data__": {"id_": "86368921-8967-43d9-9aaa-00cb2893ad8a", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\data_source_manager.py", "language": "python", "lines": 219, "filename": "data_source_manager.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\data_source_manager.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\data_source_manager.py", "language": "python", "lines": 219, "filename": "data_source_manager.py"}, "hash": "12c638b177503a5e9b7ec28f2fb997a4398458df5931398bac31766c6517cd1f", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7ea3a0e3-5c01-4c32-b45e-03d6bae9f502", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\data_source_manager.py", "language": "python", "lines": 219, "filename": "data_source_manager.py"}, "hash": "e04297cc4b0bc8f8124aa6694a46a3ceb98160ea7e0b0b0102eafbfbc9325125", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "try:\n            df = self._load_data()\n            if df.empty:\n                return pd.DataFrame()\n\n            for col, value in filters.items():\n                if col in df.columns:\n                    col_dtype = df[col].dtype\n                    try:\n                        if pd.api.types.is_numeric_dtype(col_dtype) and isinstance(value, str):\n                            converted_value = pd.to_numeric(value, errors='raise')\n                            df = df[df[col] == converted_value]\n                        elif pd.api.types.is_datetime64_any_dtype(col_dtype) and isinstance(value, str):\n                            converted_value = pd.to_datetime(value, errors='raise')\n                            df = df[df[col] == converted_value]\n                        else:\n                            df = df[df[col] == value]\n                    except (ValueError, TypeError):\n                        df = df[df[col].astype(str).str.lower() == str(value).lower()]\n                else:\n                    logger.warning(f\"Coluna '{col}' n\u00e3o encontrada\")\n                    return pd.DataFrame()\n\n            if limit:\n                df = df.head(limit)\n\n            return df\n        except Exception as e:\n            logger.error(f\"Erro ao filtrar: {e}\")\n            return pd.DataFrame()\n\n    def get_columns(self) -> List[str]:\n        \"\"\"Retorna lista de colunas.\"\"\"\n        df = self._load_data()\n        return df.columns.tolist() if not df.empty else []\n\n    def get_shape(self) -> tuple:\n        \"\"\"Retorna dimens\u00f5es dos dados.\"\"\"\n        df = self._load_data()\n        return df.shape if not df.empty else (0, 0)\n\n    def get_info(self) -> Dict[str, Any]:\n        \"\"\"Retorna informa\u00e7\u00f5es sobre os dados.\"\"\"\n        df = self._load_data()\n        if df.empty:\n            return {\"status\": \"sem_dados\"}\n\n        return {\n            \"file\": str(self.file_path),\n            \"shape\": df.shape,\n            \"columns\": df.columns.tolist(),\n            \"dtypes\": {k: str(v) for k, v in df.dtypes.to_dict().items()},\n            \"memory_mb\": round(df.memory_usage(deep=True).sum() / 1024**2, 2),\n        }\n\n\nclass DataSourceManager:\n    \"\"\"\n    Gerenciador de fonte de dados centralizado.\n    Acessa: data/parquet/admmat.parquet\n    \"\"\"\n\n    def __init__(self):\n        self._source = ParquetDataSource()\n        self._source.connect()\n\n    def get_data(\n        self, table_name: str = None, limit: int = None, source: str = None\n    ) -> pd.DataFrame:\n        \"\"\"Obt\u00e9m dados (table_name \u00e9 ignorado).\"\"\"\n        return self._source.get_data(limit)\n\n    def search_data(\n        self,\n        table_name: str = None,\n        column: str = None,\n        value: str = None,\n        limit: int = 10,\n        source: str = None,\n    ) -> pd.DataFrame:\n        \"\"\"Busca dados em coluna especificada.\"\"\"\n        if not column or not value:\n            return pd.DataFrame()\n        return self._source.search(column, value, limit)\n\n    def get_filtered_data(\n        self,\n        table_name: str = None,\n        filters: Dict[str, Any] = None,\n        limit: int = None,\n        source: str = None,\n    ) -> pd.DataFrame:\n        \"\"\"Busca com filtros.\"\"\"\n        if not filters:\n            return pd.DataFrame()\n        return self._source.get_filtered_data(filters, limit)\n\n    def execute_query(self, query: str, params: Dict = None) -> List[Dict]:\n        \"\"\"N\u00e3o suportado para Parquet.\"\"\"\n        return []\n\n    def get_available_sources(self) -> List[str]:\n        \"\"\"Retorna fontes dispon\u00edveis.\"\"\"\n        if self._source.is_connected():\n            return [\"admmat_parquet\"]\n        return []\n\n    def get_source_info(self) -> Dict[str, Any]:\n        \"\"\"Retorna informa\u00e7\u00f5es da fonte.\"\"\"\n        return self._source.get_info()\n\n\n# Inst\u00e2ncia global singleton\n_data_manager_instance: Optional[DataSourceManager] = None\n\n\ndef get_data_manager() -> DataSourceManager:\n    \"\"\"Retorna inst\u00e2ncia singleton do DataSourceManager.\"\"\"\n    global _data_manager_instance\n    if _data_manager_instance is None:\n        _data_manager_instance = DataSourceManager()\n    return _data_manager_instance", "mimetype": "text/plain", "start_char_idx": 3272, "end_char_idx": 7378, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "65264fb7-389f-4fff-afb8-9ea43ccfb1dd": {"__data__": {"id_": "65264fb7-389f-4fff-afb8-9ea43ccfb1dd", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\intelligent_chatbi.py", "language": "python", "lines": 195, "filename": "intelligent_chatbi.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\intelligent_chatbi.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\intelligent_chatbi.py", "language": "python", "lines": 195, "filename": "intelligent_chatbi.py"}, "hash": "d54dca90dce897c71ca826103532740981e3930d5c0d5ee9683d01677fbf1cee", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "56df4def-f334-41fe-a1ef-e6132e2289e6", "node_type": "1", "metadata": {}, "hash": "b5dde9384b4de3710e35628bb6769f59d9b27293cc13cc5e7b8a956e872e84ab", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nChat BI - Sistema Inteligente com Gemini\nSolu\u00e7\u00e3o definitiva para processar perguntas em linguagem natural\n\"\"\"\n\nimport google.generativeai as genai\nimport polars as pl\nfrom pathlib import Path\nimport json\nimport re\nfrom typing import Dict, Any, Optional\nimport os\n\n\nclass IntelligentChatBI:\n    \"\"\"\n    Sistema inteligente de Chat BI usando Gemini para NL2SQL\n    \"\"\"\n    \n    def __init__(self, parquet_path: Path):\n        self.parquet_path = parquet_path\n        \n        # Configurar Gemini\n        api_key = os.getenv(\"GEMINI_API_KEY\")\n        if not api_key:\n            raise ValueError(\"GEMINI_API_KEY n\u00e3o configurada\")\n        \n        genai.configure(api_key=api_key)\n        \n        # Usar modelo mais recente e inteligente\n        self.model = genai.GenerativeModel('gemini-3-flash-preview')\n        \n        # Carregar schema do Parquet\n        self.schema = self._load_schema()\n    \n    def _load_schema(self) -> Dict[str, str]:\n        \"\"\"Carrega schema do Parquet para contexto\"\"\"\n        lf = pl.scan_parquet(self.parquet_path)\n        schema = lf.collect_schema()\n        \n        return {\n            \"columns\": list(schema.names()),\n            \"description\": {\n                \"PRODUTO\": \"C\u00f3digo do produto\",\n                \"NOME\": \"Nome do produto\",\n                \"UNE\": \"Unidade de Neg\u00f3cio (loja)\",\n                \"MES_01\": \"Vendas/Pre\u00e7o do m\u00eas 1\",\n                \"MES_02\": \"Vendas/Pre\u00e7o do m\u00eas 2\",\n                \"MES_03\": \"Vendas/Pre\u00e7o do m\u00eas 3\",\n                # Adicionar mais conforme necess\u00e1rio\n            }\n        }\n    \n    def process_query(self, user_query: str) -> Dict[str, Any]:\n        \"\"\"\n        Processa pergunta do usu\u00e1rio usando Gemini\n        Retorna resposta estruturada com dados e texto\n        \"\"\"\n        \n        # Detec\u00e7\u00e3o r\u00e1pida de sauda\u00e7\u00f5es (sem usar Gemini)\n        query_lower = user_query.lower()\n        saudacoes = [\"ol\u00e1\", \"oi\", \"ola\", \"hello\", \"boa tarde\", \"bom dia\", \"boa noite\"]\n        \n        if any(saudacao in query_lower for saudacao in saudacoes):\n            return {\n                \"success\": True,\n                \"text\": \"\ud83d\udc4b Ol\u00e1! Sou seu assistente de BI.\\n\\nPosso ajudar com:\\n\u2022 Consultas de pre\u00e7os\\n\u2022 An\u00e1lise de vendas\\n\u2022 Informa\u00e7\u00f5es de produtos\\n\\nFa\u00e7a uma pergunta!\",\n                \"data\": None\n            }\n        \n        # Criar prompt SIMPLIFICADO para Gemini (evitar erro 400)\n        prompt = f\"\"\"Analise esta pergunta sobre dados de vendas e retorne JSON:\n\nPergunta: \"{user_query}\"\n\nColunas dispon\u00edveis: PRODUTO, NOME, UNE, MES_01, MES_02, MES_03\n\nRetorne JSON:\n{{\n  \"produto\": \"c\u00f3digo ou null\",\n  \"une\": \"c\u00f3digo ou null\",\n  \"meses\": [\"MES_01\", \"MES_02\", \"MES_03\"],\n  \"operacao\": \"sum|filter|count\"\n}}\n\nExemplo: \"vendas produto 59294 une 261 \u00faltimos 3 meses\"\n{{\n  \"produto\": \"59294\",\n  \"une\": \"261\",\n  \"meses\": [\"MES_01\", \"MES_02\", \"MES_03\"],\n  \"operacao\": \"sum\"\n}}\n\"\"\"\n        \n        try:\n            # Chamar Gemini\n            response = self.model.generate_content(prompt)\n            response_text = response.text.strip()\n            \n            # Extrair JSON\n            json_match = re.search(r'\\{.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3108, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "56df4def-f334-41fe-a1ef-e6132e2289e6": {"__data__": {"id_": "56df4def-f334-41fe-a1ef-e6132e2289e6", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\intelligent_chatbi.py", "language": "python", "lines": 195, "filename": "intelligent_chatbi.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\intelligent_chatbi.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\intelligent_chatbi.py", "language": "python", "lines": 195, "filename": "intelligent_chatbi.py"}, "hash": "d54dca90dce897c71ca826103532740981e3930d5c0d5ee9683d01677fbf1cee", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "65264fb7-389f-4fff-afb8-9ea43ccfb1dd", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\intelligent_chatbi.py", "language": "python", "lines": 195, "filename": "intelligent_chatbi.py"}, "hash": "66a602e4df644127e9e44369c02a5c796c05ad70541203aecb609a4fcf248cf8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "*\\}', response_text, re.DOTALL)\n            if not json_match:\n                return self._fallback_response(user_query)\n            \n            query_plan = json.loads(json_match.group())\n            \n            # Executar consulta Polars\n            lf = pl.scan_parquet(self.parquet_path)\n            \n            produto = query_plan.get(\"produto\")\n            une = query_plan.get(\"une\")\n            meses = query_plan.get(\"meses\", [\"MES_01\", \"MES_02\", \"MES_03\"])\n            \n            # Construir filtro\n            filters = []\n            if produto:\n                filters.append(pl.col(\"PRODUTO\") == produto)\n            if une:\n                filters.append(pl.col(\"UNE\") == une)\n            \n            # Aplicar filtros\n            if filters:\n                result = lf.filter(pl.all_horizontal(filters)).select([\"PRODUTO\", \"NOME\", \"UNE\"] + meses).head(1).collect()\n            else:\n                result = lf.select(meses).sum().collect()\n            \n            # Formatar resposta\n            if len(result) > 0:\n                row = result.row(0, named=True)\n                \n                if produto and une:\n                    nome = row.get(\"NOME\", \"Produto\")\n                    valores = [row.get(m, 0) for m in meses]\n                    total = sum(valores)\n                    \n                    response_text = f\"\ud83d\udcca **Produto {produto}** na UNE {une}:\\n\\n**Nome:** {nome}\\n\"\n                    for i, mes in enumerate(meses, 1):\n                        response_text += f\"**M\u00eas {i}:** {row.get(mes, 0):,.0f}\\n\"\n                    response_text += f\"\\n**Total:** {total:,.0f}\"\n                else:\n                    total = sum([row.get(m, 0) for m in meses])\n                    response_text = f\"\ud83d\udcc8 **Total de Vendas:** {total:,.0f}\"\n                \n                return {\n                    \"success\": True,\n                    \"text\": response_text,\n                    \"data\": row\n                }\n            \n            return self._fallback_response(user_query)\n            \n        except Exception as e:\n            print(f\"Erro ao processar com Gemini: {e}\")\n            import traceback\n            traceback.print_exc()\n            return self._fallback_response(user_query)\n    \n    def _format_response(self, plan: Dict, result: Any) -> Dict[str, Any]:\n        \"\"\"Formata resposta baseado no template\"\"\"\n        \n        template = plan.get(\"response_template\", \"\")\n        \n        # Extrair dados do resultado Polars\n        if isinstance(result, pl.DataFrame):\n            if len(result) > 0:\n                row = result.row(0, named=True)\n                \n                # Calcular total se houver m\u00faltiplos meses\n                total = sum([v for k, v in row.items() if k.startswith(\"MES_\")])\n                \n                # Substituir placeholders\n                text = template.format(\n                    produto=plan.get(\"produto\", \"\"),\n                    une=plan.get(\"une\", \"\"),\n                    mes_01=row.get(\"MES_01\", 0),\n                    mes_02=row.get(\"MES_02\", 0),\n                    mes_03=row.get(\"MES_03\", 0),\n                    total=total\n                )\n                \n                return {\n                    \"text\": text,\n                    \"data\": row\n                }\n        \n        return {\"text\": str(result)}\n    \n    def _fallback_response(self, query: str) -> Dict[str, Any]:\n        \"\"\"Resposta de fallback quando Gemini falha\"\"\"\n        return {\n            \"success\": False,\n            \"text\": f\"\ud83e\udd14 Desculpe, n\u00e3o consegui processar sua pergunta: '{query}'\\n\\nTente reformular ou use perguntas mais simples como:\\n\u2022 'Qual o pre\u00e7o do produto X?'\\n\u2022 'Vendas do produto X na UNE Y'\",\n            \"data\": None\n        }", "mimetype": "text/plain", "start_char_idx": 3108, "end_char_idx": 6854, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "23ff1bc8-8bbb-4c2f-8901-34cc3266eebf": {"__data__": {"id_": "23ff1bc8-8bbb-4c2f-8901-34cc3266eebf", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\llm_base.py", "language": "python", "lines": 8, "filename": "llm_base.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\llm_base.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\llm_base.py", "language": "python", "lines": 8, "filename": "llm_base.py"}, "hash": "5b370c648ec9201731d517f648e8dbaaea4c596f5e8596d076a9363354932a10", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "from abc import ABC, abstractmethod\n\n\nclass BaseLLMAdapter(ABC):\n    @abstractmethod\n    def get_completion(self, prompt: str) -> str:\n        pass", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 147, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "73e8fe35-2841-443a-8b49-759ef6bde37c": {"__data__": {"id_": "73e8fe35-2841-443a-8b49-759ef6bde37c", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\llm_factory.py", "language": "python", "lines": 88, "filename": "llm_factory.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\llm_factory.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\llm_factory.py", "language": "python", "lines": 88, "filename": "llm_factory.py"}, "hash": "640cdc05ad8982aac2e1cfd32520eac26a8a10375c37db0a29f60d9eac677e0a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nFactory para sele\u00e7\u00e3o autom\u00e1tica de adaptadores LLM.\n\"\"\"\n\nimport logging\nfrom typing import Optional\nfrom app.config.settings import settings\nfrom app.core.llm_base import BaseLLMAdapter\n\n\nclass LLMFactory:\n    \"\"\"Factory pattern para criar adaptadores LLM.\"\"\"\n\n    _instance: Optional[\"LLMFactory\"] = None\n    _adapter: Optional[BaseLLMAdapter] = None\n    _logger = logging.getLogger(__name__)\n\n    def __new__(cls):\n        if cls._instance is None:\n            cls._instance = super().__new__(cls)\n        return cls._instance\n\n    @classmethod\n    def get_adapter(cls) -> BaseLLMAdapter:\n        \"\"\"\n        Obt\u00e9m o adaptador LLM configurado (apenas Gemini).\n\n        Returns:\n            BaseLLMAdapter: Adaptador LLM inicializado\n\n        Raises:\n            ValueError: Se o adaptador Gemini n\u00e3o puder ser inicializado\n        \"\"\"\n        if cls._adapter is not None:\n            return cls._adapter\n\n        factory = cls()\n        cls._logger.info(\"Inicializando adaptador Gemini.\")\n        cls._adapter = factory._get_gemini_adapter()\n\n        if cls._adapter is None:\n            raise ValueError(\n                \"Nenhum adaptador LLM pode ser inicializado. \"\n                \"Verifique as configura\u00e7\u00f5es de GEMINI_API_KEY.\"\n            )\n\n        return cls._adapter\n\n    @staticmethod\n    def _get_gemini_adapter() -> Optional[BaseLLMAdapter]:\n        \"\"\"Tenta inicializar adaptador Gemini.\"\"\"\n        try:\n            from app.core.llm_gemini_adapter import GeminiLLMAdapter\n\n            if not settings.GEMINI_API_KEY:\n                LLMFactory._logger.warning(\"GEMINI_API_KEY n\u00e3o configurada\")\n                return None\n\n            adapter = GeminiLLMAdapter()\n            LLMFactory._logger.info(\"Adaptador Gemini inicializado com sucesso\")\n            return adapter\n\n        except Exception as e:\n            LLMFactory._logger.error(f\"Erro ao inicializar Gemini: {e}\")\n            return None\n\n    @classmethod\n    def reset(cls):\n        \"\"\"Reseta o adaptador cache (\u00fatil para testes).\"\"\"\n        cls._adapter = None\n        cls._logger.info(\"Adaptador LLM resetado\")\n\n    @classmethod\n    def get_available_providers(cls) -> dict:\n        \"\"\"\n        Verifica quais provedores est\u00e3o dispon\u00edveis.\n\n        Returns:\n            dict: {'gemini': bool}\n        \"\"\"\n        providers = {}\n        try:\n            providers[\"gemini\"] = settings.GEMINI_API_KEY is not None\n        except Exception:\n            providers[\"gemini\"] = False\n\n        return providers", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2488, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c830c9da-4199-4468-879e-d54b48f30318": {"__data__": {"id_": "c830c9da-4199-4468-879e-d54b48f30318", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\llm_gemini_adapter.py", "language": "python", "lines": 393, "filename": "llm_gemini_adapter.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\llm_gemini_adapter.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\llm_gemini_adapter.py", "language": "python", "lines": 393, "filename": "llm_gemini_adapter.py"}, "hash": "d06697dc24df2ae1f95261aeb6ee3c6d3fde79d5e8a7ea8cdcffb66a2c2354f1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9c7ad729-e66b-4206-9169-fee6ff3780d0", "node_type": "1", "metadata": {}, "hash": "3910e5ef951c761dbcc69eab49a1f904a0dd4ef3daab476c3a04328448a34be4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "from typing import List, Dict, Any, Optional\nimport logging\nimport threading\nimport time\nfrom queue import Queue\nimport json # Adicionado para json.dumps\nimport os\nfrom app.core.llm_base import BaseLLMAdapter\nfrom app.config.settings import settings\n\nGEMINI_AVAILABLE = False # Assume false until all imports succeed\nLANGCHAIN_GEMINI_AVAILABLE = False\n\ntry:\n    import google.generativeai as genai\n    from google.api_core.exceptions import RetryError, InternalServerError\n    from google.generativeai.types import FunctionDeclaration, Tool\n    GEMINI_AVAILABLE = True\nexcept ImportError as e:\n    print(f\"Erro de importa\u00e7\u00e3o do Gemini: {e}\")\n    FunctionDeclaration = Any # Fallback to avoid NameError\n\n# Disable langchain-google-genai to avoid version conflicts\n# Using native google.generativeai adapter instead\nLANGCHAIN_GEMINI_AVAILABLE = False\n\n\nclass GeminiLLMAdapter(BaseLLMAdapter):\n    \"\"\"\n    Adaptador para Google Gemini API.\n    Implementa padr\u00e3o similar ao OpenAI com retry autom\u00e1tico e tratamento de erros.\n    \"\"\"\n\n    def __init__(self, model_name: Optional[str] = None, gemini_api_key: Optional[str] = None, system_instruction: Optional[str] = None):\n        self.logger = logging.getLogger(__name__)\n\n        if not GEMINI_AVAILABLE:\n            raise ImportError(\n                \"google-generativeai n\u00e3o est\u00e1 instalado. \"\n                \"Execute: pip install google-generativeai\"\n            )\n\n        # Use provided API key or fall back to settings\n        api_key = gemini_api_key or settings.GEMINI_API_KEY\n        if not api_key:\n            raise ValueError(\"GEMINI_API_KEY n\u00e3o configurada no arquivo .env\")\n\n        genai.configure(api_key=api_key)\n        self.gemini_api_key = api_key\n\n        # Use provided model name or fall back to settings (which loads from .env)\n        self.model_name = model_name or settings.LLM_MODEL_NAME or \"gemini-3-flash-preview\"\n        self.max_retries = 3  # \u2705 Increased to 3 attempts\n        self.retry_delay = 0.5  # \u2705 500ms entre tentativas\n\n        # Store configurable system instruction (default None)\n        self.system_instruction = system_instruction\n\n        self.logger.info(f\"Gemini adapter inicializado com modelo: {self.model_name}\")\n\n    async def generate_response(self, prompt: str) -> str:\n        \"\"\"\n        Gera uma resposta de texto simples para um prompt dado.\n        Wrapper para get_completion para compatibilidade com insights.py.\n        \"\"\"\n        messages = [{\"role\": \"user\", \"content\": prompt}]\n        result = self.get_completion(messages)\n        \n        if \"error\" in result:\n            raise Exception(result[\"error\"])\n            \n        return result.get(\"content\", \"\")\n\n    def get_llm(self):\n        \"\"\"\n        Returns a LangChain-compatible ChatGoogleGenerativeAI instance.\n        This method is required by chat.py endpoint for agent initialization.\n        Falls back to self if langchain-google-genai is not available.\n        \"\"\"\n        if not LANGCHAIN_GEMINI_AVAILABLE:\n            self.logger.info(\"LangChain Google GenAI nao disponivel - usando adapter nativo\")\n            # Return self as fallback - the adapter itself can be used as an LLM\n            return self\n\n        try:\n            return ChatGoogleGenerativeAI(\n                model=self.model_name,\n                google_api_key=self.gemini_api_key,\n                temperature=0.0,\n                max_retries=self.max_retries\n            )\n        except Exception as e:\n            self.logger.error(f\"Erro ao criar ChatGoogleGenerativeAI: {e}\")\n            self.logger.info(f\"Erro ao criar ChatGoogleGenerativeAI: {e} - usando adapter nativo\")\n            return self\n\n    def invoke(self, input: Any, config: Optional[Dict] = None) -> Any:\n        \"\"\"\n        Implementation of the LangChain Runnable invoke protocol.\n        Allows the adapter to be used directly in LangChain sequences.\n        \"\"\"", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3891, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9c7ad729-e66b-4206-9169-fee6ff3780d0": {"__data__": {"id_": "9c7ad729-e66b-4206-9169-fee6ff3780d0", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\llm_gemini_adapter.py", "language": "python", "lines": 393, "filename": "llm_gemini_adapter.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\llm_gemini_adapter.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\llm_gemini_adapter.py", "language": "python", "lines": 393, "filename": "llm_gemini_adapter.py"}, "hash": "d06697dc24df2ae1f95261aeb6ee3c6d3fde79d5e8a7ea8cdcffb66a2c2354f1", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c830c9da-4199-4468-879e-d54b48f30318", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\llm_gemini_adapter.py", "language": "python", "lines": 393, "filename": "llm_gemini_adapter.py"}, "hash": "cc00aeefd7fe0ef02d8a498559a427c8c2c78d5939024a6d3708a305c68eec0e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4edce7b2-f4dd-4e94-9742-02aa6b759f21", "node_type": "1", "metadata": {}, "hash": "8c3431e6be75225c5a9abc4315d615904db1bf2170afeefd4006e1684d9a31c2", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Allows the adapter to be used directly in LangChain sequences.\n        \"\"\"\n        from langchain_core.messages import AIMessage, HumanMessage, SystemMessage, BaseMessage\n        from langchain_core.prompt_values import ChatPromptValue\n\n        messages = []\n        if isinstance(input, ChatPromptValue):\n            messages = input.to_messages()\n        elif isinstance(input, list):\n            messages = input\n        elif isinstance(input, str):\n            messages = [HumanMessage(content=input)]\n        \n        # Convert LangChain messages to the dict format expected by _convert_messages\n        adapter_messages = []\n        for msg in messages:\n            role = \"user\"\n            if isinstance(msg, AIMessage):\n                role = \"model\"\n            elif isinstance(msg, SystemMessage):\n                role = \"user\" \n            elif isinstance(msg, HumanMessage):\n                role = \"user\"\n            \n            content = msg.content if hasattr(msg, \"content\") else str(msg)\n            adapter_messages.append({\"role\": role, \"content\": content})\n\n        # Call get_completion\n        result = self.get_completion(adapter_messages)\n        \n        if \"error\" in result:\n             # Log the error but try to return it as text if possible, or raise\n             self.logger.error(f\"Error in invoke: {result['error']}\")\n             raise ValueError(result[\"error\"])\n             \n        return AIMessage(content=result.get(\"content\", \"\"))\n\n    def get_completion(\n        self,\n        messages: List[Dict[str, str]],\n        tools: Optional[Dict[str, List[Dict[str, Any]]]] = None, # Alterado aqui\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Obt\u00e9m completion da API Gemini com retry autom\u00e1tico.\n\n        Args:\n            messages: Lista de mensagens no formato OpenAI-like\n            tools: Dicion\u00e1rio opcional de ferramentas no formato Gemini (com 'function_declarations')\n\n        Returns:\n            Dicion\u00e1rio com resultado ou erro\n        \"\"\"\n        for attempt in range(self.max_retries):\n            try:\n                q = Queue()\n\n                def worker():\n                    try:\n                        gemini_messages = self._convert_messages(messages)\n                        \n                        if tools:\n                            gemini_tools = self._convert_tools(tools)\n                        else:\n                            gemini_tools = []\n\n                        # \u2705 Configura\u00e7\u00e3o otimizada para Gemini 3 Flash + BI (precis\u00e3o m\u00e1xima)\n                        # Ref: https://georgian.io/reduce-llm-costs-and-latency-guide/\n                        generation_config = genai.GenerationConfig(\n                            temperature=0.1,  # Baixo para precis\u00e3o em BI (function calling determin\u00edstico)\n                            top_p=0.9,       # Reduzido para respostas mais determin\u00edsticas\n                            top_k=20,        # Reduzido para menos variabilidade\n                            max_output_tokens=4096,  # Reduzido (gr\u00e1ficos retornam JSON pequeno)\n                        )\n\n                        # \u2705 FIX: Configurar tool_config para que o Gemini PREFIRA usar ferramentas\n                        # Quando tools est\u00e3o dispon\u00edveis, o modelo deve considerar us\u00e1-las SEMPRE\n                        tool_config = None\n                        if gemini_tools:\n                            tool_config = {\n                                \"function_calling_config\": {\n                                    \"mode\": \"AUTO\"  # AUTO com system prompt forte funciona melhor que ANY\n                                }\n                            }\n\n                        model = genai.GenerativeModel(\n                            model_name=self.model_name,\n                            tools=gemini_tools if gemini_tools else None,\n                            tool_config=tool_config,\n                            generation_config=generation_config,\n                            # Use configurable system instruction (set during __init__)\n                            system_instruction=self.system_instruction\n                        )\n\n                        # \u2705 FIX CR\u00cdTICO: Usar generate_content com contents completos\n                        # Em vez de start_chat, para preservar thought_signatures corretamente\n                        # Ref: https://ai.google.dev/gemini-api/docs/thought-signatures\n                        # O SDK gerencia thought_signatures automaticamente quando usamos generate_content\n                        self.logger.info(\n                            f\"Chamada Gemini (tentativa {attempt + 1}/\"\n                            f\"{self.max_retries}) - Gemini 3 Flash com thought signatures\"\n                        )\n\n                        response = model.generate_content(\n                            contents=gemini_messages,\n                            request_options={\"timeout\": 15}\n                        )\n\n                        self.logger.info(\"Chamada Gemini conclu\u00edda.\")", "mimetype": "text/plain", "start_char_idx": 3817, "end_char_idx": 8813, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4edce7b2-f4dd-4e94-9742-02aa6b759f21": {"__data__": {"id_": "4edce7b2-f4dd-4e94-9742-02aa6b759f21", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\llm_gemini_adapter.py", "language": "python", "lines": 393, "filename": "llm_gemini_adapter.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\llm_gemini_adapter.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\llm_gemini_adapter.py", "language": "python", "lines": 393, "filename": "llm_gemini_adapter.py"}, "hash": "d06697dc24df2ae1f95261aeb6ee3c6d3fde79d5e8a7ea8cdcffb66a2c2354f1", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9c7ad729-e66b-4206-9169-fee6ff3780d0", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\llm_gemini_adapter.py", "language": "python", "lines": 393, "filename": "llm_gemini_adapter.py"}, "hash": "24a8e8c71b9ca223471f048e1e7381c9e0f6e23633a1873b1d6dbdc58f06e260", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "91e58a52-b4a0-4234-893c-1c1442345eba", "node_type": "1", "metadata": {}, "hash": "e2a515bdae44dd5036b3f2867446b33841f0c7da443dd34957e017db46a995f5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "tool_calls = []\n                        content = \"\"\n                        \n                        if response.candidates:\n                            candidate = response.candidates[0]\n                            if candidate.content and candidate.content.parts:\n                                for part in candidate.content.parts:\n                                    if part.function_call:\n                                        function_call = part.function_call\n                                        tool_call = {\n                                            \"id\": f\"call_{function_call.name}\", # Gemini doesn't provide an ID, so we generate one\n                                            \"function\": {\n                                                \"arguments\": json.dumps(dict(function_call.args)),\n                                                \"name\": function_call.name,\n                                            },\n                                            \"type\": \"function\",\n                                        }\n\n                                        # CR\u00cdTICO: Capturar thought_signature do Gemini 3\n                                        # Thought signatures s\u00e3o OBRIGAT\u00d3RIAS no Gemini 3 para function calling\n                                        # Ref: https://ai.google.dev/gemini-api/docs/thought-signatures\n                                        if hasattr(part, 'thought_signature') and part.thought_signature:\n                                            tool_call[\"thought_signature\"] = part.thought_signature\n                                            self.logger.info(f\"\u2705 Thought signature capturado para {function_call.name}\")\n\n                                        tool_calls.append(tool_call)\n                                        # Se h\u00e1 tool_call, o conte\u00fado textual deve ser vazio\n                                        content = \"\"\n                                        break # Only handle the first function call for now\n                                    elif part.text:\n                                        content = part.text\n                                        break # Only handle the first text part for now\n                        \n                        result = {\"content\": content}\n                        if tool_calls:\n                            result[\"tool_calls\"] = tool_calls\n                        \n                        q.put(result)\n\n                    except Exception as e:\n                        error_msg = str(e).lower()\n\n                        retentable = any(\n                            [\n                                \"quota\" in error_msg,\n                                \"rate\" in error_msg,\n                                \"timeout\" in error_msg,\n                                \"500\" in error_msg,\n                                \"503\" in error_msg,\n                                \"429\" in error_msg,\n                            ]\n                        )\n\n                        self.logger.warning(\n                            f\"Erro Gemini na tentativa {attempt + 1}: {e} \"\n                            f\"(retent\u00e1vel: {retentable})\"\n                        )\n\n                        q.put({\"error\": f\"Erro: {e}\", \"retry\": retentable})\n\n                thread = threading.Thread(target=worker)\n                thread.start()\n                thread.join(timeout=15.0)  # \u2705 Gemini 3 Flash \u00e9 2x mais r\u00e1pido que 1.5\n\n                if thread.is_alive():\n                    self.logger.warning(f\"Thread timeout tentativa {attempt + 1}\")\n                    continue\n\n                result = q.get()\n\n                if \"error\" not in result:\n                    return result\n\n                if result.get(\"retry\") and (attempt < self.max_retries - 1):\n                    delay = self.retry_delay * (2**attempt)\n                    self.logger.info(\n                        f\"Aguardando {delay}s antes da pr\u00f3xima tentativa...\"\n                    )\n                    time.sleep(delay)\n                    continue\n\n                return result\n\n            except Exception as e:\n                self.logger.error(\n                    f\"Erro externo tentativa {attempt + 1}: {e}\", exc_info=True\n                )\n                if attempt < self.max_retries - 1:\n                    delay = self.retry_delay * (2**attempt)\n                    time.sleep(delay)\n                    continue\n                return {\"error\": f\"Erro ap\u00f3s {self.max_retries} tentativas: {e}\"}\n\n        return {\"error\": f\"Falha ap\u00f3s {self.max_retries} tentativas\"}\n\n    def _convert_messages(self, messages: List[Dict[str, str]]) -> List[Dict[str, Any]]:\n        \"\"\"\n        Converte mensagens do formato OpenAI-like para formato Gemini.", "mimetype": "text/plain", "start_char_idx": 8839, "end_char_idx": 13574, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "91e58a52-b4a0-4234-893c-1c1442345eba": {"__data__": {"id_": "91e58a52-b4a0-4234-893c-1c1442345eba", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\llm_gemini_adapter.py", "language": "python", "lines": 393, "filename": "llm_gemini_adapter.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\llm_gemini_adapter.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\llm_gemini_adapter.py", "language": "python", "lines": 393, "filename": "llm_gemini_adapter.py"}, "hash": "d06697dc24df2ae1f95261aeb6ee3c6d3fde79d5e8a7ea8cdcffb66a2c2354f1", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4edce7b2-f4dd-4e94-9742-02aa6b759f21", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\llm_gemini_adapter.py", "language": "python", "lines": 393, "filename": "llm_gemini_adapter.py"}, "hash": "04f15cce2c0d0c1ffacf88a10ec6bcffa958d58d1e2699c939d6039050a165a1", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Formato OpenAI-like: [{\"role\": \"user\", \"content\": \"...\"}]\n        Formato Gemini: [{\"role\": \"user\", \"parts\": [{\"text\": \"...\"}]}]\n        \"\"\"\n        gemini_messages = []\n\n        for msg in messages:\n            role = msg.get(\"role\", \"user\")\n            content = msg.get(\"content\", \"\")\n            tool_calls = msg.get(\"tool_calls\")\n            function_call = msg.get(\"function_call\")\n\n            # Determine Gemini role based on actual content and OpenAI-like role\n            # IMPORTANT: Check for tool_calls and function_call FIRST, before checking role\n            if tool_calls:\n                # Model's turn: calls a tool\n                parts = []\n                for tc in tool_calls:\n                    part = {\n                        \"function_call\": {\n                            \"name\": tc[\"function\"][\"name\"],\n                            \"args\": json.loads(tc[\"function\"][\"arguments\"])\n                        }\n                    }\n\n                    # CR\u00cdTICO: Preservar thought_signature (obrigat\u00f3rio no Gemini 3)\n                    # Sem thought_signature = erro 400 + degrada\u00e7\u00e3o de performance\n                    # Ref: https://ai.google.dev/gemini-api/docs/thought-signatures\n                    if \"thought_signature\" in tc and tc[\"thought_signature\"]:\n                        part[\"thought_signature\"] = tc[\"thought_signature\"]\n                        self.logger.info(f\"\u2705 Thought signature preservado para {tc['function']['name']}\")\n\n                    parts.append(part)\n\n                gemini_msg = {\n                    \"role\": \"model\",\n                    \"parts\": parts\n                }\n            elif function_call:\n                # User's turn: provides tool response\n                # This handles both explicit \"function\"/\"tool\" roles AND cases where\n                # LangChain sends \"user\" role with function_call metadata\n                gemini_msg = {\n                    \"role\": \"user\",\n                    \"parts\": [\n                        {\n                            \"function_response\": {\n                                \"name\": function_call[\"name\"],\n                                \"response\": {\"content\": content}\n                            }\n                        }\n                    ]\n                }\n            elif role == \"user\":\n                gemini_msg = {\"role\": \"user\", \"parts\": [{\"text\": content}]}\n            elif role == \"assistant\" or role == \"model\":\n                gemini_msg = {\"role\": \"model\", \"parts\": [{\"text\": content}]}\n            else: # Fallback for unexpected roles, treat as user to avoid errors\n                self.logger.warning(f\"Unexpected role encountered: {role}. Treating as 'user'.\")\n                gemini_msg = {\"role\": \"user\", \"parts\": [{\"text\": content}]}\n\n            gemini_messages.append(gemini_msg)\n\n        return gemini_messages\n\n    def _convert_tools(self, tools_wrapper: Dict[str, List[Dict[str, Any]]]) -> List['Tool']:\n        \"\"\"\n        Converte ferramentas do formato OpenAI-like (agora encapsulado em 'function_declarations')\n        para Gemini Tool Format.\n        \"\"\"\n        gemini_tools = []\n\n        # Extract the list of function declarations from the wrapper dictionary\n        function_declarations = tools_wrapper.get(\"function_declarations\", [])\n\n        for tool_declaration in function_declarations:\n            # Each tool_declaration is already in the format expected by FunctionDeclaration\n            # e.g., {\"name\": \"tool_name\", \"description\": \"...\", \"parameters\": {...}}\n            gemini_tool = FunctionDeclaration(\n                name=tool_declaration.get(\"name\", \"\"),\n                description=tool_declaration.get(\"description\", \"\"),\n                parameters=tool_declaration.get(\"parameters\", {}),\n            )\n            gemini_tools.append(gemini_tool)\n\n        return [Tool(function_declarations=gemini_tools)]", "mimetype": "text/plain", "start_char_idx": 13584, "end_char_idx": 17461, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5ddeeda6-58a7-4f49-a73d-a242b805006b": {"__data__": {"id_": "5ddeeda6-58a7-4f49-a73d-a242b805006b", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\llm_gemini_adapter_v2.py", "language": "python", "lines": 276, "filename": "llm_gemini_adapter_v2.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\llm_gemini_adapter_v2.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\llm_gemini_adapter_v2.py", "language": "python", "lines": 276, "filename": "llm_gemini_adapter_v2.py"}, "hash": "9d5fa29ea6c43a3f61a3d5af91adf0e3988b98de98c92478808ea4cd62126550", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "24002163-0b97-45a5-afc8-b17d0d962528", "node_type": "1", "metadata": {}, "hash": "ad2fcbe911227eed672fa1f3d00cb2b9ca2f0c56d20b5ee859df9e0fa025817a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nGeminiLLMAdapter V2 - Usando objetos nativos do SDK\nSOLU\u00c7\u00c3O PARA THOUGHT SIGNATURES - Usar Content/Part nativos em vez de dicion\u00e1rios\n\"\"\"\n\nfrom typing import List, Dict, Any, Optional\nimport logging\nimport json\nimport os\nimport google.generativeai as genai\nfrom google.generativeai.protos import Content, Part, FunctionCall, FunctionResponse\nfrom app.core.llm_base import BaseLLMAdapter\nfrom app.config.settings import settings\n\nlogger = logging.getLogger(__name__)\n\n\ndef _convert_to_serializable(obj):\n    \"\"\"\n    Converte recursivamente objetos Protobuf (MapComposite, RepeatedComposite) \n    para tipos Python nativos (dict, list).\n    \n    CR\u00cdTICO: Esta fun\u00e7\u00e3o resolve o erro \"Object of type MapComposite is not JSON serializable\"\n    que ocorre quando a API Gemini retorna objetos especiais em function_call.args.\n    \"\"\"\n    # MapComposite (dict-like do Protobuf)\n    if hasattr(obj, 'keys') and callable(getattr(obj, 'keys')):\n        return {k: _convert_to_serializable(v) for k, v in obj.items()}\n    \n    # RepeatedComposite (list-like do Protobuf)\n    elif hasattr(obj, '__iter__') and not isinstance(obj, (str, bytes)):\n        try:\n            return [_convert_to_serializable(item) for item in obj]\n        except TypeError:\n            # N\u00e3o \u00e9 iter\u00e1vel de fato\n            pass\n    \n    # Tipos primitivos - retornar como est\u00e1\n    if isinstance(obj, (str, int, float, bool, type(None))):\n        return obj\n    \n    # Fallback: tentar converter para string\n    return str(obj)", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1495, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "24002163-0b97-45a5-afc8-b17d0d962528": {"__data__": {"id_": "24002163-0b97-45a5-afc8-b17d0d962528", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\llm_gemini_adapter_v2.py", "language": "python", "lines": 276, "filename": "llm_gemini_adapter_v2.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\llm_gemini_adapter_v2.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\llm_gemini_adapter_v2.py", "language": "python", "lines": 276, "filename": "llm_gemini_adapter_v2.py"}, "hash": "9d5fa29ea6c43a3f61a3d5af91adf0e3988b98de98c92478808ea4cd62126550", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5ddeeda6-58a7-4f49-a73d-a242b805006b", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\llm_gemini_adapter_v2.py", "language": "python", "lines": 276, "filename": "llm_gemini_adapter_v2.py"}, "hash": "46e41eec3773ae5aa6c43deec16b7da8906a4cc16ae5890452b066217fbb2537", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "cf4bdbbf-4b76-46a5-ad26-579a59339ae8", "node_type": "1", "metadata": {}, "hash": "300303e9ddf20605959b5f41a6ad5d8ea00c1228a68eb3e29face8aea6373784", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "class GeminiLLMAdapterV2(BaseLLMAdapter):\n    \"\"\"\n    Adapter usando OBJETOS NATIVOS do SDK para preservar thought_signatures automaticamente\n    \"\"\"\n\n    def __init__(self, model_name: Optional[str] = None, gemini_api_key: Optional[str] = None, system_instruction: Optional[str] = None):\n        self.logger = logging.getLogger(__name__)\n\n        api_key = gemini_api_key or settings.GEMINI_API_KEY\n        if not api_key:\n            raise ValueError(\"GEMINI_API_KEY n\u00e3o configurada\")\n\n        genai.configure(api_key=api_key)\n        self.model_name = model_name or settings.LLM_MODEL_NAME or \"gemini-3-flash-preview\"\n        self.system_instruction = system_instruction\n        self.max_retries = 3\n\n        self.logger.info(f\"[OK] GeminiLLMAdapterV2 inicializado: {self.model_name}\")\n\n    def get_completion(\n        self,\n        messages: List[Dict[str, str]],\n        tools: Optional[Dict[str, List[Dict[str, Any]]]] = None,\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Obt\u00e9m completion usando objetos NATIVOS do SDK (Content/Part)\n        Isso garante que thought_signatures sejam preservados automaticamente\n        \"\"\"\n        try:\n            # Converter ferramentas para formato Gemini\n            gemini_tools = []\n            if tools:\n                gemini_tools = self._convert_tools(tools)\n\n            # Configura\u00e7\u00e3o de gera\u00e7\u00e3o\n            generation_config = genai.GenerationConfig(\n                temperature=0.1,\n                top_p=0.9,\n                top_k=20,\n                max_output_tokens=4096,\n            )\n\n            tool_config = None\n            if gemini_tools:\n                tool_config = {\n                    \"function_calling_config\": {\n                        \"mode\": \"AUTO\"\n                    }\n                }\n\n            # Criar modelo\n            model = genai.GenerativeModel(\n                model_name=self.model_name,\n                tools=gemini_tools if gemini_tools else None,\n                tool_config=tool_config,\n                generation_config=generation_config,\n                system_instruction=self.system_instruction\n            )\n\n            # [OK] CRITICAL: Converter mensagens para objetos NATIVOS Content/Part\n            contents = self._messages_to_contents(messages)\n\n            self.logger.info(f\"[SEND] Enviando {len(contents)} contents para Gemini\")\n            for i, content in enumerate(contents):\n                self.logger.info(f\"  Content {i}: role={content.role}, parts={len(content.parts)}\")\n\n            # Chamar generate_content com objetos nativos\n            response = model.generate_content(\n                contents=contents,\n                request_options={\"timeout\": 15}\n            )\n\n            self.logger.info(\"[RCV] Resposta recebida do Gemini\")\n\n            # Processar resposta\n            tool_calls = []\n            content = \"\"\n\n            if response.candidates:\n                candidate = response.candidates[0]\n                if candidate.content and candidate.content.parts:\n                    for part in candidate.content.parts:\n                        if part.function_call:\n                            # [OK] Armazenar o Part INTEIRO (inclui thought_signature automaticamente)\n                            tool_calls.append({\n                                \"id\": f\"call_{part.function_call.name}\",\n                                \"function\": {\n                                    \"name\": part.function_call.name,\n                                    # CR\u00cdTICO: Usar _convert_to_serializable para evitar erro \"MapComposite is not JSON serializable\"\n                                    \"arguments\": json.dumps(_convert_to_serializable(part.function_call.args)),\n                                },\n                                \"type\": \"function\",\n                                \"_native_part\": part  # [OK] Guardar Part nativo\n                            })\n                            self.logger.info(f\"[CALL] Function call: {part.function_call.name}\")\n                            if hasattr(part, 'thought_signature') and part.thought_signature:\n                                self.logger.info(f\"[THOUGHT] Thought signature presente ({len(part.thought_signature)} bytes)\")\n                        elif part.text:\n                            content = part.text\n\n            result = {\"content\": content}\n            if tool_calls:\n                result[\"tool_calls\"] = tool_calls\n\n            return result\n\n        except Exception as e:\n            self.logger.error(f\"[ERR] Erro ao chamar Gemini: {e}\", exc_info=True)\n            return {\"error\": str(e)}\n\n    def _messages_to_contents(self, messages: List[Dict[str, str]]) -> List[Content]:\n        \"\"\"\n        Converte mensagens do formato OpenAI-like para objetos NATIVOS Content/Part do Gemini.\n        Lida com a persist\u00eancia de hist\u00f3rico: se um tool call antigo n\u00e3o tiver _native_part\n        (porque veio do banco de dados/JSON), ele deve ser removido para evitar Erro 400 (missing thought_signature).\n        \"\"\"", "mimetype": "text/plain", "start_char_idx": 1498, "end_char_idx": 6508, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "cf4bdbbf-4b76-46a5-ad26-579a59339ae8": {"__data__": {"id_": "cf4bdbbf-4b76-46a5-ad26-579a59339ae8", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\llm_gemini_adapter_v2.py", "language": "python", "lines": 276, "filename": "llm_gemini_adapter_v2.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\llm_gemini_adapter_v2.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\llm_gemini_adapter_v2.py", "language": "python", "lines": 276, "filename": "llm_gemini_adapter_v2.py"}, "hash": "9d5fa29ea6c43a3f61a3d5af91adf0e3988b98de98c92478808ea4cd62126550", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "24002163-0b97-45a5-afc8-b17d0d962528", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\llm_gemini_adapter_v2.py", "language": "python", "lines": 276, "filename": "llm_gemini_adapter_v2.py"}, "hash": "1c9fc59abbbeff5f437d23604eb8cd4731ad6e138e07b6b556b921075f4bfe09", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "contents = []\n        last_content_was_tool_call = False\n\n        for msg in messages:\n            role = msg.get(\"role\", \"user\")\n            content_text = msg.get(\"content\", \"\")\n            tool_calls = msg.get(\"tool_calls\")\n            function_call_meta = msg.get(\"function_call\")\n\n            # Mapear role\n            gemini_role = \"model\" if role in [\"assistant\", \"model\"] else \"user\"\n\n            # 1. Se tiver tool_calls (modelo chamando fun\u00e7\u00e3o)\n            if tool_calls:\n                parts = []\n                has_native = False\n                for tc in tool_calls:\n                    # [OK] CRITICAL: Usar Part nativo se dispon\u00edvel\n                    if \"_native_part\" in tc:\n                        parts.append(tc[\"_native_part\"])\n                        self.logger.info(f\"[OK] Reusando Part nativo com thought_signature\")\n                        has_native = True\n                    else:\n                        # Se n\u00e3o tem native part (veio do hist\u00f3rico JSON), N\u00c3O podemos usar.\n                        # Gemini 3.0+ exige thought_signature. Sem ele = Erro 400.\n                        # Melhor dropar esse turno do hist\u00f3rico do que falhar.\n                        pass\n\n                if has_native:\n                    contents.append(Content(role=\"model\", parts=parts))\n                    last_content_was_tool_call = True\n                else:\n                    self.logger.warning(f\"[WARN] Dropando tool call do historico sem assinatura (evita Erro 400)\")\n                    last_content_was_tool_call = False # Marcamos que pulamos, para pular a resposta tamb\u00e9m\n\n            # 2. Se tiver function response (usu\u00e1rio respondendo com resultado da fun\u00e7\u00e3o)\n            elif function_call_meta:\n                # S\u00f3 adicionamos a resposta se a chamada anterior foi mantida.\n                # Gemini exige par Call -> Response.\n                if last_content_was_tool_call:\n                    func_name = function_call_meta.get(\"name\")\n                    parts = [\n                        Part(function_response=FunctionResponse(\n                            name=func_name,\n                            response={\"content\": content_text}\n                        ))\n                    ]\n                    contents.append(Content(role=\"user\", parts=parts))\n                    last_content_was_tool_call = False # Reset para pr\u00f3ximo ciclo\n                else:\n                    self.logger.warning(f\"[WARN] Dropando resposta de funcao orfa do historico (evita confusao do modelo)\")\n                    last_content_was_tool_call = False\n\n            # 3. Mensagem de texto normal\n            elif role != \"system\":  # Filtrar system\n                parts = [Part(text=content_text)]\n                contents.append(Content(role=gemini_role, parts=parts))\n                last_content_was_tool_call = False\n\n        return contents\n\n    def _convert_tools(self, tools_wrapper: Dict[str, List[Dict[str, Any]]]) -> List:\n        \"\"\"Converte ferramentas para formato Gemini\"\"\"\n        from google.generativeai.types import FunctionDeclaration, Tool\n\n        function_declarations = tools_wrapper.get(\"function_declarations\", [])\n        gemini_tools = []\n\n        for tool_declaration in function_declarations:\n            gemini_tool = FunctionDeclaration(\n                name=tool_declaration.get(\"name\", \"\"),\n                description=tool_declaration.get(\"description\", \"\"),\n                parameters=tool_declaration.get(\"parameters\", {}),\n            )\n            gemini_tools.append(gemini_tool)\n\n        return [Tool(function_declarations=gemini_tools)]\n\n    def get_llm(self):\n        \"\"\"Retorna self para compatibilidade\"\"\"\n        return self\n\n    def invoke(self, input: Any, config: Optional[Dict] = None) -> Any:\n        \"\"\"Implementation of LangChain Runnable protocol\"\"\"\n        from langchain_core.messages import AIMessage, HumanMessage\n\n        if isinstance(input, str):\n            messages = [{\"role\": \"user\", \"content\": input}]\n        elif isinstance(input, list):\n            # Converter LangChain messages\n            messages = []\n            for msg in input:\n                if hasattr(msg, 'content'):\n                    role = \"user\" if isinstance(msg, HumanMessage) else \"model\"\n                    messages.append({\"role\": role, \"content\": msg.content})\n        else:\n            messages = [{\"role\": \"user\", \"content\": str(input)}]\n\n        result = self.get_completion(messages)\n\n        if \"error\" in result:\n            raise ValueError(result[\"error\"])\n\n        return AIMessage(content=result.get(\"content\", \"\"))\n\n    async def generate_response(self, prompt: str) -> str:\n        \"\"\"Wrapper para compatibilidade\"\"\"\n        messages = [{\"role\": \"user\", \"content\": prompt}]\n        result = self.get_completion(messages)\n\n        if \"error\" in result:\n            raise Exception(result[\"error\"])\n\n        return result.get(\"content\", \"\")", "mimetype": "text/plain", "start_char_idx": 6517, "end_char_idx": 11433, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "3502d494-611d-4d04-a04a-db3c6ad9803c": {"__data__": {"id_": "3502d494-611d-4d04-a04a-db3c6ad9803c", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\llm_langchain_adapter.py", "language": "python", "lines": 294, "filename": "llm_langchain_adapter.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\llm_langchain_adapter.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\llm_langchain_adapter.py", "language": "python", "lines": 294, "filename": "llm_langchain_adapter.py"}, "hash": "f2b4601f3df3837beb8060dc7bdadf04ea6f5d127386677608146fbba6ab973f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a775e479-8542-4ec8-9fb6-998e9899ac27", "node_type": "1", "metadata": {}, "hash": "6fb72c19fab7314ce26a5247b08ec2d0c76dce4cdba41beb736e9387583c6fb0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# core/llm_langchain_adapter.py\nfrom typing import Any, List, Optional, Dict\nimport json\nimport logging\n\nfrom app.core.llm_base import BaseLLMAdapter\n\nlogger = logging.getLogger(__name__)\n\nLANGCHAIN_AVAILABLE = False\ntry:\n    from langchain_core.callbacks import CallbackManagerForLLMRun\n    from langchain_core.language_models import BaseChatModel\n    from langchain_core.messages import (\n        BaseMessage,\n        AIMessage,\n        HumanMessage,\n        SystemMessage,\n        FunctionMessage,\n        ToolMessage,\n        ToolCall,\n        AIMessageChunk,\n    )\n    from langchain_core.outputs import (\n        ChatResult,\n        ChatGeneration,\n        ChatGenerationChunk,\n    )\n    LANGCHAIN_AVAILABLE = True\nexcept (ImportError, OSError):\n    # Dummy classes for safe import\n    BaseChatModel = object\n    CallbackManagerForLLMRun = Any\n    BaseMessage = Any\n    ChatResult = Any\n    logger.warning(\"LangChain dependencies missing. CustomLangChainLLM will be disabled.\")\n\n\ndef _clean_json_schema(schema: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Remove a chave 'anyOf' de um dicion\u00e1rio JSON Schema, recursivamente.\n    A API Gemini n\u00e3o suporta 'anyOf' diretamente.\n    \"\"\"\n    cleaned_schema = {}\n    for key, value in schema.items():\n        if key == \"anyOf\":\n            # Ignorar 'anyOf' completamente\n            continue\n        elif isinstance(value, dict):\n            cleaned_schema[key] = _clean_json_schema(value)\n        elif isinstance(value, list):\n            cleaned_list = []\n            for item in value:\n                if isinstance(item, dict):\n                    cleaned_list.append(_clean_json_schema(item))\n                else:\n                    cleaned_list.append(item)\n            cleaned_schema[key] = cleaned_list\n        else:\n            cleaned_schema[key] = value\n    return cleaned_schema\n\n\nclass CustomLangChainLLM(BaseChatModel):\n    llm_adapter: BaseLLMAdapter\n    tools: Optional[List[Any]] = None # Adicionado para permitir o campo 'tools'\n\n    @property\n    def _llm_type(self) -> str:\n        return \"custom_llm\"\n\n    def __init__(self, llm_adapter: BaseLLMAdapter, **kwargs: Any):\n        if not LANGCHAIN_AVAILABLE:\n            raise ImportError(\"LangChain is not available.\")\n        super().__init__(llm_adapter=llm_adapter, **kwargs)\n\n    def bind_tools(\n        self,\n        tools: List[Any],\n        **kwargs: Any,\n    ) -> \"CustomLangChainLLM\":\n        \"\"\"Bind tools to the model.\"\"\"\n        if not LANGCHAIN_AVAILABLE:\n             raise ImportError(\"LangChain is not available.\")\n             \n        new_instance = self.__class__(llm_adapter=self.llm_adapter, **kwargs)\n        new_instance.tools = tools  # Store tools for _generate to access\n        return new_instance\n\n    def _generate(\n        self,\n        messages: List[BaseMessage],\n        stop: Optional[List[str]] = None,\n        run_manager: Optional[CallbackManagerForLLMRun] = None,\n        **kwargs: Any,\n    ) -> ChatResult:\n        if not LANGCHAIN_AVAILABLE:\n             raise ImportError(\"LangChain is not available.\")\n\n        # Convert LangChain messages to a generic dictionary format\n        # that GeminiLLMAdapter can understand (similar to OpenAI-like format)\n        generic_messages = []\n        for msg in messages:\n            if isinstance(msg, HumanMessage):\n                generic_messages.append({\"role\": \"user\", \"content\": msg.content})\n            elif isinstance(msg, AIMessage):\n                if msg.tool_calls:\n                    processed_tool_calls = []\n                    for tc in msg.tool_calls:\n                        tc_dict = tc if isinstance(tc, dict) else tc.dict()\n                        processed_tool_calls.append({\n                            \"id\": tc_dict.get(\"id\"),\n                            \"type\": \"function\",\n                            \"function\": {\n                                \"name\": tc_dict.get(\"name\"),\n                                \"arguments\": json.dumps(tc_dict.get(\"args\", {})),\n                            },\n                        })\n                    generic_messages.append(\n                        {\n                            \"role\": \"model\",\n                            \"content\": msg.content,\n                            \"tool_calls\": processed_tool_calls,\n                        }\n                    )\n                else:\n                    generic_messages.append(\n                        {\"role\": \"model\", \"content\": msg.content}\n                    )\n            elif isinstance(msg, SystemMessage):\n                # Treat SystemMessage as a user message for Gemini\n                generic_messages.append({\"role\": \"user\", \"content\": msg.content})\n            elif isinstance(msg,", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4714, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a775e479-8542-4ec8-9fb6-998e9899ac27": {"__data__": {"id_": "a775e479-8542-4ec8-9fb6-998e9899ac27", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\llm_langchain_adapter.py", "language": "python", "lines": 294, "filename": "llm_langchain_adapter.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\llm_langchain_adapter.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\llm_langchain_adapter.py", "language": "python", "lines": 294, "filename": "llm_langchain_adapter.py"}, "hash": "f2b4601f3df3837beb8060dc7bdadf04ea6f5d127386677608146fbba6ab973f", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3502d494-611d-4d04-a04a-db3c6ad9803c", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\llm_langchain_adapter.py", "language": "python", "lines": 294, "filename": "llm_langchain_adapter.py"}, "hash": "556886f0c6a57df9530ea499a024f52639784989e84e17aa53a3771d17a0acc6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "54139b18-3bec-4872-a986-15e94f97d4f9", "node_type": "1", "metadata": {}, "hash": "2c25c7526bf26549aced0774eee4d23139958a854ba737885a479c8182644890", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "append({\"role\": \"user\", \"content\": msg.content})\n            elif isinstance(msg, FunctionMessage):\n                # FunctionMessage is typically a tool response in LangChain\n                # Convert it to a user message with function_response for Gemini\n                generic_messages.append(\n                    {\n                        \"role\": \"user\",\n                        \"function_call\": { # This key is used by GeminiLLMAdapter to identify tool responses\n                            \"name\": msg.name, # The name of the tool that was called\n                            \"response\": {\"content\": str(msg.content)}\n                        }\n                    }\n                )\n            elif isinstance(msg, ToolMessage):\n                # ToolMessage is also a tool response in LangChain\n                # Convert it to a user message with function_response for Gemini\n\n                # Extract tool name from ToolMessage\n                tool_name = msg.name\n\n                # Fallback: if name is empty, try to extract from tool_call_id\n                if not tool_name or tool_name == \"\":\n                    if hasattr(msg, 'tool_call_id') and msg.tool_call_id:\n                        # tool_call_id format is typically \"call_<function_name>\"\n                        tool_name = msg.tool_call_id.replace(\"call_\", \"\")\n                    else:\n                        # Last resort: use a default name\n                        tool_name = \"unknown_tool\"\n\n                generic_messages.append(\n                    {\n                        \"role\": \"user\", # Tool responses are part of the user's turn\n                        \"function_call\": { # This key is used by GeminiLLMAdapter to identify tool responses\n                            \"name\": tool_name,  # The name of the tool that was called\n                            \"response\": {\"content\": str(msg.content)}\n                        }\n                    }\n                )\n            else:\n                raise ValueError(f\"Unsupported message type: {type(msg)}\")\n\n        # Check if tools were bound via bind_tools or passed directly in kwargs\n        tools_to_pass = getattr(self, 'tools', None) or kwargs.get(\"tools\")\n        if tools_to_pass:\n            generic_tools_declarations = []\n            for tool in tools_to_pass:\n                if hasattr(tool, 'name') and hasattr(tool, 'description') and hasattr(tool, 'args'):\n                    # LangChain's StructuredTool has 'name', 'description', and 'args'\n                    \n                    # Infer required parameters\n                    required_params = [\n                        param for param, details in tool.args.items() \n                        if details.get(\"default\") is None and details.get(\"type\") != \"null\"\n                    ]\n\n                    # Create a copy of tool.args and remove 'default' if it's causing issues\n                    processed_args = {}\n                    for param, details in tool.args.items():\n                        param_details = details.copy()\n                        if \"default\" in param_details:\n                            del param_details[\"default\"] # Remover a chave 'default'\n                        if \"title\" in param_details: # Remover a chave 'title'\n                            del param_details[\"title\"]\n                        processed_args[param] = param_details\n\n                    # Limpar o esquema de processed_args para remover 'anyOf'\n                    cleaned_processed_args = _clean_json_schema(processed_args)\n\n                    generic_tools_declarations.append(\n                        {\n                            \"name\": tool.name,\n                            \"description\": tool.description,\n                            \"parameters\": {\n                                \"type\": \"object\",\n                                \"properties\": cleaned_processed_args, # Usar cleaned_processed_args\n                                \"required\": required_params,\n                            },\n                        }\n                    )\n                elif isinstance(tool, dict) and \"name\" in tool and \"description\" in tool and \"parameters\" in tool:\n                    # If it's already a dictionary in the expected function declaration format\n                    generic_tools_declarations.append(tool)\n                else:\n                    # Fallback for other tool types or if the tool object is not fully formed\n                    print(f\"Warning: Unexpected tool format encountered: {type(tool)} - {tool}\")\n                    if hasattr(tool, 'name') and hasattr(tool, 'description'):\n                         generic_tools_declarations.append(\n                                {\n                                    \"name\": tool.name,\n                                    \"description\": tool.description,\n                                    \"parameters\": {\"type\": \"object\", \"properties\": {}}, # Empty parameters\n                                }\n                        )\n                    else:\n                        raise ValueError(f\"Unsupported tool object: {tool}\")\n\n            # Gemini API expects a single list of function declarations under a 'function_declarations' key\n            tools_to_pass = {\"function_declarations\": generic_tools_declarations}\n        else:\n            tools_to_pass = None", "mimetype": "text/plain", "start_char_idx": 4633, "end_char_idx": 9985, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "54139b18-3bec-4872-a986-15e94f97d4f9": {"__data__": {"id_": "54139b18-3bec-4872-a986-15e94f97d4f9", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\llm_langchain_adapter.py", "language": "python", "lines": 294, "filename": "llm_langchain_adapter.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\llm_langchain_adapter.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\llm_langchain_adapter.py", "language": "python", "lines": 294, "filename": "llm_langchain_adapter.py"}, "hash": "f2b4601f3df3837beb8060dc7bdadf04ea6f5d127386677608146fbba6ab973f", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a775e479-8542-4ec8-9fb6-998e9899ac27", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\llm_langchain_adapter.py", "language": "python", "lines": 294, "filename": "llm_langchain_adapter.py"}, "hash": "0369a53120c7f39b12404220af1a91c0da17aa872d2f24903a4c7c3f0eeaf2c8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "llm_response = self.llm_adapter.get_completion(\n            messages=generic_messages, tools=tools_to_pass\n        )\n\n        if \"error\" in llm_response:\n            raise Exception(f\"LLM Adapter Error: {llm_response['error']}\")\n\n        content = llm_response.get(\"content\") or \"\"\n        tool_calls_data = llm_response.get(\"tool_calls\")\n\n        lc_tool_calls = []\n        if tool_calls_data:\n            for tc_data in tool_calls_data:\n                try:\n                    # tc_data is already a dictionary from GeminiLLMAdapter\n                    args = json.loads(tc_data[\"function\"][\"arguments\"])\n                except (json.JSONDecodeError, TypeError):\n                    args = {\n                        \"error\": \"Argumentos em formato JSON inv\u00e1lido\",\n                        \"received\": tc_data[\"function\"][\"arguments\"],\n                    }\n\n                lc_tool_calls.append(\n                    ToolCall(name=tc_data[\"function\"][\"name\"], args=args, id=tc_data[\"id\"])\n                )\n\n        ai_message = AIMessage(content=content, tool_calls=lc_tool_calls)\n\n        return ChatResult(generations=[ChatGeneration(message=ai_message)])\n\n    async def _agenerate(\n        self,\n        messages: List[BaseMessage],\n        stop: Optional[List[str]] = None,\n        run_manager: Optional[CallbackManagerForLLMRun] = None,\n        **kwargs: Any,\n    ) -> ChatResult:\n        raise NotImplementedError(\n            \"CustomLangChainLLM does not support async generation yet.\"\n        )\n\n    def _stream(\n        self,\n        messages: List[BaseMessage],\n        stop: Optional[List[str]] = None,\n        run_manager: Optional[CallbackManagerForLLMRun] = None,\n        **kwargs: Any,\n    ) -> ChatResult:\n        if not LANGCHAIN_AVAILABLE:\n             raise ImportError(\"LangChain is not available.\")\n             \n        chat_result = self._generate(messages, stop, run_manager, **kwargs)\n        generation = chat_result.generations[0]\n        ai_message = generation.message\n\n        message_chunk = AIMessageChunk(\n            content=ai_message.content, tool_calls=ai_message.tool_calls\n        )\n\n        yield ChatGenerationChunk(message=message_chunk)", "mimetype": "text/plain", "start_char_idx": 9996, "end_char_idx": 12177, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "87bb6590-62bf-4756-927b-cb395ca8c0b5": {"__data__": {"id_": "87bb6590-62bf-4756-927b-cb395ca8c0b5", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\logging_config.py", "language": "python", "lines": 477, "filename": "logging_config.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\logging_config.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\logging_config.py", "language": "python", "lines": 477, "filename": "logging_config.py"}, "hash": "b1cd67b7cbd2f4349ca4d2b94548be432e8cfadc3cb9739446ab380aeb6f9694", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6ae21694-0a16-4722-bd7c-64ad2a0bd6cb", "node_type": "1", "metadata": {}, "hash": "b5cf54ff98bd3a84166ba038fe38a58852766169a9f41cd84d0a72bfdc7bc2cb", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nSistema de Logging Centralizado\nConfigura\u00e7\u00e3o completa de logs para o AgentBI Backend\n\"\"\"\nimport logging\nimport sys\nfrom datetime import datetime\nfrom pathlib import Path\nfrom typing import Any\nimport json\n\nfrom logging.handlers import RotatingFileHandler, TimedRotatingFileHandler\nimport structlog\n\n\nclass LogConfig:\n    \"\"\"Configura\u00e7\u00e3o centralizada de logging\"\"\"\n\n    # Diret\u00f3rios de logs\n    BASE_LOG_DIR = Path(\"logs\")\n    APP_LOG_DIR = BASE_LOG_DIR / \"app\"\n    API_LOG_DIR = BASE_LOG_DIR / \"api\"\n    SECURITY_LOG_DIR = BASE_LOG_DIR / \"security\"\n    CHAT_LOG_DIR = BASE_LOG_DIR / \"chat\"\n    ERROR_LOG_DIR = BASE_LOG_DIR / \"errors\"\n    AUDIT_LOG_DIR = BASE_LOG_DIR / \"audit\"\n\n    # Configura\u00e7\u00f5es de rota\u00e7\u00e3o\n    MAX_BYTES = 10 * 1024 * 1024  # 10 MB\n    BACKUP_COUNT = 10\n\n    # N\u00edveis de log por ambiente\n    LOG_LEVELS = {\n        \"development\": \"DEBUG\",\n        \"staging\": \"INFO\",\n        \"production\": \"WARNING\"\n    }\n\n    @classmethod\n    def setup_directories(cls):\n        \"\"\"Cria todos os diret\u00f3rios de logs necess\u00e1rios\"\"\"\n        for log_dir in [\n            cls.APP_LOG_DIR,\n            cls.API_LOG_DIR,\n            cls.SECURITY_LOG_DIR,\n            cls.CHAT_LOG_DIR,\n            cls.ERROR_LOG_DIR,\n            cls.AUDIT_LOG_DIR\n        ]:\n            log_dir.mkdir(parents=True, exist_ok=True)\n\n\nclass JSONFormatter(logging.Formatter):\n    \"\"\"Formatter que gera logs em formato JSON estruturado\"\"\"\n\n    def format(self, record: logging.LogRecord) -> str:\n        log_data = {\n            \"timestamp\": datetime.utcnow().isoformat(),\n            \"level\": record.levelname,\n            \"logger\": record.name,\n            \"message\": record.getMessage(),\n            \"module\": record.module,\n            \"function\": record.funcName,\n            \"line\": record.lineno,\n        }\n\n        # Adiciona informa\u00e7\u00f5es extras se dispon\u00edveis\n        if hasattr(record, \"user_id\"):\n            log_data[\"user_id\"] = record.user_id\n        if hasattr(record, \"request_id\"):\n            log_data[\"request_id\"] = record.request_id\n        if hasattr(record, \"ip_address\"):\n            log_data[\"ip_address\"] = record.ip_address\n        if hasattr(record, \"endpoint\"):\n            log_data[\"endpoint\"] = record.endpoint\n        if hasattr(record, \"method\"):\n            log_data[\"method\"] = record.method\n        if hasattr(record, \"status_code\"):\n            log_data[\"status_code\"] = record.status_code\n        if hasattr(record, \"duration\"):\n            log_data[\"duration\"] = record.duration\n\n        # Adiciona exception info se presente\n        if record.exc_info:\n            log_data[\"exception\"] = self.formatException(record.exc_info)\n\n        # Adiciona stack info se presente\n        if hasattr(record, \"stack_info\") and record.stack_info:\n            log_data[\"stack_info\"] = record.stack_info\n\n        return json.dumps(log_data, ensure_ascii=False)\n\n\nclass ColoredConsoleFormatter(logging.Formatter):\n    \"\"\"Formatter com cores para console (development)\"\"\"\n\n    COLORS = {\n        'DEBUG': '\\033[36m',      # Cyan\n        'INFO': '\\033[32m',       # Green\n        'WARNING': '\\033[33m',    # Yellow\n        'ERROR': '\\033[31m',      # Red\n        'CRITICAL': '\\033[35m',   # Magenta\n    }\n    RESET = '\\033[0m'\n\n    def format(self, record: logging.LogRecord) -> str:\n        color = self.COLORS.get(record.levelname, self.RESET)\n        record.levelname = f\"{color}{record.levelname}{self.RESET}\"\n        return super().format(record)\n\n\ndef get_file_handler(\n    filename: Path,\n    level: int = logging.INFO,\n    max_bytes: int = LogConfig.MAX_BYTES,\n    backup_count: int = LogConfig.BACKUP_COUNT,\n    use_json: bool = True\n) -> RotatingFileHandler:\n    \"\"\"Cria um handler rotativo para arquivo\"\"\"\n    handler = RotatingFileHandler(\n        filename=filename,\n        maxBytes=max_bytes,\n        backupCount=backup_count,\n        encoding='utf-8'\n    )\n    handler.setLevel(level)\n\n    if use_json:\n        handler.setFormatter(JSONFormatter())\n    else:\n        handler.setFormatter(\n            logging.Formatter(\n                '%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n                datefmt='%Y-%m-%d %H:%M:%S'\n            )\n        )\n\n    return handler", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4190, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "6ae21694-0a16-4722-bd7c-64ad2a0bd6cb": {"__data__": {"id_": "6ae21694-0a16-4722-bd7c-64ad2a0bd6cb", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\logging_config.py", "language": "python", "lines": 477, "filename": "logging_config.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\logging_config.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\logging_config.py", "language": "python", "lines": 477, "filename": "logging_config.py"}, "hash": "b1cd67b7cbd2f4349ca4d2b94548be432e8cfadc3cb9739446ab380aeb6f9694", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "87bb6590-62bf-4756-927b-cb395ca8c0b5", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\logging_config.py", "language": "python", "lines": 477, "filename": "logging_config.py"}, "hash": "82821470289099a3cd3b3ee05a5579142272f2aab4db6bbbe1ce12aaeed62397", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "158bb008-e571-4c8d-9086-d99eee39d4fa", "node_type": "1", "metadata": {}, "hash": "d0ec87cee44d855db921ae42c46a0fedd5162276a5c745c31f431cfaff043ebe", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "def get_timed_file_handler(\n    filename: Path,\n    level: int = logging.INFO,\n    when: str = 'midnight',\n    interval: int = 1,\n    backup_count: int = 30,\n    use_json: bool = True\n) -> TimedRotatingFileHandler:\n    \"\"\"Cria um handler com rota\u00e7\u00e3o por tempo\"\"\"\n    handler = TimedRotatingFileHandler(\n        filename=filename,\n        when=when,\n        interval=interval,\n        backupCount=backup_count,\n        encoding='utf-8'\n    )\n    handler.setLevel(level)\n\n    if use_json:\n        handler.setFormatter(JSONFormatter())\n    else:\n        handler.setFormatter(\n            logging.Formatter(\n                '%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n                datefmt='%Y-%m-%d %H:%M:%S'\n            )\n        )\n\n    return handler\n\n\ndef get_console_handler(level: int = logging.DEBUG, colored: bool = True) -> logging.StreamHandler:\n    \"\"\"Cria um handler para console\"\"\"\n    handler = logging.StreamHandler(sys.stdout)\n    handler.setLevel(level)\n\n    if colored:\n        handler.setFormatter(\n            ColoredConsoleFormatter(\n                '%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n                datefmt='%Y-%m-%d %H:%M:%S'\n            )\n        )\n    else:\n        handler.setFormatter(\n            logging.Formatter(\n                '%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n                datefmt='%Y-%m-%d %H:%M:%S'\n            )\n        )\n\n    return handler\n\n\ndef setup_logger(\n    name: str,\n    log_file: Path | None = None,\n    level: int = logging.INFO,\n    console: bool = True,\n    use_json: bool = False\n) -> logging.Logger:\n    \"\"\"\n    Configura um logger espec\u00edfico\n\n    Args:\n        name: Nome do logger\n        log_file: Caminho do arquivo de log (opcional)\n        level: N\u00edvel de log\n        console: Se deve mostrar logs no console\n        use_json: Se deve usar formato JSON\n\n    Returns:\n        Logger configurado\n    \"\"\"\n    logger = logging.getLogger(name)\n    logger.setLevel(level)\n    logger.handlers.clear()  # Remove handlers existentes\n\n    # Handler de console\n    if console:\n        logger.addHandler(get_console_handler(level, colored=True))\n\n    # Handler de arquivo\n    if log_file:\n        logger.addHandler(get_file_handler(log_file, level, use_json=use_json))\n\n    logger.propagate = False\n    return logger\n\n\ndef configure_structlog(environment: str = \"development\"):\n    \"\"\"\n    Configura structlog para logging estruturado\n\n    Args:\n        environment: Ambiente de execu\u00e7\u00e3o (development, staging, production)\n    \"\"\"\n    processors = [\n        structlog.stdlib.add_logger_name,\n        structlog.stdlib.add_log_level,\n        structlog.processors.TimeStamper(fmt=\"iso\"),\n        structlog.processors.StackInfoRenderer(),\n        structlog.processors.format_exc_info,\n        structlog.processors.UnicodeDecoder(),\n    ]\n\n    # Em desenvolvimento, usa console renderer colorido\n    # Em produ\u00e7\u00e3o, usa JSON renderer\n    if environment == \"development\":\n        processors.append(structlog.dev.ConsoleRenderer(colors=True))\n    else:\n        processors.append(structlog.processors.JSONRenderer())\n\n    structlog.configure(\n        processors=processors,\n        logger_factory=structlog.stdlib.LoggerFactory(),\n        wrapper_class=structlog.stdlib.BoundLogger,\n        cache_logger_on_first_use=True,\n    )", "mimetype": "text/plain", "start_char_idx": 4193, "end_char_idx": 7516, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "158bb008-e571-4c8d-9086-d99eee39d4fa": {"__data__": {"id_": "158bb008-e571-4c8d-9086-d99eee39d4fa", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\logging_config.py", "language": "python", "lines": 477, "filename": "logging_config.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\logging_config.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\logging_config.py", "language": "python", "lines": 477, "filename": "logging_config.py"}, "hash": "b1cd67b7cbd2f4349ca4d2b94548be432e8cfadc3cb9739446ab380aeb6f9694", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6ae21694-0a16-4722-bd7c-64ad2a0bd6cb", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\logging_config.py", "language": "python", "lines": 477, "filename": "logging_config.py"}, "hash": "1bab1918e2e14252d8136c79ee2f9ca10c1c779b8360bb310f166554c071e717", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f8127b43-7e24-4fa1-af64-dfae1d2258f1", "node_type": "1", "metadata": {}, "hash": "99437e97519ee2e772352da51415964da4794fb00bb260ac74c63af92bb926de", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "def setup_application_logging(environment: str = \"development\"):\n    \"\"\"\n    Configura todo o sistema de logging da aplica\u00e7\u00e3o\n\n    Args:\n        environment: Ambiente de execu\u00e7\u00e3o\n    \"\"\"\n    # Cria diret\u00f3rios\n    LogConfig.setup_directories()\n\n    # Configura structlog\n    configure_structlog(environment)\n\n    # N\u00edvel base de log baseado no ambiente\n    base_level = getattr(logging, LogConfig.LOG_LEVELS.get(environment, \"INFO\"))\n\n    # Logger principal da aplica\u00e7\u00e3o\n    app_logger = setup_logger(\n        \"agentbi\",\n        log_file=LogConfig.APP_LOG_DIR / \"app.log\",\n        level=base_level,\n        console=True,\n        use_json=(environment != \"development\")\n    )\n\n    # Logger de API\n    api_logger = setup_logger(\n        \"agentbi.api\",\n        log_file=LogConfig.API_LOG_DIR / \"api.log\",\n        level=logging.INFO,\n        console=(environment == \"development\"),\n        use_json=(environment != \"development\")\n    )\n\n    # Logger de seguran\u00e7a\n    security_logger = setup_logger(\n        \"agentbi.security\",\n        log_file=LogConfig.SECURITY_LOG_DIR / \"security.log\",\n        level=logging.INFO,\n        console=True,\n        use_json=True  # Sempre JSON para an\u00e1lise de seguran\u00e7a\n    )\n\n    # Logger de chat/conversas\n    chat_logger = setup_logger(\n        \"agentbi.chat\",\n        log_file=LogConfig.CHAT_LOG_DIR / \"chat.log\",\n        level=logging.INFO,\n        console=(environment == \"development\"),\n        use_json=True\n    )\n\n    # Logger de erros (todos os erros v\u00e3o aqui tamb\u00e9m)\n    error_logger = setup_logger(\n        \"agentbi.errors\",\n        log_file=LogConfig.ERROR_LOG_DIR / \"errors.log\",\n        level=logging.ERROR,\n        console=True,\n        use_json=True\n    )\n\n    # Logger de auditoria\n    audit_logger = setup_logger(\n        \"agentbi.audit\",\n        log_file=LogConfig.AUDIT_LOG_DIR / \"audit.log\",\n        level=logging.INFO,\n        console=False,\n        use_json=True  # Sempre JSON para an\u00e1lise de auditoria\n    )\n\n    # Configura handler de erros global para capturar tudo\n    root_logger = logging.getLogger()\n    root_logger.setLevel(base_level)\n\n    # Remove handlers padr\u00e3o\n    root_logger.handlers.clear()\n\n    # Adiciona handlers\n    if environment == \"development\":\n        root_logger.addHandler(get_console_handler(base_level, colored=True))\n\n    # Adiciona handler de arquivo para erros cr\u00edticos\n    root_logger.addHandler(\n        get_file_handler(\n            LogConfig.ERROR_LOG_DIR / \"critical.log\",\n            level=logging.ERROR,\n            use_json=True\n        )\n    )\n\n    return {\n        \"app\": app_logger,\n        \"api\": api_logger,\n        \"security\": security_logger,\n        \"chat\": chat_logger,\n        \"errors\": error_logger,\n        \"audit\": audit_logger,\n    }\n\n\n# Fun\u00e7\u00f5es auxiliares para logging espec\u00edfico\n\ndef log_api_request(\n    logger: logging.Logger,\n    method: str,\n    endpoint: str,\n    user_id: str | None = None,\n    ip_address: str | None = None,\n    request_id: str | None = None,\n    **kwargs\n):\n    \"\"\"Log de requisi\u00e7\u00e3o API\"\"\"\n    extra = {\n        \"method\": method,\n        \"endpoint\": endpoint,\n        \"user_id\": user_id,\n        \"ip_address\": ip_address,\n        \"request_id\": request_id,\n        **kwargs\n    }\n    logger.info(f\"API Request: {method} {endpoint}\", extra=extra)\n\n\ndef log_api_response(\n    logger: logging.Logger,\n    method: str,\n    endpoint: str,\n    status_code: int,\n    duration: float,\n    user_id: str | None = None,\n    request_id: str | None = None,\n    **kwargs\n):\n    \"\"\"Log de resposta API\"\"\"\n    extra = {\n        \"method\": method,\n        \"endpoint\": endpoint,\n        \"status_code\": status_code,\n        \"duration\": duration,\n        \"user_id\": user_id,\n        \"request_id\": request_id,\n        **kwargs\n    }\n\n    if status_code >= 500:\n        logger.error(f\"API Response: {method} {endpoint} - {status_code}\", extra=extra)\n    elif status_code >= 400:\n        logger.warning(f\"API Response: {method} {endpoint} - {status_code}\", extra=extra)\n    else:\n        logger.info(f\"API Response: {method} {endpoint} - {status_code}\", extra=extra)", "mimetype": "text/plain", "start_char_idx": 7519, "end_char_idx": 11593, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f8127b43-7e24-4fa1-af64-dfae1d2258f1": {"__data__": {"id_": "f8127b43-7e24-4fa1-af64-dfae1d2258f1", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\logging_config.py", "language": "python", "lines": 477, "filename": "logging_config.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\logging_config.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\logging_config.py", "language": "python", "lines": 477, "filename": "logging_config.py"}, "hash": "b1cd67b7cbd2f4349ca4d2b94548be432e8cfadc3cb9739446ab380aeb6f9694", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "158bb008-e571-4c8d-9086-d99eee39d4fa", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\logging_config.py", "language": "python", "lines": 477, "filename": "logging_config.py"}, "hash": "5d77d890b8469d7113c1e07004265d19e81e63cc6ca55ffba943ede09e715d86", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "def log_security_event(\n    logger: logging.Logger,\n    event_type: str,\n    user_id: str | None = None,\n    ip_address: str | None = None,\n    details: dict[str, Any] | None = None,\n    success: bool = True\n):\n    \"\"\"Log de evento de seguran\u00e7a\"\"\"\n    extra = {\n        \"event_type\": event_type,\n        \"user_id\": user_id,\n        \"ip_address\": ip_address,\n        \"success\": success,\n        \"details\": details or {}\n    }\n\n    if success:\n        logger.info(f\"Security Event: {event_type}\", extra=extra)\n    else:\n        logger.warning(f\"Security Event Failed: {event_type}\", extra=extra)\n\n\ndef log_audit_event(\n    logger: logging.Logger,\n    action: str,\n    user_id: str,\n    resource: str,\n    resource_id: str | None = None,\n    changes: dict[str, Any] | None = None,\n    ip_address: str | None = None\n):\n    \"\"\"Log de evento de auditoria\"\"\"\n    extra = {\n        \"action\": action,\n        \"user_id\": user_id,\n        \"resource\": resource,\n        \"resource_id\": resource_id,\n        \"changes\": changes or {},\n        \"ip_address\": ip_address\n    }\n    logger.info(f\"Audit: {action} on {resource}\", extra=extra)\n\n\ndef log_chat_interaction(\n    logger: logging.Logger,\n    user_id: str,\n    message: str,\n    response: str | None = None,\n    tokens_used: int | None = None,\n    duration: float | None = None,\n    model: str | None = None\n):\n    \"\"\"Log de intera\u00e7\u00e3o de chat\"\"\"\n    extra = {\n        \"user_id\": user_id,\n        \"message_preview\": message[:100] + \"...\" if len(message) > 100 else message,\n        \"response_preview\": (response[:100] + \"...\" if response and len(response) > 100 else response) if response else None,\n        \"tokens_used\": tokens_used,\n        \"duration\": duration,\n        \"model\": model\n    }\n    logger.info(f\"Chat interaction from user {user_id}\", extra=extra)", "mimetype": "text/plain", "start_char_idx": 11596, "end_char_idx": 13398, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "bf5772b8-5805-4976-bf48-cf30ea5fbd1e": {"__data__": {"id_": "bf5772b8-5805-4976-bf48-cf30ea5fbd1e", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\logging_middleware.py", "language": "python", "lines": 302, "filename": "logging_middleware.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\logging_middleware.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\logging_middleware.py", "language": "python", "lines": 302, "filename": "logging_middleware.py"}, "hash": "223c958b5d3a46b4fde646ce95a4b24ae08926bc449fbdd53fd2bd6b2595ef56", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f8e1a478-0729-405b-9d67-fde5c02cb13f", "node_type": "1", "metadata": {}, "hash": "f67d3ecfa30ece748ae2431fbcea131e6985bd2f503dba8fcb93f49118db646b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nMiddleware de Logging para FastAPI\nCaptura e registra todas as requisi\u00e7\u00f5es e respostas HTTP\n\"\"\"\nimport time\nimport uuid\nfrom typing import Callable\n\nimport structlog\nfrom fastapi import Request, Response\nfrom starlette.middleware.base import BaseHTTPMiddleware\nfrom starlette.types import ASGIApp\n\nfrom .logging_config import log_api_request, log_api_response\n\n\nclass RequestLoggingMiddleware(BaseHTTPMiddleware):\n    \"\"\"\n    Middleware que registra todas as requisi\u00e7\u00f5es HTTP\n    com informa\u00e7\u00f5es detalhadas e m\u00e9tricas de performance\n    \"\"\"\n\n    def __init__(self, app: ASGIApp, logger_name: str = \"agentbi.api\"):\n        super().__init__(app)\n        self.logger = structlog.get_logger(logger_name)\n\n    async def dispatch(self, request: Request, call_next: Callable) -> Response:\n        # Gera um ID \u00fanico para a requisi\u00e7\u00e3o\n        request_id = str(uuid.uuid4())\n        request.state.request_id = request_id\n\n        # Extrai informa\u00e7\u00f5es da requisi\u00e7\u00e3o\n        method = request.method\n        url = str(request.url)\n        path = request.url.path\n        client_host = request.client.host if request.client else None\n        user_agent = request.headers.get(\"user-agent\", \"unknown\")\n\n        # Extrai user_id se dispon\u00edvel (do token JWT)\n        user_id = None\n        if hasattr(request.state, \"user\"):\n            user_id = getattr(request.state.user, \"id\", None)\n\n        # Log da requisi\u00e7\u00e3o\n        self.logger.info(\n            \"request_started\",\n            request_id=request_id,\n            method=method,\n            url=url,\n            path=path,\n            client_host=client_host,\n            user_agent=user_agent,\n            user_id=user_id,\n        )\n\n        # Timestamp de in\u00edcio\n        start_time = time.time()\n\n        # Processa a requisi\u00e7\u00e3o\n        try:\n            response = await call_next(request)\n\n            # Calcula dura\u00e7\u00e3o\n            duration = time.time() - start_time\n\n            # Log da resposta\n            self.logger.info(\n                \"request_completed\",\n                request_id=request_id,\n                method=method,\n                path=path,\n                status_code=response.status_code,\n                duration=f\"{duration:.3f}s\",\n                duration_ms=f\"{duration * 1000:.0f}ms\",\n                user_id=user_id,\n            )\n\n            # Adiciona headers de debug\n            response.headers[\"X-Request-ID\"] = request_id\n            response.headers[\"X-Response-Time\"] = f\"{duration * 1000:.0f}ms\"\n\n            return response\n\n        except Exception as exc:\n            # Calcula dura\u00e7\u00e3o at\u00e9 o erro\n            duration = time.time() - start_time\n            \n            # Tratar erros de desconex\u00e3o/stream de forma graciosa\n            error_msg = str(exc)\n            if \"No response returned\" in error_msg or \"EndOfStream\" in type(exc).__name__:\n                self.logger.warning(\n                    \"client_disconnected\",\n                    path=path,\n                    duration=f\"{duration:.3f}s\",\n                    error=error_msg\n                )\n                # N\u00e3o relan\u00e7ar para evitar polui\u00e7\u00e3o de logs de erro, pois \u00e9 um cancelamento do cliente\n                return Response(content=\"Client disconnected\", status_code=499)\n\n            # Log do erro\n            self.logger.error(\n                \"request_failed\",\n                request_id=request_id,\n                method=method,\n                path=path,\n                error=error_msg,\n                error_type=type(exc).__name__,\n                duration=f\"{duration:.3f}s\",\n                user_id=user_id,\n                exc_info=True,\n            )\n\n            # Re-lan\u00e7a a exce\u00e7\u00e3o para ser tratada pelos handlers\n            raise\n\n\nclass PerformanceLoggingMiddleware(BaseHTTPMiddleware):\n    \"\"\"\n    Middleware que registra m\u00e9tricas de performance\n    e identifica requisi\u00e7\u00f5es lentas\n    \"\"\"\n\n    def __init__(\n        self,\n        app: ASGIApp,\n        slow_request_threshold: float = 1.0,  # segundos\n        logger_name: str = \"agentbi.performance\"\n    ):\n        super().__init__(app)\n        self.slow_request_threshold = slow_request_threshold\n        self.logger = structlog.get_logger(logger_name)\n\n    async def dispatch(self, request: Request, call_next: Callable) -> Response:\n        start_time = time.time()\n\n        response = await call_next(request)\n\n        duration = time.time() - start_time\n\n        # Log de requisi\u00e7\u00f5es lentas\n        if duration > self.slow_request_threshold:\n            self.logger.warning(\n                \"slow_request_detected\",\n                method=request.method,\n                path=request.url.path,\n                duration=f\"{duration:.3f}s\",\n                threshold=f\"{self.slow_request_threshold}s\",\n                status_code=response.status_code,\n            )\n\n        return response", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4827, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f8e1a478-0729-405b-9d67-fde5c02cb13f": {"__data__": {"id_": "f8e1a478-0729-405b-9d67-fde5c02cb13f", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\logging_middleware.py", "language": "python", "lines": 302, "filename": "logging_middleware.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\logging_middleware.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\logging_middleware.py", "language": "python", "lines": 302, "filename": "logging_middleware.py"}, "hash": "223c958b5d3a46b4fde646ce95a4b24ae08926bc449fbdd53fd2bd6b2595ef56", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bf5772b8-5805-4976-bf48-cf30ea5fbd1e", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\logging_middleware.py", "language": "python", "lines": 302, "filename": "logging_middleware.py"}, "hash": "a6196c2b8084984976628107275bfc58eba33ede151f86cbbef2b39a933dec39", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8b299532-3bd7-4cda-8c38-a95e51ea8b7f", "node_type": "1", "metadata": {}, "hash": "cb6aa35226def3d7139be7dcfc1a96d276d3fbca0cca27a12a0323b185135199", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "class SecurityLoggingMiddleware(BaseHTTPMiddleware):\n    \"\"\"\n    Middleware que registra eventos de seguran\u00e7a\n    como tentativas de autentica\u00e7\u00e3o, acessos negados, etc.\n    \"\"\"\n\n    def __init__(self, app: ASGIApp, logger_name: str = \"agentbi.security\"):\n        super().__init__(app)\n        self.logger = structlog.get_logger(logger_name)\n\n    async def dispatch(self, request: Request, call_next: Callable) -> Response:\n        # Paths que devem ser monitorados para seguran\u00e7a\n        security_paths = [\"/auth\", \"/login\", \"/admin\"]\n        path = request.url.path\n\n        # Verifica se \u00e9 uma rota de seguran\u00e7a\n        is_security_route = any(sec_path in path for sec_path in security_paths)\n\n        response = await call_next(request)\n\n        # Log de eventos de seguran\u00e7a\n        if is_security_route:\n            client_host = request.client.host if request.client else \"unknown\"\n\n            # Log de tentativas de autentica\u00e7\u00e3o\n            if \"/auth\" in path or \"/login\" in path:\n                if response.status_code == 200:\n                    self.logger.info(\n                        \"authentication_success\",\n                        path=path,\n                        client_host=client_host,\n                        user_agent=request.headers.get(\"user-agent\"),\n                    )\n                elif response.status_code == 401:\n                    self.logger.warning(\n                        \"authentication_failed\",\n                        path=path,\n                        client_host=client_host,\n                        user_agent=request.headers.get(\"user-agent\"),\n                    )\n\n            # Log de acessos negados\n            elif response.status_code == 403:\n                self.logger.warning(\n                    \"access_denied\",\n                    path=path,\n                    client_host=client_host,\n                    method=request.method,\n                )\n\n            # Log de recursos n\u00e3o encontrados (poss\u00edvel scan)\n            elif response.status_code == 404 and \"/admin\" in path:\n                self.logger.warning(\n                    \"admin_path_not_found\",\n                    path=path,\n                    client_host=client_host,\n                    method=request.method,\n                )\n\n        return response\n\n\nclass AuditLoggingMiddleware(BaseHTTPMiddleware):\n    \"\"\"\n    Middleware que registra a\u00e7\u00f5es de auditoria\n    para opera\u00e7\u00f5es de escrita (POST, PUT, DELETE, PATCH)\n    \"\"\"\n\n    def __init__(self, app: ASGIApp, logger_name: str = \"agentbi.audit\"):\n        super().__init__(app)\n        self.logger = structlog.get_logger(logger_name)\n        self.audit_methods = {\"POST\", \"PUT\", \"DELETE\", \"PATCH\"}\n\n    async def dispatch(self, request: Request, call_next: Callable) -> Response:\n        # S\u00f3 audita m\u00e9todos de escrita\n        if request.method in self.audit_methods:\n            path = request.url.path\n            client_host = request.client.host if request.client else \"unknown\"\n\n            # Extrai user_id se dispon\u00edvel\n            user_id = None\n            if hasattr(request.state, \"user\"):\n                user_id = getattr(request.state.user, \"id\", None)\n\n            # Processa a requisi\u00e7\u00e3o\n            response = await call_next(request)\n\n            # Log de auditoria\n            if response.status_code in [200, 201, 204]:\n                self.logger.info(\n                    \"audit_action\",\n                    method=request.method,\n                    path=path,\n                    user_id=user_id,\n                    client_host=client_host,\n                    status_code=response.status_code,\n                    timestamp=time.time(),\n                )\n\n            return response\n        else:\n            return await call_next(request)", "mimetype": "text/plain", "start_char_idx": 4830, "end_char_idx": 8581, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8b299532-3bd7-4cda-8c38-a95e51ea8b7f": {"__data__": {"id_": "8b299532-3bd7-4cda-8c38-a95e51ea8b7f", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\logging_middleware.py", "language": "python", "lines": 302, "filename": "logging_middleware.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\logging_middleware.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\logging_middleware.py", "language": "python", "lines": 302, "filename": "logging_middleware.py"}, "hash": "223c958b5d3a46b4fde646ce95a4b24ae08926bc449fbdd53fd2bd6b2595ef56", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f8e1a478-0729-405b-9d67-fde5c02cb13f", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\logging_middleware.py", "language": "python", "lines": 302, "filename": "logging_middleware.py"}, "hash": "0608cf6aaa3c89f3b213fc3e475d3019a8602e20910c380f4b2792a29fdbb17e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "class ErrorLoggingMiddleware(BaseHTTPMiddleware):\n    \"\"\"\n    Middleware que captura e registra todos os erros\n    \"\"\"\n\n    def __init__(self, app: ASGIApp, logger_name: str = \"agentbi.errors\"):\n        super().__init__(app)\n        self.logger = structlog.get_logger(logger_name)\n\n    async def dispatch(self, request: Request, call_next: Callable) -> Response:\n        try:\n            response = await call_next(request)\n\n            # Log de erros HTTP (4xx e 5xx)\n            if response.status_code >= 400:\n                severity = \"error\" if response.status_code >= 500 else \"warning\"\n\n                log_method = getattr(self.logger, severity)\n                try:\n                    log_method(\n                        \"http_error\",\n                        method=request.method,\n                        path=request.url.path,\n                        status_code=response.status_code,\n                        client_host=request.client.host if request.client else \"unknown\",\n                    )\n                except Exception as log_err:\n                    # Fallback simple print if structured logging fails\n                    print(f\"LOGGING ERROR: {log_err} (Original error status: {response.status_code})\")\n\n            return response\n\n        except Exception as exc:\n            # Log de exce\u00e7\u00f5es n\u00e3o tratadas\n            self.logger.error(\n                \"unhandled_exception\",\n                method=request.method,\n                path=request.url.path,\n                error=str(exc),\n                error_type=type(exc).__name__,\n                client_host=request.client.host if request.client else \"unknown\",\n                exc_info=True,\n            )\n            raise", "mimetype": "text/plain", "start_char_idx": 8584, "end_char_idx": 10291, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "64ecbbc7-b695-41e1-8b20-0236d8ecef05": {"__data__": {"id_": "64ecbbc7-b695-41e1-8b20-0236d8ecef05", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\parquet_cache.py", "language": "python", "lines": 128, "filename": "parquet_cache.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\parquet_cache.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\parquet_cache.py", "language": "python", "lines": 128, "filename": "parquet_cache.py"}, "hash": "252ba8607c76a5604c190d2319d4aaead5f5cd089bafb28d3390913e7925f2a7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nParquet Cache System with LRU eviction policy\nMaintains up to 5 Parquet DataFrames in memory (~500 MB max)\nThread-safe for concurrent access\n\"\"\"\n\nfrom collections import OrderedDict\nfrom pathlib import Path\nimport polars as pl\nimport threading\nimport logging\n\nlogger = logging.getLogger(__name__)\n\n\nclass ParquetCache:\n    \"\"\"\n    Thread-safe LRU cache for Parquet DataFrames\n    Singleton pattern ensures single cache instance across the application\n    \"\"\"\n    _instance = None\n    _lock = threading.Lock()\n\n    def __new__(cls):\n        if cls._instance is None:\n            with cls._lock:\n                if cls._instance is None:\n                    cls._instance = super().__new__(cls)\n                    cls._instance._cache = OrderedDict()\n                    cls._instance._max_size = 5  # Max 5 Parquets (~500 MB total)\n        return cls._instance\n\n    def get_dataframe(self, parquet_name: str) -> pl.DataFrame:\n        \"\"\"\n        Get DataFrame from cache or load from disk\n\n        Args:\n            parquet_name: Name of the parquet file (e.g., \"admmat.parquet\")\n\n        Returns:\n            pl.DataFrame: Cached or freshly loaded DataFrame\n\n        Raises:\n            FileNotFoundError: If parquet file doesn't exist\n        \"\"\"\n        with self._lock:\n            # Cache hit - move to end (most recently used)\n            if parquet_name in self._cache:\n                logger.info(f\"[OK] Cache HIT: {parquet_name}\")\n                self._cache.move_to_end(parquet_name)\n                return self._cache[parquet_name]\n\n            # Cache miss - load from disk\n            logger.info(f\"[MISS] Cache MISS: {parquet_name} - Loading from disk...\")\n            df = self._load_parquet(parquet_name)\n\n            # Add to cache\n            self._cache[parquet_name] = df\n            logger.info(f\"[OK] Loaded {parquet_name}: {len(df):,} rows x {len(df.columns)} columns\")\n\n            # Evict least recently used if exceeding limit\n            if len(self._cache) > self._max_size:\n                evicted_key, evicted_df = self._cache.popitem(last=False)\n                logger.warning(f\"[WARN] Cache EVICT: {evicted_key} (LRU policy - {len(evicted_df):,} rows freed)\")\n\n            return df\n\n    def _load_parquet(self, parquet_name: str) -> pl.DataFrame:\n        \"\"\"\n        Load Parquet file from disk (hybrid Docker/Dev path support)\n\n        Args:\n            parquet_name: Name of the parquet file\n\n        Returns:\n            pl.DataFrame: Loaded DataFrame\n\n        Raises:\n            FileNotFoundError: If file not found in any location\n        \"\"\"\n        # Try Docker path first\n        docker_path = Path(f\"/app/data/parquet/{parquet_name}\")\n\n        # Fallback to development path (backend/data/parquet)\n        dev_path = Path(__file__).parent.parent.parent / \"data\" / \"parquet\" / parquet_name\n\n        parquet_path = docker_path if docker_path.exists() else dev_path\n\n        if not parquet_path.exists():\n            raise FileNotFoundError(\n                f\"Parquet file not found: {parquet_name}\\n\"\n                f\"Tried paths:\\n\"\n                f\"  - Docker: {docker_path}\\n\"\n                f\"  - Dev: {dev_path}\"\n            )\n\n        # Otimiza\u00e7\u00e3o: usar streaming para arquivos grandes (> 100 MB)\n        # Isso carrega em chunks ao inv\u00e9s de tudo na mem\u00f3ria de uma vez\n        logger.info(f\"\ud83d\udcc2 Loading Parquet: {parquet_path}\")\n\n        # SEMPRE usar scan + collect(streaming=True) para arquivos Parquet grandes\n        # Isso usa menos mem\u00f3ria RAM ao processar em chunks\n        df = pl.scan_parquet(parquet_path).collect(streaming=True)\n\n        logger.info(f\"\u2705 Loaded {len(df):,} rows \u00d7 {len(df.columns)} columns\")\n        return df\n\n    def clear(self):\n        \"\"\"Clear cache (useful for testing or manual refresh)\"\"\"\n        with self._lock:\n            count = len(self._cache)\n            self._cache.clear()\n            logger.info(f\"\ud83e\uddf9 Cache cleared ({count} entries removed)\")\n\n    def get_cache_info(self) -> dict:\n        \"\"\"Get cache statistics\"\"\"\n        with self._lock:\n            return {\n                \"cached_files\": list(self._cache.keys()),\n                \"cache_size\": len(self._cache),\n                \"max_size\": self._max_size,\n                \"cache_utilization\": f\"{len(self._cache)}/{self._max_size}\"\n            }\n\n\n# Global singleton instance\ncache = ParquetCache()", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4352, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "6a5771e6-6c98-4601-8b3c-f482e6650bb4": {"__data__": {"id_": "6a5771e6-6c98-4601-8b3c-f482e6650bb4", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\query_processor.py", "language": "python", "lines": 151, "filename": "query_processor.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\query_processor.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\query_processor.py", "language": "python", "lines": 151, "filename": "query_processor.py"}, "hash": "cb6954c9b10f2f62647b947e3144673779d44d13293a849da6f53d28deb9572b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d3d29dc1-a1cd-4bff-aee9-9faf609c75f9", "node_type": "1", "metadata": {}, "hash": "9d6368ce1ccc34204c83885ca22414383c4518c1853f0aec9470c25152b90d3b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# core/query_processor.py\nimport logging\n\ntry:\n    from app.core.agents.supervisor_agent import SupervisorAgent\nexcept ImportError as e:\n    logging.getLogger(__name__).warning(f\"Failed to import SupervisorAgent: {e}\")\n    SupervisorAgent = None\n\nfrom app.core.factory.component_factory import ComponentFactory\nfrom app.core.llm_factory import LLMFactory\nfrom app.core.cache import Cache\n\n\nclass QueryProcessor:\n    \"\"\"\n    Ponto de entrada principal para o processamento de consultas.\n    Delega a tarefa para o SupervisorAgent para orquestra\u00e7\u00e3o.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Inicializa o processador de consultas e o agente supervisor.\n        \"\"\"\n        self.logger = logging.getLogger(__name__)\n        \n        # \u26a1 OTIMIZA\u00c7\u00c3O: Inicializar sistema de resposta r\u00e1pida (usando Polars diretamente)\n        try:\n            from app.core.tools.quick_response import create_quick_response_system\n            from app.core.parquet_cache import cache\n\n            # \u2705 Usar Polars DataFrame diretamente (sem convers\u00e3o para Pandas)\n            df_polars = cache.get_dataframe(\"admmat.parquet\")\n            self.quick_response = create_quick_response_system(df_polars)\n            self.logger.info(\"\u26a1 Quick Response System inicializado com Polars!\")\n        except Exception as e:\n            self.logger.warning(f\"Quick Response System n\u00e3o dispon\u00edvel: {e}\")\n            self.quick_response = None\n        \n        # Usar factory para obter adapter com fallback autom\u00e1tico\n        try:\n            self.llm_adapter = LLMFactory.get_adapter()\n            if SupervisorAgent:\n                self.supervisor = SupervisorAgent(gemini_adapter=self.llm_adapter)\n                self.logger.info(\n                    \"QueryProcessor inicializado e pronto para delegar ao SupervisorAgent.\"\n                )\n            else:\n                self.supervisor = None\n                self.logger.warning(\"SupervisorAgent n\u00e3o dispon\u00edvel (erro de importa\u00e7\u00e3o).\")\n                \n            self.cache = Cache()\n\n        except ValueError as e:\n            self.logger.error(f\"Erro ao inicializar QueryProcessor: {e}\")\n            self.llm_adapter = None\n            self.supervisor = None\n            self.cache = Cache()\n            raise RuntimeError(\n                \"GEMINI_API_KEY n\u00e3o configurada. Configure a chave da API do Google Gemini nos secrets do Streamlit Cloud.\"\n            ) from e\n\n    def process_query(self, query: str) -> dict:\n        \"\"\"\n        Processa a consulta do usu\u00e1rio, delegando-a diretamente ao SupervisorAgent.\n\n        Args:\n            query (str): A consulta do usu\u00e1rio.\n\n        Returns:\n            dict: O resultado do processamento pelo agente especialista apropriado.\n        \"\"\"\n        # \u2705 FASE 1: QUICK RESPONSE BYPASS (< 500ms)\n        # Responde queries simples SEM LLM (95% dos casos)\n        if self.quick_response:\n            quick_answer = self.quick_response.try_quick_response(query)\n            if quick_answer:\n                self.logger.info(f\"\u26a1 Quick Response! Tempo: < 500ms | Query: {query[:50]}\")\n                return {\"type\": \"text\", \"output\": quick_answer}\n\n        # Verificar se o supervisor foi inicializado\n        if self.supervisor is None:\n            return {\n                \"type\": \"text\",\n                \"output\": \"\u26a0\ufe0f **Sistema de Agentes Indispon\u00edvel**\\n\\nO Agente Supervisor n\u00e3o p\u00f4de ser inicializado (poss\u00edvel erro de importa\u00e7\u00e3o ou configura\u00e7\u00e3o). Apenas consultas simples (Quick Response) est\u00e3o dispon\u00edveis.\"\n            }\n\n        # Interceptar perguntas sobre o nome do agente\n        if query.lower() in [\"qual seu nome\", \"quem \u00e9 voc\u00ea\", \"qual o seu nome\"]:\n            return {\n                \"type\": \"text\",\n                \"output\": \"Eu sou um Agente de Neg\u00f3cios, pronto para ajudar com suas an\u00e1lises de dados.\"\n            }\n\n        cached_result = self.cache.get(query)\n        if cached_result:\n            self.logger.info(\n                f'Resultado recuperado do cache para a consulta: \"{query}\"'\n            )\n            return cached_result\n\n        self.logger.info(f'Delegando a consulta para o Supervisor: \"{query}\"')\n        result = self.supervisor.route_query(query)\n        self.cache.set(query, result)\n        return result\n\n    def stream_query(self, query: str):\n        \"\"\"\n        Processa a consulta do usu\u00e1rio com streaming de eventos do agente.\n\n        Args:\n            query (str): A consulta do usu\u00e1rio.\n\n        Yields:\n            dict: Eventos do agente (chunks de texto, a\u00e7\u00f5es, etc.)", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4513, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d3d29dc1-a1cd-4bff-aee9-9faf609c75f9": {"__data__": {"id_": "d3d29dc1-a1cd-4bff-aee9-9faf609c75f9", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\query_processor.py", "language": "python", "lines": 151, "filename": "query_processor.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\query_processor.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\query_processor.py", "language": "python", "lines": 151, "filename": "query_processor.py"}, "hash": "cb6954c9b10f2f62647b947e3144673779d44d13293a849da6f53d28deb9572b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6a5771e6-6c98-4601-8b3c-f482e6650bb4", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\query_processor.py", "language": "python", "lines": 151, "filename": "query_processor.py"}, "hash": "8b91c0b79d812642289385884e26fd9e75c8097f54121a9138a263669e8a81d2", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\n        # \u26a1 OTIMIZA\u00c7\u00c3O: Tentar resposta r\u00e1pida primeiro (< 500ms)\n        if self.quick_response:\n            quick_answer = self.quick_response.try_quick_response(query)\n            if quick_answer:\n                self.logger.info(f\"\u26a1 Resposta r\u00e1pida encontrada! Tempo: < 500ms\")\n                # Enviar resposta r\u00e1pida em chunks para simular streaming\n                for char in quick_answer:\n                    yield {\n                        \"type\": \"text\",\n                        \"content\": char\n                    }\n                return\n\n        # Verificar se o supervisor foi inicializado\n        if self.supervisor is None:\n            yield {\n                \"type\": \"text\",\n                \"content\": \"\u26a0\ufe0f **Sistema de Agentes Indispon\u00edvel**\\n\\nO Agente Supervisor n\u00e3o p\u00f4de ser inicializado.\"\n            }\n            return\n\n        # Interceptar perguntas simples (sem cache em streaming)\n        if query.lower() in [\"qual seu nome\", \"quem \u00e9 voc\u00ea\", \"qual o seu nome\"]:\n            yield {\n                \"type\": \"text\",\n                \"content\": \"Eu sou um Agente de Neg\u00f3cios, pronto para ajudar com suas an\u00e1lises de dados.\"\n            }\n            return\n\n        self.logger.info(f'Streaming da consulta para o Supervisor: \"{query}\"')\n        \n        # Delegar para m\u00e9todo de streaming do supervisor\n        for event in self.supervisor.stream_query(query):\n            yield event", "mimetype": "text/plain", "start_char_idx": 4522, "end_char_idx": 5936, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ba52c219-6524-40f0-9eab-9073505fa1ec": {"__data__": {"id_": "ba52c219-6524-40f0-9eab-9073505fa1ec", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\robust_chatbi.py", "language": "python", "lines": 318, "filename": "robust_chatbi.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\robust_chatbi.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\robust_chatbi.py", "language": "python", "lines": 318, "filename": "robust_chatbi.py"}, "hash": "6c1fc9b5a5bc689f5d1ace9af8cfd752cde8db64d642b754548a00844af26a3e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1e3feb3f-b17d-4af3-82a5-0e5d36180f83", "node_type": "1", "metadata": {}, "hash": "56d22abc681205c99bd9a20218a76aa6cda0e4cd61e1517de59e59deaca40ddf", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nChat BI - Sistema ROBUSTO com Regex (SEM depend\u00eancia de API)\nSolu\u00e7\u00e3o definitiva que funciona 100% offline\n\"\"\"\n\nimport polars as pl\nfrom pathlib import Path\nimport re\nfrom typing import Dict, Any, List, Optional\n\n\nclass RobustChatBI:\n    \"\"\"\n    Sistema robusto de Chat BI usando REGEX\n    N\u00e3o depende de APIs externas - funciona 100% offline\n    \"\"\"\n    \n    def __init__(self, parquet_path: Path):\n        self.parquet_path = parquet_path\n        \n        # Carregar schema do Parquet\n        lf = pl.scan_parquet(parquet_path)\n        self.schema = lf.collect_schema()\n        self.columns = list(self.schema.names())\n    \n    def process_query(self, user_query: str) -> Dict[str, Any]:\n        \"\"\"\n        Processa pergunta do usu\u00e1rio usando REGEX robusto\n        Retorna resposta estruturada com dados e texto\n        \"\"\"\n        \n        query_lower = user_query.lower()\n        \n        # 1. Detec\u00e7\u00e3o de sauda\u00e7\u00f5es\n        saudacoes = [\"ol\u00e1\", \"oi\", \"ola\", \"hello\", \"boa tarde\", \"bom dia\", \"boa noite\"]\n        if any(saudacao in query_lower for saudacao in saudacoes):\n            return {\n                \"success\": True,\n                \"text\": \"\ud83d\udc4b Ol\u00e1! Sou seu assistente de BI.\\n\\nPosso ajudar com:\\n\u2022 Consultas de pre\u00e7os\\n\u2022 An\u00e1lise de vendas\\n\u2022 Informa\u00e7\u00f5es de produtos\\n\\nFa\u00e7a uma pergunta!\",\n                \"data\": None\n            }\n        \n        # 2. Extrair informa\u00e7\u00f5es com REGEX\n        produto = self._extract_produto(query_lower)\n        une = self._extract_une(query_lower)\n        periodo = self._extract_periodo(query_lower)\n        tipo_consulta = self._detect_query_type(query_lower)\n        \n        # 3. Executar consulta\n        try:\n            result = self._execute_query(produto, une, periodo, tipo_consulta)\n            return result\n        except KeyError as e:\n            print(f\"[ERROR] KeyError ao executar consulta: {e}\")\n            print(f\"[DEBUG] Produto: {produto}, UNE: {une}, Periodo: {periodo}\")\n            import traceback\n            traceback.print_exc()\n            return self._fallback_response(user_query)\n        except Exception as e:\n            print(f\"[ERROR] Erro ao executar consulta: {e}\")\n            import traceback\n            traceback.print_exc()\n            return self._fallback_response(user_query)\n    \n    def _extract_produto(self, query: str) -> Optional[str]:\n        \"\"\"Extrai c\u00f3digo ou nome do produto usando regex\"\"\"\n        # 1. Tentar c\u00f3digo num\u00e9rico (prioridade)\n        patterns_code = [\n            r'produto\\s+(\\d{4,6})',\n            r'prod\\s+(\\d{4,6})',\n            r'c\u00f3digo\\s+(\\d{4,6})',\n            r'codigo\\s+(\\d{4,6})',\n            r'\\b(\\d{5,6})\\b',  # N\u00famero de 5-6 d\u00edgitos isolado\n        ]\n        for pattern in patterns_code:\n            match = re.search(pattern, query)\n            if match:\n                return match.group(1)\n        \n        # 2. Tentar nome do produto (texto ap\u00f3s 'produto')\n        # Captura tudo at\u00e9 a pr\u00f3xima palavra-chave (na, em, une, loja, nos, etc) ou fim da string\n        pattern_name = r'(?:produto|prod|vendas de|venda de)\\s+(.+?)(?:\\s+na\\s+|\\s+em\\s+|\\s+da\\s+|\\s+do\\s+|\\s+no\\s+|\\s+nos\\s+|\\s+une|\\s+loja|$)'\n        match = re.search(pattern_name, query)\n        if match:\n            # Limpar espa\u00e7os extras\n            return match.group(1).strip()\n            \n        return None\n    \n    def _extract_une(self, query: str) -> Optional[str]:\n        \"\"\"Extrai c\u00f3digo ou nome da UNE usando regex\"\"\"\n        # 1. Tentar c\u00f3digo num\u00e9rico\n        patterns_code = [\n            r'une\\s+(\\d+)',\n            r'loja\\s+(\\d+)',\n            r'unidade\\s+(\\d+)',\n        ]\n        for pattern in patterns_code:\n            match = re.search(pattern, query)\n            if match:\n                return match.group(1)\n        \n        # 2.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3763, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1e3feb3f-b17d-4af3-82a5-0e5d36180f83": {"__data__": {"id_": "1e3feb3f-b17d-4af3-82a5-0e5d36180f83", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\robust_chatbi.py", "language": "python", "lines": 318, "filename": "robust_chatbi.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\robust_chatbi.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\robust_chatbi.py", "language": "python", "lines": 318, "filename": "robust_chatbi.py"}, "hash": "6c1fc9b5a5bc689f5d1ace9af8cfd752cde8db64d642b754548a00844af26a3e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ba52c219-6524-40f0-9eab-9073505fa1ec", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\robust_chatbi.py", "language": "python", "lines": 318, "filename": "robust_chatbi.py"}, "hash": "14b2b996c0c7584e458a6180b68ee64315deedb60142bcc770a7a8c44a73e439", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5e7c0ee4-5508-44f0-a41e-845d536efafa", "node_type": "1", "metadata": {}, "hash": "a131e30714695292c692297508d53325d258ced7622da9ca5c311ca95a560179", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Tentar nome da UNE (texto ap\u00f3s 'une'/'loja')\n        pattern_name = r'(?:une|loja|unidade|na)\\s+(.+?)(?:\\s+nos\\s+|\\s+no\\s+|\\s+do\\s+|\\s+da\\s+|\\s+de\\s+|\\s+produto|$)'\n        match = re.search(pattern_name, query)\n        if match:\n            val = match.group(1).strip()\n            # Evitar capturar \"une\" se for parte de outra palavra ou muito curto\n            if len(val) > 1 and val.lower() not in [\"scr\", \"meses\", \"dias\"]:\n                return val.upper()\n        \n        # Caso especial: \"UNE SCR\" ou apenas \"SCR\"\n        if \"scr\" in query:\n            return \"SCR\"\n            \n        return None\n    \n    def _extract_periodo(self, query: str) -> List[str]:\n        \"\"\"Extrai per\u00edodo usando regex\"\"\"\n        # Padr\u00f5es: \"\u00faltimos 3 meses\", \"\u00faltimo m\u00eas\", \"3 meses\", \"m\u00eas 1\"\n        \n        # \u00daltimos X meses\n        match = re.search(r'(?:\u00faltimos?|ultimos?)\\s+(\\d+)\\s+mes', query)\n        if match:\n            num_meses = int(match.group(1))\n            return [f\"MES_{str(i).zfill(2)}\" for i in range(1, min(num_meses + 1, 13))]\n        \n        # M\u00eas espec\u00edfico\n        match = re.search(r'm\u00eas\\s+(\\d+)', query)\n        if match:\n            mes_num = int(match.group(1))\n            return [f\"MES_{str(mes_num).zfill(2)}\"]\n        \n        # Default: \u00faltimos 3 meses\n        if \"mes\" in query or \"m\u00eas\" in query:\n            return [\"MES_01\", \"MES_02\", \"MES_03\"]\n        \n        return [\"MES_01\"]\n    \n    def _detect_query_type(self, query: str) -> str:\n        \"\"\"Detecta tipo de consulta\"\"\"\n        if any(word in query for word in [\"venda\", \"vendas\", \"quantidade\", \"quantas\", \"quanto\"]):\n            return \"vendas\"\n        elif any(word in query for word in [\"pre\u00e7o\", \"preco\", \"valor\", \"custo\"]):\n            return \"preco\"\n        elif any(word in query for word in [\"total\", \"soma\", \"somar\"]):\n            return \"total\"\n        else:\n            return \"geral\"\n    \n    def _execute_query(self, produto: Optional[str], une: Optional[str], \n                      periodo: List[str], tipo: str) -> Dict[str, Any]:\n        \"\"\"Executa consulta no Parquet\"\"\"\n        \n        lf = pl.scan_parquet(self.parquet_path)\n        \n        # Construir filtros\n        filters = []\n        \n        # Filtro de PRODUTO\n        if produto:\n            if produto.isdigit():\n                # \u00c9 c\u00f3digo num\u00e9rico\n                try:\n                    produto_int = int(produto)\n                    filters.append(pl.col(\"PRODUTO\") == produto_int)\n                except ValueError:\n                    filters.append(pl.col(\"PRODUTO\").cast(pl.Utf8) == produto)\n            else:\n                # \u00c9 nome do produto - busca textual (case insensitive)\n                # Verifica se coluna NOME existe\n                if \"NOME\" in self.columns:\n                    filters.append(pl.col(\"NOME\").str.to_uppercase().str.contains(produto.upper()))\n                else:\n                    # Se n\u00e3o tem coluna NOME, n\u00e3o d\u00e1 pra buscar por nome\n                    return {\n                        \"success\": False,\n                        \"text\": f\"\u274c Desculpe, n\u00e3o consigo buscar produtos por nome ('{produto}') neste conjunto de dados. Por favor, use o c\u00f3digo do produto.", "mimetype": "text/plain", "start_char_idx": 3764, "end_char_idx": 6937, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5e7c0ee4-5508-44f0-a41e-845d536efafa": {"__data__": {"id_": "5e7c0ee4-5508-44f0-a41e-845d536efafa", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\robust_chatbi.py", "language": "python", "lines": 318, "filename": "robust_chatbi.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\robust_chatbi.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\robust_chatbi.py", "language": "python", "lines": 318, "filename": "robust_chatbi.py"}, "hash": "6c1fc9b5a5bc689f5d1ace9af8cfd752cde8db64d642b754548a00844af26a3e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1e3feb3f-b17d-4af3-82a5-0e5d36180f83", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\robust_chatbi.py", "language": "python", "lines": 318, "filename": "robust_chatbi.py"}, "hash": "827c28f74dfc3da85d6c019b070721bf33aaf305461dd4f1834196a0b52c2e5e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d51869ec-548e-43f7-ac9c-a6c2dc2c3c71", "node_type": "1", "metadata": {}, "hash": "ae8a1a967320b151a6b8e63e3811a19d19b35f6a362978d5e8acc277ce7930fe", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Por favor, use o c\u00f3digo do produto.\",\n                        \"data\": None\n                    }\n\n        # Filtro de UNE\n        if une:\n            if une.isdigit():\n                # \u00c9 c\u00f3digo num\u00e9rico\n                filters.append(\n                    (pl.col(\"UNE\").cast(pl.Utf8) == une) | \n                    (pl.col(\"UNE\") == int(une))\n                )\n            else:\n                # \u00c9 nome da UNE ou c\u00f3digo alfanum\u00e9rico (ex: SCR)\n                if \"UNE_NOME\" in self.columns:\n                    filters.append(\n                        (pl.col(\"UNE_NOME\").str.to_uppercase().str.contains(une.upper())) |\n                        (pl.col(\"UNE\").cast(pl.Utf8).str.to_uppercase() == une.upper())\n                    )\n                else:\n                    # Tentar apenas na coluna UNE como string\n                    filters.append(pl.col(\"UNE\").cast(pl.Utf8).str.to_uppercase() == une.upper())\n        \n        # Aplicar filtros\n        if filters:\n            query = lf.filter(pl.all_horizontal(filters))\n        else:\n            query = lf\n        \n        # Selecionar colunas\n        cols_to_select = [\"PRODUTO\", \"NOME\", \"UNE\"] + [p for p in periodo if p in self.columns]\n        \n        # Executar com tratamento de erro\n        try:\n            result = query.select(cols_to_select).head(1).collect()\n        except Exception as e:\n            print(f\"[ERROR] Erro ao executar query Polars: {e}\")\n            print(f\"[DEBUG] Colunas selecionadas: {cols_to_select}\")\n            import traceback\n            traceback.print_exc()\n            return {\n                \"success\": False,\n                \"text\": f\"\u274c Erro ao processar consulta. Por favor, tente novamente.", "mimetype": "text/plain", "start_char_idx": 6902, "end_char_idx": 8596, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d51869ec-548e-43f7-ac9c-a6c2dc2c3c71": {"__data__": {"id_": "d51869ec-548e-43f7-ac9c-a6c2dc2c3c71", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\robust_chatbi.py", "language": "python", "lines": 318, "filename": "robust_chatbi.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\robust_chatbi.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\robust_chatbi.py", "language": "python", "lines": 318, "filename": "robust_chatbi.py"}, "hash": "6c1fc9b5a5bc689f5d1ace9af8cfd752cde8db64d642b754548a00844af26a3e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5e7c0ee4-5508-44f0-a41e-845d536efafa", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\robust_chatbi.py", "language": "python", "lines": 318, "filename": "robust_chatbi.py"}, "hash": "2dbe9e566b2c10e4ce39e9257686d09d8c9d3a98f1895eb663629b67fb4b785d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Por favor, tente novamente.\",\n                \"data\": None\n            }\n        \n        # Formatar resposta\n        if len(result) > 0:\n            row = result.row(0, named=True)\n            \n            nome = row.get(\"NOME\", \"Produto\")\n            produto_id = row.get(\"PRODUTO\", produto or \"N/A\")\n            une_id = row.get(\"UNE\", une or \"N/A\")\n            \n            # Calcular valores\n            valores = []\n            for mes in periodo:\n                # Usar .get() para evitar KeyError se a coluna n\u00e3o existir\n                if mes in row:\n                    val = row.get(mes)\n                    # Converter para float se necess\u00e1rio\n                    if val is not None:\n                        valores.append(float(val))\n            \n            total = sum(valores) if valores else 0\n            \n            # Formatar texto da resposta\n            if tipo == \"vendas\" or tipo == \"total\":\n                response_text = f\"\ud83d\udcca **Produto {produto_id}** na UNE {une_id}:\\n\\n\"\n                response_text += f\"**Nome:** {nome}\\n\\n\"\n                \n                if len(valores) > 1:\n                    for i, (mes, valor) in enumerate(zip(periodo, valores), 1):\n                        response_text += f\"**M\u00eas {i}:** {valor:,.0f}\\n\"\n                    response_text += f\"\\n**Total:** {total:,.0f}\"\n                else:\n                    response_text += f\"**Valor:** {total:,.0f}\"\n            \n            elif tipo == \"preco\":\n                response_text = f\"\ud83d\udcca **Produto {produto_id}** na UNE {une_id}:\\n\\n\"\n                response_text += f\"**Nome:** {nome}\\n\"\n                response_text += f\"**Pre\u00e7o:** R$ {total:,.2f}\"\n            \n            else:\n                response_text = f\"\ud83d\udcca **Produto {produto_id}** na UNE {une_id}:\\n\\n\"\n                response_text += f\"**Nome:** {nome}\\n\"\n                response_text += f\"**Valor:** {total:,.0f}\"\n            \n            return {\n                \"success\": True,\n                \"text\": response_text,\n                \"data\": row\n            }\n        \n        # Nenhum resultado encontrado\n        if produto and une:\n            # Verificar se o produto existe em QUALQUER UNE\n            lf = pl.scan_parquet(self.parquet_path)\n            \n            # Filtro de produto (int ou str)\n            prod_filter = None\n            try:\n                prod_filter = (pl.col(\"PRODUTO\") == int(produto))\n            except ValueError:\n                prod_filter = (pl.col(\"PRODUTO\").cast(pl.Utf8) == produto)\n                \n            # Buscar UNEs dispon\u00edveis\n            unes_disponiveis = lf.filter(prod_filter).select(\"UNE\").unique().head(5).collect()\n            \n            if len(unes_disponiveis) > 0:\n                lista_unes = [str(r[0]) for r in unes_disponiveis.rows()]\n                unes_str = \", \".join(lista_unes)\n                return {\n                    \"success\": False,\n                    \"text\": f\"\u274c O produto {produto} n\u00e3o foi encontrado na UNE {une}.\\n\\n\u2705 Mas ele est\u00e1 dispon\u00edvel nas seguintes UNEs: **{unes_str}**...\\n\\nTente consultar uma dessas lojas!\",\n                    \"data\": None\n                }\n            else:\n                return {\n                    \"success\": False,\n                    \"text\": f\"\u274c O produto {produto} n\u00e3o foi encontrado em nenhuma UNE.\",\n                    \"data\": None\n                }\n                \n        elif produto:\n            return {\n                \"success\": False,\n                \"text\": f\"\u274c N\u00e3o encontrei o produto {produto}.\\n\\nVerifique se o c\u00f3digo est\u00e1 correto.\",\n                \"data\": None\n            }\n        else:\n            return self._fallback_response(\"\")\n    \n    def _fallback_response(self, query: str) -> Dict[str, Any]:\n        \"\"\"Resposta de fallback\"\"\"\n        return {\n            \"success\": False,\n            \"text\": \"\ud83e\udd14 N\u00e3o consegui entender sua pergunta.\\n\\nTente perguntas como:\\n\u2022 'Quantas vendas do produto 59294 na UNE 261 nos \u00faltimos 3 meses?'\\n\u2022 'Qual o pre\u00e7o do produto 59294 na UNE SCR?'\\n\u2022 'Total de vendas do produto 12345'\",\n            \"data\": None\n        }", "mimetype": "text/plain", "start_char_idx": 8569, "end_char_idx": 12655, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "766ada64-ad24-43aa-a820-21d7237d2949": {"__data__": {"id_": "766ada64-ad24-43aa-a820-21d7237d2949", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\supabase_client.py", "language": "python", "lines": 74, "filename": "supabase_client.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\supabase_client.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\supabase_client.py", "language": "python", "lines": 74, "filename": "supabase_client.py"}, "hash": "0a9d1c86d0356b24c767c3afbb6587bb87a182264a7259bdaed586c1f13cc490", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nSupabase Client Configuration\nSingleton instance for Supabase authentication and database access\n\"\"\"\n\nfrom supabase import create_client, Client\nfrom app.config.settings import get_settings\n\nsettings = get_settings()\n\n# Singleton Supabase clients\n_supabase_client: Client | None = None\n_supabase_admin_client: Client | None = None\n\n\ndef get_supabase_client() -> Client:\n    \"\"\"Get or create Supabase client instance (using anon key for regular operations)\"\"\"\n    global _supabase_client\n\n    # Only create client if Supabase auth is enabled\n    if not settings.USE_SUPABASE_AUTH:\n        raise ValueError(\n            \"Supabase authentication is disabled. \"\n            \"Set USE_SUPABASE_AUTH=true in .env to enable\"\n        )\n\n    if _supabase_client is None:\n        if not settings.SUPABASE_URL or not settings.SUPABASE_ANON_KEY:\n            raise ValueError(\n                \"Supabase credentials not configured. \"\n                \"Please set SUPABASE_URL and SUPABASE_ANON_KEY in .env\"\n            )\n\n        _supabase_client = create_client(\n            settings.SUPABASE_URL,\n            settings.SUPABASE_ANON_KEY\n        )\n\n    return _supabase_client\n\n\ndef get_supabase_admin_client() -> Client:\n    \"\"\"\n    Get or create Supabase ADMIN client (using service_role key).\n    This client has elevated privileges and should ONLY be used for admin operations\n    like creating/deleting users.\n    \"\"\"\n    global _supabase_admin_client\n\n    if not settings.USE_SUPABASE_AUTH:\n        raise ValueError(\n            \"Supabase authentication is disabled. \"\n            \"Set USE_SUPABASE_AUTH=true in .env to enable\"\n        )\n\n    if _supabase_admin_client is None:\n        if not settings.SUPABASE_URL or not settings.SUPABASE_SERVICE_ROLE_KEY:\n            raise ValueError(\n                \"Supabase admin credentials not configured. \"\n                \"Please set SUPABASE_URL and SUPABASE_SERVICE_ROLE_KEY in .env\"\n            )\n\n        _supabase_admin_client = create_client(\n            settings.SUPABASE_URL,\n            settings.SUPABASE_SERVICE_ROLE_KEY\n        )\n\n    return _supabase_admin_client\n\n\n# Convenience exports\nsupabase = get_supabase_client\nsupabase_admin = get_supabase_admin_client", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2211, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f8d95136-8ae4-4653-b70b-40732bd50f33": {"__data__": {"id_": "f8d95136-8ae4-4653-b70b-40732bd50f33", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\supabase_user_service.py", "language": "python", "lines": 323, "filename": "supabase_user_service.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\supabase_user_service.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\supabase_user_service.py", "language": "python", "lines": 323, "filename": "supabase_user_service.py"}, "hash": "65a6844158b2820a9376726a19423455c99b260ecc8a64eac589d7449db66b6f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6f05f933-a8ab-4fa9-a1ff-16837e5f6bce", "node_type": "1", "metadata": {}, "hash": "74d699b354219340145b7941a0bb1d0d18635ca8b0878567aa414ec379f25a61", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nSupabase User Management Service\nHandles user CRUD operations with Supabase Auth + user_profiles table\n\"\"\"\n\nimport logging\nfrom typing import Optional\nfrom datetime import datetime\n\n# Use ADMIN client for user management (requires service_role key)\nfrom app.core.supabase_client import get_supabase_admin_client\nfrom app.config.settings import get_settings\n\nsettings = get_settings()\nlogger = logging.getLogger(__name__)\nsecurity_logger = logging.getLogger(\"security\")\n\n\nclass SupabaseUserService:\n    \"\"\"Service for managing users in Supabase\"\"\"\n\n    def __init__(self):\n        self._client = None\n\n    @property\n    def client(self):\n        \"\"\"Lazy load Supabase ADMIN client only when needed\"\"\"\n        if self._client is None:\n            if not settings.USE_SUPABASE_AUTH:\n                raise ValueError(\n                    \"Supabase authentication is disabled. \"\n                    \"This service requires USE_SUPABASE_AUTH=true in .env\"\n                )\n            # Use ADMIN client with service_role key for user management\n            self._client = get_supabase_admin_client()\n        return self._client\n\n    def create_user(\n        self,\n        email: str,\n        password: str,\n        username: str,\n        role: str = \"user\",\n        full_name: Optional[str] = None,\n        allowed_segments: Optional[list[str]] = None\n    ) -> dict:\n        \"\"\"\n        Create a new user in Supabase Auth and user_profiles table\n\n        Args:\n            email: User's email\n            password: User's password\n            username: Username for the system\n            role: User role (admin, user, viewer)\n            full_name: Optional full name\n            allowed_segments: List of allowed segments\n\n        Returns:\n            Dictionary with user data\n\n        Raises:\n            Exception if user creation fails\n        \"\"\"\n        try:\n            # 1. Create user in Supabase Auth\n            auth_response = self.client.auth.admin.create_user({\n                \"email\": email,\n                \"password\": password,\n                \"email_confirm\": True,  # Auto-confirm email\n                \"user_metadata\": {\n                    \"username\": username,\n                    \"role\": role,\n                    \"full_name\": full_name or username,\n                    \"allowed_segments\": allowed_segments or []\n                }\n            })\n\n            if not auth_response.user:\n                raise Exception(\"Failed to create user in Supabase Auth\")\n\n            user_id = auth_response.user.id\n\n            # 2. Create profile in user_profiles table\n            profile_data = {\n                \"id\": str(user_id),\n                \"username\": username,\n                \"role\": role,\n                \"full_name\": full_name or username,\n                \"created_at\": datetime.utcnow().isoformat(),\n                \"updated_at\": datetime.utcnow().isoformat()\n            }\n\n            profile_response = self.client.table(\"user_profiles\").insert(profile_data).execute()\n\n            security_logger.info(f\"User '{username}' created successfully in Supabase (ID: {user_id})\")\n\n            return {\n                \"id\": str(user_id),\n                \"email\": email,\n                \"username\": username,\n                \"role\": role,\n                \"full_name\": full_name or username,\n                \"allowed_segments\": allowed_segments or [],\n                \"is_active\": True,\n                \"created_at\": datetime.utcnow().isoformat()\n            }\n\n        except Exception as e:\n            import traceback\n            error_details = traceback.format_exc()\n            security_logger.error(f\"Failed to create user '{username}': {e}\\n{error_details}\")\n            raise Exception(f\"Failed to create user: {str(e)}\")\n\n    def list_users(self, limit: int = 100) -> list[dict]:\n        \"\"\"\n        List all users from Supabase\n\n        Args:\n            limit: Maximum number of users to return\n\n        Returns:\n            List of user dictionaries\n        \"\"\"\n        try:\n            # Get users from user_profiles table (which links to auth.users)\n            response = self.client.table(\"user_profiles\").select(\"*\").limit(limit).execute()\n\n            users = []\n            for profile in response.data:\n                # Get auth user data to check email and status\n                try:\n                    auth_user = self.client.auth.admin.get_user_by_id(profile[\"id\"])\n                    email = auth_user.user.email if auth_user.user else \"N/A\"\n                    # Check if user is banned - the attribute may vary by Supabase version\n                    is_active = True\n                    if auth_user.user:\n                        # Try different attribute names for banned status\n                        if hasattr(auth_user.user, 'banned_until') and auth_user.user.banned_until:\n                            is_active = False\n                        elif hasattr(auth_user.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4933, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "6f05f933-a8ab-4fa9-a1ff-16837e5f6bce": {"__data__": {"id_": "6f05f933-a8ab-4fa9-a1ff-16837e5f6bce", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\supabase_user_service.py", "language": "python", "lines": 323, "filename": "supabase_user_service.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\supabase_user_service.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\supabase_user_service.py", "language": "python", "lines": 323, "filename": "supabase_user_service.py"}, "hash": "65a6844158b2820a9376726a19423455c99b260ecc8a64eac589d7449db66b6f", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f8d95136-8ae4-4653-b70b-40732bd50f33", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\supabase_user_service.py", "language": "python", "lines": 323, "filename": "supabase_user_service.py"}, "hash": "a92b0584312935ac14f93b4da6c7291ed71701444af0b2ea10a3e47196c692db", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "dc1b766f-8d21-4d66-98b9-a8a45ec5e5e8", "node_type": "1", "metadata": {}, "hash": "bf6cba463f1a844afddc95bb66311cefa7b0f6161b1bf36de0b52ed0b59eeed5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "user.banned_until:\n                            is_active = False\n                        elif hasattr(auth_user.user, 'is_banned') and auth_user.user.is_banned:\n                            is_active = False\n                    # Get allowed_segments from metadata\n                    user_metadata = auth_user.user.user_metadata or {}\n                    allowed_segments = user_metadata.get(\"allowed_segments\", [])\n                    logger.info(f\"User {profile['id']}: email={email}, segments={allowed_segments}\")\n                except Exception as e:\n                    logger.warning(f\"Failed to get auth user data for {profile['id']}: {e}\")\n                    email = \"N/A\"\n                    is_active = True\n                    allowed_segments = []\n\n                users.append({\n                    \"id\": profile[\"id\"],\n                    \"username\": profile.get(\"username\", \"N/A\"),\n                    \"email\": email,\n                    \"role\": profile.get(\"role\", \"user\"),\n                    \"full_name\": profile.get(\"full_name\", \"\"),\n                    \"allowed_segments\": allowed_segments,\n                    \"is_active\": is_active,\n                    \"created_at\": profile.get(\"created_at\", \"\"),\n                    \"updated_at\": profile.get(\"updated_at\", \"\")\n                })\n\n            logger.info(f\"Listed {len(users)} users from Supabase\")\n            return users\n\n        except Exception as e:\n            logger.error(f\"Failed to list users: {e}\")\n            return []\n\n    def get_user(self, user_id: str) -> Optional[dict]:\n        \"\"\"\n        Get a single user by ID\n\n        Args:\n            user_id: User's UUID\n\n        Returns:\n            User dictionary or None if not found\n        \"\"\"\n        try:\n            # Get profile\n            profile_response = self.client.table(\"user_profiles\").select(\"*\").eq(\"id\", user_id).execute()\n\n            if not profile_response.data:\n                return None\n\n            profile = profile_response.data[0]\n\n            # Get auth user data\n            auth_user = self.client.auth.admin.get_user_by_id(user_id)\n            email = auth_user.user.email if auth_user.user else \"N/A\"\n            is_active = not auth_user.user.banned_until if auth_user.user else True\n            \n            user_metadata = auth_user.user.user_metadata or {}\n            allowed_segments = user_metadata.get(\"allowed_segments\", [])\n\n            return {\n                \"id\": profile[\"id\"],\n                \"username\": profile.get(\"username\", \"N/A\"),\n                \"email\": email,\n                \"role\": profile.get(\"role\", \"user\"),\n                \"full_name\": profile.get(\"full_name\", \"\"),\n                \"allowed_segments\": allowed_segments,\n                \"is_active\": is_active,\n                \"created_at\": profile.get(\"created_at\", \"\"),\n                \"updated_at\": profile.get(\"updated_at\", \"\")\n            }\n\n        except Exception as e:\n            logger.error(f\"Failed to get user {user_id}: {e}\")\n            return None\n\n    def update_user(\n        self,\n        user_id: str,\n        email: Optional[str] = None,\n        username: Optional[str] = None,\n        role: Optional[str] = None,\n        full_name: Optional[str] = None,\n        password: Optional[str] = None,\n        is_active: Optional[bool] = None,", "mimetype": "text/plain", "start_char_idx": 4821, "end_char_idx": 8133, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "dc1b766f-8d21-4d66-98b9-a8a45ec5e5e8": {"__data__": {"id_": "dc1b766f-8d21-4d66-98b9-a8a45ec5e5e8", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\supabase_user_service.py", "language": "python", "lines": 323, "filename": "supabase_user_service.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\supabase_user_service.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\supabase_user_service.py", "language": "python", "lines": 323, "filename": "supabase_user_service.py"}, "hash": "65a6844158b2820a9376726a19423455c99b260ecc8a64eac589d7449db66b6f", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6f05f933-a8ab-4fa9-a1ff-16837e5f6bce", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\supabase_user_service.py", "language": "python", "lines": 323, "filename": "supabase_user_service.py"}, "hash": "cd35877b33d3e5de23e9e4bed54d155df8932f2bfb000f7aeab06f1899cb0dfb", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "is_active: Optional[bool] = None,\n        allowed_segments: Optional[list[str]] = None\n    ) -> dict:\n        \"\"\"\n        Update user in Supabase Auth and user_profiles\n\n        Args:\n            user_id: User's UUID\n            email: New email (optional)\n            username: New username (optional)\n            role: New role (optional)\n            full_name: New full name (optional)\n            password: New password (optional)\n            is_active: Active status (optional)\n            allowed_segments: New allowed segments (optional)\n\n        Returns:\n            Updated user dictionary\n\n        Raises:\n            Exception if update fails\n        \"\"\"\n        try:\n            # Update auth user if needed\n            auth_updates = {}\n            user_metadata_updates = {}\n            \n            if email:\n                auth_updates[\"email\"] = email\n            if password:\n                auth_updates[\"password\"] = password\n            if is_active is not None:\n                # Ban/unban user based on is_active\n                if not is_active:\n                    auth_updates[\"ban_duration\"] = \"876000h\"  # ~100 years (effectively permanent)\n                else:\n                    auth_updates[\"ban_duration\"] = \"none\"\n            \n            # Update metadata\n            if username:\n                user_metadata_updates[\"username\"] = username\n            if role:\n                user_metadata_updates[\"role\"] = role\n            if full_name:\n                user_metadata_updates[\"full_name\"] = full_name\n            if allowed_segments is not None:\n                user_metadata_updates[\"allowed_segments\"] = allowed_segments\n\n            if user_metadata_updates:\n                auth_updates[\"user_metadata\"] = user_metadata_updates\n\n            if auth_updates:\n                self.client.auth.admin.update_user_by_id(user_id, auth_updates)\n\n            # Update profile\n            profile_updates = {\"updated_at\": datetime.utcnow().isoformat()}\n            if username:\n                profile_updates[\"username\"] = username\n            if role:\n                profile_updates[\"role\"] = role\n            if full_name:\n                profile_updates[\"full_name\"] = full_name\n\n            self.client.table(\"user_profiles\").update(profile_updates).eq(\"id\", user_id).execute()\n\n            security_logger.info(f\"User {user_id} updated successfully\")\n\n            # Return updated user\n            return self.get_user(user_id)\n\n        except Exception as e:\n            security_logger.error(f\"Failed to update user {user_id}: {e}\")\n            raise Exception(f\"Failed to update user: {str(e)}\")\n\n    def delete_user(self, user_id: str) -> bool:\n        \"\"\"\n        Delete user from Supabase Auth and user_profiles\n\n        Args:\n            user_id: User's UUID\n\n        Returns:\n            True if successful, False otherwise\n        \"\"\"\n        try:\n            # Delete from user_profiles first\n            self.client.table(\"user_profiles\").delete().eq(\"id\", user_id).execute()\n\n            # Delete from auth\n            self.client.auth.admin.delete_user(user_id)\n\n            security_logger.info(f\"User {user_id} deleted successfully\")\n            return True\n\n        except Exception as e:\n            security_logger.error(f\"Failed to delete user {user_id}: {e}\")\n            return False\n\n\n# Global instance\nsupabase_user_service = SupabaseUserService()", "mimetype": "text/plain", "start_char_idx": 8100, "end_char_idx": 11513, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ed69023f-2dd5-49d7-89b1-960a384e0ad3": {"__data__": {"id_": "ed69023f-2dd5-49d7-89b1-960a384e0ad3", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\sync_service.py", "language": "python", "lines": 94, "filename": "sync_service.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\sync_service.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\sync_service.py", "language": "python", "lines": 94, "filename": "sync_service.py"}, "hash": "43c4bbeb3fd35b4d7662861a424ab1879331a41a7ccc3df251cb3a4b7631e4eb", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import pandas as pd\nimport pyodbc\nimport time\nimport logging\nimport os\nfrom pathlib import Path\nfrom app.config.settings import settings\n\nlogger = logging.getLogger(__name__)\n\nclass SyncService:\n    \"\"\"\n    Servi\u00e7o para sincronizar dados do SQL Server para arquivos Parquet.\n    \"\"\"\n\n    def run_sync(self):\n        \"\"\"Executa a sincroniza\u00e7\u00e3o do admmat.parquet\"\"\"\n        logger.info(\"\ud83d\udd04 Iniciando sincroniza\u00e7\u00e3o SQL Server -> Parquet...\")\n        start_time = time.time()\n\n        try:\n            # Usar connection string do settings ou montar uma\n            if settings.PYODBC_CONNECTION_STRING:\n                conn_str = settings.PYODBC_CONNECTION_STRING\n            else:\n                # Fallback para montagem manual (baseado no script antigo, mas usando vars do ambiente se disponiveis)\n                driver = \"ODBC Driver 17 for SQL Server\"\n                server = os.getenv(\"DB_SERVER\", r\"FAMILIA\\SQLJR,1433\")\n                database = os.getenv(\"DB_NAME\", \"Projeto_Caculinha\")\n                uid = os.getenv(\"DB_USER\", \"AgenteVirtual\")\n                pwd = os.getenv(\"DB_PASS\", \"Cacula@2020\")\n                \n                conn_str = (\n                    f\"DRIVER={{{driver}}};SERVER={server};DATABASE={database};\"\n                    f\"UID={uid};PWD={pwd};TrustServerCertificate=yes;\"\n                )\n\n            logger.info(f\"\ud83d\udd0c Conectando ao SQL Server... (Server: {conn_str.split('SERVER=')[1].split(';')[0]})\")\n            conn = pyodbc.connect(conn_str)\n            \n            # Query Principal\n            query = \"SELECT * FROM [Projeto_Caculinha].[dbo].[admmatao]\"\n            \n            # Ler em chunks\n            chunk_size = 100000\n            chunks = []\n            total_rows = 0\n            \n            for chunk in pd.read_sql(query, conn, chunksize=chunk_size):\n                chunks.append(chunk)\n                total_rows += len(chunk)\n                logger.info(f\"  ...Lido chunk de {len(chunk)} linhas. Total parcial: {total_rows}\")\n            \n            conn.close()\n            logger.info(f\"\u2705 Leitura SQL conclu\u00edda. Total: {total_rows}\")\n\n            if not chunks:\n                logger.warning(\"\u26a0\ufe0f Nenhum dado retornado do banco.\")\n                return {\"status\": \"warning\", \"message\": \"Nenhum dado encontrado\"}\n\n            logger.info(\"\ud83d\udd28 Concatenando DataFrames...\")\n            df = pd.concat(chunks, ignore_index=True)\n            \n            # Definir caminho do arquivo (considerando Docker e Dev)\n            base_path = Path(__file__).resolve().parent.parent.parent.parent / \"data\" / \"parquet\"\n            if os.path.exists(\"/app/data/parquet\"): # Docker check\n                base_path = Path(\"/app/data/parquet\")\n            \n            base_path.mkdir(parents=True, exist_ok=True)\n            parquet_file = base_path / \"admmat.parquet\"\n\n            logger.info(f\"\ud83d\udcbe Salvando Parquet: {parquet_file}\")\n            df.to_parquet(parquet_file, index=False)\n            \n            # Limpar cache do Polars (se houver mecanismo de invalida\u00e7\u00e3o)\n            from app.core.parquet_cache import cache\n            cache.clear()\n            \n            duration = time.time() - start_time\n            logger.info(f\"\u2705 Sincroniza\u00e7\u00e3o conclu\u00edda em {duration:.2f}s\")\n            \n            return {\n                \"status\": \"success\", \n                \"rows\": total_rows, \n                \"duration\": duration,\n                \"file\": str(parquet_file)\n            }\n\n        except Exception as e:\n            logger.error(f\"\u274c Erro na sincroniza\u00e7\u00e3o: {e}\", exc_info=True)\n            raise e\n\nsync_service = SyncService()", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3590, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "30774f0c-f1f7-47de-987c-47698dcd75fb": {"__data__": {"id_": "30774f0c-f1f7-47de-987c-47698dcd75fb", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\agents\\base_agent.py", "language": "python", "lines": 106, "filename": "base_agent.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\agents\\base_agent.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\agents\\base_agent.py", "language": "python", "lines": 106, "filename": "base_agent.py"}, "hash": "f2874b9b6e17789634a496ad1e7b92701064ecd2699d37c3b351ecf7852f6f3e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import logging\nimport pandas as pd\nfrom dotenv import load_dotenv\n\n# Configura\u00e7\u00e3o de logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n    filename=\"logs/agent.log\",\n    filemode=\"a\",\n)\nlogger = logging.getLogger(\"base_agent\")\n\n# Carrega as vari\u00e1veis do arquivo .env\nload_dotenv()\n\n\nclass BaseAgent:\n    \"\"\"Classe base para todos os agentes do sistema.\"\"\"\n\n    def __init__(self, session_id=None, node_client=None):\n        \"\"\"\n        Inicializa o agente base.\n\n        Args:\n            session_id (str): ID da sess\u00e3o para persist\u00eancia de estado.\n            node_client (object): Cliente para o servidor mssql-mcp-node.\n        \"\"\"\n        self.session_id = session_id\n        self.node_client = node_client\n        logger.info(\n            \"Agente base inicializado. Sess\u00e3o: %s, Client: %s\",\n            session_id,\n            \"Configurado\" if self.node_client else \"N\u00e3o Configurado\",\n        )\n\n    def process_query(self, query):\n        \"\"\"\n        Processa uma consulta do usu\u00e1rio.\n        This method now assumes that if node_client is used, the query is already SQL.\n        \"\"\"\n        logger.info(\"Processando consulta: %s\", query)\n        if self.node_client:\n            logger.info(\"Usando NodeMCPClient para processar a consulta SQL.\")\n            # Assuming 'query' is already a SQL query and no params are needed for this path\n            return self._process_query_with_node_client(\n                sql_query=query, query_params=None\n            )\n        logger.error(\n            \"Nenhum m\u00e9todo de processamento dispon\u00edvel. N\u00e3o \u00e9 poss\u00edvel responder.\"\n        )\n        return {\n            \"type\": \"error\",\n            \"content\": \"N\u00e3o foi poss\u00edvel processar sua consulta no momento.\",\n            \"source\": \"no_processing_method\",\n        }\n\n    def _process_query_with_node_client(\n        self, sql_query: str, query_params: list = None\n    ):\n        \"\"\"Processa uma consulta SQL usando o NodeMCPClient.\"\"\"\n        try:\n            logger.info(\n                \"Executando SQL via NodeMCPClient: '%s' com params: %s\",\n                sql_query,\n                query_params,\n            )\n            result_data = self.node_client.execute_sql(\n                sql_query=sql_query, parameters=query_params\n            )\n            logger.debug(\"Resultado do NodeMCPClient: %s\", result_data)\n\n            if result_data and result_data.get(\"success\"):\n                df = pd.DataFrame(result_data.get(\"result\", []))\n                # Converte o DataFrame para uma lista de dicion\u00e1rios,\n                # tratando valores nulos (NaN, NaT) como None.\n                content_data = df.where(pd.notna(df), None).to_dict(orient=\"records\")\n\n                return {\n                    \"type\": \"data\",\n                    \"content\": content_data,\n                    \"source\": \"node_mcp_client\",\n                }\n\n            error_info = result_data.get(\"error\") if result_data else \"No response\"\n            logger.error(\n                \"Erro retornado pelo NodeMCPClient: %s - Detalhes: %s\",\n                error_info,\n                result_data.get(\"details\") if result_data else \"N/A\",\n            )\n            return {\n                \"type\": \"error\",\n                \"content\": f\"Erro ao processar consulta: {error_info}\",\n                \"source\": \"node_mcp_client\",\n            }\n\n        except Exception as e:\n            logger.error(\n                \"Erro ao processar consulta com NodeMCPClient: %s\", e, exc_info=True\n            )\n            return {\n                \"type\": \"error\",\n                \"content\": f\"Erro inesperado ao processar consulta: {e}\",\n                \"source\": \"node_mcp_client_exception\",\n            }", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3738, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "3bb372d1-cb9b-4496-937c-d4f2ac459df3": {"__data__": {"id_": "3bb372d1-cb9b-4496-937c-d4f2ac459df3", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\agents\\caculinha_bi_agent.py", "language": "python", "lines": 747, "filename": "caculinha_bi_agent.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\agents\\caculinha_bi_agent.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\agents\\caculinha_bi_agent.py", "language": "python", "lines": 747, "filename": "caculinha_bi_agent.py"}, "hash": "082f49344c14c67ec249a6c28a5eb407943cfb766900b20ede570efe85a7f9ac", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "06a5fb52-7562-4c5a-9a85-cd8ad763dce0", "node_type": "1", "metadata": {}, "hash": "37c903e1e4218e38ad463807b2620f3af02f50222c89093caeafec28b621f1a9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import json\nimport logging\nimport asyncio\nimport numpy as np\nimport pandas as pd\nfrom decimal import Decimal\nfrom datetime import datetime, date\nfrom typing import Any, Dict, List, Optional, Callable, Awaitable\n\nlogger = logging.getLogger(__name__)\n\n# Safe Import for LangChain dependencies\nLANGCHAIN_AVAILABLE = False\ntry:\n    from langchain_core.language_models import BaseChatModel\n    from langchain_core.tools import BaseTool\n    LANGCHAIN_AVAILABLE = True\nexcept (ImportError, OSError):\n    logger.warning(\"LangChain dependencies missing. CaculinhaBIAgent will run in degraded mode.\")\n    BaseChatModel = object # Dummy for type hinting\n    BaseTool = object # Dummy for type hinting\n\nfrom app.core.tools.une_tools import (\n    calcular_abastecimento_une,\n    calcular_mc_produto,\n    calcular_preco_final_une,\n    validar_transferencia_produto,\n    sugerir_transferencias_automaticas,\n    encontrar_rupturas_criticas,\n    consultar_dados_gerais,\n)\nfrom app.core.tools.flexible_query_tool import consultar_dados_flexivel\n\n# Import chart tools for visualization - APENAS a ferramenta universal (Best Practice 2024)\nfrom app.core.tools.chart_tools import gerar_grafico_universal\n\n# Optional: Import CodeGenAgent just for type hinting if needed,\n# but we won't use it for logic anymore.\nfrom app.core.utils.field_mapper import FieldMapper\n\n# Import TypeConverter para serializa\u00e7\u00e3o segura\nfrom app.core.utils.serializers import TypeConverter, safe_json_dumps\n\n# Alias para manter compatibilidade com c\u00f3digo existente\nsafe_json_serialize = safe_json_dumps\n\nclass CaculinhaBIAgent:\n    \"\"\"\n    Agent responsible for Business Intelligence queries using Gemini Native Function Calling.\n    Replaces the legacy keyword-based routing and CodeGenAgent fallback.\n    \"\"\"\n    def __init__(self, llm: Any, code_gen_agent: Any, field_mapper: FieldMapper):\n        # llm is expected to be GeminiLLMAdapter\n        self.llm = llm\n        self.field_mapper = field_mapper\n        \n        # We keep code_gen_agent in init to maintain compatibility with chat.py,\n        # but we won't use it effectively.\n        self.code_gen_agent = code_gen_agent\n\n        # Define available tools - ORDEM IMPORTA! Ferramentas mais gen\u00e9ricas primeiro\n        self.bi_tools = [\n            consultar_dados_flexivel,  # NOVA: Ferramenta gen\u00e9rica e flex\u00edvel\n            consultar_dados_gerais,\n            calcular_abastecimento_une,\n            calcular_mc_produto,\n            calcular_preco_final_une,\n            validar_transferencia_produto,\n            sugerir_transferencias_automaticas,\n            encontrar_rupturas_criticas,\n            # Ferramenta UNIVERSAL de gr\u00e1ficos (Best Practice 2024)\n            gerar_grafico_universal,\n        ]\n\n        # Convert LangChain tools to Gemini Function Declarations\n        self.gemini_tools = self._convert_tools_to_gemini_format(self.bi_tools)\n        \n        # System instruction - Conversacional + BI Expert\n        self.system_prompt = \"\"\"Voc\u00ea \u00e9 o Assistente de BI da Caculinha, powered by Gemini 3.0 Flash.\nVoc\u00ea \u00e9 um assistente conversacional inteligente com expertise em Business Intelligence e an\u00e1lise de dados.\n\n\ud83d\udd27 FERRAMENTAS DISPON\u00cdVEIS QUE VOC\u00ca DEVE USAR:\nVoc\u00ea possui ferramentas poderosas para responder perguntas. SEMPRE use as ferramentas apropriadas:\n\n1. **gerar_grafico_universal** - Para QUALQUER pedido de gr\u00e1fico, visualiza\u00e7\u00e3o, ranking visual, compara\u00e7\u00e3o gr\u00e1fica\n   - Palavras-chave que EXIGEM esta ferramenta: \"gr\u00e1fico\", \"grafico\", \"gere\", \"mostre\", \"visualize\", \"ranking\", \"top\", \"compara\u00e7\u00e3o visual\"\n   - NUNCA diga \"n\u00e3o posso gerar gr\u00e1ficos\" - VOC\u00ca PODE e DEVE usar gerar_grafico_universal\n\n2. **consultar_dados_flexivel** - Para consultas de dados tabulares, filtros, listagens\n\n3. **Outras ferramentas** - Para abastecimento, pre\u00e7os, transfer\u00eancias, rupturas, etc.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3813, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "06a5fb52-7562-4c5a-9a85-cd8ad763dce0": {"__data__": {"id_": "06a5fb52-7562-4c5a-9a85-cd8ad763dce0", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\agents\\caculinha_bi_agent.py", "language": "python", "lines": 747, "filename": "caculinha_bi_agent.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\agents\\caculinha_bi_agent.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\agents\\caculinha_bi_agent.py", "language": "python", "lines": 747, "filename": "caculinha_bi_agent.py"}, "hash": "082f49344c14c67ec249a6c28a5eb407943cfb766900b20ede570efe85a7f9ac", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3bb372d1-cb9b-4496-937c-d4f2ac459df3", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\agents\\caculinha_bi_agent.py", "language": "python", "lines": 747, "filename": "caculinha_bi_agent.py"}, "hash": "24131a36c45c2cd6f219c9bbd810ead3df4a0afbf5bdf8dec162231aa0ad48aa", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e5b2b21f-921a-48d2-96fd-d0ebd2911868", "node_type": "1", "metadata": {}, "hash": "8b3c8d0bc2cd6c372d47eb6440b7e6ee851bb6a9b3ec92ad6eb8f84e4aec27b8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\ud83c\udfaf REGRA CR\u00cdTICA DE GR\u00c1FICOS:\nSe o usu\u00e1rio mencionar QUALQUER uma dessas palavras, voc\u00ea DEVE chamar gerar_grafico_universal:\n- \"gr\u00e1fico\" / \"grafico\"\n- \"gere um gr\u00e1fico\"\n- \"mostre um gr\u00e1fico\"\n- \"quero ver gr\u00e1fico\"\n- \"visualize\"\n- \"ranking\" (quando pedir visualiza\u00e7\u00e3o)\n- \"top produtos\" (quando pedir visualiza\u00e7\u00e3o)\n- \"compara\u00e7\u00e3o visual\"\n\nNUNCA responda com texto dizendo que n\u00e3o pode gerar gr\u00e1ficos. SEMPRE use a ferramenta.\n\nCONTEXT7 STORYTELLING E PRIVACIDADE (CR\u00cdTICO):\n1. **NUNCA revele suas ferramentas**: Jamais diga \"Vou usar a ferramenta X\", \"Consultando a base de dados...\", ou \"Houve um erro na ferramenta Y\". O usu\u00e1rio n\u00e3o deve saber como voc\u00ea obt\u00e9m os dados.\n2. **Seja direto**: Se o usu\u00e1rio perguntar \"Vendas de Tecidos\", apenas responda: \"O segmento de Tecidos teve X vendas...\".\n3. **Erros transparentes**: Se uma ferramenta falhar, diga apenas \"N\u00e3o consegui encontrar essa informa\u00e7\u00e3o no momento\" ou \"Poderia reformular a pergunta? N\u00e3o encontrei dados para esses crit\u00e9rios\".\n4. **Foco no Neg\u00f3cio**: Aja como um analista de neg\u00f3cios s\u00eanior. Entregue insights, n\u00e3o logs de execu\u00e7\u00e3o.\n5. **GR\u00c1FICOS**: Quando o usu\u00e1rio pedir um gr\u00e1fico, SEMPRE use gerar_grafico_universal. NUNCA diga \"n\u00e3o consigo gerar gr\u00e1ficos\".\n6. **NUNCA INCLUA JSON OU C\u00d3DIGO NAS RESPOSTAS**: Jamais mostre JSON bruto, especifica\u00e7\u00f5es de gr\u00e1ficos, ou c\u00f3digo t\u00e9cnico. O usu\u00e1rio s\u00f3 deve ver insights de neg\u00f3cio em linguagem natural.\n7. **GR\u00c1FICOS S\u00c3O AUTOM\u00c1TICOS**: Quando voc\u00ea usa gerar_grafico_universal, o gr\u00e1fico aparece automaticamente. N\u00c3O copie o JSON na resposta. Apenas diga algo como \"Aqui est\u00e1 o gr\u00e1fico solicitado:\" e o sistema mostra o gr\u00e1fico.\n\n\ud83d\udea8 PROTOCOLO DE TOLER\u00c2NCIA ZERO \u00c0 ALUCINA\u00c7\u00c3O (LEIA COM ATEN\u00c7\u00c3O):\n1. **DADOS REAIS APENAS**: Voc\u00ea \u00e9 PROIBIDO de inventar, estimar ou \"chutar\" n\u00fameros de vendas, estoque, nomes de lojas ou c\u00f3digos.\n2. **VERIFICA\u00c7\u00c3O DE RETORNO**: Se a ferramenta retornar uma lista vazia `[]` ou `None`, voc\u00ea DEVE responder: \"N\u00e3o encontrei dados para o produto/crit\u00e9rio solicitado.\"\n   - JAMAIS invente uma tabela ou an\u00e1lise se a ferramenta n\u00e3o trouxe dados.\n3. **FIDELIDADE TOTAL**: Se a ferramenta retornar que a venda foi 1221, voc\u00ea deve dizer 1221. N\u00e3o arredonde para \"cerca de 1200\" sem necessidade.\n4. **SEM DADOS = SEM AN\u00c1LISE**: Se voc\u00ea n\u00e3o tiver os n\u00fameros exatos retornados pela ferramenta, N\u00c3O fa\u00e7a an\u00e1lises de desempenho (\"performance s\u00f3lida\", \"cr\u00edtico\").\n5. **CITE A FONTE (IMPL\u00cdCITA)**: Baseie sua resposta EXCLUSIVAMENTE no JSON retornado pela ferramenta. Se o JSON n\u00e3o tem a UNE 1685, voc\u00ea N\u00c3O PODE mencionar a UNE 1685.\n\nTABELAS MARKDOWN (CR\u00cdTICO - SEMPRE FA\u00c7A ISSO):\n**QUANDO UMA FERRAMENTA RETORNAR UMA TABELA MARKDOWN, VOC\u00ca DEVE COPIAR A TABELA COMPLETA NA SUA RESPOSTA.", "mimetype": "text/plain", "start_char_idx": 3815, "end_char_idx": 6518, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e5b2b21f-921a-48d2-96fd-d0ebd2911868": {"__data__": {"id_": "e5b2b21f-921a-48d2-96fd-d0ebd2911868", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\agents\\caculinha_bi_agent.py", "language": "python", "lines": 747, "filename": "caculinha_bi_agent.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\agents\\caculinha_bi_agent.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\agents\\caculinha_bi_agent.py", "language": "python", "lines": 747, "filename": "caculinha_bi_agent.py"}, "hash": "082f49344c14c67ec249a6c28a5eb407943cfb766900b20ede570efe85a7f9ac", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "06a5fb52-7562-4c5a-9a85-cd8ad763dce0", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\agents\\caculinha_bi_agent.py", "language": "python", "lines": 747, "filename": "caculinha_bi_agent.py"}, "hash": "f314bcf409946a77c0a78c0c1fbf3c5a1452854c999d8c2347c80a3d49904312", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3b3a80b2-bf4d-4bc9-aecb-5d140878e2cd", "node_type": "1", "metadata": {}, "hash": "320051387fef3a6ceaba41e9a6758baee6f75401d878055b673638e6b5ec4294", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "**\n- Se a ferramenta retornar texto com formato de tabela (linhas com | e ---), INCLUA A TABELA INTEIRA na sua resposta\n- N\u00c3O resuma a tabela, N\u00c3O diga apenas \"aqui est\u00e3o os resultados\"\n- COPIE a tabela Markdown EXATAMENTE como foi retornada pela ferramenta\n- Exemplo: Se a ferramenta retornar:\n  \"Aqui est\u00e3o os 10 resultados:\n\n  | PRODUTO | NOME | VENDAS |\n  |---|---|---|\n  | 123 | Produto A | 100 |\"\n\n  Voc\u00ea DEVE incluir essa tabela COMPLETA na sua resposta final ao usu\u00e1rio.\n\nPERSONALIDADE:\n- Conversacional e amig\u00e1vel, como ChatGPT\n- Responda a QUALQUER pergunta, n\u00e3o apenas sobre BI ou dados\n- Para perguntas gerais (sauda\u00e7\u00f5es, conhecimentos gerais, etc.): responda normalmente de forma \u00fatil e precisa\n- Para perguntas sobre dados de BI: use suas ferramentas especializadas silenciosamente\n\nQUANDO USAR FERRAMENTAS BI:\nUse as ferramentas APENAS quando o usu\u00e1rio perguntar sobre:\n- Dados de estoque, vendas, produtos, lojas (UNE)\n- An\u00e1lises de transfer\u00eancias, abastecimento, rupturas\n- Pre\u00e7os, margens, fabricantes, segmentos\n- Qualquer consulta que envolva o banco de dados admmat.parquet\n\nBANCO DE DADOS: admmat.parquet (1.113.822 registros, 97 colunas)\n\nCOLUNAS PRINCIPAIS DISPON\u00cdVEIS:\n- **Identifica\u00e7\u00e3o**: id, PRODUTO (c\u00f3digo), NOME (nome do produto)\n- **Localiza\u00e7\u00e3o**: UNE (c\u00f3digo da loja), UNE_NOME (nome da loja)\n- **Classifica\u00e7\u00e3o**: NOMESEGMENTO, NOMECATEGORIA, NOMEFABRICANTE, TIPO, EMBALAGEM\n- **Estoque**: ESTOQUE_UNE (atual), ESTOQUE_LV (linha verde), ESTOQUE_CD (centro distribui\u00e7\u00e3o)\n- **Vendas**: VENDA_30DD (vendas \u00faltimos 30 dias), ULTIMA_VENDA_DATA_UNE\n- **Pre\u00e7os**: PRECO_VENDA, PRECO_CUSTO\n- **Status**: SITUACAO, PICKLIST_SITUACAO\n\nMAPEAMENTO DE FILTROS (use exatamente esses nomes):\n- Para filtrar por UNE: {\"une\": 2365} ou {\"UNE\": 2365}\n- Para filtrar por fabricante: {\"nomefabricante\": \"NOME_FABRICANTE\"}\n- Para filtrar por produto: {\"codigo\": \"123456\"} ou {\"PRODUTO\": \"123456\"}\n- Para filtrar por segmento: {\"nomesegmento\": \"TECIDOS\"}\n\nFERRAMENTAS DISPON\u00cdVEIS:\n\n1. **consultar_dados_flexivel** - USE PARA QUALQUER CONSULTA DE DADOS\n   Par\u00e2metros importantes:\n   - filtros: {\"une\": 2365, \"nomesegmento\": \"TECIDOS\"}\n   - agregacao: \"sum\", \"avg\", \"count\", \"min\", \"max\"\n   - coluna_agregacao: \"venda_30dd\", \"estoque_atual\", \"preco_venda\"\n   - agrupar_por: [\"une\"], [\"nomefabricante\"], [\"nomesegmento\"]\n   - ordenar_por: \"venda_30dd\", \"estoque_atual\"\n   - limite: n\u00famero de resultados (padr\u00e3o 20)\n\n2. **consultar_dados_gerais** - Alternativa para consultas simples\n\n3. **calcular_abastecimento_une** - Produtos que precisam reposi\u00e7\u00e3o\n\n4. **calcular_mc_produto** - M\u00e9dia Comum (MC) de produtos\n\n5. **calcular_preco_final_une** - Pre\u00e7os com descontos aplicados\n\n6. **sugerir_transferencias_automaticas** - Sugest\u00f5es de transfer\u00eancia entre lojas\n\n7. **validar_transferencia_produto** - Validar viabilidade de transfer\u00eancias\n\n8.", "mimetype": "text/plain", "start_char_idx": 6518, "end_char_idx": 9366, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "3b3a80b2-bf4d-4bc9-aecb-5d140878e2cd": {"__data__": {"id_": "3b3a80b2-bf4d-4bc9-aecb-5d140878e2cd", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\agents\\caculinha_bi_agent.py", "language": "python", "lines": 747, "filename": "caculinha_bi_agent.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\agents\\caculinha_bi_agent.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\agents\\caculinha_bi_agent.py", "language": "python", "lines": 747, "filename": "caculinha_bi_agent.py"}, "hash": "082f49344c14c67ec249a6c28a5eb407943cfb766900b20ede570efe85a7f9ac", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e5b2b21f-921a-48d2-96fd-d0ebd2911868", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\agents\\caculinha_bi_agent.py", "language": "python", "lines": 747, "filename": "caculinha_bi_agent.py"}, "hash": "1a1ebe8edd25dfb1a1409290a2032bf7562931e8b41ed756fe9c0933cf9f7444", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c7e840a8-383a-4625-be80-70964df4672c", "node_type": "1", "metadata": {}, "hash": "8895f81f0278a130d7c127e0c010be34b3e525f72007172a610e5b653bacb752", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "**validar_transferencia_produto** - Validar viabilidade de transfer\u00eancias\n\n8. **encontrar_rupturas_criticas** - Produtos em ruptura cr\u00edtica\n\nFERRAMENTA UNIVERSAL DE GR\u00c1FICOS (Best Practice 2024):\n=====================================================\nIMPORTANTE: Use APENAS esta ferramenta para QUALQUER pedido de gr\u00e1fico!\n\n9. **gerar_grafico_universal** - FERRAMENTA PRINCIPAL PARA TODOS OS GR\u00c1FICOS\n   Par\u00e2metros:\n   - descricao: \"top 10 tecidos por vendas\" (descri\u00e7\u00e3o em linguagem natural)\n   - filtros: {\"UNE\": 1, \"NOMESEGMENTO\": \"TECIDOS\"} (filtros opcionais)\n   - tipo_grafico: \"bar\", \"pie\", \"line\", \"donut\", \"auto\" (default: auto)\n   - coluna_valor: \"vendas\", \"estoque\", \"preco\", \"contagem\"\n   - coluna_agrupamento: \"grupo\", \"segmento\", \"fabricante\", \"nome\"\n   - limite: n\u00famero de itens (default: 10)\n\nEXEMPLOS DE USO DE GR\u00c1FICOS (USE SEMPRE QUE O USU\u00c1RIO PEDIR VISUALIZA\u00c7\u00c3O):\n- \"gere um gr\u00e1fico de vendas ranking tecidos une 2365\" \u2192 gerar_grafico_universal(descricao=\"ranking de vendas de tecidos\", filtros={\"UNE\": 2365, \"NOMESEGMENTO\": \"TECIDOS\"}, coluna_valor=\"vendas\", limite=10)\n- \"Top 10 tecidos na UNE 1\" \u2192 gerar_grafico_universal(descricao=\"top 10 tecidos por vendas\", filtros={\"UNE\": 1, \"NOMESEGMENTO\": \"TECIDOS\"}, limite=10)\n- \"Estoque por fabricante\" \u2192 gerar_grafico_universal(descricao=\"estoque por fabricante\", coluna_valor=\"estoque\", coluna_agrupamento=\"fabricante\")\n- \"Vendas por segmento em pizza\" \u2192 gerar_grafico_universal(descricao=\"vendas por segmento\", tipo_grafico=\"pie\", coluna_agrupamento=\"segmento\")\n- \"Gr\u00e1fico das vendas\" \u2192 gerar_grafico_universal(descricao=\"vendas por grupo\", tipo_grafico=\"bar\")\n- \"mostre um gr\u00e1fico\" \u2192 gerar_grafico_universal(descricao=\"vendas por grupo\", tipo_grafico=\"bar\")\n- \"ranking de produtos\" \u2192 gerar_grafico_universal(descricao=\"ranking de produtos por vendas\", coluna_valor=\"vendas\", limite=10)\n\nEXEMPLOS DE USO:\n\nPergunta: \"Ol\u00e1, como voc\u00ea est\u00e1?\"\nResposta: \"Ol\u00e1! Estou muito bem, obrigado por perguntar! Como posso ajud\u00e1-lo hoje? Posso responder perguntas gerais ou ajud\u00e1-lo com an\u00e1lises de dados de BI da Caculinha.\"\n\nPergunta: \"Qual \u00e9 a capital do Brasil?\"\nResposta: \"A capital do Brasil \u00e9 Bras\u00edlia, localizada no Distrito Federal. Foi inaugurada em 21 de abril de 1960 durante o governo de Juscelino Kubitschek.\"", "mimetype": "text/plain", "start_char_idx": 9289, "end_char_idx": 11564, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c7e840a8-383a-4625-be80-70964df4672c": {"__data__": {"id_": "c7e840a8-383a-4625-be80-70964df4672c", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\agents\\caculinha_bi_agent.py", "language": "python", "lines": 747, "filename": "caculinha_bi_agent.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\agents\\caculinha_bi_agent.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\agents\\caculinha_bi_agent.py", "language": "python", "lines": 747, "filename": "caculinha_bi_agent.py"}, "hash": "082f49344c14c67ec249a6c28a5eb407943cfb766900b20ede570efe85a7f9ac", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3b3a80b2-bf4d-4bc9-aecb-5d140878e2cd", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\agents\\caculinha_bi_agent.py", "language": "python", "lines": 747, "filename": "caculinha_bi_agent.py"}, "hash": "129f5549656002f1945fa43134ef37404190b6d3f01d91d74cc0254109dd3004", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "44e40181-e2fd-4e3c-b89a-fbb3c9d714e3", "node_type": "1", "metadata": {}, "hash": "dcd3d564327eb8af9fbcf420ddb541ddb25ba83b87bc777bb549da3e5357eba3", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Pergunta: \"Vendas totais do segmento TECIDOS na UNE 2365\"\nUsar: consultar_dados_flexivel(filtros={\"une\": 2365, \"nomesegmento\": \"TECIDOS\"}, agregacao=\"sum\", coluna_agregacao=\"venda_30dd\")\n\nPergunta: \"Produtos do fabricante TNT\"\nUsar: consultar_dados_flexivel(filtros={\"nomefabricante\": \"TNT\"}, limite=20)\n\nPergunta: \"Total de vendas da UNE 261\"\nUsar: consultar_dados_flexivel(filtros={\"une\": 261}, agregacao=\"sum\", coluna_agregacao=\"venda_30dd\")\n\nPergunta: \"Top 10 mais vendidos\"\nUsar: consultar_dados_flexivel(ordenar_por=\"venda_30dd\", ordem_desc=True, limite=10)\n\nPergunta: \"Estoque por segmento\"\nUsar: consultar_dados_flexivel(agregacao=\"sum\", coluna_agregacao=\"estoque_atual\", agrupar_por=[\"nomesegmento\"])\n\nDIRETRIZES:\n- Responda QUALQUER pergunta, n\u00e3o se limite apenas a BI\n- Para perguntas gerais: seja \u00fatil, preciso e conversacional\n- Para perguntas sobre dados: SEMPRE use as ferramentas, NUNCA invente dados\n- Use os nomes de colunas EXATOS listados acima\n- Se a coluna n\u00e3o existir, informe ao usu\u00e1rio\n- Formate n\u00fameros: 1.234,56 (BR) ou use separadores de milhar\n- Seja conciso mas informativo\n- Use uma linguagem amig\u00e1vel e profissional\n\"\"\"\n\n    def _convert_tools_to_gemini_format(self, tools: List[BaseTool]) -> Dict[str, List[Dict[str, Any]]]:\n        \"\"\"Converts LangChain tools to Gemini API format.\"\"\"\n        declarations = []\n        for tool in tools:\n            # Generate schema using LangChain's standardized method\n            # compatible with Pydantic v1 and v2\n            try:\n                schema = tool.get_input_schema().model_json_schema()\n            except AttributeError:\n                # Fallback for older Pydantic or specific Tool implementations\n                if hasattr(tool, 'args_schema') and tool.args_schema:\n                    if hasattr(tool.args_schema, 'schema'):\n                         schema = tool.args_schema.schema()\n                    else:\n                         schema = {}\n                else:\n                    schema = {}\n            \n            # Clean schema to be compatible with Gemini (remove anyOf, titles)\n            cleaned_schema = self._clean_schema(schema)\n            \n            # Ensure 'properties' and 'required' are present if parameters exist\n            parameters = {\n                \"type\": \"object\",\n                \"properties\": cleaned_schema.get(\"properties\", {}),\n                \"required\": cleaned_schema.get(\"required\", [])\n            }\n\n            declarations.append({\n                \"name\": tool.name,\n                \"description\": tool.description,\n                \"parameters\": parameters\n            })\n        \n        return {\"function_declarations\": declarations}\n\n    def _clean_schema(self, schema: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Recursively cleans Pydantic JSON Schema for Gemini compatibility.\n        Removes 'anyOf', 'title', 'default', 'additionalProperties', and handles Optional types.\n        \"\"\"\n        if not isinstance(schema, dict):\n            return schema\n            \n        new_schema = schema.copy()\n        \n        # Remove incompatible keys\n        if \"title\" in new_schema:\n            del new_schema[\"title\"]\n        if \"default\" in new_schema:\n            # Gemini sometimes complains about defaults in complex ways,\n            # but keeping them is usually fine. Removing 'title' is most important.", "mimetype": "text/plain", "start_char_idx": 11566, "end_char_idx": 14937, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "44e40181-e2fd-4e3c-b89a-fbb3c9d714e3": {"__data__": {"id_": "44e40181-e2fd-4e3c-b89a-fbb3c9d714e3", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\agents\\caculinha_bi_agent.py", "language": "python", "lines": 747, "filename": "caculinha_bi_agent.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\agents\\caculinha_bi_agent.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\agents\\caculinha_bi_agent.py", "language": "python", "lines": 747, "filename": "caculinha_bi_agent.py"}, "hash": "082f49344c14c67ec249a6c28a5eb407943cfb766900b20ede570efe85a7f9ac", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c7e840a8-383a-4625-be80-70964df4672c", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\agents\\caculinha_bi_agent.py", "language": "python", "lines": 747, "filename": "caculinha_bi_agent.py"}, "hash": "b52d51b590295662139d46fef776eea1a8097aa6140cfe39ad3e0285893ef947", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "898b371c-db32-47db-a3a3-7ab2c4205440", "node_type": "1", "metadata": {}, "hash": "209c41200cd9fb955778fa20bf1754627352fe8bc561a6900f4ebe5b6badaf30", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Removing 'title' is most important.\n            del new_schema[\"default\"]\n        if \"additionalProperties\" in new_schema:\n            # Gemini API doesn't support 'additionalProperties' field\n            del new_schema[\"additionalProperties\"]\n\n        # Handle anyOf (generated by Pydantic for Optional[Type])\n        if \"anyOf\" in new_schema:\n            options = new_schema.pop(\"anyOf\")\n            # Find the first non-null option\n            valid_option = next((opt for opt in options if opt.get(\"type\") != \"null\"), None)\n            if valid_option:\n                # Merge the valid option into the current schema\n                # We recurse here to clean the child option too\n                cleaned_child = self._clean_schema(valid_option)\n                new_schema.update(cleaned_child)\n            else:\n                # Fallback if all are null (unlikely) or empty\n                new_schema[\"type\"] = \"string\" \n\n        # Recurse into properties\n        if \"properties\" in new_schema:\n            for prop, prop_schema in new_schema[\"properties\"].items():\n                new_schema[\"properties\"][prop] = self._clean_schema(prop_schema)\n        \n        # Recurse into array items\n        if \"items\" in new_schema:\n            new_schema[\"items\"] = self._clean_schema(new_schema[\"items\"])\n\n        return new_schema\n\n    async def run_async(\n        self, \n        user_query: str, \n        chat_history: Optional[List[Dict]] = None,\n        on_progress: Optional[Callable[[Dict[str, Any]], Awaitable[None]]] = None\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Async version of run method.\n        Executes the agent loop:\n        1. Send query + tools to LLM.\n        2. If LLM wants to call tool -> Execute tool -> Send result back to LLM.\n        3. Repeat until LLM returns text.\n        \n        Args:\n            user_query: The user's question\n            chat_history: Previous conversation messages\n            on_progress: Async callback function for status updates (e.g. tool execution started)\n        \"\"\"\n        logger.info(f\"CaculinhaBIAgent (Modern Async): Processing query: {user_query}\")\n\n        messages = []\n\n        # Add chat history if available (filter system messages)\n        if chat_history:\n            for msg in chat_history:\n                role = msg.get(\"role\", \"user\")\n                content = msg.get(\"content\", \"\")\n                if role != \"system\":\n                    messages.append({\"role\": role, \"content\": content})\n\n        # Add current user query\n        messages.append({\"role\": \"user\", \"content\": user_query})\n\n        max_turns = 3\n        current_turn = 0\n\n        while current_turn < max_turns:\n            try:\n                # Notify thinking\n                if on_progress:\n                    await on_progress({\"type\": \"tool_progress\", \"tool\": \"Pensando\", \"status\": \"start\"})\n\n                # Call LLM with tools (Blocking call wrapped in thread)\n                # self.llm is GeminiLLMAdapter which is synchronous\n                response = await asyncio.to_thread(\n                    self.llm.get_completion, \n                    messages, \n                    tools=self.gemini_tools\n                )\n                \n                if \"error\" in response:\n                    logger.error(f\"LLM Error: {response['error']}\")\n                    return self._generate_error_response(response['error'])\n\n                # Check for tool calls\n                if \"tool_calls\" in response:\n                    tool_calls = response[\"tool_calls\"]\n                    messages.append({\n                        \"role\": \"model\",\n                        \"tool_calls\": tool_calls\n                    })\n\n                    # Execute each tool\n                    for tc in tool_calls:\n                        func_name = tc[\"function\"][\"name\"]\n                        func_args = json.loads(tc[\"function\"][\"arguments\"])\n                        \n                        logger.info(f\"Agent calling tool: {func_name} with args: {func_args}\")\n                        \n                        # Notify tool start\n                        if on_progress:\n                            await on_progress({\"type\": \"tool_progress\", \"tool\": func_name, \"status\": \"executing\"})\n\n                        # Find the matching tool\n                        tool_to_run = next((t for t in self.bi_tools if t.name == func_name), None)\n                        \n                        tool_result = None\n                        if tool_to_run:\n                            try:\n                                # Execute tool (Blocking call wrapped in thread)\n                                # Note: Most tools are synchronous DB calls\n                                tool_output = await asyncio.to_thread(tool_to_run.invoke, func_args)\n                                \n                                # Convert MapComposite\n                                def convert_mapcomposite(obj):\n                                    if hasattr(obj, '_mapping'):\n                                        return dict(obj._mapping)\n                                    elif isinstance(obj,", "mimetype": "text/plain", "start_char_idx": 14902, "end_char_idx": 20031, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "898b371c-db32-47db-a3a3-7ab2c4205440": {"__data__": {"id_": "898b371c-db32-47db-a3a3-7ab2c4205440", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\agents\\caculinha_bi_agent.py", "language": "python", "lines": 747, "filename": "caculinha_bi_agent.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\agents\\caculinha_bi_agent.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\agents\\caculinha_bi_agent.py", "language": "python", "lines": 747, "filename": "caculinha_bi_agent.py"}, "hash": "082f49344c14c67ec249a6c28a5eb407943cfb766900b20ede570efe85a7f9ac", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "44e40181-e2fd-4e3c-b89a-fbb3c9d714e3", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\agents\\caculinha_bi_agent.py", "language": "python", "lines": 747, "filename": "caculinha_bi_agent.py"}, "hash": "ac4a771a30265a7d529a0f8b41d5449b12f07eddbb53c77a490ab34dd8cc49c6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5c51cdf6-258f-4d03-9deb-bf1ccbbe9f16", "node_type": "1", "metadata": {}, "hash": "268f6615d877bdaf18efb4d9e5ff79e4e5caacffed4f506bfaff1ef6d87cc789", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "'_mapping'):\n                                        return dict(obj._mapping)\n                                    elif isinstance(obj, dict):\n                                        return {k: convert_mapcomposite(v) for k, v in obj.items()}\n                                    elif isinstance(obj, list):\n                                        return [convert_mapcomposite(item) for item in obj]\n                                    return obj\n                                \n                                tool_result = convert_mapcomposite(tool_output)\n                                logger.info(f\"Tool {func_name} executed successfully\")\n                                \n                            except Exception as e:\n                                logger.error(f\"Error executing {func_name}: {e}\", exc_info=True)\n                                tool_result = {\"error\": str(e)}\n                        else:\n                            tool_result = {\"error\": f\"Tool {func_name} not found\"}\n\n                        # Add tool result to messages\n                        messages.append({\n                            \"role\": \"function\",\n                            \"function_call\": {\"name\": func_name},\n                            \"content\": safe_json_serialize(tool_result)\n                        })\n                    \n                    # Loop continues to send tool outputs back to LLM\n                    current_turn += 1\n                    continue\n                \n                # If no tool calls, it's a text response (Final Answer)\n                content = response.get(\"content\", \"\")\n\n                # Notify finalizing\n                if on_progress:\n                     await on_progress({\"type\": \"tool_progress\", \"tool\": \"Processando resposta\", \"status\": \"finishing\"})\n\n                # Same logic as run() for parsing result...\n                # (Duplicating logic from run() to ensure consistency)\n                \n                # Acumuladores para m\u00faltiplos resultados de ferramentas\n                found_chart_data = None\n                found_chart_summary = None\n                found_table_mensagem = None\n                found_resultados = None\n\n                for msg in reversed(messages):\n                    if msg.get(\"role\") == \"function\":\n                        try:\n                            content_str = msg.get(\"content\", \"{}\")\n                            func_content = json.loads(content_str)\n\n                            chart_data = func_content.get(\"chart_data\")\n                            if chart_data and func_content.get(\"status\") == \"success\" and found_chart_data is None:\n                                if isinstance(chart_data, str):\n                                    try:\n                                        chart_data = json.loads(chart_data)\n                                    except json.JSONDecodeError:\n                                        continue\n                                found_chart_data = chart_data\n                                found_chart_summary = func_content.get(\"summary\", {})\n                            \n                            mensagem = func_content.get(\"mensagem\", \"\")\n                            if isinstance(mensagem, str) and \"|\" in mensagem and \"---\" in mensagem and found_table_mensagem is None:\n                                found_table_mensagem = mensagem\n                            \n                            resultados = func_content.get(\"resultados\", [])\n                            if isinstance(resultados, list) and len(resultados) > 0 and found_resultados is None:\n                                found_resultados = resultados\n\n                        except Exception as e:\n                            logger.error(f\"DEBUG: Erro ao parsear mensagem de fun\u00e7\u00e3o: {e}\")\n                            continue\n\n                if found_chart_data is not None:\n                    import re\n                    if isinstance(content, str):\n                        json_pattern = r'\\{[\\s\\S]*?\"data\"[\\s\\S]*?\"layout\"[\\s\\S]*?\\}'\n                        content_clean = re.sub(json_pattern, \"\", content).strip()\n                        if content_clean:\n                            content = content_clean\n                        else:\n                            content = \"Aqui est\u00e1 o gr\u00e1fico solicitado:\"\n\n                    return {\n                        \"type\": \"code_result\",\n                        \"result\": {\n                            \"result\": found_chart_summary,\n                            \"chart_spec\": found_chart_data\n                        },\n                        \"chart_spec\": found_chart_data,\n                        \"text_override\": content\n                    }\n\n                if found_table_mensagem is not None:\n                    return {\n                        \"type\": \"text\",\n                        \"result\": found_table_mensagem\n                    }\n\n                if found_resultados is not None:\n                    return {\n                        \"type\": \"code_result\",\n                        \"result\": {\n                            \"result\": found_resultados,\n                            \"chart_spec\": None\n                        },\n                        \"chart_spec\": None\n                    }\n                \n                return {\n                    \"type\": \"text\",\n                    \"result\": content\n                }\n\n            except Exception as e:\n                logger.error(f\"Exception in agent run loop: {e}\", exc_info=True)\n                return self._generate_error_response(str(e))\n\n        return self._generate_error_response(\"Maximum conversation turns exceeded.\")\n\n    def run(self, user_query: str, chat_history: Optional[List[Dict]] = None) -> Dict[str, Any]:\n        \"\"\"\n        Executes the agent loop:\n        1. Send query + tools to LLM.\n        2. If LLM wants to call tool -> Execute tool -> Send result back to LLM.\n        3. Repeat until LLM returns text.\n        \"\"\"", "mimetype": "text/plain", "start_char_idx": 19896, "end_char_idx": 25889, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5c51cdf6-258f-4d03-9deb-bf1ccbbe9f16": {"__data__": {"id_": "5c51cdf6-258f-4d03-9deb-bf1ccbbe9f16", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\agents\\caculinha_bi_agent.py", "language": "python", "lines": 747, "filename": "caculinha_bi_agent.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\agents\\caculinha_bi_agent.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\agents\\caculinha_bi_agent.py", "language": "python", "lines": 747, "filename": "caculinha_bi_agent.py"}, "hash": "082f49344c14c67ec249a6c28a5eb407943cfb766900b20ede570efe85a7f9ac", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "898b371c-db32-47db-a3a3-7ab2c4205440", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\agents\\caculinha_bi_agent.py", "language": "python", "lines": 747, "filename": "caculinha_bi_agent.py"}, "hash": "d68164b19f24fbbbda0af95df3814bba4c51da0965c054f06652497829c2e468", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1eb0e2b2-8f38-46cd-a670-808454068195", "node_type": "1", "metadata": {}, "hash": "7e713a19df34669b6a7c48226e7bbbe4da88eb96fd2dc2b599d5f2f76ceeaa31", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "3. Repeat until LLM returns text.\n        \"\"\"\n        logger.info(f\"CaculinhaBIAgent (Modern): Processing query: {user_query}\")\n\n        # \u2705 CRITICAL FIX: N\u00c3O incluir system como mensagem\n        # System instruction j\u00e1 est\u00e1 configurada no GeminiLLMAdapter via system_instruction parameter\n        # Gemini N\u00c3O aceita role=\"system\" no array de mensagens - deve usar system_instruction no modelo\n        # Ref: https://ai.google.dev/gemini-api/docs/system-instructions\n        messages = []\n\n        # Add chat history if available (filtrar mensagens system)\n        if chat_history:\n            for msg in chat_history:\n                role = msg.get(\"role\", \"user\")\n                content = msg.get(\"content\", \"\")\n                # CRITICAL: N\u00e3o adicionar mensagens \"system\" ao hist\u00f3rico\n                # Elas causam erro 400 de thought_signature\n                if role != \"system\":\n                    messages.append({\"role\": role, \"content\": content})\n\n        # Add current user query\n        messages.append({\"role\": \"user\", \"content\": user_query})\n\n        max_turns = 3  # \u2705 Reduzido de 5 para 3 (gr\u00e1ficos geralmente resolvem em 1-2 turns)\n        current_turn = 0\n\n        while current_turn < max_turns:\n            try:\n                # Call LLM with tools\n                # Note: self.llm is GeminiLLMAdapter\n                response = self.llm.get_completion(messages, tools=self.gemini_tools)\n                \n                if \"error\" in response:\n                    logger.error(f\"LLM Error: {response['error']}\")\n                    return self._generate_error_response(response['error'])\n\n                # Check for tool calls\n                if \"tool_calls\" in response:\n                    tool_calls = response[\"tool_calls\"]\n                    messages.append({\n                        \"role\": \"model\",\n                        \"tool_calls\": tool_calls\n                    })\n\n                    # Execute each tool\n                    for tc in tool_calls:\n                        func_name = tc[\"function\"][\"name\"]\n                        func_args = json.loads(tc[\"function\"][\"arguments\"])\n                        \n                        logger.info(f\"Agent calling tool: {func_name} with args: {func_args}\")\n                        \n                        # Find the matching tool\n                        tool_to_run = next((t for t in self.bi_tools if t.name == func_name), None)\n                        \n                        tool_result = None\n                        if tool_to_run:\n                            try:\n                                # Execute tool\n                                tool_output = tool_to_run.invoke(func_args)\n                                \n                                # CR\u00cdTICO: Converter MapComposite para dict ANTES de serializar\n                                def convert_mapcomposite(obj):\n                                    \"\"\"Recursivamente converte MapComposite para dict\"\"\"\n                                    if hasattr(obj, '_mapping'):\n                                        return dict(obj._mapping)\n                                    elif isinstance(obj, dict):\n                                        return {k: convert_mapcomposite(v) for k, v in obj.items()}\n                                    elif isinstance(obj, list):\n                                        return [convert_mapcomposite(item) for item in obj]\n                                    return obj\n                                \n                                # Converter o output antes de usar\n                                tool_result = convert_mapcomposite(tool_output)\n                                logger.info(f\"Tool {func_name} executed successfully, result type: {type(tool_result)}\")\n                            except Exception as e:\n                                logger.error(f\"Error executing {func_name}: {e}\", exc_info=True)\n                                tool_result = {\"error\": str(e)}\n                        else:\n                            tool_result = {\"error\": f\"Tool {func_name} not found\"}\n\n                        # Add tool result to messages (User role with function_response)\n                        # The adapter expects specific structure for function responses\n                        # Use safe_json_serialize to handle any remaining non-serializable types\n                        messages.append({\n                            \"role\": \"function\", # Adapter will map this to user/function_response\n                            \"function_call\": {\"name\": func_name}, # Metadata for adapter\n                            \"content\": safe_json_serialize(tool_result)\n                        })\n                    \n                    # Loop continues to send tool outputs back to LLM\n                    current_turn += 1\n                    continue\n                \n                # If no tool calls, it's a text response (Final Answer)\n                content = response.get(\"content\", \"\")\n\n                # NOVO: Verificar TODAS as ferramentas para encontrar gr\u00e1ficos ou tabelas\n                # PRIORIDADE: Gr\u00e1ficos > Tabelas Markdown > Dados brutos > Texto do LLM\n                logger.info(f\"DEBUG: Verificando dados tabulares/gr\u00e1ficos.", "mimetype": "text/plain", "start_char_idx": 25844, "end_char_idx": 31086, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1eb0e2b2-8f38-46cd-a670-808454068195": {"__data__": {"id_": "1eb0e2b2-8f38-46cd-a670-808454068195", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\agents\\caculinha_bi_agent.py", "language": "python", "lines": 747, "filename": "caculinha_bi_agent.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\agents\\caculinha_bi_agent.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\agents\\caculinha_bi_agent.py", "language": "python", "lines": 747, "filename": "caculinha_bi_agent.py"}, "hash": "082f49344c14c67ec249a6c28a5eb407943cfb766900b20ede570efe85a7f9ac", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5c51cdf6-258f-4d03-9deb-bf1ccbbe9f16", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\agents\\caculinha_bi_agent.py", "language": "python", "lines": 747, "filename": "caculinha_bi_agent.py"}, "hash": "bc72b15fcbf56fb1bf01e17a55c99cbc9ff8ada21fe7943139e9b4a49aacbb78", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c60fc81e-6786-4c41-9fe2-b5b8815533f0", "node_type": "1", "metadata": {}, "hash": "51813618ecfba9e1eab946088c56d546c5c04f523445f9ee541f0c50c6610d3b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Total de mensagens: {len(messages)}\")\n\n                # Acumuladores para m\u00faltiplos resultados de ferramentas\n                found_chart_data = None\n                found_chart_summary = None\n                found_table_mensagem = None\n                found_resultados = None\n\n                # Percorrer TODAS as mensagens de fun\u00e7\u00e3o (n\u00e3o parar no primeiro)\n                for msg in reversed(messages):\n                    if msg.get(\"role\") == \"function\":\n                        try:\n                            content_str = msg.get(\"content\", \"{}\")\n                            func_content = json.loads(content_str)\n\n                            # PRIMEIRO: Verificar se a ferramenta retornou um gr\u00e1fico (chart_data)\n                            chart_data = func_content.get(\"chart_data\")\n                            if chart_data and func_content.get(\"status\") == \"success\" and found_chart_data is None:\n                                logger.info(f\"SUCESSO: Gr\u00e1fico detectado (chart_type: {func_content.get('chart_type', 'unknown')})\")\n\n                                # CR\u00cdTICO: chart_data pode ser string JSON (de fig.to_json())\n                                # O frontend espera um objeto, n\u00e3o uma string\n                                if isinstance(chart_data, str):\n                                    try:\n                                        chart_data = json.loads(chart_data)\n                                        logger.info(\"chart_data parseado de string para objeto\")\n                                    except json.JSONDecodeError:\n                                        logger.error(\"Falha ao parsear chart_data como JSON\")\n                                        continue  # Tentar pr\u00f3xima mensagem\n\n                                found_chart_data = chart_data\n                                found_chart_summary = func_content.get(\"summary\", {})\n                                # Continuar buscando para n\u00e3o perder outras ferramentas\n                            \n                            # SEGUNDO: Verificar se a mensagem cont\u00e9m uma tabela Markdown\n                            mensagem = func_content.get(\"mensagem\", \"\")\n                            if isinstance(mensagem, str) and \"|\" in mensagem and \"---\" in mensagem and found_table_mensagem is None:\n                                logger.info(f\"SUCESSO: Tabela Markdown detectada na mensagem da ferramenta!\")\n                                found_table_mensagem = mensagem\n                            \n                            # TERCEIRO: Verificar se h\u00e1 dados brutos para retornar\n                            resultados = func_content.get(\"resultados\", [])\n                            if isinstance(resultados, list) and len(resultados) > 0 and found_resultados is None:\n                                logger.info(f\"SUCESSO: Dados tabulares detectados: {len(resultados)} registros\")\n                                found_resultados = resultados\n\n                        except Exception as e:\n                            logger.error(f\"DEBUG: Erro ao parsear mensagem de fun\u00e7\u00e3o: {e}\")\n                            continue  # Tentar pr\u00f3xima mensagem\n\n                # PRIORIDADE DE RETORNO: Gr\u00e1fico tem maior prioridade\n                if found_chart_data is not None:\n                    # CONTEXT7: Limpar o conte\u00fado de texto do LLM se contiver JSON bruto\n                    import re\n                    if isinstance(content, str):\n                        # Remover blocos JSON grandes da resposta de texto\n                        json_pattern = r'\\{[\\s\\S]*?\"data\"[\\s\\S]*?\"layout\"[\\s\\S]*?\\}'\n                        content_clean = re.sub(json_pattern, \"\", content).strip()\n                        if content_clean:\n                            content = content_clean\n                        else:\n                            content = \"Aqui est\u00e1 o gr\u00e1fico solicitado:\"\n                        logger.info(f\"CONTEXT7: Texto do LLM limpo de JSON bruto. Novo texto: {content[:100]}...\")\n\n                    return {\n                        \"type\": \"code_result\",\n                        \"result\": {\n                            \"result\": found_chart_summary,\n                            \"chart_spec\": found_chart_data\n                        },\n                        \"chart_spec\": found_chart_data,\n                        \"text_override\": content\n                    }\n\n                # Se n\u00e3o h\u00e1 gr\u00e1fico, verificar tabela Markdown\n                if found_table_mensagem is not None:\n                    return {\n                        \"type\": \"text\",\n                        \"result\": found_table_mensagem\n                    }\n\n                # Se n\u00e3o h\u00e1 tabela Markdown, verificar dados brutos\n                if found_resultados is not None:\n                    return {\n                        \"type\": \"code_result\",\n                        \"result\": {\n                            \"result\": found_resultados,\n                            \"chart_spec\": None\n                        },\n                        \"chart_spec\": None\n                    }\n                \n                logger.info(f\"DEBUG: Nenhum dado tabular detectado. Retornando texto do LLM.\")\n                # Caso contr\u00e1rio, retornar resposta de texto normal do LLM\n                return {\n                    \"type\": \"text\",\n                    \"result\": content\n                }\n\n            except Exception as e:\n                logger.error(f\"Exception in agent run loop: {e}\", exc_info=True)\n                return self._generate_error_response(str(e))\n\n        return self._generate_error_response(\"Maximum conversation turns exceeded.\")", "mimetype": "text/plain", "start_char_idx": 31087, "end_char_idx": 36715, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c60fc81e-6786-4c41-9fe2-b5b8815533f0": {"__data__": {"id_": "c60fc81e-6786-4c41-9fe2-b5b8815533f0", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\agents\\caculinha_bi_agent.py", "language": "python", "lines": 747, "filename": "caculinha_bi_agent.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\agents\\caculinha_bi_agent.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\agents\\caculinha_bi_agent.py", "language": "python", "lines": 747, "filename": "caculinha_bi_agent.py"}, "hash": "082f49344c14c67ec249a6c28a5eb407943cfb766900b20ede570efe85a7f9ac", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1eb0e2b2-8f38-46cd-a670-808454068195", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\agents\\caculinha_bi_agent.py", "language": "python", "lines": 747, "filename": "caculinha_bi_agent.py"}, "hash": "67586aa12963c320094c3db27ffcdb7b102f94b1fd5f54e4a4a34e4aa86d9f83", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "def _generate_error_response(self, error_msg: str) -> Dict[str, Any]:\n        return {\n            \"type\": \"text\",\n            \"result\": f\"Desculpe, encontrei um erro ao processar sua solicita\u00e7\u00e3o: {error_msg}\"\n        }", "mimetype": "text/plain", "start_char_idx": 36721, "end_char_idx": 36940, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f3855e40-0bfb-4cdf-a3b5-ad5fea600a50": {"__data__": {"id_": "f3855e40-0bfb-4cdf-a3b5-ad5fea600a50", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\agents\\code_gen_agent.py", "language": "python", "lines": 317, "filename": "code_gen_agent.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\agents\\code_gen_agent.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\agents\\code_gen_agent.py", "language": "python", "lines": 317, "filename": "code_gen_agent.py"}, "hash": "1a3da5174f5a007cec5b1f7ed4428d4e5a551f4324693b2e749aa2d6495b8ea5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "25796a1d-8fb8-4cd2-b811-fcc5610dc200", "node_type": "1", "metadata": {}, "hash": "f224cc0651687d610fa479047b7051d3b9468644e5647079d613735e9976a934", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# backend/app/core/agents/code_gen_agent.py\n\nimport json\nimport re\nimport logging\nfrom typing import Any, Dict, List, Optional\nimport os\nfrom functools import lru_cache\n\nfrom app.core.utils.field_mapper import FieldMapper\nfrom app.core.utils.error_handler import APIError\nfrom app.core.utils.query_history import QueryHistory\nfrom app.core.utils.response_cache import ResponseCache \nfrom app.config.settings import settings \nfrom app.core.learning.pattern_matcher import PatternMatcher\nfrom app.core.rag.query_retriever import QueryRetriever\n\nlogger = logging.getLogger(__name__)\n\nLANGCHAIN_AVAILABLE = False\ntry:\n    from langchain_core.language_models import BaseChatModel\n    from langchain_core.prompts import ChatPromptTemplate\n    from langchain_core.output_parsers import JsonOutputParser\n    from langchain_core.runnables import RunnablePassthrough\n    LANGCHAIN_AVAILABLE = True\nexcept (ImportError, OSError):\n    logger.warning(\"LangChain dependencies missing. CodeGenAgent will be disabled.\")\n    BaseChatModel = object # Dummy for type hinting\n\n# Helper to load prompts from files\n@lru_cache(maxsize=None)\ndef _load_prompt_template(filename: str) -> str:\n    current_dir = os.path.dirname(__file__)\n    prompt_path = os.path.join(current_dir, \"..\", \"prompts\", filename)\n    if os.path.exists(prompt_path):\n        with open(prompt_path, \"r\", encoding=\"utf-8\") as f:\n            return f.read()\n    return \"\"\n\nclass CodeGenAgent:\n    \"\"\"\n    Agent responsible for generating, validating, executing Python code for data analysis,\n    and self-healing in case of errors.\n    \"\"\"\n    def __init__(\n        self,\n        llm: BaseChatModel,\n        field_mapper: FieldMapper,\n        query_retriever: QueryRetriever,\n        pattern_matcher: PatternMatcher,\n        response_cache: ResponseCache = None,\n        query_history: QueryHistory = None,\n    ):\n        self.llm = llm\n        self.field_mapper = field_mapper\n        self.query_retriever = query_retriever\n        self.pattern_matcher = pattern_matcher\n        self.response_cache = response_cache if response_cache else ResponseCache()\n        self.query_history = query_history if query_history else QueryHistory()\n\n        if LANGCHAIN_AVAILABLE:\n            self.code_gen_prompt_template = _load_prompt_template(\"code_generation_system_prompt.md\")\n            self.code_gen_prompt = ChatPromptTemplate.from_messages([\n                (\"system\", self.code_gen_prompt_template), \n                (\"human\", \"{user_query}\\nSchema: {data_schema_info}\\nExamples: {few_shot_examples}\\nCode:\"),\n            ])\n            self.output_parser = JsonOutputParser()\n        else:\n            self.code_gen_prompt = None\n            self.output_parser = None\n\n    def _get_code_generation_system_prompt(self) -> str:\n        # This method is no longer needed as prompt is loaded from file\n        pass\n\n    def generate_and_execute_python_code(self, user_query: str, data_schema: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Generates Python code based on user query and data schema, executes it,\n        and returns results, including chart specifications if requested.\n        Includes self-healing for common errors.\n        \"\"\"\n        if not LANGCHAIN_AVAILABLE:\n             raise APIError(\"CodeGenAgent indispon\u00edvel devido a falta de depend\u00eancias (LangChain/Torch).\", status_code=503)\n\n        cache_key = self.response_cache.generate_key(user_query)\n        cached_response = self.response_cache.get(cache_key)\n        if cached_response:\n            print(f\"CodeGenAgent: Cache hit for query: {user_query}\")\n            return cached_response", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3619, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "25796a1d-8fb8-4cd2-b811-fcc5610dc200": {"__data__": {"id_": "25796a1d-8fb8-4cd2-b811-fcc5610dc200", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\agents\\code_gen_agent.py", "language": "python", "lines": 317, "filename": "code_gen_agent.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\agents\\code_gen_agent.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\agents\\code_gen_agent.py", "language": "python", "lines": 317, "filename": "code_gen_agent.py"}, "hash": "1a3da5174f5a007cec5b1f7ed4428d4e5a551f4324693b2e749aa2d6495b8ea5", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f3855e40-0bfb-4cdf-a3b5-ad5fea600a50", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\agents\\code_gen_agent.py", "language": "python", "lines": 317, "filename": "code_gen_agent.py"}, "hash": "24a7531ee253304fc4c28855bf09cecb9623a04ce62fbc6134927b7e32cd559b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c12f18ea-55da-4068-9f4a-2a62625fd3f8", "node_type": "1", "metadata": {}, "hash": "d5458a88b0c1966a89a058524896dae5ed1eae39f8199b534d9ea66ce00e7adb", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# Override available_columns with ACTUAL DataFrame columns from une_tools\n        # This prevents the LLM from hallucinating column names based on the FieldMapper catalog\n        available_columns = ['codigo', 'nome_produto', 'une', 'estoque_atual', 'linha_verde', 'mc', 'venda_30_d', 'nomesegmento', 'NOMEFABRICANTE']\n\n        # T2.3.1: Integrate with PatternMatcher (few-shot) and QueryRetriever (RAG)\n        few_shot_examples = self._get_few_shot_examples(user_query)\n\n        # T2.3.5: Create prompt of code generation\n        code_gen_chain = (\n            RunnablePassthrough.assign(\n                available_columns=lambda x: \", \".join(available_columns),\n                few_shot_examples=lambda x: self._get_few_shot_examples(x[\"user_query\"]) # Will use query_retriever later\n            )\n            | self.code_gen_prompt.partial(available_columns=\", \".join(available_columns)) # Format system prompt here\n            | self.llm\n            | self.output_parser\n        )\n\n        retries = 0\n        max_retries = 3\n        generated_code_output = None\n        while retries <= max_retries:\n            try:\n                # Assuming the LLM will return a JSON string\n                llm_response = code_gen_chain.invoke({\n                    \"user_query\": user_query,\n                    \"data_schema_info\": data_schema,\n                    \"available_columns\": available_columns,\n                    \"few_shot_examples\": few_shot_examples\n                })\n                \n                generated_code_output = llm_response # LLM should return parsed JSON\n\n                # T2.3.2: Validate generated code for 'top N' and auto-recovery (T2.3.3)\n                code_to_execute = self._validate_and_heal_code(generated_code_output.get(\"code\", \"\"), user_query, retries)\n                \n                # Execute the code - Placeholder for a safe execution environment\n                execution_result = self._safely_execute_code(code_to_execute, available_columns)\n                \n                final_response = {\n                    \"type\": \"code_result\",\n                    \"result\": execution_result,\n                    \"chart_spec\": generated_code_output.get(\"chart_spec\") # Pass through chart spec if present\n                }\n                self.response_cache.set(cache_key, final_response)\n                return final_response\n\n            except APIError as e:\n                logger.warning(f\"CodeGenAgent: APIError during code generation/execution: {e.message}. Retrying...\")\n                retries += 1\n                if retries > max_retries:\n                    raise APIError(f\"Falha na gera\u00e7\u00e3o/execu\u00e7\u00e3o de c\u00f3digo ap\u00f3s {max_retries} tentativas: {e.message}\", status_code=500) from e\n                # Potentially modify prompt for retry based on error\n                user_query = f\"{user_query}\\n\\nPrevious attempt failed with error: {e.message}. Please refine the code.\"\n            except Exception as e:\n                logger.error(f\"CodeGenAgent: Unexpected error during code generation/execution: {e}\", exc_info=True)\n                retries += 1\n                if retries > max_retries:\n                    raise APIError(f\"Erro inesperado durante a gera\u00e7\u00e3o/execu\u00e7\u00e3o de c\u00f3digo ap\u00f3s {max_retries} tentativas: {str(e)}\", status_code=500) from e\n                user_query = f\"{user_query}\\n\\nPrevious attempt failed with a general error: {str(e)}. Please refine the code.\"\n\n        raise APIError(\"CodeGenAgent: Falha cr\u00edtica na gera\u00e7\u00e3o e execu\u00e7\u00e3o de c\u00f3digo.\", status_code=500)\n\n    def _get_few_shot_examples(self, user_query: str) -> str:\n        \"\"\"\n        Combines pattern matching and RAG to provide few-shot examples.\n        T2.3.1: Integrate with PatternMatcher (few-shot) and QueryRetriever (RAG).\n        \"\"\"", "mimetype": "text/plain", "start_char_idx": 3630, "end_char_idx": 7402, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c12f18ea-55da-4068-9f4a-2a62625fd3f8": {"__data__": {"id_": "c12f18ea-55da-4068-9f4a-2a62625fd3f8", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\agents\\code_gen_agent.py", "language": "python", "lines": 317, "filename": "code_gen_agent.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\agents\\code_gen_agent.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\agents\\code_gen_agent.py", "language": "python", "lines": 317, "filename": "code_gen_agent.py"}, "hash": "1a3da5174f5a007cec5b1f7ed4428d4e5a551f4324693b2e749aa2d6495b8ea5", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "25796a1d-8fb8-4cd2-b811-fcc5610dc200", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\agents\\code_gen_agent.py", "language": "python", "lines": 317, "filename": "code_gen_agent.py"}, "hash": "db7791a9f19284c3a3f40850d26b91021d7de29bc8bb0f3222fd24c49a6e3554", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "556c4691-024e-4413-9a7d-49ef17673983", "node_type": "1", "metadata": {}, "hash": "cdb49e48cfd52530420acb7665223a32865c0cbb9650c86f2a9ea7c2ac682380", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "examples_str = \"\"\n        # From PatternMatcher (exact/known patterns)\n        pattern_match = self.pattern_matcher.match_pattern(user_query)\n        if pattern_match and pattern_match.get(\"example_code\"):\n            examples_str += f\"Exemplo de padr\u00e3o correspondente: {pattern_match['pattern_name']}\\n```python\\n{pattern_match['example_code']}\\n```\\n\"\n\n        # From QueryRetriever (semantically similar past queries)\n        similar_queries = self.query_retriever.get_similar_queries(user_query)\n        if similar_queries:\n            examples_str += \"Exemplos de queries similares passadas:\\n\"\n            for sq in similar_queries:\n                examples_str += f\"- Query: {sq.get('query')}\\n  C\u00f3digo: ```python\\n{sq.get('code')}\\n```\\n\"\n        \n        if not examples_str:\n            examples_str = \"Nenhum exemplo few-shot adicional encontrado.\"\n        return examples_str\n\n\n    def _validate_and_heal_code(self, code: str, user_query: str, attempt: int) -> str:\n        \"\"\"\n        T2.3.2: Implement validation for 'top N' and T2.3.3: auto-recovery of common errors.\n        \"\"\"\n        if not code:\n            raise APIError(\"Generated code is empty.\", status_code=400)\n        \n        # T2.3.2: Implement validation of `top N`\n        code = self._validate_top_n(code, user_query)\n\n        # T2.3.3: Implement auto-recovery of common errors based on attempt\n        if attempt > 0: # Only try healing on subsequent attempts\n            code = self._attempt_auto_healing(code, user_query)\n        \n        return code\n\n    def _validate_top_n(self, code: str, user_query: str) -> str:\n        \"\"\"\n        Detects \"top N\" or similar phrases in the user query and ensures\n        '.head(N)' or '.tail(N)' is applied to the final result if relevant.\n        \"\"\"\n        # Example: \"top 10 produtos\", \"os 5 maiores\"\n        top_n_match = re.search(r'(top|os|as)\\s*(\\d+)\\s*(maiores|menores)?', user_query, re.IGNORECASE)\n        if top_n_match:\n            n = int(top_n_match.group(2))\n            maior_menor = top_n_match.group(3)\n            \n            # Simple heuristic: look for the last assignment to 'result' or 'final_output'\n            # and append .head(n) or .tail(n) if not already present.\n            lines = code.split('\\n')\n            new_lines = []\n            applied_head_tail = False\n            for line in reversed(lines):\n                if not applied_head_tail and (\"result =\" in line or \"final_output =\" in line) and \".head(\" not in line and \".tail(\" not in line:\n                    indent = len(line) - len(line.lstrip())\n                    if maior_menor and \"menores\" in maior_menor.lower():\n                        new_lines.append(f\"{ ' ' * indent}{line.strip()}.tail({n})\")\n                    else:\n                        new_lines.append(f\"{ ' ' * indent}{line.strip()}.head({n})\")\n                    applied_head_tail = True\n                else:\n                    new_lines.append(line)\n            return \"\\n\".join(reversed(new_lines))\n        return code\n\n    def _attempt_auto_healing(self, code: str, user_query: str) -> str:\n        \"\"\"\n        Implements basic self-healing for common code errors.\n        This is a very simplistic example and would be more sophisticated with LLM interaction.\n        \"\"\"\n        # Example 1: Remove .compute() if it's causing issues with Polars\n        if \".compute()\" in code and \"PolarsError: compute\" in user_query: # Check for error msg in user_query for context\n            code = code.replace(\".compute()\", \"\")\n            logger.info(\"Auto-healing: Removed .compute() from code.\")\n            \n        # Example 2: Add .dropna() for ambiguous NA errors\n        if \"NA ambiguous\" in user_query and \".dropna()\" not in code:\n            # Find a suitable place to insert .dropna()\n            lines = code.split('\\n')\n            new_lines = []\n            inserted_dropna = False\n            for line in lines:\n                new_lines.append(line)\n                if \"df.\"", "mimetype": "text/plain", "start_char_idx": 7411, "end_char_idx": 11393, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "556c4691-024e-4413-9a7d-49ef17673983": {"__data__": {"id_": "556c4691-024e-4413-9a7d-49ef17673983", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\agents\\code_gen_agent.py", "language": "python", "lines": 317, "filename": "code_gen_agent.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\agents\\code_gen_agent.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\agents\\code_gen_agent.py", "language": "python", "lines": 317, "filename": "code_gen_agent.py"}, "hash": "1a3da5174f5a007cec5b1f7ed4428d4e5a551f4324693b2e749aa2d6495b8ea5", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c12f18ea-55da-4068-9f4a-2a62625fd3f8", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\agents\\code_gen_agent.py", "language": "python", "lines": 317, "filename": "code_gen_agent.py"}, "hash": "05a6f12057154b2e933dde67cdb53c93be5d3b17ac75e84c8f33529bf1f4fc06", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "in line and \"groupby\" in line and not inserted_dropna: # Example heuristic\n                    new_lines.append(f\"{ ' ' * (len(line) - len(line.lstrip()))}.dropna()\")\n                    inserted_dropna = True\n            if inserted_dropna:\n                code = \"\\n\".join(new_lines)\n                logger.info(\"Auto-healing: Added .dropna() to code.\")\n        \n        # Example 3: Suggest column correction via FieldMapper if error indicates missing column\n        if \"ColumnNotFound\" in user_query: # Placeholder for error message\n            missing_col_match = re.search(r\"ColumnNotFound:\\s*'([^']+)'\", user_query)\n            if missing_col_match:\n                missing_col = missing_col_match.group(1)\n                suggestion = self.field_mapper.suggest_correction(missing_col)\n                if suggestion and suggestion != missing_col:\n                    logger.info(f\"Auto-healing: Suggested correction for missing column '{missing_col}' to '{suggestion}'.\")\n                    # This would ideally involve regenerating code with the corrected column\n                    # For now, it's just a log.\n        return code\n\n    def _safely_execute_code(self, code: str, data_schema: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Executes the generated Python code in a safe environment.\n        This is a critical component for security.\n        \"\"\"\n        # CRITICAL: This is a simplified example. In a production system,\n        # code execution should happen in an isolated sandbox (e.g., Docker container, separate process)\n        # to prevent arbitrary code execution vulnerabilities.\n        \n        # Load real data from Parquet using une_tools\n        import polars as pl # Import polars here to ensure it's available for execution context\n        from app.core.tools.une_tools import _load_data\n\n        # Load real data from Parquet files\n        pandas_df = _load_data()  # Returns pandas DataFrame\n        df = pl.from_pandas(pandas_df)  # Convert to polars DataFrame\n        \n        # Provide necessary libraries and the DataFrame in the execution context\n        # Restrict builtins for enhanced safety\n        exec_globals = {\n            \"pl\": pl,\n            \"df\": df,\n            \"json\": json,\n            \"__builtins__\": {\n                \"list\": list, \"dict\": dict, \"str\": str, \"int\": int, \"float\": float,\n                \"len\": len, \"sum\": sum, \"min\": min, \"max\": max, \"range\": range,\n                \"round\": round, \"abs\": abs, \"Exception\": Exception, \"ValueError\": ValueError,\n                \"TypeError\": TypeError, \"sorted\": sorted, \"enumerate\": enumerate, \n                \"zip\": zip, \"set\": set, \"tuple\": tuple, \"any\": any, \"all\": all, \"bool\": bool\n            }\n        }\n\n        try:\n            exec(code, exec_globals)\n            \n            result = exec_globals.get(\"final_output\", {}).get(\"result\", {})\n            chart_spec = exec_globals.get(\"final_output\", {}).get(\"chart_spec\")\n\n            # Ensure result is JSON-serializable if it's a Polars object\n            if isinstance(result, pl.DataFrame):\n                result = result.to_dicts()\n            elif isinstance(result, pl.Series):\n                 result = result.to_list()\n            elif isinstance(result, list) and all(isinstance(i, (pl.Series, pl.DataFrame)) for i in result):\n                 result = [item.to_dicts() if isinstance(item, pl.DataFrame) else item.to_list() for item in result]\n            \n            return {\"result\": result, \"chart_spec\": chart_spec}\n\n        except Exception as e:\n            # This exception is caught by the error_handler_decorator\n            raise APIError(\n                message=f\"Erro durante a execu\u00e7\u00e3o do c\u00f3digo Python: {str(e)}\",\n                status_code=400,\n                details={\"code_executed\": code, \"error_type\": type(e).__name__, \"error_detail\": str(e)}\n            )", "mimetype": "text/plain", "start_char_idx": 11394, "end_char_idx": 15263, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "abcae947-3821-4ec5-9abb-ac3ecb4cf121": {"__data__": {"id_": "abcae947-3821-4ec5-9abb-ac3ecb4cf121", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\agents\\developer_agent.py", "language": "python", "lines": 136, "filename": "developer_agent.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\agents\\developer_agent.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\agents\\developer_agent.py", "language": "python", "lines": 136, "filename": "developer_agent.py"}, "hash": "b00ee088fba8a7d25cd80a265255160b0bde40e496a9b8d80749b67fe382bd1f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import logging\n\nfrom .base_agent import BaseAgent\nfrom .prompt_loader import PromptLoader\n\n# Configura\u00e7\u00e3o de logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n    filename=\"logs/agent.log\",\n    filemode=\"a\",\n)\nlogger = logging.getLogger(\"developer_agent\")\n\n\nclass DeveloperAgent(BaseAgent):\n    \"\"\"Agente especializado em desenvolvimento de c\u00f3digo.\"\"\"\n\n    def __init__(self, session_id=None, use_mock_data=False, mcp_adapter=None):\n        \"\"\"\n        Inicializa o Agente de Desenvolvimento.\n\n        Args:\n            session_id (str): ID da sess\u00e3o para persist\u00eancia de estado.\n            use_mock_data (bool): Flag para usar dados mockados.\n            mcp_adapter (object): Adaptador MCP para SQL Server.\n        \"\"\"\n        super().__init__(session_id, use_mock_data, mcp_adapter)\n        self._load_prompts()\n        logger.info(\"Agente de Desenvolvimento inicializado. Sess\u00e3o: %s\", session_id)\n\n    def _load_prompts(self):\n        \"\"\"Carrega os prompts do arquivo ou usa um fallback.\"\"\"\n        prompt_loader = PromptLoader()\n        prompt_data = prompt_loader.load_prompt(\"prompt_developer_agent\")\n\n        if prompt_data:\n            self.system_prompt = prompt_data.get(\"system_prompt\", \"\")\n            self.capabilities = prompt_data.get(\"capabilities\", [])\n            self.safety_rules = prompt_data.get(\"safety_rules\", [])\n            self.model_config = prompt_data.get(\"model_config\", {})\n            logger.info(\"Prompt carregado com sucesso para o Agente de Desenvolvimento.\")\n        else:\n            self.system_prompt = (\n                \"Voc\u00ea \u00e9 um assistente virtual \"\n                \"especializado em desenvolvimento de c\u00f3digo.\"\n            )\n            self.capabilities = [\"code_development\", \"code_review\", \"debugging\"]\n            self.safety_rules = [\"no_malicious_code\", \"portuguese_only_responses\"]\n            self.model_config = {\"model\": \"gpt-35-turbo\", \"temperature\": 0.2}\n            logger.warning(\"Usando prompt padr\u00e3o para o Agente de Desenvolvimento.\")\n\n    def process_query(self, query):\n        \"\"\"\n        Processa uma consulta com foco em desenvolvimento de c\u00f3digo.\n\n        Args:\n            query (str): A consulta do usu\u00e1rio.\n\n        Returns:\n            dict: Resposta processada.\n        \"\"\"\n        logger.info(\"Agente de Desenvolvimento processando consulta: %s\", query)\n\n        if not self._is_relevant_query(query):\n            logger.info(\"Consulta n\u00e3o relevante para o agente Dev: %s\", query)\n            return {\n                \"response\": (\n                    \"Esta consulta pode ser melhor atendida por outro \"\n                    \"agente especializado.\"\n                ),\n                \"relevant\": False,\n            }\n\n        try:\n            result = super().process_query(query)\n\n            if self._should_suggest_improvements(query):\n                result[\"response\"] += (\n                    \"\\n\\nPosso sugerir algumas melhorias para este c\u00f3digo. \"\n                    \"Gostaria de v\u00ea-las?\"\n                )\n                result[\"can_improve\"] = True\n\n            return result\n        except Exception as e:\n            logger.error(\"Erro no Agente de Desenvolvimento: %s\", e)\n            return {\n                \"response\": \"Desculpe, ocorreu um erro ao processar sua consulta.\",\n                \"error\": str(e),\n            }\n\n    def _is_relevant_query(self, query):\n        \"\"\"Verifica se a consulta \u00e9 relevante para este agente.\"\"\"\n        query_lower = query.lower()\n        keywords = [\n            \"c\u00f3digo\",\n            \"programa\u00e7\u00e3o\",\n            \"desenvolver\",\n            \"implementar\",\n            \"fun\u00e7\u00e3o\",\n            \"classe\",\n            \"m\u00e9todo\",\n            \"refatorar\",\n            \"otimizar\",\n            \"debug\",\n            \"erro\",\n            \"bug\",\n            \"python\",\n            \"javascript\",\n            \"arquitetura\",\n            \"padr\u00e3o\",\n            \"design pattern\",\n            \"api\",\n            \"interface\",\n            \"m\u00f3dulo\",\n        ]\n        return any(keyword in query_lower for keyword in keywords)\n\n    def _should_suggest_improvements(self, query):\n        \"\"\"Verifica se deve sugerir melhorias de c\u00f3digo.\"\"\"\n        query_lower = query.lower()\n        improvement_keywords = [\n            \"revisar\",\n            \"melhorar\",\n            \"otimizar\",\n            \"refatorar\",\n            \"limpar\",\n            \"performance\",\n            \"desempenho\",\n            \"legibilidade\",\n            \"manuten\u00e7\u00e3o\",\n            \"seguran\u00e7a\",\n        ]\n        return any(keyword in query_lower for keyword in improvement_keywords)", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4617, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a55741f0-4179-4fab-af05-bdbf006e9dd7": {"__data__": {"id_": "a55741f0-4179-4fab-af05-bdbf006e9dd7", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\agents\\multi_step_agent.py", "language": "python", "lines": 275, "filename": "multi_step_agent.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\agents\\multi_step_agent.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\agents\\multi_step_agent.py", "language": "python", "lines": 275, "filename": "multi_step_agent.py"}, "hash": "9d05a2ba33cc7e59695b6fa69fc413e7f4bcdc6a3cade68e433f17e3870bdfb8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "741abada-4bf1-4758-bed8-30d4f8fb5aa0", "node_type": "1", "metadata": {}, "hash": "6d85592bc956f6bf2da9ac663ee49f844b2ef15eaffd317146fc945b90b1d420", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nLangGraph Multi-Step Agent - Workflow c\u00edclico para racioc\u00ednio avan\u00e7ado\nImplementa: Planner \u2192 Executor \u2192 Validator \u2192 (loop se necess\u00e1rio)\n\"\"\"\n\nimport logging\nfrom typing import Dict, Any, List, Optional, TypedDict, Annotated\nfrom dataclasses import dataclass\nimport operator\n\nlogger = logging.getLogger(__name__)\n\n# Tentar importar LangGraph - fallback se n\u00e3o dispon\u00edvel\ntry:\n    from langgraph.graph import StateGraph, END\n    LANGGRAPH_AVAILABLE = True\nexcept ImportError:\n    LANGGRAPH_AVAILABLE = False\n    logger.warning(\"LangGraph n\u00e3o dispon\u00edvel - usando implementa\u00e7\u00e3o simplificada\")\n\n\nclass AgentState(TypedDict):\n    \"\"\"Estado do agente durante execu\u00e7\u00e3o do workflow.\"\"\"\n    query: str                          # Pergunta original\n    plan: Optional[str]                 # Plano gerado\n    tool_calls: List[Dict[str, Any]]    # Chamadas de ferramentas\n    results: List[Dict[str, Any]]       # Resultados das ferramentas\n    response: Optional[str]             # Resposta final\n    validation: Optional[Dict[str, Any]]  # Resultado da valida\u00e7\u00e3o\n    iteration: int                      # N\u00famero da itera\u00e7\u00e3o\n    should_retry: bool                  # Se deve tentar novamente\n    error: Optional[str]                # Mensagem de erro\n\n\nclass MultiStepAgent:\n    \"\"\"\n    Agente multi-step com workflow c\u00edclico.\n    \n    Workflow:\n    1. Planner: Analisa query e define estrat\u00e9gia\n    2. Executor: Executa ferramentas necess\u00e1rias\n    3. Validator: Valida resultado e decide se precisa retry\n    4. (Loop): Se necess\u00e1rio, refina e tenta novamente\n    \"\"\"\n    \n    MAX_ITERATIONS = 3\n    \n    def __init__(self, agent, validator=None):\n        \"\"\"\n        Args:\n            agent: Agente base (CaculinhaBIAgent)\n            validator: Validador de respostas (opcional)\n        \"\"\"\n        self.agent = agent\n        self.validator = validator\n        self.execution_count = 0\n        \n        # Construir grafo se LangGraph dispon\u00edvel\n        if LANGGRAPH_AVAILABLE:\n            self.graph = self._build_graph()\n        else:\n            self.graph = None\n    \n    def _build_graph(self):\n        \"\"\"Constr\u00f3i o grafo de estados do workflow.\"\"\"\n        workflow = StateGraph(AgentState)\n        \n        # Adicionar nodes\n        workflow.add_node(\"planner\", self._planner_node)\n        workflow.add_node(\"executor\", self._executor_node)\n        workflow.add_node(\"validator\", self._validator_node)\n        \n        # Definir edges\n        workflow.set_entry_point(\"planner\")\n        workflow.add_edge(\"planner\", \"executor\")\n        workflow.add_edge(\"executor\", \"validator\")\n        \n        # Conditional edge: retry ou finalizar\n        workflow.add_conditional_edges(\n            \"validator\",\n            self._should_retry,\n            {\n                \"retry\": \"planner\",\n                \"end\": END\n            }\n        )\n        \n        return workflow.compile()\n    \n    def _planner_node(self, state: AgentState) -> AgentState:\n        \"\"\"Node de planejamento: analisa query e define estrat\u00e9gia.\"\"\"\n        logger.info(f\"\ud83d\udcdd Planner: Analisando query (iter={state['iteration']})\")\n        \n        # Criar plano baseado na query e itera\u00e7\u00e3o anterior\n        plan = f\"Analisar: {state['query'][:100]}\"\n        \n        if state['iteration'] > 0 and state.get('error'):\n            plan = f\"Retry devido a: {state['error'][:50]}. \" + plan\n        \n        return {**state, \"plan\": plan}\n    \n    def _executor_node(self, state: AgentState) -> AgentState:\n        \"\"\"Node de execu\u00e7\u00e3o: chama o agente base.\"\"\"\n        logger.info(f\"\u2699\ufe0f Executor: Executando plano\")\n        \n        try:\n            # Chamar agente base\n            result = self.agent.run(state['query'])\n            \n            return {\n                **state,\n                \"results\": [result],\n                \"response\": result.get(\"result\", \"\"),\n                \"error\": None\n            }\n        except Exception as e:\n            logger.error(f\"Erro no Executor: {e}\")\n            return {\n                **state,\n                \"error\": str(e),\n                \"response\": None\n            }\n    \n    def _validator_node(self, state: AgentState) -> AgentState:\n        \"\"\"Node de valida\u00e7\u00e3o: verifica qualidade da resposta.\"\"\"", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4214, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "741abada-4bf1-4758-bed8-30d4f8fb5aa0": {"__data__": {"id_": "741abada-4bf1-4758-bed8-30d4f8fb5aa0", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\agents\\multi_step_agent.py", "language": "python", "lines": 275, "filename": "multi_step_agent.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\agents\\multi_step_agent.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\agents\\multi_step_agent.py", "language": "python", "lines": 275, "filename": "multi_step_agent.py"}, "hash": "9d05a2ba33cc7e59695b6fa69fc413e7f4bcdc6a3cade68e433f17e3870bdfb8", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a55741f0-4179-4fab-af05-bdbf006e9dd7", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\agents\\multi_step_agent.py", "language": "python", "lines": 275, "filename": "multi_step_agent.py"}, "hash": "ee699ebe3e18fb5e5e944954574b2f55f24c8ab948ddc7f11550374b61d6a200", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "89d236b9-f029-4959-b677-aa92c10b740a", "node_type": "1", "metadata": {}, "hash": "6515b5a84a1d95d51e577ac2edf343c1cdbeac1ade69a1bef31999b5b23be4c4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "logger.info(f\"\u2705 Validator: Validando resposta\")\n        \n        # Se houve erro, marcar para retry\n        if state.get('error'):\n            return {\n                **state,\n                \"should_retry\": state['iteration'] < self.MAX_ITERATIONS,\n                \"iteration\": state['iteration'] + 1\n            }\n        \n        # Usar validador se dispon\u00edvel\n        if self.validator:\n            validation = self.validator.validate(\n                {\"result\": state.get('response', '')},\n                state['query']\n            )\n            \n            should_retry = (\n                not validation.is_valid and \n                validation.confidence < 0.5 and\n                state['iteration'] < self.MAX_ITERATIONS\n            )\n            \n            return {\n                **state,\n                \"validation\": {\n                    \"is_valid\": validation.is_valid,\n                    \"confidence\": validation.confidence,\n                    \"issues\": validation.issues\n                },\n                \"should_retry\": should_retry,\n                \"iteration\": state['iteration'] + 1\n            }\n        \n        # Sem validador, aceitar resposta\n        return {\n            **state,\n            \"validation\": {\"is_valid\": True, \"confidence\": 1.0},\n            \"should_retry\": False,\n            \"iteration\": state['iteration'] + 1\n        }\n    \n    def _should_retry(self, state: AgentState) -> str:\n        \"\"\"Decide se deve fazer retry ou finalizar.\"\"\"\n        if state.get('should_retry', False):\n            logger.info(f\"\ud83d\udd04 Retry: iteration={state['iteration']}\")\n            return \"retry\"\n        return \"end\"\n    \n    def run(self, query: str, chat_history: List[Dict] = None) -> Dict[str, Any]:\n        \"\"\"\n        Executa workflow multi-step.\n        \n        Args:\n            query: Pergunta do usu\u00e1rio\n            chat_history: Hist\u00f3rico de chat (opcional)\n            \n        Returns:\n            Resultado do agente\n        \"\"\"\n        self.execution_count += 1\n        logger.info(f\"\ud83d\ude80 MultiStepAgent: Iniciando workflow para: {query[:50]}...\")\n        \n        # Estado inicial\n        initial_state: AgentState = {\n            \"query\": query,\n            \"plan\": None,\n            \"tool_calls\": [],\n            \"results\": [],\n            \"response\": None,\n            \"validation\": None,\n            \"iteration\": 0,\n            \"should_retry\": False,\n            \"error\": None\n        }\n        \n        # Usar LangGraph se dispon\u00edvel\n        if self.graph and LANGGRAPH_AVAILABLE:\n            try:\n                final_state = self.graph.invoke(initial_state)\n                \n                return {\n                    \"type\": \"text\",\n                    \"result\": final_state.get(\"response\", \"\"),\n                    \"validation\": final_state.get(\"validation\"),\n                    \"iterations\": final_state.get(\"iteration\", 1)\n                }\n            except Exception as e:\n                logger.error(f\"Erro no LangGraph: {e}\")\n                # Fallback para implementa\u00e7\u00e3o simples\n        \n        # Implementa\u00e7\u00e3o simplificada (fallback)\n        return self._run_simple(query, chat_history)\n    \n    def _run_simple(self, query: str, chat_history: List[Dict] = None) -> Dict[str, Any]:\n        \"\"\"Implementa\u00e7\u00e3o simplificada sem LangGraph.\"\"\"\n        logger.info(\"\ud83d\udcdd Usando implementa\u00e7\u00e3o simplificada (sem LangGraph)\")\n        \n        for iteration in range(self.MAX_ITERATIONS):\n            try:\n                # Executar agente\n                result = self.agent.run(query, chat_history)\n                \n                # Validar se poss\u00edvel\n                if self.validator:\n                    validation = self.validator.validate(result, query)\n                    \n                    if validation.is_valid or validation.confidence >= 0.5:\n                        return {\n                            **result,\n                            \"validation\": {\n                                \"confidence\": validation.confidence,\n                                \"issues\": validation.issues\n                            },\n                            \"iterations\": iteration + 1\n                        }\n                    \n                    logger.warning(f\"Valida\u00e7\u00e3o falhou (iter={iteration}): {validation.issues}\")\n                else:\n                    return {**result, \"iterations\": iteration + 1}\n                    \n            except Exception as e:\n                logger.error(f\"Erro na itera\u00e7\u00e3o {iteration}: {e}\")\n                if iteration == self.MAX_ITERATIONS - 1:\n                    return {\n                        \"type\": \"text\",\n                        \"result\": f\"Erro ap\u00f3s {self.MAX_ITERATIONS} tentativas: {str(e)}\",\n                        \"iterations\": iteration + 1\n                    }\n        \n        return {\n            \"type\": \"text\",\n            \"result\": \"N\u00e3o foi poss\u00edvel obter uma resposta v\u00e1lida.\",\n            \"iterations\": self.MAX_ITERATIONS\n        }\n    \n    def get_stats(self) -> Dict[str, Any]:\n        \"\"\"Retorna estat\u00edsticas do agente.\"\"\"", "mimetype": "text/plain", "start_char_idx": 4223, "end_char_idx": 9290, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "89d236b9-f029-4959-b677-aa92c10b740a": {"__data__": {"id_": "89d236b9-f029-4959-b677-aa92c10b740a", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\agents\\multi_step_agent.py", "language": "python", "lines": 275, "filename": "multi_step_agent.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\agents\\multi_step_agent.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\agents\\multi_step_agent.py", "language": "python", "lines": 275, "filename": "multi_step_agent.py"}, "hash": "9d05a2ba33cc7e59695b6fa69fc413e7f4bcdc6a3cade68e433f17e3870bdfb8", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "741abada-4bf1-4758-bed8-30d4f8fb5aa0", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\agents\\multi_step_agent.py", "language": "python", "lines": 275, "filename": "multi_step_agent.py"}, "hash": "09e1df4346d0a83cb409d4b0f5a7f3cdb98657385e42c440252b07ebdd27dcfe", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "return {\n            \"execution_count\": self.execution_count,\n            \"max_iterations\": self.MAX_ITERATIONS,\n            \"langgraph_available\": LANGGRAPH_AVAILABLE\n        }\n\n\n# Factory function\ndef create_multi_step_agent(base_agent, validator=None) -> MultiStepAgent:\n    \"\"\"Cria inst\u00e2ncia do MultiStepAgent.\"\"\"\n    return MultiStepAgent(agent=base_agent, validator=validator)", "mimetype": "text/plain", "start_char_idx": 9299, "end_char_idx": 9681, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f5d22f14-d91d-4179-9e5b-dc8429195921": {"__data__": {"id_": "f5d22f14-d91d-4179-9e5b-dc8429195921", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\agents\\product_agent.py", "language": "python", "lines": 368, "filename": "product_agent.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\agents\\product_agent.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\agents\\product_agent.py", "language": "python", "lines": 368, "filename": "product_agent.py"}, "hash": "3368c356670aa6164e34c001d5fe582690b9c9fef3f4e47a1702be6be756b785", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "853be3c2-b53e-406a-a8d7-64e6cd41be26", "node_type": "1", "metadata": {}, "hash": "7259e3cc8650225ddce027fa9f64cad17bd508234423f6c34ec9223bd8aa5924", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import logging\nimport re\nimport pandas as pd  # Importar pandas\n\nfrom app.core.utils.db_utils import get_table_df\n\n\nimport json\nfrom app.core.agents.caculinha_bi_agent import initialize_agent_for_session\n\n\nclass ProductAgent:\n    \"\"\"\n    Agente para consulta e an\u00e1lise de produtos, usando apenas Parquet.\n    \"\"\"\n\n    PRODUCT_TABLES = [\"ADMAT\", \"Admat_OPCOM\"]\n\n    def __init__(self):\n        self.logger = logging.getLogger(\"ProductAgent\")\n        self.catalog = self._load_catalog()\n        # Inicializa o agente LLM que ser\u00e1 usado para raciocinar sobre os dados\n        self.llm_agent = initialize_agent_for_session()\n        self.logger.info(\n            \"ProductAgent inicializado com o cat\u00e1logo de dados e agente LLM.\"\n        )\n\n    def _load_catalog(self):\n        \"\"\"Carrega o cat\u00e1logo de dados enriquecido.\"\"\"\n        catalog_path = \"data/CATALOGO_PARA_EDICAO.json\"\n        try:\n            with open(catalog_path, \"r\", encoding=\"utf-8\") as f:\n                return json.load(f)\n        except FileNotFoundError:\n            self.logger.error(\n                f\"Arquivo de cat\u00e1logo n\u00e3o encontrado em {catalog_path}. O agente pode n\u00e3o funcionar corretamente.\"\n            )\n            return []\n        except json.JSONDecodeError:\n            self.logger.error(\n                f\"Erro ao decodificar o JSON do cat\u00e1logo em {catalog_path}.\"\n            )\n            return []\n\n    def search_products(self, query, limit=10):\n        self.logger.info(f'Iniciando busca de produtos para a query: \"{query}\"')\n\n        prompt_for_llm = self._build_prompt_for_filter_extraction(query)\n\n        llm_response_raw = self.llm_agent.process_query(prompt_for_llm)\n\n        llm_response_obj = llm_response_raw.get(\"output\", llm_response_raw)\n\n        self.logger.info(f\"Resposta bruta do LLM: {llm_response_obj}\")\n\n        if isinstance(llm_response_obj, str):\n            try:\n                json_match = re.search(\n                    r\"```json\\n(.*?)```\", llm_response_obj, re.DOTALL\n                )\n                if json_match:\n                    json_str = json_match.group(1).strip()\n                else:\n                    json_str = llm_response_obj.strip()\n                extracted_filters = json.loads(json_str)\n            except json.JSONDecodeError as e:\n                self.logger.error(\n                    f\"Falha ao decodificar JSON da resposta do LLM: '{llm_response_obj}'. Erro: {e}\"\n                )\n                return {\n                    \"success\": False,\n                    \"message\": \"N\u00e3o consegui entender os crit\u00e9rios para a busca.\",\n                }\n        else:\n            extracted_filters = llm_response_obj\n\n        target_file = extracted_filters.get(\"target_file\", \"ADMAT.parquet\")\n        filters = extracted_filters.get(\"filters\", [])\n\n        self.logger.info(f\"Filtros extra\u00eddos: {filters} para o arquivo {target_file}\")\n\n        df = get_table_df(target_file.replace(\".parquet\", \"\"))\n        if df is None:\n            return {\n                \"success\": False,\n                \"message\": f\"Arquivo de dados {target_file} n\u00e3o encontrado.\",\n            }\n\n        results = df\n        if filters:\n            for f in filters:\n                col, op, val = f.get(\"column\"), f.get(\"operator\"), f.get(\"value\")\n                if col in results.columns:\n                    try:\n                        if op != \"contains\":\n                            results[col] = pd.to_numeric(results[col], errors=\"coerce\")\n                            val = pd.to_numeric(val)\n\n                        if op == \">\":\n                            results = results[results[col] > val]\n                        elif op == \"<\":\n                            results = results[results[col] < val]\n                        elif op == \"==\":\n                            results = results[results[col] == val]\n                        elif op == \"!=\":\n                            results = results[results[col] != val]\n                        elif op == \"contains\":\n                            results = results[\n                                results[col]\n                                .astype(str)\n                                .str.contains(str(val), case=False, na=False)\n                            ]\n                    except (ValueError, TypeError) as e:\n                        self.logger.error(\n                            f\"Erro ao aplicar filtro na coluna '{col}': {e}\"\n                        )\n                        results = results[\n                            results[col]\n                            .astype(str)\n                            .str.contains(str(val), case=False, na=False)\n                        ]\n                else:\n                    self.logger.warning(f\"Coluna '{col}' n\u00e3o encontrada.\")\n\n        if results.empty:\n            return {\n                \"success\": False,\n                \"message\": \"Nenhum produto encontrado.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4899, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "853be3c2-b53e-406a-a8d7-64e6cd41be26": {"__data__": {"id_": "853be3c2-b53e-406a-a8d7-64e6cd41be26", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\agents\\product_agent.py", "language": "python", "lines": 368, "filename": "product_agent.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\agents\\product_agent.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\agents\\product_agent.py", "language": "python", "lines": 368, "filename": "product_agent.py"}, "hash": "3368c356670aa6164e34c001d5fe582690b9c9fef3f4e47a1702be6be756b785", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f5d22f14-d91d-4179-9e5b-dc8429195921", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\agents\\product_agent.py", "language": "python", "lines": 368, "filename": "product_agent.py"}, "hash": "1db08706445997a5792ab8e4cddd585b358ee3c8e92df702002aa0c10d0ee07a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ab396180-76a2-46dc-b858-d4ceb94476c4", "node_type": "1", "metadata": {}, "hash": "20cd92ee1b004ff699b8eb544cc19127d38e37d3a7d10799455fbadc64087544", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\",\n                \"data\": [],\n            }\n\n        data = results.head(limit).to_dict(orient=\"records\")\n        column_descriptions = next(\n            (\n                item.get(\"column_descriptions\", {})\n                for item in self.catalog\n                if item.get(\"file_name\") == target_file\n            ),\n            {},\n        )\n\n        return {\n            \"success\": True,\n            \"data\": data,\n            \"total_found\": len(results),\n            \"column_descriptions\": column_descriptions,\n        }\n\n    def _build_prompt_for_filter_extraction(self, query):\n        \"\"\"Constr\u00f3i o prompt para o LLM extrair filtros da query do usu\u00e1rio.\"\"\"\n        prompt_template = \"\"\"\n        Voc\u00ea \u00e9 um especialista em an\u00e1lise de dados. Sua tarefa \u00e9 converter a pergunta de um usu\u00e1rio em filtros JSON para uma busca em um DataFrame pandas.\n        Use o cat\u00e1logo de dados abaixo como sua \u00fanica fonte de verdade sobre a estrutura dos dados.\n\n        [CAT\u00c1LOGO DE DADOS]\n        {catalog}\n        \n        [PERGUNTA DO USU\u00c1RIO]\n        \"{query}\"\n\n        [INSTRU\u00c7\u00d5ES]\n        1. Analise a pergunta do usu\u00e1rio e o cat\u00e1logo de dados para identificar o arquivo e as colunas mais relevantes.\n        2. Para perguntas sobre vendas, priorize o arquivo `ADMAT.parquet` e use a coluna `VENDA_30DD` para representar a quantidade de vendas.\n        3. Converta a pergunta em uma lista de filtros JSON. Cada filtro deve ser um objeto com \"column\", \"operator\" e \"value\".\n        4. Operadores suportados: `==` (igual a), `!=` (diferente de), `>` (maior que), `<` (menor que), `contains` (para strings).\n        5. Para buscas em colunas de texto (string), sempre use o operador `contains`.\n        6. Para buscas em colunas num\u00e9ricas, use `==`, `!=`, `>`, `<`.\n        7. **Sua resposta deve conter APENAS o c\u00f3digo JSON, sem nenhum texto, explica\u00e7\u00e3o ou formata\u00e7\u00e3o adicional.**\n\n        [EXEMPLO 1]\n        Pergunta: \"quais os produtos da categoria brinquedos com pre\u00e7o maior que 50?\"\n        Resposta JSON:\n        ```json\n        {{\n            \"target_file\": \"ADMAT.parquet\",\n            \"filters\": [\n                {{\n                    \"column\": \"NOMECATEGORIA\",\n                    \"operator\": \"contains\",\n                    \"value\": \"brinquedos\"\n                }},\n                {{\n                    \"column\": \"LIQUIDO_38\",\n                    \"operator\": \">\",\n                    \"value\": 50\n                }}\n            ]\n        }}\n        ```\n\n        [EXEMPLO 2]\n        Pergunta: \"liste os itens do fabricante ACME que n\u00e3o sejam do grupo Papelaria\"\n        Resposta JSON:\n        ```json\n        {{\n            \"target_file\": \"ADMAT.parquet\",\n            \"filters\": [\n                {{\n                    \"column\": \"NOMEFABRICANTE\",\n                    \"operator\": \"contains\",\n                    \"value\": \"ACME\"\n                }},\n                {{\n                    \"column\": \"NOMEGRUPO\",\n                    \"operator\": \"!=\",\n                    \"value\": \"Papelaria\"\n                }}\n            ]\n        }}\n        ```\n\n        [RESPOSTA JSON]\n        \"\"\"\n        return prompt_template.format(\n            catalog=json.dumps(self.catalog, indent=2, ensure_ascii=False), query=query\n        )\n\n    def _simulate_llm_filter_extraction(self, query):\n        \"\"\"Fun\u00e7\u00e3o de simula\u00e7\u00e3o para demonstrar a extra\u00e7\u00e3o de filtros. Substituir por uma chamada real ao LLM.\"\"\"\n        self.logger.warning(\n            \"Usando extra\u00e7\u00e3o de filtros simulada. Substituir por chamada real ao LLM.\"", "mimetype": "text/plain", "start_char_idx": 4899, "end_char_idx": 8408, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ab396180-76a2-46dc-b858-d4ceb94476c4": {"__data__": {"id_": "ab396180-76a2-46dc-b858-d4ceb94476c4", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\agents\\product_agent.py", "language": "python", "lines": 368, "filename": "product_agent.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\agents\\product_agent.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\agents\\product_agent.py", "language": "python", "lines": 368, "filename": "product_agent.py"}, "hash": "3368c356670aa6164e34c001d5fe582690b9c9fef3f4e47a1702be6be756b785", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "853be3c2-b53e-406a-a8d7-64e6cd41be26", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\agents\\product_agent.py", "language": "python", "lines": 368, "filename": "product_agent.py"}, "hash": "d311396d17ec0c876873ef98710fcc667f3f04a72b00d87da530cfe574d98fee", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "71452bd2-2aee-405a-b872-6cfc528ca98c", "node_type": "1", "metadata": {}, "hash": "d71e7508511d6e74ce8e7f8228553bb0d0dda457ae565c4f78e927cad7a31a0b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Substituir por chamada real ao LLM.\"\n        )\n        if \"brinquedos\" in query.lower():\n            return {\n                \"target_file\": \"ADMAT.parquet\",\n                \"filters\": {\"CATEGORIA\": \"brinquedos\"},\n            }\n        if \"pre\u00e7o maior que 100\" in query.lower():\n            return {\n                \"target_file\": \"ADMAT.parquet\",\n                \"filters\": {\n                    \"PRECO_38PERCENT\": \"> 100\"\n                },  # A l\u00f3gica de aplica\u00e7\u00e3o precisaria tratar '>'\n            }\n        # Simula\u00e7\u00e3o de busca por nome\n        match = re.search(r\"produtos com nome (\\w+)\", query, re.IGNORECASE)\n        if match:\n            product_name = match.group(1)\n            return {\"target_file\": \"ADMAT.parquet\", \"filters\": {\"NOME\": product_name}}\n        return {\"target_file\": \"ADMAT.parquet\", \"filters\": {}}\n\n    def get_product_details(self, product_code):\n        self.logger.info(f\"Buscando detalhes do produto com c\u00f3digo: {product_code}\")\n        filters = {\"PRODUTO\": product_code}\n        df = get_table_df(\"ADMAT\", filters=filters)\n        if df is None or df.empty:\n            self.logger.warning(\n                f\"Produto com c\u00f3digo {product_code} n\u00e3o encontrado ou arquivo Parquet ausente.\"\n            )\n            return {\n                \"success\": False,\n                \"message\": \"Produto n\u00e3o encontrado ou arquivo Parquet ausente\",\n            }\n\n        prod = df.iloc[0][\n            [\n                \"PRODUTO\",\n                \"NOME\",\n                \"LIQUIDO_38\",\n                \"NOMEFABRICANTE\",\n                \"NOMECATEGORIA\",\n                \"NOMEGRUPO\",\n            ]\n        ]\n        product = {\n            \"codigo\": prod[\"PRODUTO\"],\n            \"nome\": prod[\"NOME\"],\n            \"preco\": prod[\"LIQUIDO_38\"],\n            \"fabricante\": prod[\"NOMEFABRICANTE\"],\n            \"categoria\": prod[\"NOMECATEGORIA\"],\n            \"grupo\": prod[\"NOMEGRUPO\"],\n        }\n        self.logger.info(\n            f\"Detalhes do produto {product_code} encontrados: {product['nome']}\"\n        )\n        return {\"success\": True, \"product\": product}\n\n    def get_columns_info(self):\n        df = get_table_df(\"ADMAT\")\n        if df is None:\n            return {\n                \"success\": False,\n                \"message\": \"Arquivo Parquet da tabela ADMAT n\u00e3o encontrado\",\n            }\n        columns = list(df.columns)\n        dtypes = {col: str(df[col].dtype) for col in columns}\n        return {\"success\": True, \"columns\": columns, \"dtypes\": dtypes}\n\n    def analyze_product_performance(self, product_code):\n        details = self.get_product_details(product_code)\n        if not details.get(\"success\"):\n            return details\n        preco = float(details[\"product\"].get(\"preco\", 0))\n        analysis = {\n            \"product_id\": product_code,\n            \"analysis\": (f\"An\u00e1lise do produto {details['product'].get('nome', 'N/A')}\"),\n            \"price_category\": (\n                \"Alto\" if preco > 100 else \"M\u00e9dio\" if preco > 50 else \"Baixo\"\n            ),\n            \"recommendations\": [\n                \"Verificar estoque regularmente\",\n                \"Monitorar pre\u00e7os da concorr\u00eancia\",\n            ],\n            \"score\": min(10, max(1, preco / 10)),\n        }\n        return {\"success\": True, \"analysis\": analysis}\n\n    def get_sales_history(self, product_code):\n        self.logger.info(f\"Buscando hist\u00f3rico de vendas para o produto: {product_code}\")\n\n        df_admat = get_table_df(\"ADMAT\")\n        if df_admat is None or df_admat.empty:\n            self.logger.warning(\n                \"ADMAT.parquet n\u00e3o encontrado ou vazio. N\u00e3o \u00e9 poss\u00edvel gerar hist\u00f3rico de vendas.\"\n            )\n            return {\"success\": False, \"message\": \"Dados de vendas n\u00e3o dispon\u00edveis.\"}\n\n        # Encontrar a linha do produto\n        product_row = df_admat[df_admat[\"PRODUTO\"] == product_code]\n        if product_row.empty:\n            self.logger.warning(\n                f\"Produto {product_code} n\u00e3o encontrado em ADMAT.parquet.\"\n            )\n            return {\n                \"success\": False,\n                \"message\": f\"Produto {product_code} n\u00e3o encontrado nos dados de vendas.", "mimetype": "text/plain", "start_char_idx": 8372, "end_char_idx": 12496, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "71452bd2-2aee-405a-b872-6cfc528ca98c": {"__data__": {"id_": "71452bd2-2aee-405a-b872-6cfc528ca98c", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\agents\\product_agent.py", "language": "python", "lines": 368, "filename": "product_agent.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\agents\\product_agent.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\agents\\product_agent.py", "language": "python", "lines": 368, "filename": "product_agent.py"}, "hash": "3368c356670aa6164e34c001d5fe582690b9c9fef3f4e47a1702be6be756b785", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ab396180-76a2-46dc-b858-d4ceb94476c4", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\agents\\product_agent.py", "language": "python", "lines": 368, "filename": "product_agent.py"}, "hash": "d9e5e2950e1e3df04a6a220a33344afd13f2985dd2d3fa07026b89aea2e59bdd", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\",\n            }\n\n        product_row = product_row.iloc[0]\n\n        sales_data = []\n        # Coletar dados de vendas mensais (assumindo colunas de data)\n        # Ex: '2023-05-01 00:00:00', '2023-06-01 00:00:00', etc.\n        # E 'VENDA_30DD' (vendas dos \u00faltimos 30 dias)\n\n        # Tentativa de coletar dados de vendas mensais\n        for col in df_admat.columns:\n            try:\n                # Tenta converter o nome da coluna para data\n                date_obj = pd.to_datetime(col)\n                # Verifica se \u00e9 uma coluna de m\u00eas/ano e se o valor n\u00e3o \u00e9 nulo\n                if not pd.isna(product_row[col]):\n                    sales_data.append(\n                        {\n                            \"date\": date_obj.strftime(\"%Y-%m\"),\n                            \"quantity\": product_row[col],\n                        }\n                    )\n            except ValueError:\n                continue  # N\u00e3o \u00e9 uma coluna de data\n\n        # Adicionar VENDA_30DD se existir e n\u00e3o for nulo\n        if \"VENDA_30DD\" in product_row and not pd.isna(product_row[\"VENDA_30DD\"]):\n            sales_data.append(\n                {\"date\": \"\u00daltimos 30 Dias\", \"quantity\": product_row[\"VENDA_30DD\"]}\n            )\n\n        if not sales_data:\n            self.logger.warning(\n                f\"Nenhum dado de vendas encontrado para o produto {product_code} em ADMAT.parquet.\"\n            )\n            return {\n                \"success\": False,\n                \"message\": f\"Nenhum dado de vendas encontrado para o produto {product_code}.\",\n            }\n\n        return {\"success\": True, \"sales_history\": sales_data}", "mimetype": "text/plain", "start_char_idx": 12496, "end_char_idx": 14105, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "09a50ea9-8734-4a05-af88-75e345d3954b": {"__data__": {"id_": "09a50ea9-8734-4a05-af88-75e345d3954b", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\agents\\prompt_loader.py", "language": "python", "lines": 133, "filename": "prompt_loader.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\agents\\prompt_loader.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\agents\\prompt_loader.py", "language": "python", "lines": 133, "filename": "prompt_loader.py"}, "hash": "8808cf113ea815487ce9f35b554b26b5766fb905bbf16863143a9fecf49df224", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9297d392-c2b3-45c3-92e1-a7c2df1a3b0c", "node_type": "1", "metadata": {}, "hash": "c6d8eb0f26b713762f3e8e36ae70bb1fd2c0f4b7bbf084e2f177220fefb7ee25", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import json\nimport logging\nimport os\nfrom typing import Any, Dict, Optional\n\n# Configura\u00e7\u00e3o de logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n    filename=\"logs/agent.log\",\n    filemode=\"a\",\n)\nlogger = logging.getLogger(\"prompt_loader\")", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 309, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9297d392-c2b3-45c3-92e1-a7c2df1a3b0c": {"__data__": {"id_": "9297d392-c2b3-45c3-92e1-a7c2df1a3b0c", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\agents\\prompt_loader.py", "language": "python", "lines": 133, "filename": "prompt_loader.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\agents\\prompt_loader.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\agents\\prompt_loader.py", "language": "python", "lines": 133, "filename": "prompt_loader.py"}, "hash": "8808cf113ea815487ce9f35b554b26b5766fb905bbf16863143a9fecf49df224", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "09a50ea9-8734-4a05-af88-75e345d3954b", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\agents\\prompt_loader.py", "language": "python", "lines": 133, "filename": "prompt_loader.py"}, "hash": "d6484a8fae30bc1f3a04d22cca074bc58fa0f2c1e889704823126d437c84bcc2", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "class PromptLoader:\n    \"\"\"\n    Classe respons\u00e1vel por carregar prompts externos em formato JSON\n    \"\"\"\n\n    def __init__(self, prompts_dir: str = None):\n        \"\"\"\n        Inicializa o carregador de prompts\n\n        Args:\n            prompts_dir (str): Diret\u00f3rio onde os arquivos de prompt est\u00e3o localizados\n        \"\"\"\n        # Define o diret\u00f3rio de prompts padr\u00e3o se n\u00e3o for especificado\n        if prompts_dir is None:\n            base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n            self.prompts_dir = os.path.join(base_dir, \"prompts\")\n        else:\n            self.prompts_dir = prompts_dir\n\n        # Cria o diret\u00f3rio de prompts se n\u00e3o existir\n        if not os.path.exists(self.prompts_dir):\n            try:\n                os.makedirs(self.prompts_dir)\n                logger.info(f\"Diret\u00f3rio de prompts criado: {self.prompts_dir}\")\n            except Exception as e:\n                logger.error(f\"Erro ao criar diret\u00f3rio de prompts: {e}\")\n\n        logger.info(\n            f\"Carregador de prompts inicializado. Diret\u00f3rio: {self.prompts_dir}\"\n        )\n\n    def load_prompt(self, prompt_name: str) -> Optional[Dict[str, Any]]:\n        \"\"\"\n        Carrega um prompt espec\u00edfico pelo nome do arquivo\n\n        Args:\n            prompt_name (str): Nome do arquivo de prompt (sem extens\u00e3o)\n\n        Returns:\n            dict: Conte\u00fado do prompt carregado ou None se ocorrer erro\n        \"\"\"\n        # Adiciona a extens\u00e3o .json se n\u00e3o estiver presente\n        if not prompt_name.endswith(\".json\"):\n            prompt_file = f\"{prompt_name}.json\"\n        else:\n            prompt_file = prompt_name\n\n        # Constr\u00f3i o caminho completo do arquivo\n        prompt_path = os.path.join(self.prompts_dir, prompt_file)\n\n        # Verifica se o arquivo existe\n        if not os.path.exists(prompt_path):\n            logger.error(f\"Arquivo de prompt n\u00e3o encontrado: {prompt_path}\")\n            return None\n\n        # Carrega o arquivo JSON\n        try:\n            with open(prompt_path, \"r\", encoding=\"utf-8\") as file:\n                prompt_data = json.load(file)\n                logger.info(f\"Prompt carregado com sucesso: {prompt_name}\")\n                return prompt_data\n        except json.JSONDecodeError as e:\n            logger.error(f\"Erro ao decodificar JSON do prompt {prompt_name}: {e}\")\n            return None\n        except Exception as e:\n            logger.error(f\"Erro ao carregar prompt {prompt_name}: {e}\")\n            return None\n\n    def list_available_prompts(self) -> list:\n        \"\"\"\n        Lista todos os prompts dispon\u00edveis no diret\u00f3rio\n\n        Returns:\n            list: Lista de nomes de arquivos de prompt dispon\u00edveis\n        \"\"\"\n        try:\n            # Lista todos os arquivos .json no diret\u00f3rio de prompts\n            prompt_files = [\n                f\n                for f in os.listdir(self.prompts_dir)\n                if f.endswith(\".json\")\n                and os.path.isfile(os.path.join(self.prompts_dir, f))\n            ]\n            return prompt_files\n        except Exception as e:\n            logger.error(f\"Erro ao listar prompts dispon\u00edveis: {e}\")\n            return []\n\n    def save_prompt(self, prompt_name: str, prompt_data: Dict[str, Any]) -> bool:\n        \"\"\"\n        Salva um prompt em formato JSON\n\n        Args:\n            prompt_name (str): Nome do arquivo de prompt (sem extens\u00e3o)\n            prompt_data (dict): Dados do prompt a serem salvos\n\n        Returns:\n            bool: True se o prompt foi salvo com sucesso, False caso contr\u00e1rio\n        \"\"\"\n        # Adiciona a extens\u00e3o .json se n\u00e3o estiver presente\n        if not prompt_name.endswith(\".json\"):\n            prompt_file = f\"{prompt_name}.json\"\n        else:\n            prompt_file = prompt_name\n\n        # Constr\u00f3i o caminho completo do arquivo\n        prompt_path = os.path.join(self.prompts_dir, prompt_file)\n\n        # Salva o arquivo JSON\n        try:\n            with open(prompt_path, \"w\", encoding=\"utf-8\") as file:\n                json.dump(prompt_data, file, ensure_ascii=False, indent=4)\n                logger.info(f\"Prompt salvo com sucesso: {prompt_name}\")\n                return True\n        except Exception as e:\n            logger.error(f\"Erro ao salvar prompt {prompt_name}: {e}\")\n            return False", "mimetype": "text/plain", "start_char_idx": 312, "end_char_idx": 4595, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a2d303c8-8f09-4d97-b048-67f5f8fda439": {"__data__": {"id_": "a2d303c8-8f09-4d97-b048-67f5f8fda439", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\agents\\supervisor_agent.py", "language": "python", "lines": 138, "filename": "supervisor_agent.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\agents\\supervisor_agent.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\agents\\supervisor_agent.py", "language": "python", "lines": 138, "filename": "supervisor_agent.py"}, "hash": "f3ad81ba43b19a7f5bcf823c9a29b8ede99e6a68b2d3221ecfdaa018d8fccc3a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# core/agents/supervisor_agent.py\nimport logging\nfrom typing import Dict, Any\n\n\nclass SupervisorAgent:\n    \"\"\"\n    Agente supervisor simplificado que roteia consultas para o ToolAgent.\n    REMOVIDA importa\u00e7\u00e3o circular com tool_agent.\n    \"\"\"\n\n    CHART_KEYWORDS = [\n        \"gr\u00e1fico\",\n        \"gr\u00e1ficos\",\n        \"grafico\",\n        \"graficos\",\n        \"visualizar\",\n        \"visualiza\u00e7\u00e3o\",\n        \"visualizacao\",\n        \"mostrar\",\n        \"chart\",\n        \"charts\",\n        \"vendas\",\n        \"estoque\",\n        \"distribui\u00e7\u00e3o\",\n        \"distribuicao\",\n        \"an\u00e1lise\",\n        \"analise\",\n        \"compara\u00e7\u00e3o\",\n        \"comparacao\",\n        \"pizza\",\n        \"barras\",\n        \"linha\",\n        \"histograma\",\n        \"dashboard\",\n        \"plot\",\n        \"plotar\",\n        \"desenhar\",\n        \"temporal\",\n        \"s\u00e9rie\",\n        \"serie\",\n        \"evolu\u00e7\u00e3o\",\n        \"evolucao\",\n        \"mensal\",\n        \"m\u00eas\",\n        \"mes\",\n        \"semanal\",\n        \"trend\",\n        \"tend\u00eancia\",\n        \"tendencia\",\n        \"produto\",\n        \"sku\",\n        \"c\u00f3digo\",\n        \"codigo\",\n    ]\n\n    def __init__(self, gemini_adapter):\n        \"\"\"\n        Inicializa o supervisor.\n        NOTA: ToolAgent agora \u00e9 inicializado sob demanda para evitar importa\u00e7\u00e3o circular.\n        \"\"\"\n        self.logger = logging.getLogger(__name__)\n        self.gemini_adapter = gemini_adapter\n        self._tool_agent = None  # Lazy initialization\n        self.logger.info(\"SupervisorAgent inicializado.\")\n\n    @property\n    def tool_agent(self):\n        \"\"\"Lazy initialization do ToolAgent para evitar importa\u00e7\u00e3o circular.\"\"\"\n        if self._tool_agent is None:\n            # Importa\u00e7\u00e3o local para evitar circular dependency\n            from app.core.agents.tool_agent import ToolAgent\n            self._tool_agent = ToolAgent(llm_adapter=self.gemini_adapter)\n            self.logger.info(\"ToolAgent inicializado (lazy)\")\n        return self._tool_agent\n\n    def _detect_chart_intent(self, query: str) -> bool:\n        \"\"\"\n        Detecta se a consulta tem inten\u00e7\u00e3o de gerar gr\u00e1ficos.\n\n        Args:\n            query: Consulta do usu\u00e1rio\n\n        Returns:\n            True se detecta inten\u00e7\u00e3o de gr\u00e1fico, False caso contr\u00e1rio\n        \"\"\"\n        query_lower = query.lower()\n\n        # Verificar se cont\u00e9m palavras-chave de gr\u00e1ficos\n        for keyword in self.CHART_KEYWORDS:\n            if keyword in query_lower:\n                self.logger.info(f\"Inten\u00e7\u00e3o de gr\u00e1fico detectada: '{keyword}'\")\n                return True\n\n        return False\n\n    def route_query(self, query: str) -> Dict[str, Any]:\n        \"\"\"\n        Roteia a consulta para o ToolAgent.\n\n        Args:\n            query: Consulta do usu\u00e1rio\n\n        Returns:\n            Resposta do ToolAgent\n        \"\"\"\n        # Detectar se \u00e9 requisi\u00e7\u00e3o de gr\u00e1fico\n        is_chart_request = self._detect_chart_intent(query)\n\n        if is_chart_request:\n            self.logger.info(f\"Roteando consulta de gr\u00e1fico para ToolAgent: '{query}'\")\n        else:\n            self.logger.info(f\"Roteando consulta padr\u00e3o para ToolAgent: '{query}'\")\n\n        # Ambos os tipos v\u00e3o para ToolAgent que decidir\u00e1 qual ferramenta usar\n        return self.tool_agent.process_query(query)\n\n    def stream_query(self, query: str):\n        \"\"\"\n        Roteia a consulta para o ToolAgent com streaming.\n\n        Args:\n            query: Consulta do usu\u00e1rio\n\n        Yields:\n            dict: Eventos do agente (chunks de texto, a\u00e7\u00f5es, etc.)\n        \"\"\"\n        # Detectar se \u00e9 requisi\u00e7\u00e3o de gr\u00e1fico\n        is_chart_request = self._detect_chart_intent(query)\n\n        if is_chart_request:\n            self.logger.info(f\"Streaming de consulta de gr\u00e1fico para ToolAgent: '{query}'\")\n        else:\n            self.logger.info(f\"Streaming de consulta padr\u00e3o para ToolAgent: '{query}'\")\n\n        # Delegar para m\u00e9todo de streaming do ToolAgent\n        for event in self.tool_agent.stream_query(query):\n            yield event", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3932, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "07bc0f44-9daf-426b-8c14-4acc43fa1f30": {"__data__": {"id_": "07bc0f44-9daf-426b-8c14-4acc43fa1f30", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\agents\\tool_agent.py", "language": "python", "lines": 201, "filename": "tool_agent.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\agents\\tool_agent.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\agents\\tool_agent.py", "language": "python", "lines": 201, "filename": "tool_agent.py"}, "hash": "6dfd4cdf63ac3baa2a2ed6fdaeaf62ddda05cd0e81138d4d8002240122cafae2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a3ea291f-822d-4eed-9e86-12ab3439f7ad", "node_type": "1", "metadata": {}, "hash": "9599d2c07c8bfcb170913f2c8d86b8ef2b87f19490f8e33c51be5c23085a6d36", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# core/agents/tool_agent.py\nimport logging\nimport sys\nimport os\nfrom typing import Any, Dict, List, Optional\n\n# Suppress transformers warnings about torch\nos.environ['TRANSFORMERS_OFFLINE'] = '1'\nos.environ['HF_HUB_OFFLINE'] = '1'\n\nLANGCHAIN_AVAILABLE = False\ntry:\n    try:\n        from langchain.agents import AgentExecutor, create_tool_calling_agent\n    except ImportError:\n        # Fallback for environments using langchain-classic\n        from langchain_classic.agents import AgentExecutor, create_tool_calling_agent\n\n    from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n    from langchain_core.messages import BaseMessage\n    from langchain_core.runnables import RunnableConfig\n    from langchain_core.agents import AgentAction, AgentFinish\n    \n    # Check for torch dependency explicitly to fail fast inside try block\n    import transformers\n    \n    LANGCHAIN_AVAILABLE = True\nexcept (ImportError, OSError) as e:\n    logging.warning(f\"LangChain/Transformers dependencies not available: {e}. ToolAgent will run in fallback mode.\")\n    # Define dummy classes for type hinting if needed, or just use Any\n    BaseMessage = Any\n\nfrom app.core.llm_base import BaseLLMAdapter\nfrom app.core.llm_gemini_adapter import GeminiLLMAdapter\nfrom app.core.llm_langchain_adapter import CustomLangChainLLM\nfrom app.core.utils.response_parser import parse_agent_response\nfrom app.core.utils.chart_saver import save_chart\n\nfrom app.core.tools.unified_data_tools import unified_tools\nfrom app.core.tools.date_time_tools import date_time_tools\nfrom app.core.tools.chart_tools import chart_tools\n\n\nclass ToolAgent:\n    def __init__(self, llm_adapter: BaseLLMAdapter):\n        self.logger = logging.getLogger(__name__)\n        self.llm_adapter = llm_adapter\n        self.agent_executor = None\n\n        if LANGCHAIN_AVAILABLE:\n            try:\n                self.langchain_llm = CustomLangChainLLM(llm_adapter=self.llm_adapter)\n                self.tools = unified_tools + date_time_tools + chart_tools\n                self.agent_executor = self._create_agent_executor()\n                self.logger.info(\"ToolAgent inicializado com adaptador Gemini (LangChain ativo).\")\n            except Exception as e:\n                self.logger.error(f\"Erro ao inicializar LangChain Agent: {e}\")\n                self.agent_executor = None\n        else:\n            self.logger.warning(\"ToolAgent rodando em modo degradado (sem LangChain).\")\n\n    def _create_agent_executor(self):\n        \"\"\"Cria e retorna um AgentExecutor com agente de ferramentas.\"\"\"\n        if not LANGCHAIN_AVAILABLE:\n            return None\n            \n        # \u2705 FASE 3: PROMPT MINIMALISTA (30 linhas vs 168 linhas)\n        prompt = ChatPromptTemplate.from_messages(\n            [\n                (\n                    \"system\",\n                    \"Voc\u00ea \u00e9 um assistente BI especializado. Use as ferramentas dispon\u00edveis para responder queries sobre dados.\\n\\n\"\n                    \"REGRAS:\\n\"\n                    \"1. Responda de forma natural e direta\\n\"\n                    \"2. Use formata\u00e7\u00e3o Markdown para valores (**R$ X,XX**, **X unidades**)\\n\"\n                    \"3. NUNCA mencione nomes t\u00e9cnicos de colunas\\n\"\n                    \"4. SEMPRE use ferramentas para consultar dados\\n\\n\"\n                    \"FERRAMENTAS PRINCIPAIS:\\n\"\n                    \"- consultar_dados(coluna, valor, coluna_retorno) - Consulta dados espec\u00edficos\\n\"\n                    \"- listar_colunas_disponiveis() - Lista colunas dispon\u00edveis\\n\"\n                    \"- gerar_grafico_* - Gera gr\u00e1ficos\\n\\n\"\n                    \"EXEMPLOS:\\n\"\n                    \"Query: 'pre\u00e7o do produto 123'\\n\"\n                    \"Ferramenta: consultar_dados('PRODUTO', '123', 'LIQUIDO_38')\\n\"\n                    \"Resposta: 'O pre\u00e7o do produto 123 \u00e9 **R$ 45,90**'\\n\\n\"\n                    \"COLUNAS COMUNS: PRODUTO, NOME, LIQUIDO_38 (pre\u00e7o), ESTOQUE_UNE (estoque), NOMEFABRICANTE\\n\"\n                    \"Use listar_colunas_disponiveis() para ver todas.\\n\\n\"\n                    \"Seja direto e profissional.\"", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4043, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a3ea291f-822d-4eed-9e86-12ab3439f7ad": {"__data__": {"id_": "a3ea291f-822d-4eed-9e86-12ab3439f7ad", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\agents\\tool_agent.py", "language": "python", "lines": 201, "filename": "tool_agent.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\agents\\tool_agent.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\agents\\tool_agent.py", "language": "python", "lines": 201, "filename": "tool_agent.py"}, "hash": "6dfd4cdf63ac3baa2a2ed6fdaeaf62ddda05cd0e81138d4d8002240122cafae2", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "07bc0f44-9daf-426b-8c14-4acc43fa1f30", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\agents\\tool_agent.py", "language": "python", "lines": 201, "filename": "tool_agent.py"}, "hash": "08445dbb58bb6366d878af18e3bda1f535cade4c1df61c6d30c6c40193f806a9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "),\n                MessagesPlaceholder(variable_name=\"chat_history\"),\n                (\"human\", \"{input}\"),\n                MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n            ]\n        )\n\n        agent = create_tool_calling_agent(\n            llm=self.langchain_llm, tools=self.tools, prompt=prompt\n        )\n\n        return AgentExecutor(\n            agent=agent,\n            tools=self.tools,\n            verbose=True,\n            return_intermediate_steps=True,\n        )\n\n    def process_query(\n        self, query: str, chat_history: List[Any] = None\n    ) -> Dict[str, Any]:\n        \"\"\"Processa a query do usu\u00e1rio usando o agente LangChain.\"\"\"\n        \n        if not self.agent_executor:\n            return {\n                \"type\": \"text\",\n                \"output\": \"\u26a0\ufe0f O sistema de Agentes Inteligentes est\u00e1 temporariamente indispon\u00edvel (depend\u00eancia ausente). Por favor, use o painel de Monitoramento ou contate o administrador.\"\n            }\n\n        self.logger.info(f\"Processando query com o Agente de Ferramentas: {query}\")\n        try:\n            # Ensure chat_history is not None for invoke\n            if chat_history is None:\n                chat_history = []\n\n            config = RunnableConfig(recursion_limit=10)\n\n            self.logger.debug(\n                f\"Invocando agente com query: {query} \"\n                f\"e chat_history: {chat_history}\"\n            )\n            response = self.agent_executor.invoke(\n                {\"input\": query, \"chat_history\": chat_history}, config=config\n            )\n            self.logger.debug(f\"Resposta bruta do agente: {response}\")\n\n            # Adicionando log detalhado para depura\u00e7\u00e3o\n            self.logger.info(f\"CONTE\u00daDO COMPLETO DA RESPOSTA DO AGENTE: {response}\")\n\n            final_output = response.get(\"output\", \"N\u00e3o foi poss\u00edvel gerar uma resposta.\")\n            response_type = \"text\" # Padr\u00e3o\n\n            # Verificar se h\u00e1 passos intermedi\u00e1rios e extrair a sa\u00edda da ferramenta se aplic\u00e1vel\n            if \"intermediate_steps\" in response and response[\"intermediate_steps\"]:\n                for step in reversed(response[\"intermediate_steps\"]):\n                    if isinstance(step, tuple) and len(step) == 2:\n                        action, observation = step\n                        \n                        # Se a observa\u00e7\u00e3o for um dicion\u00e1rio de uma ferramenta de gr\u00e1fico bem-sucedida\n                        if isinstance(observation, dict) and observation.get(\"status\") == \"success\" and \"chart_data\" in observation:\n                            self.logger.info(f\"Extraindo dados do gr\u00e1fico da ferramenta: {action.tool}\")\n                            final_output = observation[\"chart_data\"]\n                            response_type = \"chart\"\n                            save_chart(final_output)  # Salvar o gr\u00e1fico\n                            break\n                        \n                        # L\u00f3gica existente para ferramentas que retornam string\n                        elif isinstance(action, AgentAction) and isinstance(observation, str):\n                            if action.tool == \"consultar_dados\":\n                                final_output = observation\n                                self.logger.info(f\"Usando sa\u00edda direta da ferramenta consultar_dados: {final_output}\")\n                                break\n\n            # Se o tipo de resposta for gr\u00e1fico, retorna diretamente\n            if response_type == \"chart\":\n                return {\n                    \"type\": \"chart\",\n                    \"output\": final_output,\n                }\n\n            # Processamento legado para texto\n            response_type, processed = parse_agent_response(final_output)\n            return {\n                \"type\": \"text\", # Changed from response_type to \"text\" to ensure text output for general queries\n                \"output\": processed.get(\"output\", final_output),\n            }\n\n        except Exception as e:\n            self.logger.error(f\"Erro ao invocar o agente LangChain: {e}\", exc_info=True)\n            \n            # Debug: Write error to file\n            try:\n                import traceback\n                with open(\"error_log_agent.txt\", \"w\", encoding=\"utf-8\") as f:\n                    f.write(f\"Error: {str(e)}\\n\")\n                    f.write(traceback.format_exc())\n            except:\n                pass\n                \n            return {\n                \"type\": \"error\",\n                \"output\": (\n                    \"Desculpe, n\u00e3o consegui processar sua solicita\u00e7\u00e3o \"\n                    \"no momento. Por favor, tente novamente ou reformule \"\n                    \"sua pergunta.\"\n                ),\n            }\n\n\ndef initialize_agent_for_session():\n    \"\"\"Fun\u00e7\u00e3o de f\u00e1brica para inicializar o agente.\"\"\"\n    return ToolAgent(llm_adapter=GeminiLLMAdapter())", "mimetype": "text/plain", "start_char_idx": 4060, "end_char_idx": 8873, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c75cd658-ef16-4f71-b7c6-8816faf4d5d2": {"__data__": {"id_": "c75cd658-ef16-4f71-b7c6-8816faf4d5d2", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\agents\\__init__.py", "language": "python", "lines": 8, "filename": "__init__.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\agents\\__init__.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\agents\\__init__.py", "language": "python", "lines": 8, "filename": "__init__.py"}, "hash": "3cde386aecad6ce33e15c60e4c24ff117c2a300ed77af7a00ff4af14d51c0796", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "from .supervisor_agent import SupervisorAgent\nfrom .tool_agent import ToolAgent\n\n__all__ = [\n    \"SupervisorAgent\",\n    \"ToolAgent\",\n]", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 134, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "157ea64c-29a0-417b-8561-29707217607d": {"__data__": {"id_": "157ea64c-29a0-417b-8561-29707217607d", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\factory\\component_factory.py", "language": "python", "lines": 55, "filename": "component_factory.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\factory\\component_factory.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\factory\\component_factory.py", "language": "python", "lines": 55, "filename": "component_factory.py"}, "hash": "471fcd0581c7da0fba372d822d85cdd68c7e16ea1b75859d7cdc5ce59b615e80", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nF\u00e1brica de Componentes\n\nEste m\u00f3dulo implementa o padr\u00e3o Factory para criar e gerenciar inst\u00e2ncias\ndos diversos componentes do sistema, facilitando a integra\u00e7\u00e3o entre eles\ne reduzindo o acoplamento.\n\"\"\"\n\nimport logging\nfrom typing import Any, Dict, Optional\n\nlogger = logging.getLogger(__name__)\n\n\nclass ComponentFactory:\n    \"\"\"F\u00e1brica para criar e gerenciar componentes do sistema\"\"\"\n\n    # Dicion\u00e1rio para armazenar as inst\u00e2ncias dos componentes (Singleton)\n    _components: Dict[str, Any] = {}\n\n    @classmethod\n    def get_data_adapter(cls):\n        \"\"\"Obt\u00e9m uma inst\u00e2ncia do adaptador de dados h\u00edbrido\"\"\"\n        if \"data_adapter\" not in cls._components:\n            from app.infrastructure.data.hybrid_adapter import HybridDataAdapter\n            logger.info(\"Criando nova inst\u00e2ncia do HybridDataAdapter\")\n            cls._components[\"data_adapter\"] = HybridDataAdapter()\n        return cls._components[\"data_adapter\"]\n\n    @classmethod\n    def reset_component(cls, component_name: str) -> bool:\n        \"\"\"Reinicia um componente espec\u00edfico, removendo sua inst\u00e2ncia atual\n\n        Args:\n            component_name (str): Nome do componente a ser reiniciado\n\n        Returns:\n            bool: True se o componente foi reiniciado com sucesso, False caso contr\u00e1rio\n        \"\"\"\n        if component_name in cls._components:\n            del cls._components[component_name]\n            logger.info(f\"Componente reiniciado: {component_name}\")\n            return True\n\n        logger.warning(\n            f\"Tentativa de reiniciar componente inexistente: {component_name}\"\n        )\n        return False\n\n    @classmethod\n    def reset_all(cls) -> None:\n        \"\"\"Reinicia todos os componentes, removendo todas as inst\u00e2ncias atuais\"\"\"\n        cls._components.clear()\n        logger.info(\"Todos os componentes foram reiniciados\")", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1831, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9262ea5b-daff-4eb0-8f66-55f44a38f11d": {"__data__": {"id_": "9262ea5b-daff-4eb0-8f66-55f44a38f11d", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\factory\\__init__.py", "language": "python", "lines": 2, "filename": "__init__.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\factory\\__init__.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\factory\\__init__.py", "language": "python", "lines": 2, "filename": "__init__.py"}, "hash": "bedf6a97d92ad7dbbdac943e34c67c726b1de0ba60653481b55972d9c9043897", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# Factory module", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 16, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0b3d75a7-d12e-4822-b714-48380c02b354": {"__data__": {"id_": "0b3d75a7-d12e-4822-b714-48380c02b354", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\graph\\agent.py", "language": "python", "lines": 91, "filename": "agent.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\graph\\agent.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\graph\\agent.py", "language": "python", "lines": 91, "filename": "agent.py"}, "hash": "9987ab5953334bede5a15b049f1e4beb39fd0909cab93023cf6fc1d8c5b89ecb", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import logging\n\nfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n\nfrom ..llm_factory import LLMFactory # Added\nfrom ..llm_langchain_adapter import CustomLangChainLLM # Added\nfrom ..tools.sql_server_tools import db_schema_info, sql_server_tools\n\n# Configura\u00e7\u00e3o de logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\nclass GraphAgent:\n    \"\"\"\n    Agente principal do grafo, respons\u00e1vel por orquestrar o LLM e as ferramentas.\n    \"\"\"\n\n    def __init__(self, llm=None, tools=None):\n        \"\"\"\n        Inicializa o agente.\n\n        Args:\n            llm (BaseChatModel, optional): O modelo de linguagem a ser usado.\n            tools (list, optional): A lista de ferramentas dispon\u00edveis.\n        \"\"\"\n        if llm is None:\n            llm_adapter = LLMFactory.get_adapter()\n            self.llm = CustomLangChainLLM(llm_adapter=llm_adapter)\n        else:\n            self.llm = llm\n\n        self.tools = tools or sql_server_tools\n        self.agent_runnable = self._create_agent_runnable()\n\n    def _get_system_prompt_template(self):\n        \"\"\"Retorna o template do prompt do sistema.\"\"\"\n        schema = db_schema_info or \"Schema n\u00e3o dispon\u00edvel. Use get_database_schema.\"\n        tool_names = \", \".join([t.name for t in self.tools])\n\n        return (\n            \"Voc\u00ea \u00e9 um Agente de Neg\u00f3cios especialista em SQL Server.\\n\"\n            \"Seu papel \u00e9 responder perguntas executando consultas SELECT seguras.\\n\"\n            f\"Schema do Banco: {schema}\\n\"\n            f\"Ferramentas: {tool_names}\\n\"\n            \"**Regras:**\\n\"\n            \"1. Responda em portugu\u00eas.\\n\"\n            \"2. Se n\u00e3o souber o schema, use `get_database_schema` PRIMEIRO.\\n\"\n            \"3. Depois, use `execute_sql_query` com um SELECT v\u00e1lido.\\n\"\n            \"4. NUNCA use DELETE, UPDATE, INSERT. Apenas permiss\u00e3o de leitura.\\n\"\n            \"5. Se a consulta falhar, informe o usu\u00e1rio e pe\u00e7a para reformular.\\n\"\n        )\n\n    def _create_agent_runnable(self):\n        \"\"\"Cria o 'Agent Runnable' com as ferramentas vinculadas.\"\"\"\n        system_prompt = self._get_system_prompt_template()\n        prompt = ChatPromptTemplate.from_messages(\n            [\n                (\"system\", system_prompt),\n                MessagesPlaceholder(variable_name=\"messages\"),\n            ]\n        )\n        # openai_tools = [convert_to_openai_tool(t) for t in self.tools] # Removed\n        return prompt | self.llm.bind_tools(self.tools) # Changed to use self.tools directly\n\n    def process(self, messages):\n        \"\"\"\n        Processa uma lista de mensagens atrav\u00e9s do agente.\n\n        Args:\n            messages (list): A lista de mensagens da conversa.\n\n        Returns:\n            A resposta do agente.\n        \"\"\"\n        logger.info(\"Processando mensagem com o GraphAgent...\")\n        return self.agent_runnable.invoke({\"messages\": messages})\n\n\nif __name__ == \"__main__\":\n    # Exemplo de como usar o agente\n    print(\"Inicializando o GraphAgent para teste...\")\n    agent = GraphAgent()\n    print(\"Agente inicializado.\")\n    # Para testar, voc\u00ea precisaria de uma lista de mensagens, por exemplo:\n    # from langchain_core.messages import HumanMessage\n    # messages = [HumanMessage(content=\"Qual o produto mais vendido?\")]\n    # response = agent.process(messages)\n    # print(\"Resposta do agente:\", response)\n    print(\"Script conclu\u00eddo.\")", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3363, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e5c247c5-c1de-4686-b6b8-e95869bf0a56": {"__data__": {"id_": "e5c247c5-c1de-4686-b6b8-e95869bf0a56", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\graph\\__init__.py", "language": "python", "lines": 18, "filename": "__init__.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\graph\\__init__.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\graph\\__init__.py", "language": "python", "lines": 18, "filename": "__init__.py"}, "hash": "792ce3e7808c8e34ffeed6006585cacc825f320a66e79ff76863bf01dc451004", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import logging\n\nlogger = logging.getLogger(__name__)\n\n\n# Configura\u00e7\u00e3o b\u00e1sica de logging para este pacote, se necess\u00e1rio\ntry:\n    # seu c\u00f3digo principal aqui\n    pass\nexcept Exception as e:\n    logger.error(f\"Erro geral: {e}\")\n\n# Arquivo vazio para marcar o diret\u00f3rio como um pacote Python\n\nif __name__ == \"__main__\":\n    print(\"Rodando como script...\")\n    # TODO: Adicionar chamada a uma fun\u00e7\u00e3o principal se necess\u00e1rio", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 419, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "922d2f8c-ae8e-4779-b2e0-e079ae3f271c": {"__data__": {"id_": "922d2f8c-ae8e-4779-b2e0-e079ae3f271c", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\learning\\feedback_system.py", "language": "python", "lines": 248, "filename": "feedback_system.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\learning\\feedback_system.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\learning\\feedback_system.py", "language": "python", "lines": 248, "filename": "feedback_system.py"}, "hash": "7a1dc34ccfd018bcbe3d29a59c6c12410b1fb615a85309a88ef06da11b620789", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1c5baf03-8174-46e7-99a6-6266f85a45e2", "node_type": "1", "metadata": {}, "hash": "a05ccf457ca074e957bb719c68bc3dca0728990d4a4b933af57357cfd4006f57", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nSistema de coleta e an\u00e1lise de feedback do usu\u00e1rio.\n\"\"\"\n\nimport json\nimport os\nimport logging\nfrom datetime import datetime\nfrom typing import Dict, Any, Optional\n\n\nclass FeedbackSystem:\n    \"\"\"\n    Sistema para coletar, armazenar e analisar feedback do usu\u00e1rio\n    sobre queries e respostas do sistema.\n    \"\"\"\n\n    def __init__(self, feedback_dir: str = None):\n        \"\"\"\n        Inicializa o sistema de feedback.\n\n        Args:\n            feedback_dir: Diret\u00f3rio para armazenar feedback (opcional)\n        \"\"\"\n        self.logger = logging.getLogger(__name__)\n\n        if feedback_dir is None:\n            feedback_dir = os.path.join(os.getcwd(), \"data\", \"feedback\")\n\n        self.feedback_dir = feedback_dir\n        os.makedirs(self.feedback_dir, exist_ok=True)\n\n        self.logger.info(f\"\u2705 FeedbackSystem inicializado em {self.feedback_dir}\")\n\n    def record_feedback(\n        self,\n        query: str,\n        code: str,\n        feedback_type: str,\n        user_comment: Optional[str] = None,\n        result_rows: int = 0,\n        session_id: Optional[str] = None,\n        user_id: Optional[str] = None\n    ) -> bool:\n        \"\"\"\n        Registra feedback do usu\u00e1rio sobre uma query.\n\n        Args:\n            query: Query original do usu\u00e1rio\n            code: C\u00f3digo gerado\n            feedback_type: 'positive', 'negative', ou 'partial'\n            user_comment: Coment\u00e1rio adicional do usu\u00e1rio (opcional)\n            result_rows: N\u00famero de linhas retornadas\n            session_id: ID da sess\u00e3o (opcional)\n            user_id: ID do usu\u00e1rio (opcional)\n\n        Returns:\n            True se salvou com sucesso\n        \"\"\"\n        try:\n            feedback_entry = {\n                'timestamp': datetime.now().isoformat(),\n                'query': query,\n                'code': code,\n                'feedback_type': feedback_type,\n                'user_comment': user_comment,\n                'result_rows': result_rows,\n                'session_id': session_id,\n                'user_id': user_id\n            }\n\n            # Salvar em arquivo di\u00e1rio\n            date_str = datetime.now().strftime('%Y%m%d')\n            feedback_file = os.path.join(self.feedback_dir, f'feedback_{date_str}.jsonl')\n\n            with open(feedback_file, 'a', encoding='utf-8') as f:\n                f.write(json.dumps(feedback_entry, ensure_ascii=False) + '\\n')\n\n            self.logger.info(f\"\u2705 Feedback '{feedback_type}' registrado\")\n            return True\n\n        except Exception as e:\n            self.logger.error(f\"\u274c Erro ao registrar feedback: {e}\")\n            return False\n\n    def get_feedback_stats(self, days: int = 7) -> Dict[str, Any]:\n        \"\"\"\n        Calcula estat\u00edsticas de feedback dos \u00faltimos N dias.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2726, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1c5baf03-8174-46e7-99a6-6266f85a45e2": {"__data__": {"id_": "1c5baf03-8174-46e7-99a6-6266f85a45e2", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\learning\\feedback_system.py", "language": "python", "lines": 248, "filename": "feedback_system.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\learning\\feedback_system.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\learning\\feedback_system.py", "language": "python", "lines": 248, "filename": "feedback_system.py"}, "hash": "7a1dc34ccfd018bcbe3d29a59c6c12410b1fb615a85309a88ef06da11b620789", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "922d2f8c-ae8e-4779-b2e0-e079ae3f271c", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\learning\\feedback_system.py", "language": "python", "lines": 248, "filename": "feedback_system.py"}, "hash": "d33f0863e3e720a6ae026260f64371bf8e29267657b77ede6747db08931b74b0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "90ac3a75-05f0-4289-948b-430d3a053aff", "node_type": "1", "metadata": {}, "hash": "93a8c9f1345a53bc0b87270cc9c2109cbe2594703e93428caa3b2de0b89790f9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Args:\n            days: N\u00famero de dias para analisar\n\n        Returns:\n            Dicion\u00e1rio com estat\u00edsticas\n        \"\"\"\n        from datetime import timedelta\n\n        stats = {\n            'total': 0,\n            'positive': 0,\n            'negative': 0,\n            'partial': 0,\n            'success_rate': 0.0,\n            'common_issues': []\n        }\n\n        try:\n            # Ler arquivos dos \u00faltimos N dias\n            today = datetime.now()\n            feedback_entries = []\n\n            for i in range(days):\n                date = today - timedelta(days=i)\n                date_str = date.strftime('%Y%m%d')\n                feedback_file = os.path.join(self.feedback_dir, f'feedback_{date_str}.jsonl')\n\n                if os.path.exists(feedback_file):\n                    with open(feedback_file, 'r', encoding='utf-8') as f:\n                        for line in f:\n                            try:\n                                feedback_entries.append(json.loads(line.strip()))\n                            except json.JSONDecodeError:\n                                continue\n\n            # Calcular estat\u00edsticas\n            stats['total'] = len(feedback_entries)\n\n            if stats['total'] > 0:\n                for entry in feedback_entries:\n                    feedback_type = entry.get('feedback_type', '')\n                    if feedback_type == 'positive':\n                        stats['positive'] += 1\n                    elif feedback_type == 'negative':\n                        stats['negative'] += 1\n                    elif feedback_type == 'partial':\n                        stats['partial'] += 1\n\n                # Taxa de sucesso = (positivo + parcial/2) / total\n                stats['success_rate'] = (\n                    (stats['positive'] + stats['partial'] * 0.5) / stats['total'] * 100\n                )\n\n                # Coletar problemas comuns (coment\u00e1rios negativos)\n                issues = [\n                    entry.get('user_comment', '')\n                    for entry in feedback_entries\n                    if entry.get('feedback_type') == 'negative' and entry.get('user_comment')\n                ]\n                stats['common_issues'] = issues[:10]  # Top 10\n\n            self.logger.info(f\"\ud83d\udcca Stats: {stats['total']} feedbacks, {stats['success_rate']:.1f}% sucesso\")\n\n        except Exception as e:\n            self.logger.error(f\"\u274c Erro ao calcular estat\u00edsticas: {e}\")\n\n        return stats\n\n    def get_problematic_queries(self, limit: int = 10) -> list:\n        \"\"\"\n        Retorna queries que receberam mais feedback negativo.\n\n        Args:\n            limit: N\u00famero m\u00e1ximo de queries a retornar\n\n        Returns:\n            Lista de queries problem\u00e1ticas\n        \"\"\"\n        try:\n            from collections import Counter\n\n            negative_queries = []\n\n            # Ler todos os arquivos de feedback\n            for filename in os.listdir(self.feedback_dir):\n                if filename.startswith('feedback_') and filename.endswith('.jsonl'):\n                    feedback_file = os.path.join(self.feedback_dir, filename)\n\n                    with open(feedback_file, 'r', encoding='utf-8') as f:\n                        for line in f:\n                            try:\n                                entry = json.loads(line.strip())\n                                if entry.get('feedback_type') == 'negative':\n                                    negative_queries.append(entry.get('query', ''))\n                            except json.JSONDecodeError:\n                                continue\n\n            # Contar queries mais problem\u00e1ticas\n            query_counts = Counter(negative_queries)\n            most_common = query_counts.most_common(limit)\n\n            return [\n                {\n                    'query': query,\n                    'negative_count': count\n                }\n                for query, count in most_common\n            ]\n\n        except Exception as e:\n            self.logger.error(f\"\u274c Erro ao buscar queries problem\u00e1ticas: {e}\")\n            return []\n\n    def export_feedback_for_training(self, output_file: str = None) -> bool:\n        \"\"\"\n        Exporta feedback positivo para treinar o sistema (RAG/few-shot).", "mimetype": "text/plain", "start_char_idx": 2736, "end_char_idx": 6957, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "90ac3a75-05f0-4289-948b-430d3a053aff": {"__data__": {"id_": "90ac3a75-05f0-4289-948b-430d3a053aff", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\learning\\feedback_system.py", "language": "python", "lines": 248, "filename": "feedback_system.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\learning\\feedback_system.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\learning\\feedback_system.py", "language": "python", "lines": 248, "filename": "feedback_system.py"}, "hash": "7a1dc34ccfd018bcbe3d29a59c6c12410b1fb615a85309a88ef06da11b620789", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1c5baf03-8174-46e7-99a6-6266f85a45e2", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\learning\\feedback_system.py", "language": "python", "lines": 248, "filename": "feedback_system.py"}, "hash": "eada4e2ff2d4cd74953158dd26709dd34ec71502dd9ade335b67f5ceace108e5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Args:\n            output_file: Arquivo de sa\u00edda (opcional)\n\n        Returns:\n            True se exportou com sucesso\n        \"\"\"\n        if output_file is None:\n            output_file = os.path.join(self.feedback_dir, 'positive_examples.json')\n\n        try:\n            positive_examples = []\n\n            # Ler todos os arquivos de feedback\n            for filename in os.listdir(self.feedback_dir):\n                if filename.startswith('feedback_') and filename.endswith('.jsonl'):\n                    feedback_file = os.path.join(self.feedback_dir, filename)\n\n                    with open(feedback_file, 'r', encoding='utf-8') as f:\n                        for line in f:\n                            try:\n                                entry = json.loads(line.strip())\n                                if entry.get('feedback_type') == 'positive':\n                                    positive_examples.append({\n                                        'query': entry.get('query'),\n                                        'code': entry.get('code'),\n                                        'result_rows': entry.get('result_rows'),\n                                        'timestamp': entry.get('timestamp')\n                                    })\n                            except json.JSONDecodeError:\n                                continue\n\n            # Salvar exemplos positivos\n            with open(output_file, 'w', encoding='utf-8') as f:\n                json.dump(positive_examples, f, indent=2, ensure_ascii=False)\n\n            self.logger.info(f\"\u2705 {len(positive_examples)} exemplos positivos exportados para {output_file}\")\n            return True\n\n        except Exception as e:\n            self.logger.error(f\"\u274c Erro ao exportar feedback: {e}\")\n            return False", "mimetype": "text/plain", "start_char_idx": 6967, "end_char_idx": 8755, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b4c9d948-edb7-4948-9632-ce4b6a32335b": {"__data__": {"id_": "b4c9d948-edb7-4948-9632-ce4b6a32335b", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\learning\\pattern_matcher.py", "language": "python", "lines": 63, "filename": "pattern_matcher.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\learning\\pattern_matcher.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\learning\\pattern_matcher.py", "language": "python", "lines": 63, "filename": "pattern_matcher.py"}, "hash": "5719938a7396cad4c96c5124792a5de5a4665493663cd9cf739a95f1a1c31aeb", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# backend/app/core/learning/pattern_matcher.py\n\nfrom typing import Any, Dict, List, Optional\n\nclass PatternMatcher:\n    \"\"\"\n    Detects known query patterns and provides few-shot examples for code generation.\n    \"\"\"\n    def __init__(self, patterns_config_path: str = \"data/query_patterns.json\"):\n        self.patterns = self._load_patterns(patterns_config_path)\n\n    def _load_patterns(self, patterns_config_path: str) -> List[Dict[str, Any]]:\n        \"\"\"\n        Loads pre-defined patterns and their associated example code/structure.\n        \"\"\"\n        # Placeholder: In a real scenario, load from JSON file\n        # Example structure:\n        # [\n        #   {\"name\": \"SalesBySegment\", \"keywords\": [\"vendas por segmento\"], \"example_code\": \"df.groupby('segmento')['vendas'].sum().to_dicts()\"},\n        #   {\"name\": \"TopNProducts\", \"keywords\": [\"top n produtos\", \"n maiores produtos\"], \"example_code\": \"df.groupby('produto')['vendas'].sum().sort('vendas', descending=True).head(N).to_dicts()\"}\n        # ]\n        print(f\"PatternMatcher placeholder: Loading patterns from {patterns_config_path}\")\n        return [\n            {\"name\": \"SalesBySegment\", \"keywords\": [\"vendas por segmento\", \"quanto vendi por segmento\"], \"example_code\": \"\"\"\nimport polars as pl\nresult = df.group_by('segmento').agg(pl.sum('vendas').alias('total_vendas')).sort('total_vendas', descending=True).to_dicts()\nfinal_output = {'result': result}\n\"\"\"},\n            {\"name\": \"TopNProducts\", \"keywords\": [\"top\", \"maiores\", \"melhores produtos\", \"produtos mais vendidos\"], \"example_code\": \"\"\"\nimport polars as pl\n# Replace N with actual number from query\nresult = df.group_by('produto_id').agg(pl.sum('vendas').alias('total_vendas')).sort('total_vendas', descending=True).head(N).to_dicts()\nfinal_output = {'result': result}\n\"\"\"},\n            {\"name\": \"MCbyProduct\", \"keywords\": [\"margem de contribuicao por produto\", \"mc por produto\"], \"example_code\": \"\"\"\nimport polars as pl\nresult = df.group_by('produto_id').agg(pl.mean('media_considerada_lv').alias('mc_media')).to_dicts()\nfinal_output = {'result': result}\n\"\"\"}\n        ]\n\n    def match_pattern(self, query: str) -> Optional[Dict[str, Any]]:\n        \"\"\"\n        Attempts to match the user query against known patterns.\n        Returns the pattern with example code if a match is found.\n        \"\"\"\n        query_lower = query.lower()\n        for pattern in self.patterns:\n            for keyword in pattern[\"keywords\"]:\n                if keyword in query_lower:\n                    print(f\"PatternMatcher: Matched pattern '{pattern['name']}' for query: '{query}'\")\n                    return pattern\n        return None\n\nif __name__ == '__main__':\n    print(\"--- Testing PatternMatcher ---\")\n    matcher = PatternMatcher()\n    \n    print(f\"Matching 'vendas por segmento': {matcher.match_pattern('Me mostre as vendas por segmento.')}\")\n    print(f\"Matching 'top 5 produtos mais vendidos': {matcher.match_pattern('Quais os top 5 produtos mais vendidos?')}\")\n    print(f\"Matching 'margem de contribuicao por produto': {matcher.match_pattern('Calcule a margem de contribuicao por produto.')}\")\n    print(f\"Matching 'query sem match': {matcher.match_pattern('Qual o clima hoje?')}\")", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3205, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b0f78a20-e1be-4614-8cfe-f7975e3e265b": {"__data__": {"id_": "b0f78a20-e1be-4614-8cfe-f7975e3e265b", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\monitoring\\metrics_dashboard.py", "language": "python", "lines": 183, "filename": "metrics_dashboard.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\monitoring\\metrics_dashboard.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\monitoring\\metrics_dashboard.py", "language": "python", "lines": 183, "filename": "metrics_dashboard.py"}, "hash": "ee165176bf37cf336bb176461489ea1a4b118151cb38cc860b2948149718b6bc", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d2cb0dd5-b8cb-4501-8ee2-236dd56a174b", "node_type": "1", "metadata": {}, "hash": "2ab867df52bddaf347272c40adee4089c61dc09c9c20336aeb2807c5f21164dd", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# backend/app/core/monitoring/metrics_dashboard.py\n\nimport json\nimport os\nfrom datetime import datetime, timedelta\nfrom typing import Any, Dict, List, Optional\nfrom collections import defaultdict\nfrom pathlib import Path\n\nfrom app.config.settings import settings\nfrom app.core.utils.query_history import QueryHistory # To get query data\nfrom app.core.utils.response_cache import ResponseCache # To query cache stats\n\nclass MetricsDashboard:\n    \"\"\"\n    Collects and provides various metrics for monitoring the BI agent's performance.\n    (T4.4.2 from TASK_LIST)\n    \"\"\"\n    def __init__(self, query_history: Optional[QueryHistory] = None, response_cache: Optional[ResponseCache] = None):\n        self.query_history = query_history if query_history else QueryHistory(history_dir=settings.LEARNING_EXAMPLES_PATH) # Using LEARNING_EXAMPLES_PATH as history\n        self.response_cache = response_cache if response_cache else ResponseCache(cache_dir=settings.LEARNING_FEEDBACK_PATH, ttl_minutes=settings.CACHE_TTL_MINUTES) # Using LEARNING_FEEDBACK_PATH as cache\n\n    def get_metrics(self, days: int = 7) -> Dict[str, Any]:\n        \"\"\"\n        Retrieves key performance indicators (KPIs) for the last N days.\n        - Success Rate (from feedback)\n        - Average Response Time (placeholder)\n        - Cache Hit Rate\n        - Total Queries\n        - Total Errors\n        \"\"\"\n        end_date = datetime.now()\n        start_date = end_date - timedelta(days=days)\n\n        all_queries = self.query_history.get_history(start_date=start_date, end_date=end_date, limit=None)\n        \n        total_queries = len(all_queries)\n        total_errors = sum(1 for q in all_queries if \"error\" in q.get(\"response_summary\", \"\").lower()) # Simple error detection\n        \n        # Cache hit rate (placeholder - requires more sophisticated cache logging)\n        # For now, we'll simulate. In a real system, the cache would log hits/misses.\n        cache_hits = 0 # Placeholder for actual cache hits\n        cache_misses = total_queries # Placeholder for actual cache misses\n        cache_hit_rate = (cache_hits / total_queries) * 100 if total_queries > 0 else 0\n\n        # Success rate (placeholder - needs dedicated feedback system)\n        # Assuming feedback is stored by QueryHistory for now\n        feedback_file_path = Path(settings.LEARNING_FEEDBACK_PATH) / \"feedback.jsonl\"\n        positive_feedback = 0\n        negative_feedback = 0\n        try:\n            if os.path.exists(feedback_file_path):\n                with open(feedback_file_path, 'r', encoding='utf-8') as f:\n                    for line in f:\n                        if not line.strip():\n                            continue\n                        try:\n                            feedback_entry = json.loads(line)\n                            timestamp_str = feedback_entry.get(\"timestamp\", \"\")\n                            if not timestamp_str:\n                                continue\n\n                            # Handle different timestamp formats\n                            try:\n                                entry_timestamp = datetime.fromisoformat(timestamp_str.replace('Z', '+00:00'))\n                            except (ValueError, AttributeError):\n                                continue\n\n                            if start_date <= entry_timestamp <= end_date:\n                                if feedback_entry.get(\"feedback_type\") == \"positive\":\n                                    positive_feedback += 1\n                                elif feedback_entry.get(\"feedback_type\") == \"negative\":\n                                    negative_feedback += 1\n                        except (json.JSONDecodeError, KeyError) as parse_error:\n                            continue\n        except Exception as e:\n            print(f\"Error reading feedback file: {e}\")\n\n        total_feedback = positive_feedback + negative_feedback\n        success_rate = (positive_feedback / total_feedback) * 100 if total_feedback > 0 else 0\n\n\n        return {\n            \"total_queries\": total_queries,\n            \"total_errors\": total_errors,\n            \"success_rate_feedback\": round(success_rate, 2),\n            \"cache_hit_rate\": round(cache_hit_rate, 2), # Needs actual implementation\n            \"average_response_time_ms\": \"N/A\" # Placeholder, needs instrumented timing\n        }\n\n    def get_error_trend(self, days: int = 30) -> List[Dict[str, Any]]:\n        \"\"\"\n        Provides a daily trend of errors for the last N days.\n        \"\"\"", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4495, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d2cb0dd5-b8cb-4501-8ee2-236dd56a174b": {"__data__": {"id_": "d2cb0dd5-b8cb-4501-8ee2-236dd56a174b", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\monitoring\\metrics_dashboard.py", "language": "python", "lines": 183, "filename": "metrics_dashboard.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\monitoring\\metrics_dashboard.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\monitoring\\metrics_dashboard.py", "language": "python", "lines": 183, "filename": "metrics_dashboard.py"}, "hash": "ee165176bf37cf336bb176461489ea1a4b118151cb38cc860b2948149718b6bc", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b0f78a20-e1be-4614-8cfe-f7975e3e265b", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\monitoring\\metrics_dashboard.py", "language": "python", "lines": 183, "filename": "metrics_dashboard.py"}, "hash": "683af168a37c4c2649b76a54b385da6ba04ebfa9fc3a421c72a000bea8d776e7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "end_date = datetime.now()\n        start_date = end_date - timedelta(days=days)\n        \n        error_counts_by_date = defaultdict(int)\n        all_queries = self.query_history.get_history(start_date=start_date, end_date=end_date, limit=None)\n\n        for query_entry in all_queries:\n            if \"error\" in query_entry.get(\"response_summary\", \"\").lower():\n                query_date = datetime.fromisoformat(query_entry[\"timestamp\"]).strftime(\"%Y-%m-%d\")\n                error_counts_by_date[query_date] += 1\n        \n        trend_data = []\n        current_date = start_date\n        while current_date <= end_date:\n            date_str = current_date.strftime(\"%Y-%m-%d\")\n            trend_data.append({\n                \"date\": date_str,\n                \"error_count\": error_counts_by_date[date_str]\n            })\n            current_date += timedelta(days=1)\n        \n        return trend_data\n\n    def get_top_queries(self, days: int = 7, limit: int = 10) -> List[Dict[str, Any]]:\n        \"\"\"\n        Identifies the most frequent queries in the last N days.\n        \"\"\"\n        end_date = datetime.now()\n        start_date = end_date - timedelta(days=days)\n\n        query_counts = defaultdict(int)\n        all_queries = self.query_history.get_history(start_date=start_date, end_date=end_date, limit=None)\n\n        for query_entry in all_queries:\n            query_text = query_entry.get(\"query\", \"\")\n            if query_text:\n                query_counts[query_text] += 1\n        \n        top_queries = sorted(query_counts.items(), key=lambda item: item[1], reverse=True)\n        return [{\"query\": q, \"count\": count} for q, count in top_queries[:limit]]\n\nif __name__ == '__main__':\n    from app.config.settings import Settings\n    temp_settings = Settings()\n    os.makedirs(temp_settings.LEARNING_FEEDBACK_PATH, exist_ok=True) # Ensure dir exists for feedback.jsonl\n    os.makedirs(temp_settings.LEARNING_EXAMPLES_PATH, exist_ok=True) # Ensure dir exists for query_history\n    \n    # Setup dummy query history and feedback\n    history = QueryHistory(history_dir=temp_settings.LEARNING_EXAMPLES_PATH)\n    history.add_query(\"user1\", \"Vendas por produto?\", {\"type\": \"text\", \"text\": \"OK\"})\n    history.add_query(\"user1\", \"Erro na consulta de estoque.\", {\"type\": \"error\", \"error\": \"simulated error\"})\n    history.add_query(\"user2\", \"Quais os top 5 produtos?\", {\"type\": \"text\", \"text\": \"OK\"})\n    history.add_query(\"user1\", \"Vendas por produto?\", {\"type\": \"text\", \"text\": \"OK\"}) # Duplicate query\n    \n    # Simulate feedback\n    feedback_file = Path(temp_settings.LEARNING_FEEDBACK_PATH) / \"feedback.jsonl\"\n    with open(feedback_file, 'a', encoding='utf-8') as f:\n        f.write(json.dumps({\"timestamp\": datetime.now().isoformat(), \"user_id\": \"user1\", \"feedback_type\": \"positive\"}) + \"\\n\")\n        f.write(json.dumps({\"timestamp\": (datetime.now() - timedelta(days=1)).isoformat(), \"user_id\": \"user1\", \"feedback_type\": \"negative\"}) + \"\\n\")\n    \n    dashboard = MetricsDashboard(query_history=history)\n\n    print(\"\\n--- Testing get_metrics ---\")\n    metrics = dashboard.get_metrics(days=7)\n    print(json.dumps(metrics, indent=2))\n    assert metrics[\"total_queries\"] >= 4\n    assert metrics[\"total_errors\"] >= 1\n    assert metrics[\"success_rate_feedback\"] > 0\n\n    print(\"\\n--- Testing get_error_trend ---\")\n    error_trend = dashboard.get_error_trend(days=7)\n    print(json.dumps(error_trend, indent=2))\n    assert any(item[\"error_count\"] > 0 for item in error_trend)\n\n    print(\"\\n--- Testing get_top_queries ---\")\n    top_queries = dashboard.get_top_queries(days=7, limit=2)\n    print(json.dumps(top_queries, indent=2))\n    assert top_queries[0][\"query\"] == \"Vendas por produto?\"\n    assert top_queries[0][\"count\"] == 2\n\n    # Clean up dummy files\n    for filename in os.listdir(temp_settings.LEARNING_EXAMPLES_PATH):\n        if filename.startswith(\"queries_\"):\n            os.remove(os.path.join(temp_settings.LEARNING_EXAMPLES_PATH, filename))\n    if os.path.exists(feedback_file):\n        os.remove(feedback_file)\n    print(\"\\nCleaned up dummy metrics files.\")\n    print(\"\\nMetricsDashboard tests passed!\")", "mimetype": "text/plain", "start_char_idx": 4504, "end_char_idx": 8619, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "19f2d2e3-aa6c-44d4-9c78-09ee0a97ec6d": {"__data__": {"id_": "19f2d2e3-aa6c-44d4-9c78-09ee0a97ec6d", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\rag\\example_collector.py", "language": "python", "lines": 129, "filename": "example_collector.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\rag\\example_collector.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\rag\\example_collector.py", "language": "python", "lines": 129, "filename": "example_collector.py"}, "hash": "b2a2c0e4116678b6756c8b7922c017eb670dcaba7c2106f4cdad5bd0578af7f8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "289f6ffd-cf92-44a3-ab99-9cd883d65803", "node_type": "1", "metadata": {}, "hash": "6eeb333f979d748fbff8082ce4409e3260b98469dda5ff3e0c4f5c27825c6a3a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# backend/app/core/rag/example_collector.py\n\nimport json\nimport os\nfrom datetime import datetime\nfrom typing import Any, Dict, List, Optional\n\nfrom app.config.settings import settings\n\nclass ExampleCollector:\n    \"\"\"\n    Collects successful queries, their generated code, and results to serve as\n    few-shot examples for RAG and continuous learning.\n    (T6.4.2 from TASK_LIST)\n    \"\"\"\n    def __init__(self, examples_dir: str = settings.LEARNING_EXAMPLES_PATH):\n        self.examples_dir = examples_dir\n        os.makedirs(self.examples_dir, exist_ok=True)\n        print(f\"ExampleCollector initialized in {self.examples_dir}\")\n\n    def _get_daily_file_path(self, date: Optional[datetime] = None) -> str:\n        \"\"\"Generates the file path for a given day's examples.\"\"\"\n        if date is None:\n            date = datetime.now()\n        date_str = date.strftime(\"%Y-%m-%d\")\n        return os.path.join(self.examples_dir, f\"examples_{date_str}.jsonl\")\n\n    def add_example(self, user_id: str, query: str, code: str, result: Dict[str, Any], intent: str, timestamp: Optional[datetime] = None):\n        \"\"\"\n        Adds a new successful example to the daily examples file.\n        \"\"\"\n        if timestamp is None:\n            timestamp = datetime.now()\n        \n        entry = {\n            \"timestamp\": timestamp.isoformat(),\n            \"user_id\": user_id,\n            \"query\": query,\n            \"code\": code,\n            \"result_summary\": self._summarize_result(result),\n            \"intent\": intent # e.g., \"sales_analysis\", \"product_comparison\"\n        }\n        file_path = self._get_daily_file_path(timestamp)\n        \n        try:\n            with open(file_path, \"a\", encoding=\"utf-8\") as f:\n                f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n            print(f\"Example added to collector for user {user_id}.\")\n        except OSError as e:\n            print(f\"Error writing example file {file_path}: {e}\")\n\n    def _summarize_result(self, result: Dict[str, Any]) -> str:\n        \"\"\"Creates a brief summary of the result.\"\"\"\n        # For simplicity, just return the first 100 chars of the result if it's a string, or its type.\n        if isinstance(result, dict) and \"result\" in result:\n            res = result[\"result\"]\n            if isinstance(res, str):\n                return res[:100] + (\"...\" if len(res) > 100 else \"\")\n            return f\"Dict result with keys: {list(res.keys())}\"\n        return str(type(result))\n\n    def get_all_examples(self, start_date: Optional[datetime] = None, end_date: Optional[datetime] = None) -> List[Dict[str, Any]]:\n        \"\"\"\n        Retrieves all examples within a date range.\n        \"\"\"", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2663, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "289f6ffd-cf92-44a3-ab99-9cd883d65803": {"__data__": {"id_": "289f6ffd-cf92-44a3-ab99-9cd883d65803", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\rag\\example_collector.py", "language": "python", "lines": 129, "filename": "example_collector.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\rag\\example_collector.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\rag\\example_collector.py", "language": "python", "lines": 129, "filename": "example_collector.py"}, "hash": "b2a2c0e4116678b6756c8b7922c017eb670dcaba7c2106f4cdad5bd0578af7f8", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "19f2d2e3-aa6c-44d4-9c78-09ee0a97ec6d", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\rag\\example_collector.py", "language": "python", "lines": 129, "filename": "example_collector.py"}, "hash": "d8b18d6d9122f7706872257c3ca7d939f7d1dcfe72ae74e61da29f107c883d8c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "all_examples: List[Dict[str, Any]] = []\n        \n        if start_date is None:\n            start_date = datetime.min\n        if end_date is None:\n            end_date = datetime.max\n\n        for filename in sorted(os.listdir(self.examples_dir)):\n            if filename.startswith(\"examples_\") and filename.endswith(\".jsonl\"):\n                file_date_str = filename[9:19] # YYYY-MM-DD\n                file_date = datetime.strptime(file_date_str, \"%Y-%m-%d\")\n                \n                if file_date > end_date.replace(hour=23, minute=59, second=59, microsecond=999999):\n                    continue\n                if file_date < start_date.replace(hour=0, minute=0, second=0, microsecond=0):\n                    continue\n\n                file_path = os.path.join(self.examples_dir, filename)\n                try:\n                    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n                        for line in f:\n                            try:\n                                entry = json.loads(line)\n                                entry_timestamp = datetime.fromisoformat(entry[\"timestamp\"])\n\n                                if start_date <= entry_timestamp <= end_date:\n                                    all_examples.append(entry)\n                            except json.JSONDecodeError:\n                                print(f\"Warning: Corrupt JSON line in {filename}: {line.strip()}\")\n                except OSError as e:\n                    print(f\"Error reading examples file {file_path}: {e}\")\n        \n        return all_examples\n\n# Example usage\nif __name__ == '__main__':\n    from app.config.settings import Settings\n    temp_settings = Settings()\n\n    # Ensure examples directory exists for testing\n    os.makedirs(temp_settings.LEARNING_EXAMPLES_PATH, exist_ok=True)\n\n    collector = ExampleCollector(examples_dir=temp_settings.LEARNING_EXAMPLES_PATH)\n\n    user1_id = \"test_user_1\"\n    \n    # Add some examples\n    collector.add_example(user1_id, \"Vendas totais por produto\", \"df.groupby('product').sum()\", {\"result\": \"ok\"}, \"sales_analysis\")\n    collector.add_example(user1_id, \"Top 5 clientes\", \"df.groupby('client').count().sort()\", {\"result\": \"ok\"}, \"customer_segmentation\")\n    collector.add_example(user1_id, \"M\u00e9dia de pre\u00e7o por categoria\", \"df.groupby('category').mean('price')\", {\"result\": \"ok\"}, \"pricing_analysis\")\n\n    print(\"\\n--- Testing get_all_examples ---\")\n    all_examples = collector.get_all_examples()\n    print(f\"All examples ({len(all_examples)} records):\")\n    for entry in all_examples:\n        print(f\"  [{entry['timestamp']}] User {entry['user_id']}: {entry['query']} -> {entry['intent']}\")\n\n    # Clean up dummy files\n    for filename in os.listdir(temp_settings.LEARNING_EXAMPLES_PATH):\n        if filename.startswith(\"examples_\"):\n            os.remove(os.path.join(temp_settings.LEARNING_EXAMPLES_PATH, filename))\n    print(\"\\nCleaned up dummy example files.\")\n    print(\"\\nExampleCollector tests passed!\")", "mimetype": "text/plain", "start_char_idx": 2672, "end_char_idx": 5643, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b3012dee-1841-40be-b766-5b8d59b7b4b3": {"__data__": {"id_": "b3012dee-1841-40be-b766-5b8d59b7b4b3", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\rag\\query_retriever.py", "language": "python", "lines": 179, "filename": "query_retriever.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\rag\\query_retriever.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\rag\\query_retriever.py", "language": "python", "lines": 179, "filename": "query_retriever.py"}, "hash": "da5b23b78208c811a4f1817c7908848058a0e584d91a4328d66db237b759a486", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4f1464ba-77ec-43c7-aa8c-ef4b54a75920", "node_type": "1", "metadata": {}, "hash": "4fb16fc8a3020b846bfdf34dfca7ce54f9e3b355aea6052b90d2fa1c1691c634", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# backend/app/core/rag/query_retriever.py\n\nfrom typing import Any, Dict, List, Optional\nimport os\nimport json\nimport functools # Added import\n\n# Import ExampleCollector\nfrom app.core.rag.example_collector import ExampleCollector\nfrom app.config.settings import settings\n\n# Placeholder for SentenceTransformer and FAISS.\n# In a real implementation, these would be loaded conditionally/lazily.\ntry:\n    from sentence_transformers import SentenceTransformer\n    import faiss\n    HAS_RAG_DEPS = True\nexcept (ImportError, OSError, Exception) as e: # Catch OSError for PyTorch/DLL issues\n    print(f\"Warning: RAG dependencies (sentence_transformers, faiss) failed to load: {e}. RAG functionality will be limited.\")\n    HAS_RAG_DEPS = False\n\nclass QueryRetriever:\n    \"\"\"\n    Retrieves semantically similar past queries and their associated metadata (code, results)\n    to serve as few-shot examples for RAG.\n    (T6.4.1 from TASK_LIST)\n    \"\"\"\n    def __init__(self, embedding_model_name: str = settings.RAG_EMBEDDING_MODEL, faiss_index_path: str = settings.RAG_FAISS_INDEX_PATH, examples_path: str = settings.LEARNING_EXAMPLES_PATH):\n        self.embedding_model_name = embedding_model_name\n        self.faiss_index_path = faiss_index_path\n        self.examples_path = examples_path # Used by ExampleCollector\n        self.model = None\n        self.index = None\n        self.examples_data: List[Dict[str, Any]] = [] # Stored as a list of dicts\n\n        self.example_collector = ExampleCollector(examples_dir=self.examples_path)\n\n        if HAS_RAG_DEPS:\n            self._load_model()\n            self._load_index_and_examples()\n        else:\n            print(\"RAG dependencies not available. QueryRetriever will operate without semantic search.\")\n\n    @functools.lru_cache(maxsize=1) # Cache the model instance\n    def _get_cached_model(self):\n        \"\"\"Internal method to get a cached SentenceTransformer model instance.\"\"\"\n        if not HAS_RAG_DEPS:\n            return None\n        try:\n            model = SentenceTransformer(self.embedding_model_name)\n            print(f\"RAG: Loaded embedding model: {self.embedding_model_name}\")\n            return model\n        except Exception as e:\n            print(f\"Error loading SentenceTransformer model: {e}\")\n            return None\n\n    def _load_model(self):\n        \"\"\"Loads the Sentence Transformer model lazily using a cached internal method.\"\"\"\n        if self.model is None:\n            self.model = self._get_cached_model()\n    \n    def _load_index_and_examples(self):\n        \"\"\"Loads FAISS index and corresponding examples data.\"\"\"\n        if not HAS_RAG_DEPS or self.model is None:\n            print(\"RAG: Cannot load index or examples without model and dependencies.\")\n            return\n\n        # Attempt to load examples data from ExampleCollector\n        self.examples_data = self.example_collector.get_all_examples()\n        if not self.examples_data:\n            print(\"RAG: No examples found in collector to load or index.\")\n            return\n\n        if not os.path.exists(self.faiss_index_path):\n            print(f\"RAG: FAISS index not found at {self.faiss_index_path}. Indexing examples...\")\n            self._index_examples_data()\n            return\n\n        try:\n            self.index = faiss.read_index(self.faiss_index_path)\n            print(f\"RAG: Loaded FAISS index from {self.faiss_index_path}\")\n            print(f\"RAG: Loaded {len(self.examples_data)} examples for RAG.\")\n        except Exception as e:\n            print(f\"Error loading FAISS index: {e}. Re-indexing...\")\n            self._index_examples_data()\n\n    def _index_examples_data(self):\n        \"\"\"\n        Indexes examples data (from self.examples_data) into FAISS.\n        \"\"\"\n        if not HAS_RAG_DEPS or self.model is None:\n            print(\"Cannot index examples: RAG dependencies or model not available.\")\n            return\n        if not self.examples_data:\n            print(\"No examples data to index.\")\n            return\n\n        queries = [ex[\"query\"] for ex in self.examples_data]\n        embeddings = self.model.encode(queries, convert_to_numpy=True)\n\n        dimension = embeddings.shape[1]\n        self.index = faiss.IndexFlatL2(dimension)\n        self.index.add(embeddings)\n\n        faiss.write_index(self.index, self.faiss_index_path)\n        print(f\"RAG: Indexed {len(self.examples_data)} examples and saved FAISS index.\")\n\n    def _index_examples_from_files(self):\n        \"\"\"\n        (Deprecated) Collects and indexes examples from JSONL files in the examples_path.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4536, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4f1464ba-77ec-43c7-aa8c-ef4b54a75920": {"__data__": {"id_": "4f1464ba-77ec-43c7-aa8c-ef4b54a75920", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\rag\\query_retriever.py", "language": "python", "lines": 179, "filename": "query_retriever.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\rag\\query_retriever.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\rag\\query_retriever.py", "language": "python", "lines": 179, "filename": "query_retriever.py"}, "hash": "da5b23b78208c811a4f1817c7908848058a0e584d91a4328d66db237b759a486", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b3012dee-1841-40be-b766-5b8d59b7b4b3", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\rag\\query_retriever.py", "language": "python", "lines": 179, "filename": "query_retriever.py"}, "hash": "5756f362817482687e06d10021993717254bfb151baf16a24df2bcdce5840bb5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Now uses ExampleCollector.get_all_examples()\n        \"\"\"\n        print(\"RAG: _index_examples_from_files is deprecated. Using ExampleCollector.\")\n        self.examples_data = self.example_collector.get_all_examples()\n        self._index_examples_data()\n\n    def get_similar_queries(self, query: str, top_k: int = 3) -> List[Dict[str, Any]]:\n        \"\"\"\n        Retrieves top_k semantically similar queries from the indexed examples.\n        \"\"\"\n        if not HAS_RAG_DEPS or self.model is None or self.index is None:\n            print(\"QueryRetriever: RAG not fully initialized. Returning empty list.\")\n            return []\n\n        query_embedding = self.model.encode([query], convert_to_numpy=True)\n        distances, indices = self.index.search(query_embedding, top_k)\n\n        similar_examples = []\n        for i in indices[0]:\n            if 0 <= i < len(self.examples_data): # Ensure index is valid\n                similar_examples.append(self.examples_data[i])\n        \n        print(f\"QueryRetriever: Found {len(similar_examples)} similar examples for query: '{query}'\")\n        return similar_examples\n\nif __name__ == '__main__':\n    # Setup dummy environment for testing\n    from app.config.settings import Settings\n    temp_settings = Settings()\n    \n    # Ensure data/learning directory exists\n    os.makedirs(temp_settings.LEARNING_EXAMPLES_PATH, exist_ok=True)\n    \n    # Create some dummy example data\n    dummy_examples = [\n        {\"query\": \"Mostre as vendas por produto no segmento A\", \"code\": \"code1\", \"result\": \"res1\"},\n        {\"query\": \"Quantos produtos vendemos no segmento B\", \"code\": \"code2\", \"result\": \"res2\"},\n        {\"query\": \"Analise o desempenho de vendas por categoria\", \"code\": \"code3\", \"result\": \"res3\"},\n        {\"query\": \"Qual o total de vendas por segmento\", \"code\": \"code4\", \"result\": \"res4\"},\n    ]\n    with open(os.path.join(temp_settings.LEARNING_EXAMPLES_PATH, \"dummy_examples.jsonl\"), 'w', encoding='utf-8') as f:\n        for ex in dummy_examples:\n            f.write(json.dumps(ex) + '\\n')\n\n    print(\"--- Testing QueryRetriever ---\")\n    retriever = QueryRetriever(\n        embedding_model_name=temp_settings.RAG_EMBEDDING_MODEL,\n        faiss_index_path=temp_settings.RAG_FAISS_INDEX_PATH,\n        examples_path=temp_settings.LEARNING_EXAMPLES_PATH\n    )\n\n    if HAS_RAG_DEPS:\n        # Test semantic search\n        similar_queries = retriever.get_similar_queries(\"Quais foram os produtos mais vendidos por segmento?\", top_k=2)\n        print(\"\\nSimilar queries found:\")\n        for q in similar_queries:\n            print(f\"- {q['query']}\")\n    else:\n        print(\"\\nSkipping semantic search test as RAG dependencies are not available.\")\n\n    # Clean up dummy files\n    if os.path.exists(os.path.join(temp_settings.LEARNING_EXAMPLES_PATH, \"dummy_examples.jsonl\")):\n        os.remove(os.path.join(temp_settings.LEARNING_EXAMPLES_PATH, \"dummy_examples.jsonl\"))\n    if os.path.exists(temp_settings.RAG_FAISS_INDEX_PATH):\n        os.remove(temp_settings.RAG_FAISS_INDEX_PATH)\n    if os.path.exists(os.path.join(temp_settings.LEARNING_EXAMPLES_PATH, \"indexed_examples.jsonl\")):\n        os.remove(os.path.join(temp_settings.LEARNING_EXAMPLES_PATH, \"indexed_examples.jsonl\"))\n    print(\"\\nCleaned up dummy RAG files.\")", "mimetype": "text/plain", "start_char_idx": 4545, "end_char_idx": 7804, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "58fc70ee-b486-4e44-815f-876b9e935eb5": {"__data__": {"id_": "58fc70ee-b486-4e44-815f-876b9e935eb5", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\security\\data_masking.py", "language": "python", "lines": 95, "filename": "data_masking.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\security\\data_masking.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\security\\data_masking.py", "language": "python", "lines": 95, "filename": "data_masking.py"}, "hash": "ae7a396361b4987e4ddc1e3443d287ce11d94ede1b5d7c47f81fb8b73b43ade4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# backend/app/core/security/data_masking.py\n\nimport re\nfrom typing import List, Dict, Any, Optional\n\ndef mask_pii(text: str) -> str:\n    \"\"\"\n    Masks common Personally Identifiable Information (PII) like CPF, email, and phone numbers.\n    CPF: Replaces numbers with '*' except for the last two digits.\n    Email: Masks username part, keeps domain.\n    Phone: Masks most digits, keeps last four.\n    \"\"\"\n    if not isinstance(text, str):\n        return text\n\n    # Mask CPF (e.g., XXX.XXX.XXX-XX or XXXXXXXXXXX)\n    # 11 digits, with or without dots and hyphens\n    text = re.sub(r'(\\d{3}\\.?\\d{3}\\.?\\d{3}-?\\d{2})', \n                  lambda m: '***.***.***-' + m.group(1)[-2:], text)\n    \n    # Mask Email\n    text = re.sub(r'(\\b[a-zA-Z0-9._%+-]+)@([a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\\b)', \n                  lambda m: '***@' + m.group(2), text)\n\n    # Mask Phone Numbers (e.g., (XX) XXXXX-XXXX or XXXXXXXXX)\n    # Simple mask: keep country code if present, and last 4 digits\n    # (NN) NNNNN-NNNN\n    text = re.sub(r'(\\(?\\d{2}\\)?\\s?\\d{4,5}-?\\d{4})', \n                  lambda m: re.sub(r'\\d(?=\\d{4})', '*', m.group(1)), text)\n    \n    return text\n\ndef get_pii_summary(text: str) -> Dict[str, List[str]]:\n    \"\"\"\n    Detects and categorizes types of PII present in the text.\n    Returns a dictionary with PII types as keys and detected PII fragments as values.\n    \"\"\"\n    if not isinstance(text, str):\n        return {}\n\n    pii_found: Dict[str, List[str]] = {\n        \"cpf\": [],\n        \"email\": [],\n        \"phone\": []\n    }\n\n    # Detect CPF\n    cpf_matches = re.findall(r'\\d{3}\\.?\\d{3}\\.?\\d{3}-?\\d{2}', text)\n    if cpf_matches:\n        pii_found[\"cpf\"].extend(cpf_matches)\n\n    # Detect Email\n    email_matches = re.findall(r'\\b[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\\b', text)\n    if email_matches:\n        pii_found[\"email\"].extend(email_matches)\n\n    # Detect Phone Numbers\n    phone_matches = re.findall(r'(\\(?\\d{2}\\)?\\s?\\d{4,5}-?\\d{4})', text)\n    if phone_matches:\n        pii_found[\"phone\"].extend(phone_matches)\n    \n    return {k: list(set(v)) for k, v in pii_found.items() if v} # Remove duplicates and empty lists\n\n# Example usage\nif __name__ == '__main__':\n    test_text = \"\"\"\n    O cliente Jo\u00e3o Silva (joao.silva@example.com) com CPF 123.456.789-00 e telefone (11) 98765-4321\n    fez um pedido. Outro CPF: 99988877766. E-mail alternativo: j.silva@mail.com. Telefone comercial: 21991234567.\n    \"\"\"\n    \n    print(\"--- Original Text ---\")\n    print(test_text)\n\n    print(\"\\n--- Masked Text (mask_pii) ---\")\n    masked_text = mask_pii(test_text)\n    print(masked_text)\n    assert \"***.***.***-00\" in masked_text\n    assert \"***@example.com\" in masked_text\n    assert \"(**) *****-4321\" in masked_text\n    assert \"***@mail.com\" in masked_text\n    assert \"**991234567\" in masked_text\n\n\n    print(\"\\n--- PII Summary (get_pii_summary) ---\")\n    pii_summary = get_pii_summary(test_text)\n    print(json.dumps(pii_summary, indent=2))\n    assert \"cpf\" in pii_summary\n    assert \"email\" in pii_summary\n    assert \"phone\" in pii_summary\n    assert \"123.456.789-00\" in pii_summary[\"cpf\"]\n    assert \"joao.silva@example.com\" in pii_summary[\"email\"]\n    assert \"(11) 98765-4321\" in pii_summary[\"phone\"]\n\n    print(\"\\nData masking and PII detection tests passed!\")", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3266, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ac11fc4e-22db-437a-bf6a-f372bf494216": {"__data__": {"id_": "ac11fc4e-22db-437a-bf6a-f372bf494216", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\security\\input_validator.py", "language": "python", "lines": 81, "filename": "input_validator.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\security\\input_validator.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\security\\input_validator.py", "language": "python", "lines": 81, "filename": "input_validator.py"}, "hash": "9323b43e8543abebde729785ad2cb2a8bf4a314018ca58e8c78d1f9e3c24b412", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# backend/app/core/security/input_validator.py\n\nimport re\n\ndef sanitize_username(username: str) -> str:\n    \"\"\"\n    Sanitizes a username by allowing only alphanumeric characters and underscores.\n    \"\"\"\n    if not isinstance(username, str):\n        raise TypeError(\"Username must be a string.\")\n    \n    # Remove any characters that are not alphanumeric or underscore\n    sanitized = re.sub(r'[^a-zA-Z0-9_]', '', username)\n    return sanitized\n\ndef validate_password_strength(password: str) -> bool:\n    \"\"\"\n    Validates password strength based on a set of criteria:\n    - Minimum 8 characters\n    - At least one uppercase letter\n    - At least one lowercase letter\n    - At least one digit\n    - At least one special character\n    \"\"\"\n    if not isinstance(password, str):\n        raise TypeError(\"Password must be a string.\")\n\n    if len(password) < 8:\n        return False\n    if not re.search(r\"[A-Z]\", password):\n        return False\n    if not re.search(r\"[a-z]\", password):\n        return False\n    if not re.search(r\"\\d\", password):\n        return False\n    if not re.search(r\"[!@#$%^&*(),.?\\\":{}|<>]\", password):\n        return False\n    \n    return True\n\ndef sanitize_sql_input(text: str) -> str:\n    \"\"\"\n    Sanitizes text to prevent SQL injection.\n    This is a basic sanitization. For actual database queries, parameterized queries\n    or ORMs should always be preferred. This function is mainly for sanitizing\n    input that might eventually be part of a dynamic query (e.g., column names)\n    or used in a context where full parameterization is not possible.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"Input for SQL sanitization must be a string.\")\n\n    # Remove or escape common SQL injection characters\n    # This is an example; a robust solution might need more context-aware escaping\n    sanitized = text.replace(\"'\", \"''\") # Escape single quotes\n    sanitized = sanitized.replace(\";\", \"\") # Remove semicolons\n    sanitized = sanitized.replace(\"--\", \"\") # Remove SQL comments\n    sanitized = sanitized.replace(\"/*\", \"\") # Remove multi-line comments\n    sanitized = sanitized.replace(\"*/\", \"\")\n    \n    # Further sanitization could involve whitelisting allowed characters\n    # For user-provided column names, you might only allow a-z, A-Z, 0-9, _\n    sanitized = re.sub(r'[^\\w\\s.-]', '', sanitized) # Allow word chars, space, dot, dash\n    \n    return sanitized\n\nif __name__ == '__main__':\n    print(\"--- Username Sanitization ---\")\n    print(f\"Original: 'user@name-123!' -> Sanitized: '{sanitize_username('user@name-123!')}'\")\n    print(f\"Original: 'valid_user_42' -> Sanitized: '{sanitize_username('valid_user_42')}'\")\n\n    print(\"\\n--- Password Strength Validation ---\")\n    print(f\"'Password123!' is strong: {validate_password_strength('Password123!')}\")\n    print(f\"'weakpass' is strong: {validate_password_strength('weakpass')}\")\n    print(f\"'NoDigit!' is strong: {validate_password_strength('NoDigit!')}\")\n    print(f\"'NoSpecial1' is strong: {validate_password_strength('NoSpecial1')}\")\n\n    print(\"\\n--- SQL Input Sanitization ---\")\n    print(f\"Original: 'DROP TABLE users;--' -> Sanitized: '{sanitize_sql_input('DROP TABLE users;--')}'\")\n    print(f\"Original: '1 OR 1=1' -> Sanitized: '{sanitize_sql_input('1 OR 1=1')}'\")\n    print(f\"Original: 'valid_column_name' -> Sanitized: '{sanitize_sql_input('valid_column_name')}'\")", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3376, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "fc19df88-bdc1-4ab5-bc46-c91f9d7c23f0": {"__data__": {"id_": "fc19df88-bdc1-4ab5-bc46-c91f9d7c23f0", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\chart_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "hash": "9ac656311e15dc4fad15c54781c106118803f6fcff851c0b9365e30f3ec6b45b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "27613711-c0aa-4f0e-b0e4-9bcd68a4ea59", "node_type": "1", "metadata": {}, "hash": "a89045f1aee2c219b732c783ff8122402e129d59251b730e7dd1fb68923a19df", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nFerramentas para gera\u00e7\u00e3o de gr\u00e1ficos e visualiza\u00e7\u00f5es.\nIntegra\u00e7\u00e3o com Plotly para an\u00e1lise visual de dados.\n\"\"\"\n\nimport logging\nfrom typing import Dict, Any\nimport pandas as pd\nimport plotly.graph_objects as go\nfrom langchain_core.tools import tool\nfrom app.core.data_source_manager import get_data_manager\nfrom app.core.visualization.advanced_charts import AdvancedChartGenerator\nfrom app.core.utils.serializers import TypeConverter, safe_json_dumps\n\nlogger = logging.getLogger(__name__)\n\n# ==================== MAPEAMENTO DE COLUNAS DO PARQUET ====================\n# Baseado no schema real do admmat.parquet (2025-12-16)\nCOLUMN_VARIANTS = {\n    'grupo': ['NOMEGRUPO', 'nomegrupo', 'GRUPO', 'Grupo', 'grupo'],\n    'nome': ['NOME', 'nome', 'DESCRI\u00c7\u00c3O', 'DESCRICAO', 'nome_produto'],\n    'estoque': ['ESTOQUE_UNE', 'ESTOQUE_LV', 'ESTOQUE', 'estoque_atual', 'QTD'],\n    'preco': ['LIQUIDO_38', 'preco_38_percent', 'PRECO', 'VENDA UNIT R$'],\n    'vendas': ['VENDA_30DD', 'venda_30_d', 'VENDAS_30D'],\n    'codigo': ['PRODUTO', 'codigo', 'CODIGO', 'ITEM'],\n    'segmento': ['NOMESEGMENTO', 'nomesegmento', 'SEGMENTO'],\n    'fabricante': ['NOMEFABRICANTE', 'FABRICANTE'],\n    'categoria': ['NOMECATEGORIA', 'CATEGORIA'],\n}\n\n\ndef _get_column(df: pd.DataFrame, column_type: str) -> str:\n    \"\"\"\n    Retorna o nome correto da coluna no DataFrame baseado no tipo.\n    \n    Args:\n        df: DataFrame com os dados\n        column_type: Tipo de coluna ('grupo', 'nome', 'estoque', 'preco', etc.)\n        \n    Returns:\n        Nome da coluna encontrada ou None se n\u00e3o existir\n    \"\"\"\n    variants = COLUMN_VARIANTS.get(column_type, [])\n    for col in variants:\n        if col in df.columns:\n            return col\n    return None\n\n\ndef _get_grupo_column(df: pd.DataFrame) -> str:\n    \"\"\"Alias para compatibilidade - retorna coluna de grupo.\"\"\"\n    return _get_column(df, 'grupo')\n\n\ndef _get_theme_template() -> str:\n    \"\"\"Retorna o template de tema padr\u00e3o.\"\"\"\n    return \"plotly_white\"\n\n\ndef _apply_chart_customization(\n    fig: go.Figure, title: str = \"\", show_legend: bool = True\n) -> go.Figure:\n    \"\"\"\n    Aplica customiza\u00e7\u00f5es padr\u00e3o aos gr\u00e1ficos.\n\n    Args:\n        fig: Figura Plotly\n        title: T\u00edtulo do gr\u00e1fico\n        show_legend: Se mostra legenda\n\n    Returns:\n        Figura com customiza\u00e7\u00f5es aplicadas\n    \"\"\"\n    fig.update_layout(\n        template=_get_theme_template(),\n        title={\n            \"text\": title,\n            \"x\": 0.5,\n            \"xanchor\": \"center\",\n            \"font\": {\"size\": 20, \"color\": \"#1f77b4\"},\n        },\n        hovermode=\"x unified\",\n        font=dict(size=11, family=\"Arial\"),\n        margin=dict(l=50, r=50, t=80, b=50),\n        showlegend=show_legend,\n        height=500,\n        paper_bgcolor=\"rgba(240, 240, 240, 0.5)\",\n        plot_bgcolor=\"rgba(255, 255, 255, 0.9)\",\n        # \u2705 MELHORIA 2024: uirevision preserva zoom/pan durante updates\n        uirevision='constant',\n        # \u2705 MELHORIA 2024: Configura\u00e7\u00e3o responsiva otimizada\n        autosize=True,\n    )\n    \n    # \u2705 MELHORIA 2024: Config otimizado para performance e UX\n    fig.update_layout(\n        modebar=dict(\n            bgcolor='rgba(255, 255, 255, 0.7)',\n            color='#1f77b4',\n            activecolor='#ff7f0e'\n        )\n    )\n    \n    return fig\n\n\ndef _export_chart_to_json(fig: go.Figure) -> str:\n    \"\"\"\n    Exporta figura como JSON para Streamlit.\n\n    Args:\n        fig: Figura Plotly\n\n    Returns:\n        JSON string da figura\n    \"\"\"\n    return fig.to_json()", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3485, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "27613711-c0aa-4f0e-b0e4-9bcd68a4ea59": {"__data__": {"id_": "27613711-c0aa-4f0e-b0e4-9bcd68a4ea59", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\chart_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "hash": "9ac656311e15dc4fad15c54781c106118803f6fcff851c0b9365e30f3ec6b45b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fc19df88-bdc1-4ab5-bc46-c91f9d7c23f0", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "hash": "05be7a711e3a84458563fa51e1cf0e6fbf0d3f199887a2344ac6c8b9f55eecd6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ad4d0279-ee52-4580-ba94-041ded31a9e4", "node_type": "1", "metadata": {}, "hash": "796fea02307b0e11cb4f7f6fd4a6bc6583add1546ba24bb061824a4d5385d645", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# ==================== FERRAMENTA UNIVERSAL DE GR\u00c1FICOS ====================\n# Best Practice 2024: Uma \u00fanica ferramenta flex\u00edvel em vez de 15+ espec\u00edficas\n\n@tool\ndef gerar_grafico_universal(\n    descricao: str,\n    filtros: Dict[str, Any] = None,\n    tipo_grafico: str = \"auto\",\n    coluna_valor: str = \"vendas\",\n    coluna_agrupamento: str = \"grupo\",\n    limite: int = 10,\n    titulo: str = None\n) -> Dict[str, Any]:\n    \"\"\"\n    **FERRAMENTA PRINCIPAL PARA GERAR GR\u00c1FICOS E VISUALIZA\u00c7\u00d5ES**\n\n    Use esta ferramenta SEMPRE que o usu\u00e1rio pedir qualquer tipo de gr\u00e1fico, visualiza\u00e7\u00e3o, ranking, compara\u00e7\u00e3o visual ou an\u00e1lise gr\u00e1fica.\n    Gera gr\u00e1ficos Plotly interativos (barras, pizza, linhas, etc.) com os dados do Parquet.\n\n    **QUANDO USAR (SEMPRE que o usu\u00e1rio mencionar):**\n    - \"gere um gr\u00e1fico\"\n    - \"mostre um gr\u00e1fico\"\n    - \"quero ver gr\u00e1fico\"\n    - \"visualize\"\n    - \"ranking\"\n    - \"top produtos\"\n    - \"compara\u00e7\u00e3o visual\"\n    - Qualquer pedido de visualiza\u00e7\u00e3o de dados\n\n    Args:\n        descricao: Descri\u00e7\u00e3o do gr\u00e1fico em linguagem natural.\n                   Ex: \"ranking de vendas de tecidos\", \"top 10 produtos por estoque\"\n        filtros: Filtros para aplicar nos dados. Exemplos:\n                 {\"UNE\": 2365} - Filtrar por loja espec\u00edfica\n                 {\"NOMESEGMENTO\": \"TECIDOS\"} - Filtrar por segmento\n                 {\"NOMEFABRICANTE\": \"TNT\"} - Filtrar por fabricante\n                 {\"UNE\": 2365, \"NOMESEGMENTO\": \"TECIDOS\"} - M\u00faltiplos filtros\n        tipo_grafico: \"bar\", \"pie\", \"line\", \"donut\", \"scatter\" ou \"auto\" (recomendado)\n        coluna_valor: \"vendas\", \"estoque\", \"preco\" ou \"contagem\"\n        coluna_agrupamento: \"grupo\", \"segmento\", \"fabricante\" ou \"nome\"\n        limite: Quantidade de itens no gr\u00e1fico (padr\u00e3o: 10)\n        titulo: T\u00edtulo customizado (opcional, gerado automaticamente se n\u00e3o informado)\n\n    Returns:\n        Dicion\u00e1rio com chart_data (gr\u00e1fico Plotly em JSON), summary (resumo) e status\n\n    **Exemplos pr\u00e1ticos:**\n        \"gere um gr\u00e1fico de vendas ranking tecidos une 2365\" \u2192\n        gerar_grafico_universal(descricao=\"ranking de vendas de tecidos\",\n                               filtros={\"UNE\": 2365, \"NOMESEGMENTO\": \"TECIDOS\"},\n                               coluna_valor=\"vendas\", limite=10)\n\n        \"mostre top 10 produtos por estoque\" \u2192\n        gerar_grafico_universal(descricao=\"top 10 produtos por estoque\",\n                               coluna_valor=\"estoque\", limite=10)\n    \"\"\"\n    logger.info(f\"Gerando gr\u00e1fico universal: {descricao} | filtros={filtros} | tipo={tipo_grafico}\")\n    \n    try:\n        # 1. Carregar dados\n        manager = get_data_manager()\n        df = manager.get_data()\n        \n        if df is None or df.empty:\n            return {\"status\": \"error\", \"message\": \"N\u00e3o foi poss\u00edvel carregar dados.\"}\n        \n        logger.info(f\"Dados carregados: {len(df)} registros, {len(df.columns)} colunas\")\n        \n        # 2.", "mimetype": "text/plain", "start_char_idx": 3488, "end_char_idx": 6399, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ad4d0279-ee52-4580-ba94-041ded31a9e4": {"__data__": {"id_": "ad4d0279-ee52-4580-ba94-041ded31a9e4", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\chart_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "hash": "9ac656311e15dc4fad15c54781c106118803f6fcff851c0b9365e30f3ec6b45b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "27613711-c0aa-4f0e-b0e4-9bcd68a4ea59", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "hash": "ef731ae75ca65356d69a750702802e871485fa4d3c1d265dc2aa9f38cd38a21e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "19717d32-23c3-4402-9c6b-96d32ee3982c", "node_type": "1", "metadata": {}, "hash": "b6b7bad4132c16602cf71dbbc83d570e6eac04e125ade6f25222064235b70ea5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Aplicar filtros\n        if filtros:\n            for col_filter, valor in filtros.items():\n                # Buscar variantes do nome da coluna\n                col_real = None\n                col_upper = col_filter.upper()\n                \n                # Verificar se a coluna existe diretamente\n                if col_filter in df.columns:\n                    col_real = col_filter\n                elif col_upper in df.columns:\n                    col_real = col_upper\n                else:\n                    # Tentar encontrar via COLUMN_VARIANTS\n                    for tipo, variantes in COLUMN_VARIANTS.items():\n                        if col_upper in [v.upper() for v in variantes]:\n                            col_real = _get_column(df, tipo)\n                            break\n                \n                if col_real:\n                    if isinstance(valor, str):\n                        # Filtro case-insensitive para strings\n                        df = df[df[col_real].astype(str).str.upper().str.contains(str(valor).upper(), na=False)]\n                    else:\n                        df = df[df[col_real] == valor]\n                    logger.info(f\"Filtro aplicado: {col_real}={valor}, restaram {len(df)} registros\")\n                else:\n                    logger.warning(f\"Coluna de filtro '{col_filter}' n\u00e3o encontrada\")\n        \n        if df.empty:\n            return {\n                \"status\": \"error\", \n                \"message\": f\"Nenhum dado encontrado com os filtros aplicados: {filtros}\"\n            }\n        \n        # 3. Detectar colunas reais\n        col_valor_real = None\n        col_grupo_real = None\n        \n        # Mapeamento de nomes amig\u00e1veis para tipos de coluna\n        valor_map = {\n            \"vendas\": \"vendas\", \"venda\": \"vendas\", \"sales\": \"vendas\",\n            \"estoque\": \"estoque\", \"stock\": \"estoque\", \"quantidade\": \"estoque\",\n            \"preco\": \"preco\", \"price\": \"preco\", \"valor\": \"preco\",\n            \"contagem\": None  # Contagem n\u00e3o precisa de coluna de valor\n        }\n        grupo_map = {\n            \"grupo\": \"grupo\", \"categoria\": \"categoria\", \"group\": \"grupo\",\n            \"segmento\": \"segmento\", \"segment\": \"segmento\",\n            \"fabricante\": \"fabricante\", \"marca\": \"fabricante\", \"brand\": \"fabricante\",\n            \"nome\": \"nome\", \"produto\": \"nome\", \"name\": \"nome\"\n        }\n        \n        # Encontrar coluna de valor\n        tipo_valor = valor_map.get(coluna_valor.lower(), coluna_valor)\n        if tipo_valor:\n            col_valor_real = _get_column(df, tipo_valor)\n        \n        # Encontrar coluna de agrupamento\n        tipo_grupo = grupo_map.get(coluna_agrupamento.lower(), coluna_agrupamento)\n        col_grupo_real = _get_column(df, tipo_grupo)\n        \n        # Fallbacks\n        if not col_grupo_real:\n            col_grupo_real = _get_column(df, 'grupo') or _get_column(df, 'segmento') or _get_column(df, 'nome')\n        \n        if not col_grupo_real:\n            return {\"status\": \"error\", \"message\": f\"Coluna de agrupamento n\u00e3o encontrada. Dispon\u00edveis: {list(df.columns)[:10]}\"}\n        \n        logger.info(f\"Colunas detectadas: valor={col_valor_real}, grupo={col_grupo_real}\")\n        \n        # 4. Preparar dados para o gr\u00e1fico\n        if coluna_valor.lower() == \"contagem\" or not col_valor_real:\n            # Contagem simples\n            df_chart = df[col_grupo_real].value_counts().head(limite).reset_index()\n            df_chart.columns = [\"categoria\", \"valor\"]\n        else:\n            # Converter coluna de valor para num\u00e9rico\n            df[col_valor_real] = pd.to_numeric(df[col_valor_real], errors='coerce').fillna(0)\n            \n            # Agregar por grupo\n            df_chart = df.groupby(col_grupo_real)[col_valor_real].sum().sort_values(ascending=False).head(limite).reset_index()\n            df_chart.columns = [\"categoria\", \"valor\"]\n        \n        if df_chart.empty:\n            return {\"status\": \"error\", \"message\": \"N\u00e3o foi poss\u00edvel gerar dados para o gr\u00e1fico\"}\n        \n        # 5.", "mimetype": "text/plain", "start_char_idx": 6400, "end_char_idx": 10402, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "19717d32-23c3-4402-9c6b-96d32ee3982c": {"__data__": {"id_": "19717d32-23c3-4402-9c6b-96d32ee3982c", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\chart_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "hash": "9ac656311e15dc4fad15c54781c106118803f6fcff851c0b9365e30f3ec6b45b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ad4d0279-ee52-4580-ba94-041ded31a9e4", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "hash": "57b3cceed43ca96846354fe2d4ab03cb418c67e9cc76f45f708b70925be61712", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ffdee957-9a55-453b-8db4-29720e371074", "node_type": "1", "metadata": {}, "hash": "3ac2b0afb8ed31dfe16cbaf6b46b07e25aa602e0e5c8e95156cbb2e185de942e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Auto-detectar tipo de gr\u00e1fico se necess\u00e1rio\n        if tipo_grafico == \"auto\":\n            num_categorias = len(df_chart)\n            if num_categorias <= 5:\n                tipo_grafico = \"pie\"\n            elif num_categorias <= 15:\n                tipo_grafico = \"bar\"\n            else:\n                tipo_grafico = \"bar\"  # Barras horizontais para muitos itens\n        \n        # 6. Gerar t\u00edtulo se n\u00e3o fornecido\n        if not titulo:\n            filtro_desc = \"\"\n            if filtros:\n                filtro_desc = \" | \" + \", \".join([f\"{k}={v}\" for k, v in filtros.items()])\n            titulo = f\"Top {limite} {coluna_agrupamento.title()} por {coluna_valor.title()}{filtro_desc}\"\n        \n        # 7. Criar gr\u00e1fico Plotly\n        fig = go.Figure()\n        \n        if tipo_grafico in [\"pie\", \"donut\"]:\n            fig.add_trace(go.Pie(\n                labels=df_chart[\"categoria\"],\n                values=df_chart[\"valor\"],\n                hole=0.4 if tipo_grafico == \"donut\" else 0,\n                textinfo='label+percent',\n                hovertemplate=\"<b>%{label}</b><br>Valor: %{value:,.0f}<br>%{percent}<extra></extra>\"\n            ))\n        elif tipo_grafico == \"bar\":\n            fig.add_trace(go.Bar(\n                x=df_chart[\"categoria\"],\n                y=df_chart[\"valor\"],\n                marker=dict(\n                    color=df_chart[\"valor\"],\n                    colorscale=\"Blues\",\n                    showscale=False\n                ),\n                text=df_chart[\"valor\"].apply(lambda x: f\"{x:,.0f}\"),\n                textposition='outside',\n                hovertemplate=\"<b>%{x}</b><br>Valor: %{y:,.0f}<extra></extra>\"\n            ))\n        elif tipo_grafico == \"line\":\n            fig.add_trace(go.Scatter(\n                x=df_chart[\"categoria\"],\n                y=df_chart[\"valor\"],\n                mode='lines+markers',\n                line=dict(color='#2563EB', width=3),\n                marker=dict(size=10),\n                hovertemplate=\"<b>%{x}</b><br>Valor: %{y:,.0f}<extra></extra>\"\n            ))\n        else:  # scatter ou outros\n            fig.add_trace(go.Scatter(\n                x=df_chart[\"categoria\"],\n                y=df_chart[\"valor\"],\n                mode='markers',\n                marker=dict(size=12, color=df_chart[\"valor\"], colorscale=\"Viridis\"),\n                hovertemplate=\"<b>%{x}</b><br>Valor: %{y:,.0f}<extra></extra>\"\n            ))\n        \n        # 8. Aplicar estilos\n        fig = _apply_chart_customization(fig, title=titulo, show_legend=tipo_grafico in [\"pie\", \"donut\"])\n        \n        if tipo_grafico == \"bar\":\n            fig.update_xaxes(tickangle=-45)\n            fig.update_layout(height=500)\n        \n        # 9. Retornar resultado com serializa\u00e7\u00e3o segura\n        summary_data = {\n            \"total_categorias\": len(df_chart),\n            \"total_valor\": float(df_chart[\"valor\"].sum()),\n            \"top_categoria\": str(df_chart.iloc[0][\"categoria\"]) if len(df_chart) > 0 else None,\n            \"filtros_aplicados\": filtros or {},\n            \"descricao\": descricao\n        }\n\n        # Converter para garantir serializa\u00e7\u00e3o segura (remove MapComposite, etc.)\n        summary_serializable = TypeConverter.convert(summary_data)\n\n        return {\n            \"status\": \"success\",\n            \"chart_type\": tipo_grafico,\n            \"chart_data\": _export_chart_to_json(fig),\n            \"summary\": summary_serializable\n        }\n        \n    except Exception as e:\n        logger.error(f\"Erro ao gerar gr\u00e1fico universal: {e}\", exc_info=True)\n        return {\"status\": \"error\", \"message\": f\"Erro ao gerar gr\u00e1fico: {str(e)}\"}\n\n\n# ==================== FERRAMENTAS LEGADAS (manter para compatibilidade) ====================\n# As ferramentas abaixo s\u00e3o mantidas para retrocompatibilidade, mas gerar_grafico_universal\n# deve ser a ferramenta principal usada pelo agente.", "mimetype": "text/plain", "start_char_idx": 10403, "end_char_idx": 14256, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ffdee957-9a55-453b-8db4-29720e371074": {"__data__": {"id_": "ffdee957-9a55-453b-8db4-29720e371074", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\chart_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "hash": "9ac656311e15dc4fad15c54781c106118803f6fcff851c0b9365e30f3ec6b45b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "19717d32-23c3-4402-9c6b-96d32ee3982c", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "hash": "92f5b3ec2f0b6e65fbc4454e1c1a387dc7c31ff13058570269179ea24b563db6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a1be6b57-b747-44dc-8294-377c6100a1f8", "node_type": "1", "metadata": {}, "hash": "a84bddd7b50789527f086f831f484a9aceedb116641324197dacb984fce42821", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "def gerar_grafico_vendas_por_categoria(\n    limite: int = 10, ordenar_por: str = \"descendente\"\n) -> Dict[str, Any]:\n    \"\"\"\n    Gera gr\u00e1fico de barras com o total de produtos por grupo (categoria).\n    \u00datil para an\u00e1lise de categorias de produtos.\n\n    Args:\n        limite: N\u00famero m\u00e1ximo de categorias a mostrar\n        ordenar_por: \"ascendente\" ou \"descendente\"\n\n    Returns:\n        Dicion\u00e1rio com gr\u00e1fico Plotly e dados\n    \"\"\"\n    logger.info(f\"Gerando gr\u00e1fico de produtos por grupo (limite={limite})\")\n\n    try:\n        manager = get_data_manager()\n        df = manager.get_data()\n\n        if df is None or df.empty:\n            return {\n                \"status\": \"error\",\n                \"message\": \"N\u00e3o foi poss\u00edvel carregar dados.\",\n            }\n        \n        grupo_col = _get_grupo_column(df)\n        if grupo_col is None:\n            return {\n                \"status\": \"error\",\n                \"message\": \"N\u00e3o foi poss\u00edvel encontrar a coluna de grupo (GRUPO/nomegrupo).\",\n            }\n\n        # Preparar dados\n        vendas_por_categoria = df[grupo_col].value_counts().reset_index()\n        vendas_por_categoria.columns = [\"grupo\", \"total\"]\n\n        if ordenar_por == \"ascendente\":\n            vendas_por_categoria = vendas_por_categoria.sort_values(\n                \"total\", ascending=True\n            )\n        else:\n            vendas_por_categoria = vendas_por_categoria.sort_values(\n                \"total\", ascending=False\n            )\n\n        df_chart = vendas_por_categoria.head(limite)\n\n        # Usar o novo gerador de gr\u00e1ficos\n        chart_generator = AdvancedChartGenerator()\n        fig = chart_generator.create_segmentation_chart(\n            df=df_chart,\n            segment_column=\"grupo\",\n            value_column=\"total\",\n            chart_type=\"donut\",\n        )\n\n        # Customiza\u00e7\u00f5es adicionais se necess\u00e1rio\n        fig.update_layout(title_text=f\"Top {limite} Grupos por Quantidade de Produtos\")\n\n        return {\n            \"status\": \"success\",\n            \"chart_type\": \"donut\",\n            \"chart_data\": _export_chart_to_json(fig),\n            \"summary\": {\n                \"total_grupos\": len(df_chart),\n                \"grupos\": df_chart.set_index(\"grupo\")[\"total\"].to_dict(),\n                \"total_itens\": int(df_chart[\"total\"].sum()),\n            },\n        }\n    except Exception as e:\n        logger.error(f\"Erro ao gerar gr\u00e1fico de vendas: {e}\", exc_info=True)\n        return {\"status\": \"error\", \"message\": f\"Erro ao gerar gr\u00e1fico: {str(e)}\"}", "mimetype": "text/plain", "start_char_idx": 14259, "end_char_idx": 16756, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a1be6b57-b747-44dc-8294-377c6100a1f8": {"__data__": {"id_": "a1be6b57-b747-44dc-8294-377c6100a1f8", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\chart_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "hash": "9ac656311e15dc4fad15c54781c106118803f6fcff851c0b9365e30f3ec6b45b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ffdee957-9a55-453b-8db4-29720e371074", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "hash": "a1b15adebe47696853e4e1bac8a9a8da4c5f42063cabb87fce249e55f84e00e9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4d156409-ea01-4576-a226-12bd402a946d", "node_type": "1", "metadata": {}, "hash": "3d053305071dfbb69a315f7906c0e9b5dff95df3e03341e596b05984dc4b864f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "@tool\ndef gerar_grafico_estoque_por_produto(\n    limite: int = 15, minimo_estoque: int = 0\n) -> Dict[str, Any]:\n    \"\"\"\n    Gera gr\u00e1fico de estoque dispon\u00edvel por produto.\n    Mostra produtos com mais estoque em destaque.\n\n    Args:\n        limite: N\u00famero m\u00e1ximo de produtos a mostrar\n        minimo_estoque: Estoque m\u00ednimo para incluir\n\n    Returns:\n        Dicion\u00e1rio com gr\u00e1fico e dados de estoque\n    \"\"\"\n    logger.info(f\"Gerando gr\u00e1fico de estoque por produto (limite={limite})\")\n\n    try:\n        manager = get_data_manager()\n        df = manager.get_data()\n\n        if df is None or df.empty:\n            return {\"status\": \"error\", \"message\": \"N\u00e3o foi poss\u00edvel carregar dados\"}\n\n        # Detectar colunas dinamicamente (baseado no schema real do Parquet)\n        estoque_col = _get_column(df, 'estoque')\n        nome_col = _get_column(df, 'nome')\n\n        if estoque_col is None or nome_col is None:\n            return {\n                \"status\": \"error\",\n                \"message\": f\"Colunas de estoque ou nome n\u00e3o encontradas. Dispon\u00edveis: {list(df.columns)[:15]}...\",\n            }\n\n        # Preparar dados\n        df_estoque = df[[nome_col, estoque_col]].copy()\n        df_estoque[estoque_col] = pd.to_numeric(df_estoque[estoque_col], errors='coerce').fillna(0)\n        df_estoque = df_estoque[df_estoque[estoque_col] >= minimo_estoque]\n        df_estoque = df_estoque.sort_values(estoque_col, ascending=False).head(limite)\n\n        # Criar gr\u00e1fico\n        fig = go.Figure(\n            data=[\n                go.Bar(\n                    x=df_estoque[nome_col],\n                    y=df_estoque[estoque_col],\n                    marker=dict(\n                        color=df_estoque[estoque_col],\n                        colorscale=\"RdYlGn\",\n                        showscale=True,\n                        colorbar=dict(title=\"Estoque\"),\n                    ),\n                    hovertemplate=\"<b>%{x}</b><br>Estoque: %{y}<extra></extra>\",\n                    text=df_estoque[estoque_col],\n                    textposition='auto',\n                    texttemplate='%{text:.2s}'\n                )\n            ]\n        )\n\n        fig.update_layout(\n            xaxis_tickangle=-45,\n            height=600,\n        )\n\n        fig = _apply_chart_customization(\n            fig, title=f\"Estoque Dispon\u00edvel por Produto (Top {limite})\"\n        )\n\n        fig.update_xaxes(title_text=\"Produto\")\n        fig.update_yaxes(title_text=\"Quantidade em Estoque\")\n\n        return {\n            \"status\": \"success\",\n            \"chart_type\": \"bar_vertical\",\n            \"chart_data\": _export_chart_to_json(fig),\n            \"summary\": {\n                \"total_produtos\": len(df_estoque),\n                \"estoque_total\": int(df_estoque[estoque_col].sum()),\n                \"estoque_medio\": float(df_estoque[estoque_col].mean()),\n                \"estoque_maximo\": int(df_estoque[estoque_col].max()),\n            },\n        }\n    except Exception as e:\n        logger.error(f\"Erro ao gerar gr\u00e1fico de estoque: {e}\", exc_info=True)\n        return {\"status\": \"error\", \"message\": f\"Erro ao gerar gr\u00e1fico: {str(e)}\"}", "mimetype": "text/plain", "start_char_idx": 16759, "end_char_idx": 19868, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4d156409-ea01-4576-a226-12bd402a946d": {"__data__": {"id_": "4d156409-ea01-4576-a226-12bd402a946d", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\chart_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "hash": "9ac656311e15dc4fad15c54781c106118803f6fcff851c0b9365e30f3ec6b45b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a1be6b57-b747-44dc-8294-377c6100a1f8", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "hash": "ef4899214e5fd06f070a4fec226390656e212a148fcc61e875f13b1fa3c94c9a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1606ec3f-0a65-480c-b34e-cafc98c60b30", "node_type": "1", "metadata": {}, "hash": "b77684a9a4d98c6912cfc973b752f85b0561c52d9e3803464cf59efdca913592", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "@tool\ndef gerar_comparacao_precos_categorias() -> Dict[str, Any]:\n    \"\"\"\n    Gera gr\u00e1fico de compara\u00e7\u00e3o de pre\u00e7os m\u00e9dios por grupo (categoria).\n    \u00datil para an\u00e1lise de precifica\u00e7\u00e3o.\n\n    Returns:\n        Dicion\u00e1rio com gr\u00e1fico comparativo de pre\u00e7os\n    \"\"\"\n    logger.info(\"Gerando gr\u00e1fico de compara\u00e7\u00e3o de pre\u00e7os por grupo\")\n\n    try:\n        manager = get_data_manager()\n        df = manager.get_data()\n\n        if df is None or df.empty:\n            return {\"status\": \"error\", \"message\": \"N\u00e3o foi poss\u00edvel carregar dados\"}\n\n        # Detectar colunas dinamicamente\n        categoria_col = _get_grupo_column(df)\n        preco_col = _get_column(df, 'preco')\n\n        if categoria_col is None:\n            return {\n                \"status\": \"error\",\n                \"message\": \"Coluna de grupo (NOMEGRUPO) n\u00e3o encontrada\",\n            }\n        if preco_col is None:\n            return {\n                \"status\": \"error\",\n                \"message\": \"Coluna de pre\u00e7o (LIQUIDO_38) n\u00e3o encontrada\",\n            }\n\n        # Calcular pre\u00e7o m\u00e9dio por categoria\n        df[preco_col] = pd.to_numeric(df[preco_col], errors='coerce')\n        df = df.dropna(subset=[preco_col])\n        \n        preco_medio = (\n            df.groupby(categoria_col)[preco_col]\n            .agg([\"mean\", \"min\", \"max\", \"count\"])\n            .reset_index()\n        )\n        preco_medio = preco_medio.sort_values(\"mean\", ascending=False)\n\n        # Criar gr\u00e1fico com m\u00faltiplas s\u00e9ries\n        fig = go.Figure()\n\n        fig.add_trace(\n            go.Bar(\n                x=preco_medio[categoria_col],\n                y=preco_medio[\"mean\"],\n                name=\"Pre\u00e7o M\u00e9dio\",\n                marker_color=\"lightblue\",\n            )\n        )\n\n        fig.add_trace(\n            go.Scatter(\n                x=preco_medio[categoria_col],\n                y=preco_medio[\"max\"],\n                mode=\"markers+lines\",\n                name=\"Pre\u00e7o M\u00e1ximo\",\n                line=dict(dash=\"dash\", color=\"red\"),\n                marker=dict(size=8),\n            )\n        )\n\n        fig = _apply_chart_customization(\n            fig, title=\"Compara\u00e7\u00e3o de Pre\u00e7os por Grupo\", show_legend=True\n        )\n\n        fig.update_xaxes(title_text=\"Grupo\")\n        fig.update_yaxes(title_text=\"Pre\u00e7o (R$)\")\n        fig.update_layout(xaxis_tickangle=-45, height=500)\n\n        return {\n            \"status\": \"success\",\n            \"chart_type\": \"bar_line_combo\",\n            \"chart_data\": _export_chart_to_json(fig),\n            \"summary\": {\n                \"grupos\": len(preco_medio),\n                \"preco_medio_geral\": float(df[preco_col].mean()),\n                \"preco_maximo\": float(preco_medio[\"max\"].max()),\n                \"preco_minimo\": float(preco_medio[\"min\"].min()),\n                \"grupos_data\": preco_medio.to_dict(\"records\"),\n            },\n        }\n    except Exception as e:\n        logger.error(f\"Erro ao gerar gr\u00e1fico de compara\u00e7\u00e3o: {e}\", exc_info=True)\n        return {\"status\": \"error\", \"message\": f\"Erro ao gerar gr\u00e1fico: {str(e)}\"}", "mimetype": "text/plain", "start_char_idx": 19871, "end_char_idx": 22880, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1606ec3f-0a65-480c-b34e-cafc98c60b30": {"__data__": {"id_": "1606ec3f-0a65-480c-b34e-cafc98c60b30", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\chart_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "hash": "9ac656311e15dc4fad15c54781c106118803f6fcff851c0b9365e30f3ec6b45b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4d156409-ea01-4576-a226-12bd402a946d", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "hash": "e6f59fef71d2690d20114f3e0c76b436a8234198665d9fee781b3dfac5b70c64", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8aaa3dd6-2ec4-4b7a-8ebb-73e6223af0a1", "node_type": "1", "metadata": {}, "hash": "244c0a5a4ec5c302ded0c6ae9f57c8b20a29271b072249cc93dc4271c818d96b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "@tool\ndef gerar_analise_distribuicao_estoque() -> Dict[str, Any]:\n    \"\"\"\n    Gera histograma e box plot da distribui\u00e7\u00e3o de estoque.\n    \u00datil para an\u00e1lise estat\u00edstica de n\u00edveis de estoque.\n\n    Returns:\n        Dicion\u00e1rio com gr\u00e1ficos de distribui\u00e7\u00e3o\n    \"\"\"\n    logger.info(\"Gerando an\u00e1lise de distribui\u00e7\u00e3o de estoque\")\n\n    try:\n        manager = get_data_manager()\n        df = manager.get_data()\n\n        if df is None or df.empty:\n            return {\"status\": \"error\", \"message\": \"N\u00e3o foi poss\u00edvel carregar dados\"}\n\n        # Detectar coluna de estoque dinamicamente\n        estoque_col = _get_column(df, 'estoque')\n\n        if estoque_col is None:\n            return {\"status\": \"error\", \"message\": \"Coluna de estoque n\u00e3o encontrada\"}\n\n        # Converter para num\u00e9rico\n        df[estoque_col] = pd.to_numeric(df[estoque_col], errors=\"coerce\")\n        df = df.dropna(subset=[estoque_col])\n\n        # Criar subplots\n        from plotly.subplots import make_subplots\n\n        fig = make_subplots(\n            rows=1,\n            cols=2,\n            subplot_titles=(\"Distribui\u00e7\u00e3o de Estoque\", \"Box Plot\"),\n            specs=[[{\"secondary_y\": False}, {\"secondary_y\": False}]],\n        )\n\n        # Histograma\n        fig.add_trace(\n            go.Histogram(\n                x=df[estoque_col],\n                nbinsx=30,\n                name=\"Estoque\",\n                marker_color=\"rgba(31, 119, 180, 0.7)\",\n                hovertemplate=\"Faixa: %{x}<br>Frequ\u00eancia: %{y}<extra></extra>\",\n            ),\n            row=1,\n            col=1,\n        )\n\n        # Box plot\n        fig.add_trace(\n            go.Box(\n                y=df[estoque_col],\n                name=\"Estoque\",\n                marker_color=\"rgba(31, 119, 180, 0.7)\",\n                boxmean=\"sd\",\n            ),\n            row=1,\n            col=2,\n        )\n\n        fig.update_xaxes(title_text=\"N\u00edvel de Estoque\", row=1, col=1)\n        fig.update_yaxes(title_text=\"Frequ\u00eancia\", row=1, col=1)\n        fig.update_yaxes(title_text=\"Quantidade\", row=1, col=2)\n\n        fig = _apply_chart_customization(\n            fig, title=\"An\u00e1lise de Distribui\u00e7\u00e3o de Estoque\"\n        )\n\n        # Calcular estat\u00edsticas\n        stats = {\n            \"media\": float(df[estoque_col].mean()),\n            \"mediana\": float(df[estoque_col].median()),\n            \"desvio_padrao\": float(df[estoque_col].std()),\n            \"minimo\": float(df[estoque_col].min()),\n            \"maximo\": float(df[estoque_col].max()),\n            \"q1\": float(df[estoque_col].quantile(0.25)),\n            \"q3\": float(df[estoque_col].quantile(0.75)),\n        }\n\n        return {\n            \"status\": \"success\",\n            \"chart_type\": \"distribution\",\n            \"chart_data\": _export_chart_to_json(fig),\n            \"summary\": stats,\n        }\n    except Exception as e:\n        logger.error(f\"Erro ao gerar an\u00e1lise de distribui\u00e7\u00e3o: {e}\", exc_info=True)\n        return {\"status\": \"error\", \"message\": f\"Erro ao gerar gr\u00e1fico: {str(e)}\"}", "mimetype": "text/plain", "start_char_idx": 22883, "end_char_idx": 25851, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8aaa3dd6-2ec4-4b7a-8ebb-73e6223af0a1": {"__data__": {"id_": "8aaa3dd6-2ec4-4b7a-8ebb-73e6223af0a1", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\chart_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "hash": "9ac656311e15dc4fad15c54781c106118803f6fcff851c0b9365e30f3ec6b45b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1606ec3f-0a65-480c-b34e-cafc98c60b30", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "hash": "942eb42521b964b81faf5d19756693ec1fe50caa0b11f8842e618fd158b334de", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "be7f8ffa-f847-4e3c-a5ab-4f416adcf866", "node_type": "1", "metadata": {}, "hash": "f264a36f28cf13e2350bd75b5b3c8109d29ed684dd6cebfee7b0d8f1aeb32135", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "@tool\ndef gerar_grafico_pizza_categorias() -> Dict[str, Any]:\n    \"\"\"\n    Gera gr\u00e1fico de pizza mostrando propor\u00e7\u00e3o de produtos por grupo (categoria).\n    \u00datil para visualizar distribui\u00e7\u00e3o percentual.\n\n    Returns:\n        Dicion\u00e1rio com gr\u00e1fico de pizza e propor\u00e7\u00f5es\n    \"\"\"\n    logger.info(\"Gerando gr\u00e1fico de pizza por grupo\")\n\n    try:\n        manager = get_data_manager()\n        df = manager.get_data()\n\n        if df is None or df.empty:\n            return {\"status\": \"error\", \"message\": \"N\u00e3o foi poss\u00edvel carregar dados\"}\n\n        # Detectar coluna de categoria dinamicamente\n        categoria_col = _get_grupo_column(df)\n\n        if categoria_col is None:\n            return {\"status\": \"error\", \"message\": \"Coluna de grupo (GRUPO/nomegrupo) n\u00e3o encontrada\"}\n\n        # Contar por categoria\n        categorias = df[categoria_col].value_counts()\n\n        # Criar gr\u00e1fico\n        fig = go.Figure(\n            data=[\n                go.Pie(\n                    labels=categorias.index,\n                    values=categorias.values,\n                    hovertemplate=\"<b>%{label}</b><br>Quantidade: %{value}<br>Percentual: %{percent}<extra></extra>\",\n                )\n            ]\n        )\n\n        fig = _apply_chart_customization(\n            fig, title=\"Distribui\u00e7\u00e3o de Produtos por Grupo\"\n        )\n\n        fig.update_layout(height=600)\n\n        return {\n            \"status\": \"success\",\n            \"chart_type\": \"pie\",\n            \"chart_data\": _export_chart_to_json(fig),\n            \"summary\": {\n                \"total_categorias\": len(categorias),\n                \"total_produtos\": int(categorias.sum()),\n                \"categorias\": categorias.to_dict(),\n            },\n        }\n    except Exception as e:\n        logger.error(f\"Erro ao gerar gr\u00e1fico de pizza: {e}\", exc_info=True)\n        return {\"status\": \"error\", \"message\": f\"Erro ao gerar gr\u00e1fico: {str(e)}\"}", "mimetype": "text/plain", "start_char_idx": 25854, "end_char_idx": 27737, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "be7f8ffa-f847-4e3c-a5ab-4f416adcf866": {"__data__": {"id_": "be7f8ffa-f847-4e3c-a5ab-4f416adcf866", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\chart_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "hash": "9ac656311e15dc4fad15c54781c106118803f6fcff851c0b9365e30f3ec6b45b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8aaa3dd6-2ec4-4b7a-8ebb-73e6223af0a1", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "hash": "b78c1af301175c5cefeee8a0f666adebb2f9ca6292b6857ab1b2fec189a38713", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "00d1c81a-c75d-427a-8443-115c24dd707d", "node_type": "1", "metadata": {}, "hash": "98bd340a507ad966e043f80f1c6503a3117da8e118a6a8b393e95ecb8a4ec4ff", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "@tool\ndef gerar_dashboard_analise_completa() -> Dict[str, Any]:\n    \"\"\"\n    Gera dashboard completo com m\u00faltiplas visualiza\u00e7\u00f5es em um \u00fanico lugar.\n    Combina 4 gr\u00e1ficos em um layout 2x2.\n\n    Returns:\n        Dicion\u00e1rio com dashboard e m\u00faltiplos gr\u00e1ficos\n    \"\"\"\n    logger.info(\"Gerando dashboard completo\")\n\n    try:\n        manager = get_data_manager()\n        df = manager.get_data()\n\n        if df is None or df.empty:\n            return {\"status\": \"error\", \"message\": \"N\u00e3o foi poss\u00edvel carregar dados\"}\n\n        from plotly.subplots import make_subplots\n\n        # Encontrar colunas dinamicamente (baseado no schema real do Parquet)\n        categoria_col = _get_grupo_column(df)\n        estoque_col = _get_column(df, 'estoque')\n        preco_col = _get_column(df, 'preco')\n        nome_col = _get_column(df, 'nome')\n\n        if categoria_col is None:\n            return {\"status\": \"error\", \"message\": \"Coluna de grupo (NOMEGRUPO) n\u00e3o encontrada\"}\n        if not all([estoque_col, preco_col, nome_col]):\n            return {\"status\": \"error\", \"message\": f\"Colunas necess\u00e1rias n\u00e3o encontradas. Faltando: estoque={estoque_col}, preco={preco_col}, nome={nome_col}\"}\n\n        # Preparar dados\n        df_conv = df.copy()\n        df_conv[estoque_col] = pd.to_numeric(df_conv[estoque_col], errors=\"coerce\")\n        df_conv[preco_col] = pd.to_numeric(df_conv[preco_col], errors=\"coerce\")\n\n        # Criar subplots 2x2\n        fig = make_subplots(\n            rows=2,\n            cols=2,\n            subplot_titles=(\n                \"Produtos por Grupo\",\n                \"Top 10 Produtos - Estoque\",\n                \"Distribui\u00e7\u00e3o de Estoque\",\n                \"Pre\u00e7o M\u00e9dio por Grupo\",\n            ),\n            specs=[\n                [{\"type\": \"pie\"}, {\"type\": \"bar\"}],\n                [{\"type\": \"histogram\"}, {\"type\": \"bar\"}],\n            ],\n        )\n\n        # Gr\u00e1fico 1: Pizza\n        cat_counts = df_conv[categoria_col].value_counts()\n        fig.add_trace(\n            go.Pie(\n                labels=cat_counts.index, values=cat_counts.values, name=\"Grupos\"\n            ),\n            row=1,\n            col=1,\n        )\n\n        # Gr\u00e1fico 2: Top 10 Estoque\n        top_estoque = df_conv.nlargest(10, estoque_col)\n        fig.add_trace(\n            go.Bar(\n                x=top_estoque[nome_col],\n                y=top_estoque[estoque_col],\n                name=\"Estoque\",\n                marker_color=\"lightblue\",\n            ),\n            row=1,\n            col=2,\n        )\n\n        # Gr\u00e1fico 3: Histograma\n        fig.add_trace(\n            go.Histogram(\n                x=df_conv[estoque_col],\n                nbinsx=20,\n                name=\"Distribui\u00e7\u00e3o\",\n                marker_color=\"lightgreen\",\n            ),\n            row=2,\n            col=1,\n        )\n\n        # Gr\u00e1fico 4: Pre\u00e7o m\u00e9dio\n        preco_med = (\n            df_conv.groupby(categoria_col)[preco_col]\n            .mean()\n            .sort_values(ascending=False)\n        )\n        fig.add_trace(\n            go.Bar(\n                x=preco_med.index,\n                y=preco_med.values,\n                name=\"Pre\u00e7o M\u00e9dio\",\n                marker_color=\"lightyellow\",\n            ),\n            row=2,\n            col=2,\n        )\n\n        # Atualizar layout\n        fig.update_layout(\n            title_text=\"Dashboard de An\u00e1lise - Vis\u00e3o Geral\",\n            height=900,\n            showlegend=False,\n            template=_get_theme_template(),\n        )\n\n        fig.update_xaxes(title_text=\"Produto\", row=1, col=2)\n        fig.update_xaxes(title_text=\"Estoque\", row=2, col=1)\n        fig.update_yaxes(title_text=\"Quantidade\", row=1, col=2)\n        fig.update_yaxes(title_text=\"Frequ\u00eancia\", row=2, col=1)\n        fig.update_xaxes(title_text=\"Grupo\", row=2, col=2)\n        fig.update_yaxes(title_text=\"Pre\u00e7o M\u00e9dio (R$)\", row=2, col=2)", "mimetype": "text/plain", "start_char_idx": 27740, "end_char_idx": 31558, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "00d1c81a-c75d-427a-8443-115c24dd707d": {"__data__": {"id_": "00d1c81a-c75d-427a-8443-115c24dd707d", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\chart_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "hash": "9ac656311e15dc4fad15c54781c106118803f6fcff851c0b9365e30f3ec6b45b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "be7f8ffa-f847-4e3c-a5ab-4f416adcf866", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "hash": "ab7aba3d2caee8fdd8580a5150d4c013bad40cd6366bcf5ecab2b7db4ca0fdf5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a57e879b-96c0-418e-bdb6-2e08f2839740", "node_type": "1", "metadata": {}, "hash": "95d2459810c9a8bebb367675afca7fd8df460d84ded65cc54ff99a2d3c253ed8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "return {\n            \"status\": \"success\",\n            \"chart_type\": \"dashboard\",\n            \"chart_data\": _export_chart_to_json(fig),\n            \"summary\": {\n                \"total_produtos\": len(df_conv),\n                \"total_categorias\": df_conv[categoria_col].nunique(),\n                \"estoque_total\": float(df_conv[estoque_col].sum()),\n                \"estoque_medio\": float(df_conv[estoque_col].mean()),\n            },\n        }\n    except Exception as e:\n        logger.error(f\"Erro ao gerar dashboard: {e}\", exc_info=True)\n        return {\"status\": \"error\", \"message\": f\"Erro ao gerar dashboard: {str(e)}\"}\n\n\n@tool\ndef gerar_grafico_vendas_por_produto(\n    codigo_produto: int,\n) -> Dict[str, Any]:\n    \"\"\"\n    Gera gr\u00e1fico de s\u00e9rie temporal de vendas de um produto espec\u00edfico.\n    Este \u00e9 um alias para gerar_grafico_vendas_mensais_produto.\n\n    Args:\n        codigo_produto: C\u00f3digo do produto (ITEM)\n\n    Returns:\n        Dicion\u00e1rio com gr\u00e1fico de s\u00e9rie temporal e an\u00e1lise\n    \"\"\"\n    logger.info(\n        f\"Gerando gr\u00e1fico de vendas do produto {codigo_produto} (alias)\"\n    )\n    return gerar_grafico_vendas_mensais_produto(codigo_produto=codigo_produto)\n\n\n@tool\ndef gerar_grafico_automatico(descricao: str) -> Dict[str, Any]:\n    \"\"\"\n    Gera qualquer tipo de gr\u00e1fico baseado na descri\u00e7\u00e3o do usu\u00e1rio.\n    O LLM interpreta a descri\u00e7\u00e3o e seleciona o gr\u00e1fico mais apropriado.", "mimetype": "text/plain", "start_char_idx": 31569, "end_char_idx": 32957, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a57e879b-96c0-418e-bdb6-2e08f2839740": {"__data__": {"id_": "a57e879b-96c0-418e-bdb6-2e08f2839740", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\chart_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "hash": "9ac656311e15dc4fad15c54781c106118803f6fcff851c0b9365e30f3ec6b45b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "00d1c81a-c75d-427a-8443-115c24dd707d", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "hash": "fc243a52b1132802dc77071d8d550b3f02c11b98491539b021e42ea149c0a57e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "015dfa15-f3dd-4a79-9ca4-b7fb0dc869ee", "node_type": "1", "metadata": {}, "hash": "534b0e95629bb7e89c1e3d39a5ebc2f5e67e5b9cf2e7370e714691aab746a114", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "O LLM interpreta a descri\u00e7\u00e3o e seleciona o gr\u00e1fico mais apropriado.\n\n    Args:\n        descricao: Descri\u00e7\u00e3o do gr\u00e1fico desejado em linguagem natural\n\n    Returns:\n        Gr\u00e1fico Plotly JSON correspondente ao tipo solicitado\n\n    Exemplos de uso:\n      - \"gr\u00e1fico de vendas por categoria\"\n      - \"mostrar estoque dispon\u00edvel por produto\"\n      - \"an\u00e1lise de distribui\u00e7\u00e3o de estoque\"\n      - \"comparar pre\u00e7os entre categorias\"\n      - \"vendas do produto 59294\"\n      - \"dashboard completo\"\n    \"\"\"\n    logger.info(f\"Gerando gr\u00e1fico autom\u00e1tico: {descricao}\")\n\n    descricao_lower = descricao.lower()\n\n    # Detectar tipo de gr\u00e1fico pela descri\u00e7\u00e3o\n    if any(\n        word in descricao_lower\n        for word in [\n            \"vendas\",\n            \"venda\",\n            \"sales\",\n            \"categoria\",\n            \"categor\",\n            \"top\",\n            \"ranking\",\n        ]\n    ):\n        logger.info(\"Detectado: Gr\u00e1fico de vendas por categoria\")\n        return gerar_grafico_vendas_por_categoria.invoke(\n            {\"limite\": 10, \"ordenar_por\": \"descendente\"}\n        )\n\n    elif any(\n        word in descricao_lower\n        for word in [\n            \"estoque\",\n            \"stock\",\n            \"dispon\u00edvel\",\n            \"quantidade\",\n            \"quantidade\",\n            \"inv\",\n            \"por produto\",\n        ]\n    ):\n        logger.info(\"Detectado: Gr\u00e1fico de estoque por produto\")\n        return gerar_grafico_estoque_por_produto.invoke(\n            {\"limite\": 15, \"minimo_estoque\": 0}\n        )\n\n    elif any(\n        word in descricao_lower\n        for word in [\n            \"pre\u00e7o\",\n            \"preco\",\n            \"price\",\n            \"pre\u00e7os\",\n            \"compara\u00e7\u00e3o\",\n            \"comparar\",\n            \"pricing\",\n        ]\n    ):\n        logger.info(\"Detectado: Gr\u00e1fico de compara\u00e7\u00e3o de pre\u00e7os\")\n        return gerar_comparacao_precos_categorias.invoke({})\n\n    elif any(\n        word in descricao_lower\n        for word in [\n            \"distribui\u00e7\u00e3o\",\n            \"distribuicao\",\n            \"distribui\u00e7\u00e3o\",\n            \"an\u00e1lise\",\n            \"analise\",\n            \"histograma\",\n            \"box plot\",\n        ]\n    ):\n        logger.info(\"Detectado: An\u00e1lise de distribui\u00e7\u00e3o\")\n        return gerar_analise_distribuicao_estoque.invoke({})\n\n    elif any(\n        word in descricao_lower\n        for word in [\"pizza\", \"pie\", \"propor\", \"percent\", \"propor\u00e7\u00e3o\"]\n    ):\n        logger.info(\"Detectado: Gr\u00e1fico de pizza\")\n        return gerar_grafico_pizza_categorias.invoke({})\n\n    elif any(\n        word in descricao_lower\n        for word in [\n            \"dashboard\",\n            \"tudo\",\n            \"vis\u00e3o\",\n            \"visao\",\n            \"completo\",\n            \"overview\",\n            \"resumo\",\n        ]\n    ):\n        logger.info(\"Detectado: Dashboard completo\")\n        return gerar_dashboard_analise_completa.invoke({})\n\n    elif any(\n        word in descricao_lower\n        for word in [\n            \"produto\",\n            \"temporal\",\n            \"s\u00e9rie\",\n            \"serie\",\n            \"evolu\u00e7\u00e3o\",\n            \"evolucao\",\n            \"sku\",\n            \"mensal\",\n            \"m\u00eas\",\n            \"mes\",\n            \"vendas produto\",\n        ]\n    ):\n        logger.info(\"Detectado: Gr\u00e1fico de vendas por produto\")\n        # Extrair c\u00f3digo do produto se presente\n        import re\n\n        match = re.search(r\"\\d+\", descricao)\n        codigo = int(match.group()) if match else 59294\n\n        # Tentar usar a vers\u00e3o com dados mensais pivotados (estrutura real)\n        resultado = gerar_grafico_vendas_mensais_produto.invoke(\n            {\"codigo_produto\": codigo, \"unidade_filtro\": None}\n        )\n\n        # Se falhar, retornar gr\u00e1fico de s\u00e9rie temporal alternativo\n        if resultado.get(\"status\") == \"error\":\n            logger.info(\"Gr\u00e1fico mensal falhou, tentando s\u00e9rie temporal\")\n            return gerar_grafico_vendas_por_produto.invoke(\n                {\"codigo_produto\": codigo, \"unidade\": \"SCR\"}\n            )\n\n        return resultado\n\n    else:\n        # Por padr\u00e3o, gera dashboard completo\n        logger.info(\"Tipo n\u00e3o reconhecido, gerando dashboard padr\u00e3o\")\n        return gerar_dashboard_analise_completa.invoke({})", "mimetype": "text/plain", "start_char_idx": 32890, "end_char_idx": 37056, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "015dfa15-f3dd-4a79-9ca4-b7fb0dc869ee": {"__data__": {"id_": "015dfa15-f3dd-4a79-9ca4-b7fb0dc869ee", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\chart_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "hash": "9ac656311e15dc4fad15c54781c106118803f6fcff851c0b9365e30f3ec6b45b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a57e879b-96c0-418e-bdb6-2e08f2839740", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "hash": "fe1135c120f7d112950ee07c8d7598a6f14b28baff20898cae34aba16f62ad6d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "48b9bfc9-92dd-4f6d-8978-059a58a077c7", "node_type": "1", "metadata": {}, "hash": "ce729f57463bdc740fe7638a92e84affa5d0d9dcf725041eab57764154def3ed", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "@tool\ndef gerar_grafico_vendas_mensais_produto(\n    codigo_produto: int,\n) -> Dict[str, Any]:\n    \"\"\"\n    Gera gr\u00e1fico de vendas mensais para um produto espec\u00edfico.\n    Trabalha com a estrutura de dados da Filial Madureira.\n\n    Args:\n        codigo_produto: C\u00f3digo do produto (ITEM)\n\n    Returns:\n        Dicion\u00e1rio com gr\u00e1fico de vendas mensais\n    \"\"\"\n    logger.info(f\"Gerando gr\u00e1fico de vendas mensais do produto {codigo_produto}\")\n\n    try:\n        manager = get_data_manager()\n        df_raw = manager.get_data()\n\n        if df_raw is None or df_raw.empty:\n            return {\"status\": \"error\", \"message\": \"N\u00e3o foi poss\u00edvel carregar dados\"}\n\n        # A coluna de c\u00f3digo do produto \u00e9 'PRODUTO' (conforme schema do admmat.parquet)\n        codigo_col = 'PRODUTO'\n        \n        # Converter a coluna 'PRODUTO' para num\u00e9rico para garantir a compara\u00e7\u00e3o\n        df_raw[codigo_col] = pd.to_numeric(df_raw[codigo_col], errors='coerce')\n        \n        # Filtrar por c\u00f3digo de produto\n        df_produto = df_raw[df_raw[codigo_col] == codigo_produto].copy()\n\n        if df_produto.empty:\n            return {\n                \"status\": \"error\",\n                \"message\": (\n                    f\"Produto com c\u00f3digo {codigo_produto} n\u00e3o encontrado. \"\n                    \"Verifique o c\u00f3digo informado.\"\n                ),\n            }\n\n        # Extrair colunas de meses\n        mes_cols = {\n            'JAN': 'VENDA QTD JAN', 'FEV': 'VENDA QTD FEV', 'MAR': 'VENDA QTD MAR',\n            'ABR': 'VENDA QTD ABR', 'MAI': 'VENDA QTD MAI', 'JUN': 'VENDA QTD JUN',\n            'JUL': 'VENDA QTD JUL', 'AGO': 'VENDA QTD AGO', 'SET': 'VENDA QTD SET',\n            'OUT': 'VENDA QTD OUT', 'NOV': 'VENDA QTD NOV', 'DEZ': 'VENDA QTD DEZ'\n        }\n        \n        vendas_mensais = []\n        mes_labels = []\n        \n        for mes_abrev, col_name in mes_cols.items():\n            if col_name in df_produto.columns:\n                valor_bruto = df_produto[col_name].iloc[0]\n                valor_numerico = pd.to_numeric(valor_bruto, errors='coerce')\n                valor = 0 if pd.isna(valor_numerico) else valor_numerico\n                vendas_mensais.append(valor)\n                mes_labels.append(mes_abrev)\n\n        if not vendas_mensais:\n            return {\n                \"status\": \"error\",\n                \"message\": \"Colunas de vendas mensais n\u00e3o encontradas na estrutura de dados.", "mimetype": "text/plain", "start_char_idx": 37059, "end_char_idx": 39446, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "48b9bfc9-92dd-4f6d-8978-059a58a077c7": {"__data__": {"id_": "48b9bfc9-92dd-4f6d-8978-059a58a077c7", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\chart_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "hash": "9ac656311e15dc4fad15c54781c106118803f6fcff851c0b9365e30f3ec6b45b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "015dfa15-f3dd-4a79-9ca4-b7fb0dc869ee", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "hash": "3b0bcabbb5526bd3b54949fea0c28e4b0bb077cccca81a86792d89f4fbeca09e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "cfe7de0e-8e6c-4967-8d24-e58678a36644", "node_type": "1", "metadata": {}, "hash": "0fe7b86ed3ac68110c638d61d5dc2ac7e70c0689e37c45bf506cb4b5ea8fe921", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\",\n            }\n\n        # Criar gr\u00e1fico\n        fig = go.Figure()\n\n        fig.add_trace(\n            go.Scatter(\n                x=mes_labels,\n                y=vendas_mensais,\n                mode=\"lines+markers+text\", # Adicionar 'text' ao modo\n                name=\"Vendas\",\n                line=dict(color=\"#2563EB\", width=3),\n                marker=dict(\n                    size=10,\n                    color=\"#2563EB\",\n                    line=dict(width=2, color=\"white\"),\n                    symbol=\"circle\",\n                ),\n                hovertemplate=(\n                    \"<b>M\u00eas: %{x}</b><br>\" \"Quantidade: %{y:,.0f} unidades<extra></extra>\"\n                ),\n                fill=\"tozeroy\",\n                fillcolor=\"rgba(37, 99, 235, 0.2)\",\n                text=vendas_mensais,\n                textposition=\"top center\"\n            )\n        )\n\n        # Adicionar linha de m\u00e9dia\n        if vendas_mensais:\n            media_vendas = sum(vendas_mensais) / len(vendas_mensais)\n            fig.add_hline(\n                y=media_vendas,\n                line_dash=\"dash\",\n                line_color=\"red\",\n                annotation_text=\"M\u00e9dia\",\n                annotation_position=\"right\",\n            )\n\n        fig = _apply_chart_customization(\n            fig, title=(f\"Vendas Mensais - Produto {codigo_produto}\")\n        )\n\n        fig.update_xaxes(title_text=\"M\u00eas\")\n        fig.update_yaxes(title_text=\"Quantidade (unidades)\")\n        fig.update_layout(height=600, hovermode=\"x unified\")\n\n        # Calcular estat\u00edsticas\n        total_vendas = sum(vendas_mensais)\n        venda_media = total_vendas / len(vendas_mensais) if vendas_mensais else 0\n        venda_max = max(vendas_mensais) if vendas_mensais else 0\n        venda_min = min(vendas_mensais) if vendas_mensais else 0\n        venda_max_mes = mes_labels[vendas_mensais.index(venda_max)] if vendas_mensais and venda_max > 0 else \"N/A\"\n        venda_min_mes = mes_labels[vendas_mensais.index(venda_min)] if vendas_mensais else \"N/A\"\n\n        # Extrair informa\u00e7\u00f5es adicionais do produto\n        produto_info = {}\n        for col in [\"DESCRI\u00c7\u00c3O\", \"FABRICANTE\", \"GRUPO\"]:\n            if col in df_produto.columns:\n                valor = df_produto[col].iloc[0]\n                produto_info[col] = str(valor)\n\n        return {\n            \"status\": \"success\",\n            \"chart_type\": \"line_temporal_mensal\",\n            \"chart_data\": _export_chart_to_json(fig),\n            \"summary\": {\n                \"codigo_produto\": codigo_produto,\n                \"total_vendas\": int(total_vendas),\n                \"venda_media\": float(venda_media),\n                \"venda_maxima\": int(venda_max),\n                \"venda_minima\": int(venda_min),\n                \"mes_maior_venda\": venda_max_mes,\n                \"mes_menor_venda\": venda_min_mes,\n                \"variacao\": float(\n                    (venda_max - venda_min) / venda_media * 100\n                    if venda_media > 0\n                    else 0\n                ),\n                \"meses_analisados\": len(mes_labels),\n                \"produto_info\": produto_info,\n                \"dados_mensais\": {\n                    mes_labels[i]: int(vendas_mensais[i])\n                    for i in range(len(mes_labels))\n                },\n            },\n        }\n\n    except Exception as e:\n        logger.error(f\"Erro ao gerar gr\u00e1fico de vendas mensais: {e}\", exc_info=True)\n        return {\"status\": \"error\", \"message\": f\"Erro ao gerar gr\u00e1fico: {str(e)}\"}\n\n\n@tool\ndef gerar_grafico_vendas_por_grupo(\n    nome_grupo: str, agregacao: str = \"soma\"\n) -> Dict[str, Any]:\n    \"\"\"\n    Gera gr\u00e1fico de vendas mensais para todos os produtos de um grupo espec\u00edfico.\n    \u00datil para an\u00e1lise de desempenho de categorias de produtos ao longo do ano.\n\n    Args:\n        nome_grupo: Nome do grupo/categoria (ex: \"ESMALTES\", \"CREMES\", etc.)", "mimetype": "text/plain", "start_char_idx": 39446, "end_char_idx": 43297, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "cfe7de0e-8e6c-4967-8d24-e58678a36644": {"__data__": {"id_": "cfe7de0e-8e6c-4967-8d24-e58678a36644", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\chart_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "hash": "9ac656311e15dc4fad15c54781c106118803f6fcff851c0b9365e30f3ec6b45b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "48b9bfc9-92dd-4f6d-8978-059a58a077c7", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "hash": "66368fcd85a3371d3b547a5f6efc9d89fea52879b3e4762b2648e7d41f1e9407", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9604cba0-85d3-42f0-89cf-b8dfd4d68d71", "node_type": "1", "metadata": {}, "hash": "154d278665b1b1adbf2ed5f919e4aa8aa111227922b96a33a9907a312e1348a5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "agregacao: Tipo de agrega\u00e7\u00e3o - \"soma\" (padr\u00e3o) ou \"media\"\n\n    Returns:\n        Dicion\u00e1rio com gr\u00e1fico de vendas mensais do grupo\n    \"\"\"\n    logger.info(f\"Gerando gr\u00e1fico de vendas do grupo: {nome_grupo}\")\n\n    try:\n        manager = get_data_manager()\n        df = manager.get_data()\n\n        if df is None or df.empty:\n            return {\"status\": \"error\", \"message\": \"N\u00e3o foi poss\u00edvel carregar dados\"}\n\n        # Detectar coluna de grupo dinamicamente\n        grupo_col = _get_grupo_column(df)\n        if grupo_col is None:\n            return {\n                \"status\": \"error\",\n                \"message\": \"Coluna de grupo (NOMEGRUPO) n\u00e3o encontrada no dataset\"\n            }\n\n        # Filtrar produtos do grupo (case-insensitive)\n        df_grupo = df[df[grupo_col].str.upper().str.contains(nome_grupo.upper(), na=False)].copy()\n\n        if df_grupo.empty:\n            grupos_disponiveis = df[grupo_col].unique()[:10]\n            return {\n                \"status\": \"error\",\n                \"message\": (\n                    f\"Grupo '{nome_grupo}' n\u00e3o encontrado. \"\n                    f\"Grupos dispon\u00edveis: {', '.join(map(str, grupos_disponiveis))}\"\n                )\n            }\n\n        # Colunas de vendas mensais\n        mes_cols = {\n            'JAN': 'VENDA QTD JAN', 'FEV': 'VENDA QTD FEV', 'MAR': 'VENDA QTD MAR',\n            'ABR': 'VENDA QTD ABR', 'MAI': 'VENDA QTD MAI', 'JUN': 'VENDA QTD JUN',\n            'JUL': 'VENDA QTD JUL', 'AGO': 'VENDA QTD AGO', 'SET': 'VENDA QTD SET',\n            'OUT': 'VENDA QTD OUT', 'NOV': 'VENDA QTD NOV', 'DEZ': 'VENDA QTD DEZ'\n        }\n\n        # Converter para num\u00e9rico\n        for col in mes_cols.values():\n            if col in df_grupo.columns:\n                df_grupo[col] = pd.to_numeric(df_grupo[col], errors='coerce').fillna(0)\n\n        # Agregar vendas mensais\n        vendas_mensais = []\n        mes_labels = []\n\n        for mes_abrev, col_name in mes_cols.items():\n            if col_name in df_grupo.columns:\n                if agregacao == \"media\":\n                    valor = df_grupo[col_name].mean()\n                else:  # soma (padr\u00e3o)\n                    valor = df_grupo[col_name].sum()\n\n                vendas_mensais.append(float(valor))\n                mes_labels.append(mes_abrev)\n\n        if not vendas_mensais:\n            return {\n                \"status\": \"error\",\n                \"message\": \"Colunas de vendas mensais n\u00e3o encontradas\"\n            }\n\n        # Criar gr\u00e1fico\n        fig = go.Figure()\n\n        fig.add_trace(\n            go.Scatter(\n                x=mes_labels,\n                y=vendas_mensais,\n                mode=\"lines+markers+text\",\n                name=\"Vendas\",\n                line=dict(color=\"#10B981\", width=3),\n                marker=dict(\n                    size=12,\n                    color=\"#10B981\",\n                    line=dict(width=2, color=\"white\"),\n                    symbol=\"circle\",\n                ),\n                hovertemplate=(\n                    \"<b>M\u00eas: %{x}</b><br>\"\n                    \"Quantidade: %{y:,.0f} unidades<extra></extra>\"\n                ),\n                fill=\"tozeroy\",\n                fillcolor=\"rgba(16, 185, 129, 0.2)\",\n                text=[f\"{int(v):,}\" for v in vendas_mensais],\n                textposition=\"top center\",\n                textfont=dict(size=10)\n            )\n        )\n\n        # Adicionar linha de m\u00e9dia\n        if vendas_mensais:\n            media_vendas = sum(vendas_mensais) / len(vendas_mensais)\n            fig.add_hline(\n                y=media_vendas,\n                line_dash=\"dash\",\n                line_color=\"red\",\n                annotation_text=f\"M\u00e9dia: {int(media_vendas):,}\",\n                annotation_position=\"right\",\n            )\n\n        tipo_agregacao = \"Total\" if agregacao == \"soma\" else \"M\u00e9dia\"\n        titulo = f\"Vendas Mensais - Grupo: {nome_grupo.", "mimetype": "text/plain", "start_char_idx": 43306, "end_char_idx": 47161, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9604cba0-85d3-42f0-89cf-b8dfd4d68d71": {"__data__": {"id_": "9604cba0-85d3-42f0-89cf-b8dfd4d68d71", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\chart_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "hash": "9ac656311e15dc4fad15c54781c106118803f6fcff851c0b9365e30f3ec6b45b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "cfe7de0e-8e6c-4967-8d24-e58678a36644", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "hash": "7c1effa12426093f2b459883fccf792b323518ebff856326d23ea59d3c9dcf86", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0d5fc255-5de0-4cf1-abf0-7c5099d90fc0", "node_type": "1", "metadata": {}, "hash": "2fee541e497f4b963f4a74c3da8428e67bcf72e1bd967405737a262548367793", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "upper()} ({tipo_agregacao})\"\n\n        fig = _apply_chart_customization(fig, title=titulo)\n\n        fig.update_xaxes(title_text=\"M\u00eas\")\n        fig.update_yaxes(title_text=\"Quantidade (unidades)\")\n        fig.update_layout(height=600, hovermode=\"x unified\")\n\n        # Calcular estat\u00edsticas\n        total_vendas = sum(vendas_mensais)\n        venda_media = total_vendas / len(vendas_mensais) if vendas_mensais else 0\n        venda_max = max(vendas_mensais) if vendas_mensais else 0\n        venda_min = min(vendas_mensais) if vendas_mensais else 0\n        venda_max_mes = mes_labels[vendas_mensais.index(venda_max)] if vendas_mensais and venda_max > 0 else \"N/A\"\n        venda_min_mes = mes_labels[vendas_mensais.index(venda_min)] if vendas_mensais else \"N/A\"\n\n        return {\n            \"status\": \"success\",\n            \"chart_type\": \"line_temporal_grupo\",\n            \"chart_data\": _export_chart_to_json(fig),\n            \"summary\": {\n                \"grupo\": nome_grupo.upper(),\n                \"total_produtos\": len(df_grupo),\n                \"agregacao\": agregacao,\n                \"total_vendas\": int(total_vendas),\n                \"venda_media_mensal\": float(venda_media),\n                \"venda_maxima\": int(venda_max),\n                \"venda_minima\": int(venda_min),\n                \"mes_maior_venda\": venda_max_mes,\n                \"mes_menor_venda\": venda_min_mes,\n                \"meses_analisados\": len(mes_labels),\n                \"dados_mensais\": {\n                    mes_labels[i]: int(vendas_mensais[i])\n                    for i in range(len(mes_labels))\n                },\n            },\n        }\n\n    except Exception as e:\n        logger.error(f\"Erro ao gerar gr\u00e1fico de vendas por grupo: {e}\", exc_info=True)\n        return {\"status\": \"error\", \"message\": f\"Erro ao gerar gr\u00e1fico: {str(e)}\"}", "mimetype": "text/plain", "start_char_idx": 47161, "end_char_idx": 48973, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0d5fc255-5de0-4cf1-abf0-7c5099d90fc0": {"__data__": {"id_": "0d5fc255-5de0-4cf1-abf0-7c5099d90fc0", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\chart_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "hash": "9ac656311e15dc4fad15c54781c106118803f6fcff851c0b9365e30f3ec6b45b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9604cba0-85d3-42f0-89cf-b8dfd4d68d71", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "hash": "1c32529b20bcaf80ae9c4d547798f5ee28dbb319b23f0d883b738498e0976c24", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "57cd3ee1-f53a-4a22-af63-10157d71029e", "node_type": "1", "metadata": {}, "hash": "9853debcd203fd8a71e40c4b939a265b3b65bcaffd13eaf9305f27167532e7e8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"message\": f\"Erro ao gerar gr\u00e1fico: {str(e)}\"}\n\n\n@tool\ndef gerar_ranking_produtos_mais_vendidos(top_n: int = 10) -> Dict[str, Any]:\n    \"\"\"\n    Gera um gr\u00e1fico de barras horizontais com o ranking dos produtos mais vendidos no ano.\n    \u00datil para identificar os produtos mais populares.\n\n    Args:\n        top_n: O n\u00famero de produtos a serem inclu\u00eddos no ranking (padr\u00e3o: 10).\n\n    Returns:\n        Dicion\u00e1rio com o gr\u00e1fico de ranking e dados.\n    \"\"\"\n    logger.info(f\"Gerando ranking dos {top_n} produtos mais vendidos.\")\n\n    try:\n        manager = get_data_manager()\n        df = manager.get_data()\n\n        if df is None or df.empty:\n            return {\"status\": \"error\", \"message\": \"N\u00e3o foi poss\u00edvel carregar dados.\"}\n\n        mes_cols = [col for col in df.columns if 'VENDA QTD' in col]\n        if not mes_cols:\n            return {\"status\": \"error\", \"message\": \"Nenhuma coluna de vendas mensais encontrada.\"}\n\n        # Calcular vendas totais\n        df['VENDAS_TOTAIS'] = df[mes_cols].sum(axis=1)\n\n        # Preparar dados para o gr\u00e1fico\n        ranking_df = df.sort_values('VENDAS_TOTAIS', ascending=False).head(top_n)\n        ranking_df = ranking_df.sort_values('VENDAS_TOTAIS', ascending=True) # Para exibi\u00e7\u00e3o correta no gr\u00e1fico de barras horizontal\n\n        # Criar gr\u00e1fico\n        fig = go.Figure(go.Bar(\n            x=ranking_df['VENDAS_TOTAIS'],\n            y=ranking_df['DESCRI\u00c7\u00c3O'],\n            orientation='h',\n            marker=dict(color='#2563EB'),\n            text=ranking_df['VENDAS_TOTAIS'],\n            textposition='auto',\n            texttemplate='%{text:.2s}'\n        ))\n\n        fig = _apply_chart_customization(\n            fig, title=f\"Top {top_n} Produtos Mais Vendidos\"\n        )\n        fig.update_layout(\n            yaxis=dict(tickmode='linear'),\n            xaxis_title=\"Total de Vendas (Unidades)\",\n            yaxis_title=\"Produto\"\n        )\n\n        return {\n            \"status\": \"success\",\n            \"chart_type\": \"bar_horizontal\",\n            \"chart_data\": _export_chart_to_json(fig),\n            \"summary\": {\n                \"top_n\": top_n,\n                \"produtos\": ranking_df[['DESCRI\u00c7\u00c3O', 'VENDAS_TOTAIS']].to_dict('records')\n            }\n        }\n\n    except Exception as e:\n        logger.error(f\"Erro ao gerar ranking de produtos: {e}\", exc_info=True)\n        return {\"status\": \"error\", \"message\": f\"Erro ao gerar ranking: {str(e)}\"}\n\n\n@tool\ndef listar_graficos_disponiveis() -> Dict[str, Any]:\n    \"\"\"\n    Lista todos os tipos de gr\u00e1ficos e dashboards dispon\u00edveis no sistema.\n    Use esta ferramenta quando o usu\u00e1rio perguntar \"quais gr\u00e1ficos voc\u00ea pode gerar?\",\n    \"que tipos de visualiza\u00e7\u00f5es existem?\", ou similares.", "mimetype": "text/plain", "start_char_idx": 48927, "end_char_idx": 51603, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "57cd3ee1-f53a-4a22-af63-10157d71029e": {"__data__": {"id_": "57cd3ee1-f53a-4a22-af63-10157d71029e", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\chart_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "hash": "9ac656311e15dc4fad15c54781c106118803f6fcff851c0b9365e30f3ec6b45b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0d5fc255-5de0-4cf1-abf0-7c5099d90fc0", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "hash": "2393fe8ad294dbaf016145a9a5a211a93317eb12c644047c3b0516cf0f34a5f5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2b1628d6-ac21-499b-8876-9c8ebbf63327", "node_type": "1", "metadata": {}, "hash": "1385c0e6f380b0230bfd91a1cde7c0a38a65b96e9dacf3826bec943a204b3bb6", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\",\n    \"que tipos de visualiza\u00e7\u00f5es existem?\", ou similares.\n\n    Returns:\n        Dicion\u00e1rio com lista completa de gr\u00e1ficos dispon\u00edveis e suas descri\u00e7\u00f5es\n    \"\"\"\n    logger.info(\"Listando gr\u00e1ficos dispon\u00edveis\")\n\n    graficos_info = {\n        \"total_tipos\": 12,\n        \"categorias\": {\n            \"An\u00e1lise de Vendas\": [\n                {\n                    \"nome\": \"gerar_grafico_vendas_por_grupo\",\n                    \"descricao\": \"Vendas mensais de um grupo/categoria espec\u00edfica (ex: esmaltes, cremes)\",\n                    \"exemplo\": \"gerar_grafico_vendas_por_grupo(nome_grupo='esmaltes')\"\n                },\n                {\n                    \"nome\": \"gerar_grafico_vendas_mensais_produto\",\n                    \"descricao\": \"Evolu\u00e7\u00e3o de vendas mensais de um produto espec\u00edfico\",\n                    \"exemplo\": \"gerar_grafico_vendas_mensais_produto(codigo_produto=9)\"\n                },\n                {\n                    \"nome\": \"gerar_ranking_produtos_mais_vendidos\",\n                    \"descricao\": \"Ranking dos produtos mais vendidos do ano\",\n                    \"exemplo\": \"gerar_ranking_produtos_mais_vendidos(top_n=10)\"\n                }\n            ],\n            \"An\u00e1lise de Categorias\": [\n                {\n                    \"nome\": \"gerar_grafico_vendas_por_categoria\",\n                    \"descricao\": \"Gr\u00e1fico donut com total de produtos por grupo\",\n                    \"exemplo\": \"gerar_grafico_vendas_por_categoria(limite=10)\"\n                },\n                {\n                    \"nome\": \"gerar_grafico_pizza_categorias\",\n                    \"descricao\": \"Pizza com propor\u00e7\u00e3o percentual de produtos por grupo\",\n                    \"exemplo\": \"gerar_grafico_pizza_categorias()\"\n                },\n                {\n                    \"nome\": \"gerar_comparacao_precos_categorias\",\n                    \"descricao\": \"Compara\u00e7\u00e3o de pre\u00e7os m\u00e9dios entre grupos\",\n                    \"exemplo\": \"gerar_comparacao_precos_categorias()\"\n                }\n            ],\n            \"An\u00e1lise de Estoque\": [\n                {\n                    \"nome\": \"gerar_grafico_estoque_por_produto\",\n                    \"descricao\": \"Barras verticais com estoque dispon\u00edvel por produto\",\n                    \"exemplo\": \"gerar_grafico_estoque_por_produto(limite=15)\"\n                },\n                {\n                    \"nome\": \"gerar_analise_distribuicao_estoque\",\n                    \"descricao\": \"Histograma + Box Plot de distribui\u00e7\u00e3o de estoque\",\n                    \"exemplo\": \"gerar_analise_distribuicao_estoque()\"\n                }\n            ],\n            \"Dashboards Completos\": [\n                {\n                    \"nome\": \"gerar_dashboard_analise_completa\",\n                    \"descricao\": \"Dashboard 2x2 com vis\u00e3o geral do neg\u00f3cio (produtos, estoque, pre\u00e7os)\",\n                    \"exemplo\": \"gerar_dashboard_analise_completa()\"\n                },\n                {\n                    \"nome\": \"gerar_dashboard_dinamico\",\n                    \"descricao\": \"Dashboard customizado com at\u00e9 4 gr\u00e1ficos escolhidos\",\n                    \"exemplo\": \"gerar_dashboard_dinamico(graficos=['gerar_grafico_pizza_categorias', 'gerar_ranking_produtos_mais_vendidos'])\"\n                },\n                {\n                    \"nome\": \"gerar_dashboard_executivo\",\n                    \"descricao\": \"Dashboard executivo otimizado para tomada de decis\u00e3o\",\n                    \"exemplo\": \"gerar_dashboard_executivo()\"\n                }\n            ],\n            \"Gr\u00e1ficos Inteligentes\": [\n                {\n                    \"nome\": \"gerar_grafico_automatico\",\n                    \"descricao\": \"Detec\u00e7\u00e3o autom\u00e1tica do tipo de gr\u00e1fico baseado na descri\u00e7\u00e3o\",\n                    \"exemplo\": \"gerar_grafico_automatico(descricao='vendas por categoria')\"\n                }\n            ]\n        },\n        \"dicas\": [\n            \"Para an\u00e1lise de vendas de categorias, use gerar_grafico_vendas_por_grupo\",\n            \"Para vis\u00e3o geral r\u00e1pida, use gerar_dashboard_analise_completa\",\n            \"Para dashboards personalizados, use gerar_dashboard_dinamico\",\n            \"O gerar_grafico_automatico tenta detectar automaticamente o que voc\u00ea precisa\"\n        ]\n    }\n\n    return {\n        \"status\": \"success\",\n        \"graficos_disponiveis\": graficos_info,\n        \"message\": f\"Total de {graficos_info['total_tipos']} tipos de gr\u00e1ficos dispon\u00edveis\"\n    }", "mimetype": "text/plain", "start_char_idx": 51544, "end_char_idx": 55904, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2b1628d6-ac21-499b-8876-9c8ebbf63327": {"__data__": {"id_": "2b1628d6-ac21-499b-8876-9c8ebbf63327", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\chart_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "hash": "9ac656311e15dc4fad15c54781c106118803f6fcff851c0b9365e30f3ec6b45b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "57cd3ee1-f53a-4a22-af63-10157d71029e", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "hash": "d3fee61d8e629bee867639e31d674edf0203f7a48a3acc81e93a6f2aef8e8a92", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "10204078-1621-46d0-a928-c43be2ca7d54", "node_type": "1", "metadata": {}, "hash": "5b5bd28e5884b32018f31d4b6d223cdc2654318d13bb53a5b12bfd5a05cffbdd", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "@tool\ndef gerar_dashboard_executivo() -> Dict[str, Any]:\n    \"\"\"\n    Gera dashboard executivo completo com os principais indicadores de neg\u00f3cio.\n    Layout 2x3 otimizado para an\u00e1lise gerencial e tomada de decis\u00e3o.\n\n    Inclui:\n    - Vendas por categoria (Top 10)\n    - Ranking produtos mais vendidos\n    - An\u00e1lise de estoque\n    - Compara\u00e7\u00e3o de pre\u00e7os\n    - Distribui\u00e7\u00e3o de produtos\n    - M\u00e9tricas principais\n\n    Returns:\n        Dicion\u00e1rio com dashboard executivo completo\n    \"\"\"\n    logger.info(\"Gerando dashboard executivo\")\n\n    try:\n        manager = get_data_manager()\n        df = manager.get_data()\n\n        if df is None or df.empty:\n            return {\"status\": \"error\", \"message\": \"N\u00e3o foi poss\u00edvel carregar dados\"}\n\n        from plotly.subplots import make_subplots\n\n        # Preparar dados\n        df_conv = df.copy()\n\n        # Converter colunas para num\u00e9rico\n        for col in ['QTD', 'VENDA UNIT R$', 'VENDA R$', 'LUCRO R$']:\n            if col in df_conv.columns:\n                df_conv[col] = pd.to_numeric(df_conv[col], errors='coerce').fillna(0)\n\n        # Calcular vendas totais se n\u00e3o existir\n        mes_cols = [col for col in df_conv.columns if 'VENDA QTD' in col]\n        if mes_cols:\n            df_conv['VENDAS_TOTAIS'] = df_conv[mes_cols].sum(axis=1)\n\n        # Criar subplots 2x3\n        fig = make_subplots(\n            rows=2, cols=3,\n            subplot_titles=(\n                \"Top 10 Grupos (Quantidade)\",\n                \"Top 10 Produtos Mais Vendidos\",\n                \"An\u00e1lise de Lucro por Grupo\",\n                \"Distribui\u00e7\u00e3o de Estoque\",\n                \"Pre\u00e7o M\u00e9dio por Grupo\",\n                \"Status de Vendas Mensais\"\n            ),\n            specs=[\n                [{\"type\": \"bar\"}, {\"type\": \"bar\"}, {\"type\": \"bar\"}],\n                [{\"type\": \"histogram\"}, {\"type\": \"bar\"}, {\"type\": \"scatter\"}]\n            ],\n            vertical_spacing=0.12,\n            horizontal_spacing=0.1\n        )\n\n        # 1. Top 10 Grupos\n        grupo_col = _get_grupo_column(df_conv)\n        if grupo_col:\n            grupos = df_conv[grupo_col].value_counts().head(10)\n            fig.add_trace(\n                go.Bar(\n                    x=grupos.index,\n                    y=grupos.values,\n                    name=\"Produtos\",\n                    marker_color=\"#2563EB\"\n                ),\n                row=1, col=1\n            )\n\n        # 2. Top 10 Produtos Mais Vendidos\n        if 'VENDAS_TOTAIS' in df_conv.columns and 'DESCRI\u00c7\u00c3O' in df_conv.columns:\n            top_vendas = df_conv.nlargest(10, 'VENDAS_TOTAIS')\n            fig.add_trace(\n                go.Bar(\n                    x=top_vendas['VENDAS_TOTAIS'],\n                    y=top_vendas['DESCRI\u00c7\u00c3O'],\n                    orientation='h',\n                    name=\"Vendas\",\n                    marker_color=\"#10B981\"\n                ),\n                row=1, col=2\n            )\n\n        # 3. Lucro por Grupo\n        if grupo_col and 'LUCRO R$' in df_conv.columns:\n            lucro_grupo = df_conv.groupby(grupo_col)['LUCRO R$'].sum().sort_values(ascending=False).head(10)\n            fig.add_trace(\n                go.Bar(\n                    x=lucro_grupo.index,\n                    y=lucro_grupo.values,\n                    name=\"Lucro\",\n                    marker_color=\"#F59E0B\"\n                ),\n                row=1, col=3\n            )\n\n        # 4. Distribui\u00e7\u00e3o de Estoque\n        estoque_col = _get_column(df_conv, 'estoque')\n        if estoque_col:\n            fig.add_trace(\n                go.Histogram(\n                    x=df_conv[estoque_col],\n                    nbinsx=30,\n                    name=\"Estoque\",\n                    marker_color=\"#8B5CF6\"\n                ),\n                row=2, col=1\n            )\n\n        # 5.", "mimetype": "text/plain", "start_char_idx": 55907, "end_char_idx": 59665, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "10204078-1621-46d0-a928-c43be2ca7d54": {"__data__": {"id_": "10204078-1621-46d0-a928-c43be2ca7d54", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\chart_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "hash": "9ac656311e15dc4fad15c54781c106118803f6fcff851c0b9365e30f3ec6b45b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2b1628d6-ac21-499b-8876-9c8ebbf63327", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "hash": "cfcee0f229213d1f245301a77d20c74bbc87a940eabe15a3616ae4a33e4de230", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c29a704d-ed32-4598-aca2-c4cdff6f40e2", "node_type": "1", "metadata": {}, "hash": "95feba7a7e225b5f318f10b6b71d4d748d4df54de3b70b969f28dc51c2d66b2c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Pre\u00e7o M\u00e9dio por Grupo\n        preco_col = _get_column(df_conv, 'preco')\n        if grupo_col and preco_col:\n            preco_grupo = df_conv.groupby(grupo_col)[preco_col].mean().sort_values(ascending=False).head(10)\n            fig.add_trace(\n                go.Bar(\n                    x=preco_grupo.index,\n                    y=preco_grupo.values,\n                    name=\"Pre\u00e7o M\u00e9dio\",\n                    marker_color=\"#EC4899\"\n                ),\n                row=2, col=2\n            )\n\n        # 6. Vendas Mensais Totais\n        if mes_cols:\n            vendas_mensais = df_conv[mes_cols].sum()\n            meses = ['JAN', 'FEV', 'MAR', 'ABR', 'MAI', 'JUN', 'JUL', 'AGO', 'SET', 'OUT', 'NOV', 'DEZ']\n            fig.add_trace(\n                go.Scatter(\n                    x=meses,\n                    y=vendas_mensais.values,\n                    mode='lines+markers',\n                    name=\"Vendas Mensais\",\n                    line=dict(color=\"#14B8A6\", width=3),\n                    marker=dict(size=8),\n                    fill='tozeroy'\n                ),\n                row=2, col=3\n            )\n\n        # Atualizar layout\n        fig.update_layout(\n            title_text=\"Dashboard Executivo - Vis\u00e3o Geral do Neg\u00f3cio\",\n            height=900,\n            showlegend=False,\n            template=_get_theme_template(),\n            margin=dict(l=60, r=60, t=100, b=60)\n        )\n\n        # Ajustar eixos\n        fig.update_xaxes(tickangle=-45, row=1, col=1)\n        fig.update_xaxes(tickangle=-45, row=1, col=3)\n        fig.update_xaxes(tickangle=-45, row=2, col=2)\n\n        # Calcular m\u00e9tricas\n        estoque_col_final = _get_column(df_conv, 'estoque')\n        preco_col_final = _get_column(df_conv, 'preco')\n        metricas = {\n            \"total_produtos\": len(df_conv),\n            \"total_grupos\": df_conv[grupo_col].nunique() if grupo_col else 0,\n            \"lucro_total\": float(df_conv['LUCRO R$'].sum()) if 'LUCRO R$' in df_conv.columns else 0,\n            \"vendas_totais\": float(df_conv['VENDAS_TOTAIS'].sum()) if 'VENDAS_TOTAIS' in df_conv.columns else 0,\n            \"estoque_total\": float(df_conv[estoque_col_final].sum()) if estoque_col_final else 0,\n            \"valor_estoque\": float((df_conv[estoque_col_final] * df_conv[preco_col_final]).sum()) if all([estoque_col_final, preco_col_final]) else 0\n        }\n\n        return {\n            \"status\": \"success\",\n            \"chart_type\": \"dashboard_executivo\",\n            \"chart_data\": _export_chart_to_json(fig),\n            \"summary\": metricas\n        }\n\n    except Exception as e:\n        logger.error(f\"Erro ao gerar dashboard executivo: {e}\", exc_info=True)\n        return {\"status\": \"error\", \"message\": f\"Erro ao gerar dashboard: {str(e)}\"}\n\n\n@tool\ndef gerar_dashboard_dinamico(graficos: list) -> Dict[str, Any]:\n    \"\"\"\n    Gera um dashboard din\u00e2mico com uma sele\u00e7\u00e3o de gr\u00e1ficos.\n\n    Args:\n        graficos: Uma lista dos nomes das ferramentas de gr\u00e1fico a serem inclu\u00eddas.\n                  Exemplos de nomes de ferramentas v\u00e1lidas:\n                  - 'gerar_grafico_vendas_por_categoria'\n                  - 'gerar_grafico_estoque_por_produto'\n                  - 'gerar_comparacao_precos_categorias'\n                  - 'gerar_analise_distribuicao_estoque'\n                  - 'gerar_grafico_pizza_categorias'\n                  - 'gerar_ranking_produtos_mais_vendidos'\n\n    Returns:\n        Dicion\u00e1rio com o dashboard e m\u00faltiplos gr\u00e1ficos.\n    \"\"\"\n    logger.info(f\"Gerando dashboard din\u00e2mico com os seguintes gr\u00e1ficos: {graficos}\")\n\n    if not graficos:\n        return {\"status\": \"error\", \"message\": \"Nenhum gr\u00e1fico especificado para o dashboard.\"}", "mimetype": "text/plain", "start_char_idx": 59666, "end_char_idx": 63317, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c29a704d-ed32-4598-aca2-c4cdff6f40e2": {"__data__": {"id_": "c29a704d-ed32-4598-aca2-c4cdff6f40e2", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\chart_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "hash": "9ac656311e15dc4fad15c54781c106118803f6fcff851c0b9365e30f3ec6b45b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "10204078-1621-46d0-a928-c43be2ca7d54", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "hash": "e174e9357d405644cffbcba2f01ea347e86afa406048755010e1bc286eeeed9c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "deac9ae4-ca57-4a3d-b12b-de04b42cff74", "node_type": "1", "metadata": {}, "hash": "b1b3e25bd3c53984010edf0627c52bf5af4e4fc11599a41da759b228759a0906", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "from plotly.subplots import make_subplots\n    import math\n    import json\n\n    num_graficos = len(graficos)\n    if num_graficos > 4:\n        return {\"status\": \"error\", \"message\": \"O dashboard din\u00e2mico suporta no m\u00e1ximo 4 gr\u00e1ficos.\"}\n    \n    rows = math.ceil(num_graficos / 2)\n    cols = 2 if num_graficos > 1 else 1\n    \n    # Mapeamento de nomes de ferramentas para fun\u00e7\u00f5es\n    tool_map = {\n        'gerar_grafico_vendas_por_categoria': gerar_grafico_vendas_por_categoria,\n        'gerar_grafico_estoque_por_produto': gerar_grafico_estoque_por_produto,\n        'gerar_comparacao_precos_categorias': gerar_comparacao_precos_categorias,\n        'gerar_analise_distribuicao_estoque': gerar_analise_distribuicao_estoque,\n        'gerar_grafico_pizza_categorias': gerar_grafico_pizza_categorias,\n        'gerar_ranking_produtos_mais_vendidos': gerar_ranking_produtos_mais_vendidos,\n    }\n\n    figuras = []\n    titulos = []\n    for nome_ferramenta in graficos:\n        if nome_ferramenta in tool_map:\n            try:\n                resultado = tool_map[nome_ferramenta].invoke({})\n                if resultado.get(\"status\") == \"success\":\n                    chart_data = json.loads(resultado[\"chart_data\"])\n                    figura_individual = go.Figure(chart_data)\n                    figuras.append(figura_individual)\n                    titulos.append(figura_individual.layout.title.text)\n                else:\n                    logger.warning(f\"A ferramenta '{nome_ferramenta}' falhou: {resultado.get('message')}\")\n            except Exception as e:\n                logger.error(f\"Erro ao executar a ferramenta '{nome_ferramenta}': {e}\", exc_info=True)\n    \n    if not figuras:\n        return {\"status\": \"error\", \"message\": \"Nenhum dos gr\u00e1ficos solicitados p\u00f4de ser gerado.\"}\n\n    # Recalcular layout com base nos gr\u00e1ficos gerados com sucesso\n    num_graficos = len(figuras)\n    rows = math.ceil(num_graficos / 2)\n    cols = 2 if num_graficos > 1 else 1\n\n    fig = make_subplots(\n        rows=rows, \n        cols=cols, \n        subplot_titles=titulos,\n        vertical_spacing=0.15, # Aumentar espa\u00e7amento vertical\n        horizontal_spacing=0.1 # Aumentar espa\u00e7amento horizontal\n    )\n\n    for i, figura_individual in enumerate(figuras):\n        row = i // cols + 1\n        col = i % cols + 1\n        for trace in figura_individual.data:\n            fig.add_trace(trace, row=row, col=col)\n\n    fig.update_layout(\n        title_text=\"Dashboard Din\u00e2mico\",\n        height=450 * rows, # Ajustar altura\n        showlegend=False,\n        template=_get_theme_template(),\n        margin=dict(l=40, r=40, t=120, b=40), # Adicionar margens\n    )\n    # Ajustar tamanho da fonte dos subt\u00edtulos\n    fig.update_annotations(font_size=14)\n\n    return {\n        \"status\": \"success\",\n        \"chart_type\": \"dashboard\",\n        \"chart_data\": _export_chart_to_json(fig),\n        \"summary\": {\n            \"total_graficos\": len(figuras),\n            \"graficos_incluidos\": titulos,\n        },\n    }", "mimetype": "text/plain", "start_char_idx": 63323, "end_char_idx": 66306, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "deac9ae4-ca57-4a3d-b12b-de04b42cff74": {"__data__": {"id_": "deac9ae4-ca57-4a3d-b12b-de04b42cff74", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\chart_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "hash": "9ac656311e15dc4fad15c54781c106118803f6fcff851c0b9365e30f3ec6b45b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c29a704d-ed32-4598-aca2-c4cdff6f40e2", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\chart_tools.py", "language": "python", "lines": 1883, "filename": "chart_tools.py"}, "hash": "32e51513ede4e62230ee004c8db01d4fee414e4f710a4d38c892336714b1cc66", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# Lista de todas as ferramentas de gr\u00e1ficos dispon\u00edveis\nchart_tools = [\n    # Ferramentas de an\u00e1lise e consulta\n    listar_graficos_disponiveis,  # NOVO: Lista todos os gr\u00e1ficos dispon\u00edveis\n\n    # Gr\u00e1ficos individuais\n    gerar_grafico_vendas_por_categoria,\n    gerar_grafico_estoque_por_produto,\n    gerar_comparacao_precos_categorias,\n    gerar_analise_distribuicao_estoque,\n    gerar_grafico_pizza_categorias,\n    gerar_grafico_vendas_por_produto,\n    gerar_grafico_vendas_mensais_produto,\n    gerar_grafico_vendas_por_grupo,  # Gr\u00e1fico de vendas por grupo/categoria\n    gerar_ranking_produtos_mais_vendidos,\n\n    # Dashboards completos\n    gerar_dashboard_analise_completa,\n    gerar_dashboard_executivo,  # NOVO: Dashboard executivo 2x3\n    gerar_dashboard_dinamico,\n\n    # Gr\u00e1ficos inteligentes\n    gerar_grafico_automatico,\n]", "mimetype": "text/plain", "start_char_idx": 66309, "end_char_idx": 67141, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d9153119-d2df-4528-ac79-1abf29261045": {"__data__": {"id_": "d9153119-d2df-4528-ac79-1abf29261045", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\check_gui_dependencies.py", "language": "python", "lines": 57, "filename": "check_gui_dependencies.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\check_gui_dependencies.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\check_gui_dependencies.py", "language": "python", "lines": 57, "filename": "check_gui_dependencies.py"}, "hash": "eb9d7d5e4b4c840e3e2a412345a9f968cf3d8fbf7d6c3de3f7baaf5c8960a796", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import subprocess\nimport sys\n\n\"\"\"\nVerifica se todas as depend\u00eancias necess\u00e1rias para a interface gr\u00e1fica est\u00e3o instaladas.\n\"\"\"\n\n\ndef check_dependency(module_name):\n    \"\"\"Verifica se um m\u00f3dulo est\u00e1 instalado e tenta instal\u00e1-lo se n\u00e3o estiver.\"\"\"\n    try:\n        print(f\"\u2713 {module_name} j\u00e1 est\u00e1 instalado\")\n        return True\n    except ImportError:\n        print(f\"\u2717 {module_name} n\u00e3o est\u00e1 instalado. Tentando instalar...\")\n        try:\n            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", module_name])\n            print(f\"\u2713 {module_name} foi instalado com sucesso\")\n            return True\n        except subprocess.CalledProcessError:\n            print(f\"\u2717 Falha ao instalar {module_name}\")\n            return False\n\n\ndef main():\n    \"\"\"Fun\u00e7\u00e3o principal para verificar depend\u00eancias.\"\"\"\n    print(\"Verificando depend\u00eancias para a interface gr\u00e1fica...\")\n\n    # Lista de depend\u00eancias necess\u00e1rias\n    dependencies = [\n        \"streamlit\",\n        \"langchain\",\n\n        \"langchain_community\",\n        \"sqlalchemy\",\n        \"pyodbc\",\n        \"python-dotenv\",\n    ]\n\n    all_installed = True\n    for dep in dependencies:\n        if not check_dependency(dep):\n            all_installed = False\n\n    if all_installed:\n        print(\"\\nTodas as depend\u00eancias est\u00e3o instaladas!\")\n        print(\n            \"Voc\u00ea pode executar a interface Streamlit com: streamlit run streamlit_app.py\"\n        )\n    else:\n        print(\"\\nAlgumas depend\u00eancias n\u00e3o puderam ser instaladas.\")\n        print(\"Por favor, instale-as manualmente e tente novamente.\")\n\n\nif __name__ == \"__main__\":\n    main()", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1598, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "343ec929-0561-49f5-96d0-0fcf7a7a99f3": {"__data__": {"id_": "343ec929-0561-49f5-96d0-0fcf7a7a99f3", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\check_integration.py", "language": "python", "lines": 1, "filename": "check_integration.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\check_integration.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\check_integration.py", "language": "python", "lines": 1, "filename": "check_integration.py"}, "hash": "617ead1e7d47da0e80463a2765a919d99cbdbe456de0edfe08b229bc04c4b876", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 0, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "264211dc-aa95-486e-9733-e33f44cdb262": {"__data__": {"id_": "264211dc-aa95-486e-9733-e33f44cdb262", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\code_interpreter.py", "language": "python", "lines": 276, "filename": "code_interpreter.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\code_interpreter.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\code_interpreter.py", "language": "python", "lines": 276, "filename": "code_interpreter.py"}, "hash": "a44b4c5d59e15ebda127f4148bff78e45d2a1a2f45202f3c3608cd1179073e03", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b34e3d22-6348-4505-abd3-a34dd5621b6a", "node_type": "1", "metadata": {}, "hash": "5d8ff30080ff0827184f8d240df4c064a4e5e81fc3fa1c290879de037f660a85", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nCode Interpreter - Sandbox seguro para execu\u00e7\u00e3o de c\u00f3digo Python\nPermite an\u00e1lises din\u00e2micas de dados com pandas, numpy, etc.\n\"\"\"\n\nimport logging\nimport io\nimport sys\nimport traceback\nfrom typing import Dict, Any, Optional, List\nfrom contextlib import redirect_stdout, redirect_stderr\nimport pandas as pd\nfrom langchain_core.tools import tool\n\nlogger = logging.getLogger(__name__)\n\n# Bibliotecas permitidas no sandbox\nALLOWED_MODULES = {\n    'pandas', 'numpy', 'math', 'statistics', 'datetime',\n    'json', 're', 'collections', 'itertools', 'functools'\n}\n\n# Fun\u00e7\u00f5es perigosas bloqueadas\nBLOCKED_FUNCTIONS = {\n    'exec', 'eval', 'compile', 'open', 'input',\n    '__import__', 'globals', 'locals', 'vars',\n    'getattr', 'setattr', 'delattr', 'hasattr'\n}\n\n\nclass CodeInterpreter:\n    \"\"\"\n    Executor seguro de c\u00f3digo Python para an\u00e1lise de dados.\n    \n    Features:\n    - Sandbox com restri\u00e7\u00f5es de seguran\u00e7a\n    - Acesso a pandas e numpy\n    - Captura de stdout/stderr\n    - Timeout configur\u00e1vel\n    \"\"\"\n    \n    def __init__(self, timeout_seconds: int = 10):\n        self.timeout = timeout_seconds\n        self.execution_count = 0\n        self.error_count = 0\n        \n        # Namespace seguro para execu\u00e7\u00e3o\n        self._safe_namespace = self._create_safe_namespace()\n    \n    def _create_safe_namespace(self) -> Dict[str, Any]:\n        \"\"\"Cria namespace seguro com bibliotecas permitidas.\"\"\"\n        namespace = {\n            '__builtins__': {\n                'len': len, 'range': range, 'list': list, 'dict': dict,\n                'str': str, 'int': int, 'float': float, 'bool': bool,\n                'print': print, 'sum': sum, 'min': min, 'max': max,\n                'abs': abs, 'round': round, 'sorted': sorted,\n                'enumerate': enumerate, 'zip': zip, 'map': map,\n                'filter': filter, 'any': any, 'all': all,\n                'isinstance': isinstance, 'type': type,\n                'True': True, 'False': False, 'None': None,\n            }\n        }\n        \n        # Adicionar pandas e numpy\n        try:\n            import pandas as pd\n            import numpy as np\n            namespace['pd'] = pd\n            namespace['np'] = np\n            namespace['DataFrame'] = pd.DataFrame\n        except ImportError:\n            logger.warning(\"pandas/numpy n\u00e3o dispon\u00edvel\")\n        \n        # Adicionar math e statistics\n        try:\n            import math\n            import statistics\n            namespace['math'] = math\n            namespace['statistics'] = statistics\n        except ImportError:\n            pass\n        \n        return namespace\n    \n    def _validate_code(self, code: str) -> tuple[bool, str]:\n        \"\"\"Valida c\u00f3digo antes de executar.\"\"\"\n        code_lower = code.lower()\n        \n        # Verificar fun\u00e7\u00f5es bloqueadas\n        for blocked in BLOCKED_FUNCTIONS:\n            if blocked in code_lower:\n                return False, f\"Fun\u00e7\u00e3o '{blocked}' n\u00e3o permitida\"\n        \n        # Verificar imports perigosos\n        if 'import os' in code_lower or 'import sys' in code_lower:\n            return False, \"Imports de sistema n\u00e3o permitidos\"\n        \n        if 'import subprocess' in code_lower:\n            return False, \"subprocess n\u00e3o permitido\"\n        \n        # Verificar acesso a arquivos\n        if 'open(' in code and 'file' in code_lower:\n            return False, \"Acesso direto a arquivos n\u00e3o permitido\"\n        \n        return True, \"\"\n    \n    def execute(self, code: str, data: pd.DataFrame = None) -> Dict[str, Any]:\n        \"\"\"\n        Executa c\u00f3digo Python de forma segura.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3554, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b34e3d22-6348-4505-abd3-a34dd5621b6a": {"__data__": {"id_": "b34e3d22-6348-4505-abd3-a34dd5621b6a", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\code_interpreter.py", "language": "python", "lines": 276, "filename": "code_interpreter.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\code_interpreter.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\code_interpreter.py", "language": "python", "lines": 276, "filename": "code_interpreter.py"}, "hash": "a44b4c5d59e15ebda127f4148bff78e45d2a1a2f45202f3c3608cd1179073e03", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "264211dc-aa95-486e-9733-e33f44cdb262", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\code_interpreter.py", "language": "python", "lines": 276, "filename": "code_interpreter.py"}, "hash": "3db46f196eef5b41f0a363ac4ba7b2d4dbfe4695a3e4fa0c6b5670f803a1eb9c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e5e9f0da-9ccb-48df-9a6b-16ce16aaff27", "node_type": "1", "metadata": {}, "hash": "206eb4dee6f630bee6bc40336ad4eb3db21e9186d6c607c3e99df6b23bcbdab2", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Args:\n            code: C\u00f3digo Python a executar\n            data: DataFrame opcional para an\u00e1lise\n            \n        Returns:\n            Dict com resultado, output e erro\n        \"\"\"\n        self.execution_count += 1\n        logger.info(f\"\ud83d\udc0d CodeInterpreter: Executando c\u00f3digo ({len(code)} chars)\")\n        \n        # Validar c\u00f3digo\n        is_valid, error_msg = self._validate_code(code)\n        if not is_valid:\n            self.error_count += 1\n            return {\n                \"success\": False,\n                \"error\": error_msg,\n                \"output\": \"\",\n                \"result\": None\n            }\n        \n        # Preparar namespace\n        namespace = self._safe_namespace.copy()\n        \n        # Adicionar DataFrame se fornecido\n        if data is not None:\n            namespace['df'] = data\n            namespace['data'] = data\n        \n        # Capturar stdout e stderr\n        stdout_capture = io.StringIO()\n        stderr_capture = io.StringIO()\n        \n        try:\n            with redirect_stdout(stdout_capture), redirect_stderr(stderr_capture):\n                # Executar c\u00f3digo\n                exec(code, namespace)\n            \n            # Extrair resultado (\u00faltima vari\u00e1vel definida ou 'result')\n            result = namespace.get('result', None)\n            \n            # Se n\u00e3o houver 'result', tentar encontrar \u00faltima vari\u00e1vel\n            if result is None:\n                for var_name in ['output', 'resultado', 'answer', 'resposta']:\n                    if var_name in namespace:\n                        result = namespace[var_name]\n                        break\n            \n            # Converter DataFrame para dict se necess\u00e1rio\n            if isinstance(result, pd.DataFrame):\n                result = {\n                    \"type\": \"dataframe\",\n                    \"shape\": result.shape,\n                    \"columns\": list(result.columns),\n                    \"data\": result.head(50).to_dict(orient='records')\n                }\n            elif isinstance(result, pd.Series):\n                result = {\n                    \"type\": \"series\",\n                    \"data\": result.to_dict()\n                }\n            \n            output = stdout_capture.getvalue()\n            \n            logger.info(f\"\u2705 C\u00f3digo executado com sucesso\")\n            \n            return {\n                \"success\": True,\n                \"error\": None,\n                \"output\": output,\n                \"result\": result\n            }\n            \n        except Exception as e:\n            self.error_count += 1\n            error_trace = traceback.format_exc()\n            logger.error(f\"\u274c Erro na execu\u00e7\u00e3o: {e}\")\n            \n            return {\n                \"success\": False,\n                \"error\": str(e),\n                \"output\": stdout_capture.getvalue(),\n                \"traceback\": error_trace,\n                \"result\": None\n            }\n    \n    def get_stats(self) -> Dict[str, Any]:\n        \"\"\"Retorna estat\u00edsticas do interpreter.\"\"\"\n        error_rate = (self.error_count / self.execution_count * 100) if self.execution_count > 0 else 0\n        \n        return {\n            \"execution_count\": self.execution_count,\n            \"error_count\": self.error_count,\n            \"error_rate\": f\"{error_rate:.1f}%\",\n            \"timeout\": self.timeout\n        }\n\n\n# Inst\u00e2ncia global\n_interpreter: Optional[CodeInterpreter] = None\n\n\ndef get_interpreter() -> CodeInterpreter:\n    \"\"\"Retorna inst\u00e2ncia singleton do interpreter.\"\"\"\n    global _interpreter\n    if _interpreter is None:\n        _interpreter = CodeInterpreter()\n    return _interpreter", "mimetype": "text/plain", "start_char_idx": 3572, "end_char_idx": 7169, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e5e9f0da-9ccb-48df-9a6b-16ce16aaff27": {"__data__": {"id_": "e5e9f0da-9ccb-48df-9a6b-16ce16aaff27", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\code_interpreter.py", "language": "python", "lines": 276, "filename": "code_interpreter.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\code_interpreter.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\code_interpreter.py", "language": "python", "lines": 276, "filename": "code_interpreter.py"}, "hash": "a44b4c5d59e15ebda127f4148bff78e45d2a1a2f45202f3c3608cd1179073e03", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b34e3d22-6348-4505-abd3-a34dd5621b6a", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\code_interpreter.py", "language": "python", "lines": 276, "filename": "code_interpreter.py"}, "hash": "d5cf69bfa8d6d9df1c556fadb5d4e0f7a670f7373777a60c2b5d3acc0cdadc78", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# Ferramenta LangChain para o agente\n@tool\ndef executar_codigo_python(\n    codigo: str,\n    descricao: str = \"\"\n) -> Dict[str, Any]:\n    \"\"\"\n    Executa c\u00f3digo Python para an\u00e1lise de dados.\n    \n    Use esta ferramenta quando precisar:\n    - Fazer c\u00e1lculos complexos\n    - Processar dados de forma personalizada\n    - Criar an\u00e1lises estat\u00edsticas\n    \n    Args:\n        codigo: C\u00f3digo Python a executar. Use 'df' para acessar os dados.\n        descricao: Descri\u00e7\u00e3o do que o c\u00f3digo faz\n        \n    Returns:\n        Resultado da execu\u00e7\u00e3o\n        \n    Exemplo:\n        >>> executar_codigo_python(\n        ...     codigo=\"result = df['vendas'].sum()\",\n        ...     descricao=\"Calcula soma das vendas\"\n        ... )\n    \"\"\"\n    logger.info(f\"\ud83d\udcdd Executando c\u00f3digo: {descricao or 'sem descri\u00e7\u00e3o'}\")\n    \n    interpreter = get_interpreter()\n    \n    # Carregar dados do Parquet\n    try:\n        from app.config.settings import settings\n        df = pd.read_parquet(settings.PARQUET_FILE_PATH)\n    except Exception as e:\n        logger.error(f\"Erro ao carregar dados: {e}\")\n        df = None\n    \n    result = interpreter.execute(codigo, data=df)\n    \n    if result[\"success\"]:\n        return {\n            \"sucesso\": True,\n            \"resultado\": result[\"result\"],\n            \"output\": result[\"output\"],\n            \"mensagem\": f\"C\u00f3digo executado: {descricao}\" if descricao else \"C\u00f3digo executado com sucesso\"\n        }\n    else:\n        return {\n            \"sucesso\": False,\n            \"erro\": result[\"error\"],\n            \"mensagem\": f\"Erro ao executar c\u00f3digo: {result['error']}\"\n        }", "mimetype": "text/plain", "start_char_idx": 7172, "end_char_idx": 8761, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ac330131-3a1d-494c-bfdc-4f69105871b5": {"__data__": {"id_": "ac330131-3a1d-494c-bfdc-4f69105871b5", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\date_time_tools.py", "language": "python", "lines": 19, "filename": "date_time_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\date_time_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\date_time_tools.py", "language": "python", "lines": 19, "filename": "date_time_tools.py"}, "hash": "be8e274efd9b8359ee0b189358912bf331008fe603d0b8b5bc306b51b3d0235a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# core/tools/date_time_tools.py\nfrom datetime import datetime\nfrom langchain_core.tools import tool\nimport logging\n\n\n@tool\ndef get_current_datetime() -> str:\n    \"\"\"\n    Returns the current date and time.\n    \"\"\"\n    logging.info(\"Getting current date and time.\")\n    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n\n\ndate_time_tools = [\n    get_current_datetime,\n]", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 369, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "539ff5b4-252d-43a0-b951-9e8d7c2de8c1": {"__data__": {"id_": "539ff5b4-252d-43a0-b951-9e8d7c2de8c1", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\debug_server.py", "language": "python", "lines": 43, "filename": "debug_server.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\debug_server.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\debug_server.py", "language": "python", "lines": 43, "filename": "debug_server.py"}, "hash": "4c62c7ff5573beff15464ad196663f202f53de85ee379d940cb20ec6257c69a6", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import logging\nimport os\nimport sys\n\nfrom app.core.config import SQLALCHEMY_DATABASE_URI\n\n\"\"\"\nScript para depurar o servidor e identificar erros.\n\"\"\"\n\n# Configura\u00e7\u00e3o do logging\nlogging.basicConfig(\n    level=logging.DEBUG,\n    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n    handlers=[logging.FileHandler(\"debug.log\"), logging.StreamHandler()],\n)\n\n# Adiciona o diret\u00f3rio raiz ao PATH para importa\u00e7\u00f5es relativas\nsys.path.append(os.path.dirname(os.path.abspath(__file__)))\n\ntry:\n    logging.info(\"Verificando importa\u00e7\u00f5es...\")\n\n    # Tenta importar as depend\u00eancias\n    logging.info(\"SQLDatabase importado com sucesso\")\n\n    # Verifica a configura\u00e7\u00e3o\n    logging.info(\"Verificando configura\u00e7\u00e3o...\")\n\n    if not SQLALCHEMY_DATABASE_URI:\n        logging.error(\"SQLALCHEMY_DATABASE_URI n\u00e3o est\u00e1 configurada\")\n    else:\n        logging.info(\"SQLALCHEMY_DATABASE_URI configurada\")\n\n    # Verifica as ferramentas SQL\n    logging.info(\"Verificando ferramentas SQL...\")\n    logging.info(\"Ferramentas SQL importadas com sucesso\")\n\n    logging.info(\"Verifica\u00e7\u00e3o de configura\u00e7\u00e3o e ferramentas SQL conclu\u00edda com sucesso\")\n\nexcept Exception as e:\n    logging.error(f\"Erro durante a verifica\u00e7\u00e3o: {e}\", exc_info=True)", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1206, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "216b2743-84d1-4c4d-b855-57f657a2df1a": {"__data__": {"id_": "216b2743-84d1-4c4d-b855-57f657a2df1a", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\flexible_query_tool.py", "language": "python", "lines": 219, "filename": "flexible_query_tool.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\flexible_query_tool.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\flexible_query_tool.py", "language": "python", "lines": 219, "filename": "flexible_query_tool.py"}, "hash": "6f7cc62fdba0819568612ac8b01355db698553cfdb3f10e74d0158e966eac4b1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9d2088a2-319a-4c3d-8dd1-c32148ba8040", "node_type": "1", "metadata": {}, "hash": "584d4f0a9bb77105be06832a9ba42b4d2a0812985df387454cbe82e8201fa166", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nFerramenta gen\u00e9rica e flex\u00edvel para consultas ao Parquet\nPermite ao agente consultar qualquer dado de forma inteligente\n\nCORRE\u00c7\u00c3O 2024-12-13: Resolvido erro \"DataFrame constructor not properly called\"\n- Carrega Parquet diretamente (evita HybridAdapter problem\u00e1tico)\n- Serializa\u00e7\u00e3o JSON correta com .to_dict(orient='records')\n- Mapeamento case-insensitive de colunas\n\"\"\"\n\nfrom langchain_core.tools import tool\nimport pandas as pd\nimport numpy as np\nimport logging\nimport os\nfrom typing import Dict, Any, List, Optional\nfrom app.core.utils.error_handler import error_handler_decorator\n\nlogger = logging.getLogger(__name__)\n\n# Mapeamento de colunas (lowercase \u2192 original)\nCOLUMN_MAPPING = {\n    'nomesegmento': 'NOMESEGMENTO',\n    'nomefabricante': 'NOMEFABRICANTE',\n    'nomecategoria': 'NOMECATEGORIA',\n    'une': 'UNE',\n    'produto': 'PRODUTO',\n    'codigo': 'PRODUTO',\n    'nome': 'NOME',\n    'estoque_une': 'ESTOQUE_UNE',\n    'estoque_atual': 'ESTOQUE_UNE',  # Alias para estoque_atual\n    'estoque_lv': 'ESTOQUE_LV',\n    'estoque_cd': 'ESTOQUE_CD',\n    'venda_30dd': 'VENDA_30DD',\n    'venda_30_d': 'VENDA_30DD',  # Alias para venda_30_d (compatibilidade com une_tools)\n    'preco_venda': 'PRECO_VENDA',\n    'preco_custo': 'PRECO_CUSTO',\n}\n\n\ndef _safe_serialize(value):\n    \"\"\"Converte valor para JSON-safe.\"\"\"\n    if pd.isna(value) or value is None:\n        return None\n    elif isinstance(value, (np.integer, np.int64, np.int32)):\n        return int(value)\n    elif isinstance(value, (np.floating, np.float64, np.float32)):\n        return float(value) if not np.isnan(value) else None\n    elif isinstance(value, (pd.Timestamp, np.datetime64)):\n        return str(value)\n    elif isinstance(value, bytes):\n        return value.decode('utf-8', errors='ignore')\n    else:\n        return value\n\n\ndef _get_parquet_path():\n    \"\"\"Retorna caminho do arquivo Parquet.\"\"\"\n    try:\n        from app.config.settings import settings\n        return getattr(settings, 'PARQUET_FILE_PATH', None)\n    except:\n        pass\n    \n    # Fallback\n    default_path = os.path.join(os.getcwd(), 'data', 'parquet', 'admmat.parquet')\n    if os.path.exists(default_path):\n        return default_path\n    return None\n\n\ndef _find_column(df: pd.DataFrame, col_name: str) -> Optional[str]:\n    \"\"\"Encontra coluna no DataFrame (case-insensitive).\"\"\"\n    col_lower = col_name.lower()\n    \n    # Primeiro: mapeamento conhecido\n    if col_lower in COLUMN_MAPPING:\n        mapped = COLUMN_MAPPING[col_lower]\n        if mapped in df.columns:\n            return mapped\n    \n    # Segundo: busca exata\n    if col_name in df.columns:\n        return col_name\n    \n    # Terceiro: busca case-insensitive\n    for df_col in df.columns:\n        if df_col.lower() == col_lower:\n            return df_col\n    \n    return None\n\n\n@tool\n@error_handler_decorator(\n    context_func=lambda **kwargs: {\"funcao\": \"consultar_dados_flexivel\", \"params\": kwargs},\n    return_on_error={\"error\": \"Erro ao consultar dados\", \"total_resultados\": 0, \"resultados\": []}\n)\ndef consultar_dados_flexivel(\n    filtros: Optional[Dict[str, Any]] = None,\n    colunas: Optional[List[str]] = None,\n    agregacao: Optional[str] = None,\n    coluna_agregacao: Optional[str] = None,\n    agrupar_por: Optional[List[str]] = None,\n    ordenar_por: Optional[str] = None,\n    ordem_desc: bool = True,\n    limite: int = 20\n) -> Dict[str, Any]:\n    \"\"\"\n    Ferramenta GEN\u00c9RICA e FLEX\u00cdVEL para consultar dados do Parquet.\n    Garante alta performance usando cache centralizado.\n    \"\"\"", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3507, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9d2088a2-319a-4c3d-8dd1-c32148ba8040": {"__data__": {"id_": "9d2088a2-319a-4c3d-8dd1-c32148ba8040", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\flexible_query_tool.py", "language": "python", "lines": 219, "filename": "flexible_query_tool.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\flexible_query_tool.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\flexible_query_tool.py", "language": "python", "lines": 219, "filename": "flexible_query_tool.py"}, "hash": "6f7cc62fdba0819568612ac8b01355db698553cfdb3f10e74d0158e966eac4b1", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "216b2743-84d1-4c4d-b855-57f657a2df1a", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\flexible_query_tool.py", "language": "python", "lines": 219, "filename": "flexible_query_tool.py"}, "hash": "0ec55ac171b3f9d88668ba252473a8b0e6c81031af9d7061461beb0c0e8bd673", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e098c6f5-fced-4d63-84a9-c4e675149d5c", "node_type": "1", "metadata": {}, "hash": "fed87dae4df6b24ee1e79d49c1d69bd67036b8d4a21d614b0dbdf6905e017855", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Garante alta performance usando cache centralizado.\n    \"\"\"\n    try:\n        # HARD LIMIT: Previne estouro de contexto do LLM\n        if limite > 50:\n            limite = 50\n            \n        logger.info(f\"\ud83d\udcca Consulta flex\u00edvel otimizada - Filtros: {filtros}, Agrega\u00e7\u00e3o: {agregacao}, Limite: {limite}\")\n        \n        # 1. Mapeamento de colunas e filtros\n        from app.infrastructure.data.duckdb_adapter import duckdb_adapter\n        \n        # Mapear filtros para nomes reais do Parquet\n        duckdb_filters = {}\n        if filters:\n            for key, val in filters.items():\n                if isinstance(val, dict): continue # Skip complex nested filters for now\n                real_col = _find_column(pd.DataFrame(columns=list(COLUMN_MAPPING.values())), key)\n                # Fallback to direct mapping if _find_column fails without data\n                if not real_col:\n                     real_col = COLUMN_MAPPING.get(key.lower(), key)\n                duckdb_filters[real_col] = val\n\n        # 2. Executar consulta via DuckDB\n        if agregacao and coluna_agregacao:\n            # Mapear colunas de agrega\u00e7\u00e3o\n            real_agg_col = COLUMN_MAPPING.get(coluna_agregacao.lower(), coluna_agregacao)\n            real_group_cols = []\n            if agrupar_por:\n                real_group_cols = [COLUMN_MAPPING.get(c.lower(), c) for c in agrupar_por]\n            \n            logger.info(f\"\ud83d\udcca DuckDB Agrega\u00e7\u00e3o: {agregacao}({real_agg_col}) GroupBy={real_group_cols}\")\n            \n            df_result = duckdb_adapter.execute_aggregation(\n                agg_col=real_agg_col,\n                agg_func=agregacao,\n                group_by=real_group_cols,\n                filters=duckdb_filters,\n                limit=limite\n            )\n            \n            # Se for agrega\u00e7\u00e3o escalar (sem group by), formatar retorno\n            if not real_group_cols and not df_result.empty:\n                 valor = df_result.iloc[0]['valor']\n                 return {\"total_resultados\": 1, \"resultado_agregado\": {\"valor\": _safe_serialize(valor)}, \"mensagem\": f\"{agregacao.upper()}: {_safe_serialize(valor)}\"}\n\n        else:\n            # Consulta simples (Load Data)\n            # Mapear colunas solicitadas\n            real_cols = None\n            if colunas:\n                real_cols = [COLUMN_MAPPING.get(c.lower(), c) for c in colunas]\n            \n            # Ordena\u00e7\u00e3o\n            real_order = None\n            if ordenar_por:\n                real_sort_col = COLUMN_MAPPING.get(ordenar_por.lower(), ordenar_por)\n                direction = \"DESC\" if ordem_desc else \"ASC\"\n                real_order = f\"{real_sort_col} {direction}\"\n\n            logger.info(f\"\ud83d\udcca DuckDB Consulta: Cols={real_cols}, Filters={list(duckdb_filters.keys())}\")\n            \n            df_result = duckdb_adapter.load_data(\n                columns=real_cols,\n                filters=duckdb_filters,\n                limit=limite,\n                order_by=real_order\n            )\n\n        if df_result.empty:\n            return {\"total_resultados\": 0, \"resultados\": [], \"mensagem\": \"Nenhum dado encontrado.\"}\n\n        # 5. OTIMIZA\u00c7\u00c3O DE COLUNAS: Retornar apenas o essencial para economizar tokens\n        # (L\u00f3gica mantida para garantir output limpo para o LLM)\n        df_final = df_result # J\u00e1 vem filtrado do DuckDB se 'colunas' foi passado\n        \n        # 6.", "mimetype": "text/plain", "start_char_idx": 3448, "end_char_idx": 6810, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e098c6f5-fced-4d63-84a9-c4e675149d5c": {"__data__": {"id_": "e098c6f5-fced-4d63-84a9-c4e675149d5c", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\flexible_query_tool.py", "language": "python", "lines": 219, "filename": "flexible_query_tool.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\flexible_query_tool.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\flexible_query_tool.py", "language": "python", "lines": 219, "filename": "flexible_query_tool.py"}, "hash": "6f7cc62fdba0819568612ac8b01355db698553cfdb3f10e74d0158e966eac4b1", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9d2088a2-319a-4c3d-8dd1-c32148ba8040", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\flexible_query_tool.py", "language": "python", "lines": 219, "filename": "flexible_query_tool.py"}, "hash": "7ef8015f71d383237d160dcdbf6fdb650d8d0860aaf588223b1642cbfdafae70", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Serializar\n        resultados = []\n        for _, row in df_final.iterrows():\n            resultados.append({col: _safe_serialize(row[col]) for col in df_final.columns})\n            \n        # Gerar Markdown simplificado\n        mensagem_tabela = f\"Exibindo os primeiros {len(resultados)} resultados:\\n\\n\"\n        if len(resultados) > 0:\n            cols_to_show = df_final.columns[:5]\n            mensagem_tabela += \"| \" + \" | \".join(cols_to_show) + \" |\\n\"\n            mensagem_tabela += \"|\" + \"|\".join([\"---\" for _ in range(len(cols_to_show))]) + \"|\\n\"\n            for item in resultados[:10]: # Limitar tabela markdown a 10 linhas no prompt\n                mensagem_tabela += \"| \" + \" | \".join([str(item.get(c, \"-\"))[:20] for c in cols_to_show]) + \" |\\n\"\n\n        return {\n            \"total_resultados\": len(resultados),\n            \"resultados\": resultados,\n            \"mensagem\": mensagem_tabela\n        }\n        \n    except Exception as e:\n        logger.error(f\"\u274c Erro em consultar_dados_flexivel: {e}\", exc_info=True)\n        return {\n            \"error\": f\"Erro na consulta: {str(e)}\",\n            \"total_resultados\": 0,\n            \"resultados\": [],\n            \"mensagem\": \"Ocorreu um erro ao processar sua consulta.\"\n        }\n\n\n# Exportar ferramenta\n__all__ = ['consultar_dados_flexivel']", "mimetype": "text/plain", "start_char_idx": 6811, "end_char_idx": 8115, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d384c133-b0fc-4463-85b8-e078ea1bbf0a": {"__data__": {"id_": "d384c133-b0fc-4463-85b8-e078ea1bbf0a", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\graph_integration.py", "language": "python", "lines": 160, "filename": "graph_integration.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\graph_integration.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\graph_integration.py", "language": "python", "lines": 160, "filename": "graph_integration.py"}, "hash": "fec170da759553f4d2679a18e5b537da5c53c8783a0a2ab9da42df0f2ffaa1a1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7c06d9d3-37fa-4df9-a680-9ca51b150821", "node_type": "1", "metadata": {}, "hash": "0b27a0f3341855589680930a1205fb469b509c07916a188ccecaf7bdf52e2f7c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import logging\nimport os\nfrom typing import Any, Dict\n\nimport pandas as pd\n\nfrom app.core.tools.visualization_tools import generate_plotly_chart_code\n\n# Importa as funcionalidades de visualiza\u00e7\u00e3o existentes\n\n# Importa a fun\u00e7\u00e3o de processamento de gr\u00e1ficos do novo m\u00f3dulo\n\n# Configura\u00e7\u00e3o de logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n    filename=\"logs/graph_integration.log\",\n    filemode=\"a\",\n)\nlogger = logging.getLogger(\"graph_integration\")\n\n# Diret\u00f3rio para salvar gr\u00e1ficos do agente_visual\nPLOT_DIR = \"outputs/plots\"\nos.makedirs(PLOT_DIR, exist_ok=True)\n\n# Diret\u00f3rio para salvar gr\u00e1ficos do sistema existente\nCHART_OUTPUT_DIR = os.path.join(\n    os.path.dirname(os.path.dirname(os.path.dirname(__file__))), \"generated_charts\"\n)\nos.makedirs(CHART_OUTPUT_DIR, exist_ok=True)", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 854, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7c06d9d3-37fa-4df9-a680-9ca51b150821": {"__data__": {"id_": "7c06d9d3-37fa-4df9-a680-9ca51b150821", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\graph_integration.py", "language": "python", "lines": 160, "filename": "graph_integration.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\graph_integration.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\graph_integration.py", "language": "python", "lines": 160, "filename": "graph_integration.py"}, "hash": "fec170da759553f4d2679a18e5b537da5c53c8783a0a2ab9da42df0f2ffaa1a1", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d384c133-b0fc-4463-85b8-e078ea1bbf0a", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\graph_integration.py", "language": "python", "lines": 160, "filename": "graph_integration.py"}, "hash": "e8d1a8491cc8822b4000966d95f887f985543e22fe1eec4a1ecedaf27654d448", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "dc9fa2c7-02a9-48ad-82c6-783b3f834c9b", "node_type": "1", "metadata": {}, "hash": "b3411b8f074be3d8c81c59d24d4622c83a5f5de23c63aff26668ba5caaca29d6", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "def processar_resposta_com_grafico(resposta: Any) -> Dict[str, Any]:\n    \"\"\"\n    Processa a resposta do agente e gera gr\u00e1fico se apropriado,\n    integrando as funcionalidades do agente_visual.py com o sistema existente.\n\n    Args:\n        resposta: Resposta do agente (pode ser dict, string ou objeto)\n\n    Returns:\n        Dict com a resposta processada e caminho do gr\u00e1fico se gerado\n    \"\"\"\n    try:\n        # Converte para formato padr\u00e3o se n\u00e3o for um dicion\u00e1rio\n        if not isinstance(resposta, dict):\n            resultado = {\"output\": str(resposta), \"type\": \"text\"}\n        else:\n            resultado = resposta\n\n        # Extrai o texto da resposta\n        texto = resultado.get(\"output\", str(resposta))\n\n        # Verifica se h\u00e1 inten\u00e7\u00e3o de visualizar gr\u00e1fico\n        termos_grafico = [\n            \"gr\u00e1fico\",\n            \"visualizar\",\n            \"tend\u00eancia\",\n            \"mostrar gr\u00e1fico\",\n            \"exibir gr\u00e1fico\",\n        ]\n        if any(termo in texto.lower() for termo in termos_grafico):\n            # Tenta obter DataFrame da resposta\n            df = None\n\n            # Verifica se h\u00e1 um DataFrame na resposta\n            if hasattr(resposta, \"result\") and isinstance(\n                resposta.result, pd.DataFrame\n            ):\n                df = resposta.result\n            elif isinstance(resposta, dict):\n                if \"result\" in resposta and isinstance(\n                    resposta[\"result\"], pd.DataFrame\n                ):\n                    df = resposta[\"result\"]\n                elif \"data\" in resposta and isinstance(resposta[\"data\"], list):\n                    df = pd.DataFrame(resposta[\"data\"])\n                elif \"output\" in resposta and isinstance(resposta[\"output\"], list):\n                    df = pd.DataFrame(resposta[\"output\"])\n\n            # Se encontrou dados, gera o gr\u00e1fico\n            if df is not None and not df.empty:\n                # Tenta gerar o gr\u00e1fico usando o agente_visual\n                # Importa dinamicamente a fun\u00e7\u00e3o gerar_grafico para evitar importa\u00e7\u00e3o circular\n                try:\n                    from agente_visual import gerar_grafico\n\n                    caminho_grafico = gerar_grafico(df, \"Visualiza\u00e7\u00e3o de Dados\")\n                except ImportError as e:\n                    logger.error(f\"Erro ao importar fun\u00e7\u00e3o gerar_grafico: {e}\")\n                    caminho_grafico = None\n\n                if caminho_grafico:\n                    # Adiciona o caminho do gr\u00e1fico \u00e0 resposta\n                    resultado[\"chart\"] = caminho_grafico\n                    resultado[\"chart_type\"] = \"matplotlib\"\n                    resultado[\"output\"] = (\n                        f\"{texto}\\n\\n[Grafico gerado]: {caminho_grafico}\"\n                    )\n\n                    logger.info(f\"Gr\u00e1fico gerado com matplotlib: {caminho_grafico}\")\n                    return resultado\n                else:\n                    # Fallback: tenta gerar com Plotly se o matplotlib falhar\n                    try:\n                        # Gera c\u00f3digo para o gr\u00e1fico Plotly\n                        chart_description = \"Gerar visualiza\u00e7\u00e3o dos dados fornecidos\"\n                        plotly_code = generate_plotly_chart_code(df, chart_description)\n\n                        # Executa o c\u00f3digo e salva o gr\u00e1fico\n                        chart_result = execute_chart_code_and_save(plotly_code)\n\n                        if \"Gr\u00e1fico gerado e salvo com sucesso\" in chart_result:\n                            # Extrai o caminho do gr\u00e1fico da mensagem\n                            caminho = chart_result.split(\"sucesso em: \")[1]\n                            resultado[\"chart\"] = caminho\n                            resultado[\"chart_type\"] = \"plotly\"\n                            resultado[\"output\"] = (\n                                f\"{texto}\\n\\n[Grafico gerado]: {caminho}\"\n                            )\n\n                            logger.info(f\"Gr\u00e1fico gerado com Plotly: {caminho}\")\n                            return resultado\n                    except Exception as e:\n                        logger.error(f\"Erro ao gerar gr\u00e1fico com Plotly: {e}\")\n\n            # Se chegou aqui, n\u00e3o conseguiu gerar o gr\u00e1fico\n            resultado[\"output\"] = (\n                f\"{texto}\\n\\n[Aviso]: N\u00e3o foi poss\u00edvel gerar um gr\u00e1fico com os dados fornecidos.\"\n            )\n            return resultado\n\n        # Se n\u00e3o h\u00e1 inten\u00e7\u00e3o de gr\u00e1fico, retorna a resposta original\n        return resultado\n\n    except Exception as e:\n        logger.error(f\"Erro ao processar resposta com gr\u00e1fico: {e}\")\n        return {\n            \"output\": f\"{str(resposta)}\\n\\n[Erro] ao processar gr\u00e1fico: {e}\",\n            \"error\": str(e),\n        }", "mimetype": "text/plain", "start_char_idx": 857, "end_char_idx": 5526, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "dc9fa2c7-02a9-48ad-82c6-783b3f834c9b": {"__data__": {"id_": "dc9fa2c7-02a9-48ad-82c6-783b3f834c9b", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\graph_integration.py", "language": "python", "lines": 160, "filename": "graph_integration.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\graph_integration.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\graph_integration.py", "language": "python", "lines": 160, "filename": "graph_integration.py"}, "hash": "fec170da759553f4d2679a18e5b537da5c53c8783a0a2ab9da42df0f2ffaa1a1", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7c06d9d3-37fa-4df9-a680-9ca51b150821", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\graph_integration.py", "language": "python", "lines": 160, "filename": "graph_integration.py"}, "hash": "b10178a24d68ad57f210766fc9bf451ccbef65be2f11326458415edbdd1ebf22", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "if __name__ == \"__main__\":\n    print(\"Rodando como script...\")\n    \n    # Teste simples da fun\u00e7\u00e3o\n    test_response = {\n        \"output\": \"Por favor, gere um gr\u00e1fico das vendas de tecidos.\",\n        \"data\": [\n            {\"Categoria\": \"Tecidos\", \"Vendas\": 1500},\n            {\"Categoria\": \"Papelaria\", \"Vendas\": 1200},\n            {\"Categoria\": \"Pintura\", \"Vendas\": 800}\n        ]\n    }\n    \n    print(\"Processando resposta de teste...\")\n    result = processar_resposta_com_grafico(test_response)\n    print(\"Resultado:\", result)", "mimetype": "text/plain", "start_char_idx": 5529, "end_char_idx": 6057, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "68b89e98-1ec6-4c40-af62-925e9938a6b1": {"__data__": {"id_": "68b89e98-1ec6-4c40-af62-925e9938a6b1", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\mcp_parquet_tools.py", "language": "python", "lines": 115, "filename": "mcp_parquet_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\mcp_parquet_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\mcp_parquet_tools.py", "language": "python", "lines": 115, "filename": "mcp_parquet_tools.py"}, "hash": "fb3582eef411a87bbaab500cdefff7bc8c39a33c18f1354e25e38becf125003d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5b40b53a-11ae-4e6f-97da-f81ba7a35653", "node_type": "1", "metadata": {}, "hash": "b72ce1840b0dd13fcf5920dd491960146a2c15d7e5b9e60a2b45dc0394ed7b59", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# core/tools/mcp_sql_server_tools.py\nimport os\nimport pandas as pd\nfrom typing import Dict, Any\nfrom langchain_core.tools import tool\nimport logging\n\n# Caminho para o arquivo Parquet - Fonte \u00fanica: Filial_Madureira\nPARQUET_DIR = os.path.join(os.path.dirname(__file__), \"..\", \"..\", \"data\", \"parquet\")\nFILIAL_MADUREIRA_PATH = os.path.join(PARQUET_DIR, \"Filial_Madureira.parquet\")\n\n\n@tool\ndef get_product_data(product_code: str) -> Dict[str, Any]:\n    \"\"\"Busca dados de um produto em Filial_Madureira.parquet.\"\"\"\n    logging.info(f\"Buscando produto: {product_code}\")\n\n    try:\n        if not os.path.exists(FILIAL_MADUREIRA_PATH):\n            logging.error(f\"Arquivo n\u00e3o encontrado: {FILIAL_MADUREIRA_PATH}\")\n            return {\"error\": \"Fonte de dados n\u00e3o encontrada.\"}\n\n        df = pd.read_parquet(FILIAL_MADUREIRA_PATH)\n\n        # Converter para string se a coluna de c\u00f3digo existir\n        if \"CODIGO\" in df.columns:\n            df[\"CODIGO\"] = df[\"CODIGO\"].astype(str)\n            product_code = str(product_code)\n            product_info = df[df[\"CODIGO\"] == product_code]\n        elif \"codigo\" in df.columns:\n            df[\"codigo\"] = df[\"codigo\"].astype(str)\n            product_code = str(product_code)\n            product_info = df[df[\"codigo\"] == product_code]\n        else:\n            return {\"error\": \"Coluna de c\u00f3digo n\u00e3o encontrada.\"}\n\n        if product_info.empty:\n            return {\"data\": f\"Produto n\u00e3o encontrado: {product_code}\"}\n\n        return {\"data\": product_info.to_dict(orient=\"records\")}\n\n    except Exception as e:\n        logging.error(f\"Erro ao buscar produto: {e}\", exc_info=True)\n        return {\"error\": f\"Erro ao buscar dados: {e}\"}\n\n\n@tool\ndef get_product_stock(product_id: int) -> Dict[str, Any]:\n    \"\"\"Retorna dados de um produto espec\u00edfico em Filial_Madureira.\"\"\"\n    logging.info(f\"Buscando dados do produto: {product_id}\")\n    try:\n        if not os.path.exists(FILIAL_MADUREIRA_PATH):\n            logging.error(f\"Arquivo n\u00e3o encontrado: {FILIAL_MADUREIRA_PATH}\")\n            return {\"error\": \"Fonte de dados n\u00e3o encontrada.\"}\n\n        df = pd.read_parquet(FILIAL_MADUREIRA_PATH)\n\n        product_stock_info = df[df[\"PRODUTO\"] == product_id_str]\n\n        if product_stock_info.empty:\n            return {\"data\": f\"Nenhum produto encontrado com o ID {product_id}.\"}\n\n        # Assumindo que a coluna de estoque se chama 'ESTOQUE'\n        stock = product_stock_info[\"ESTOQUE\"].iloc[\n            0\n        ]  # Pega o primeiro valor de estoque encontrado\n        return {\"data\": {\"product_id\": product_id, \"stock\": stock}}\n\n    except Exception as e:\n        logging.error(f\"Erro ao buscar estoque do produto: {e}\", exc_info=True)\n        return {\n            \"error\": f\"Ocorreu um erro inesperado ao buscar o estoque do produto: {e}\"\n        }", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2785, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5b40b53a-11ae-4e6f-97da-f81ba7a35653": {"__data__": {"id_": "5b40b53a-11ae-4e6f-97da-f81ba7a35653", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\mcp_parquet_tools.py", "language": "python", "lines": 115, "filename": "mcp_parquet_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\mcp_parquet_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\mcp_parquet_tools.py", "language": "python", "lines": 115, "filename": "mcp_parquet_tools.py"}, "hash": "fb3582eef411a87bbaab500cdefff7bc8c39a33c18f1354e25e38becf125003d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "68b89e98-1ec6-4c40-af62-925e9938a6b1", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\mcp_parquet_tools.py", "language": "python", "lines": 115, "filename": "mcp_parquet_tools.py"}, "hash": "810c080a01ca227fdf6ea00932db075a10101705f63677b65d9933ab29a6ba0a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "@tool\ndef list_product_categories() -> Dict[str, Any]:\n    \"\"\"\n    Retorna uma lista de todas as categorias de produtos dispon\u00edveis no arquivo Parquet 'Filial_Madureira.parquet'.\n    \"\"\"\n    logging.info(\n        \"Listando categorias de produtos do arquivo Parquet 'Filial_Madureira.parquet'.\"\n    )\n    try:\n        if not os.path.exists(FILIAL_MADUREIRA_PATH):\n            logging.error(f\"Arquivo Parquet n\u00e3o encontrado em: {FILIAL_MADUREIRA_PATH}\")\n            return {\n                \"error\": \"Fonte de dados de produtos (Filial_Madureira.parquet) n\u00e3o encontrada.\"\n            }\n\n        df = pd.read_parquet(FILIAL_MADUREIRA_PATH)\n\n        # Assumindo que a coluna de categoria se chama 'CATEGORIA'\n        if \"CATEGORIA\" not in df.columns:\n            return {\n                \"error\": \"Coluna 'CATEGORIA' n\u00e3o encontrada no arquivo Filial_Madureira.parquet.\"\n            }\n\n        categories = df[\"CATEGORIA\"].unique().tolist()\n        return {\"data\": {\"categories\": categories}}\n\n    except Exception as e:\n        logging.error(f\"Erro ao listar categorias de produtos: {e}\", exc_info=True)\n        return {\n            \"error\": f\"Ocorreu um erro inesperado ao listar categorias de produtos: {e}\"\n        }\n\n\n# A lista de ferramentas agora reflete a nova arquitetura.\nsql_tools = [\n    get_product_data,\n    get_product_stock,\n    list_product_categories,\n]", "mimetype": "text/plain", "start_char_idx": 2788, "end_char_idx": 4154, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f0483fb3-a796-45d3-bc56-bd8df7f1bc3e": {"__data__": {"id_": "f0483fb3-a796-45d3-bc56-bd8df7f1bc3e", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\mcp_sql_server_tools.py", "language": "python", "lines": 122, "filename": "mcp_sql_server_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\mcp_sql_server_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\mcp_sql_server_tools.py", "language": "python", "lines": 122, "filename": "mcp_sql_server_tools.py"}, "hash": "ebb3381e1bbc30d0b02eeb6c689844992a26df5328c4b28b826825c840b60240", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5a0b1bf2-1986-4b95-82b2-90b4d31b46b1", "node_type": "1", "metadata": {}, "hash": "5299f9fb4455361d7562466545e66512a18a781373c09f2b2c637b74a5aa821f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# core/tools/mcp_sql_server_tools.py\nimport os\nimport pandas as pd\nfrom typing import Dict, Any\nfrom langchain_core.tools import tool\nimport logging\n\n# Caminho \u00fanico para Filial_Madureira\nPARQUET_DIR = os.path.join(os.path.dirname(__file__), \"..\", \"..\", \"data\", \"parquet\")\nFILIAL_MADUREIRA_PATH = os.path.join(PARQUET_DIR, \"Filial_Madureira.parquet\")\n\n\n@tool\ndef get_product_data(product_code: str) -> Dict[str, Any]:\n    \"\"\"Busca dados de um produto em Filial_Madureira.parquet.\"\"\"\n    logging.info(f\"Buscando produto: {product_code}\")\n\n    try:\n        if not os.path.exists(FILIAL_MADUREIRA_PATH):\n            logging.error(f\"Arquivo n\u00e3o encontrado: {FILIAL_MADUREIRA_PATH}\")\n            return {\"error\": \"Fonte de dados n\u00e3o encontrada.\"}\n\n        df = pd.read_parquet(FILIAL_MADUREIRA_PATH)\n\n        # Procurar coluna de c\u00f3digo (CODIGO ou codigo)\n        codigo_col = None\n        if \"CODIGO\" in df.columns:\n            codigo_col = \"CODIGO\"\n        elif \"codigo\" in df.columns:\n            codigo_col = \"codigo\"\n\n        if not codigo_col:\n            return {\"error\": \"Coluna de c\u00f3digo n\u00e3o encontrada.\"}\n\n        df[codigo_col] = df[codigo_col].astype(str)\n        product_code = str(product_code)\n        product_info = df[df[codigo_col] == product_code]\n\n        if product_info.empty:\n            return {\"data\": f\"Produto n\u00e3o encontrado: {product_code}\"}\n\n        return {\"data\": product_info.to_dict(orient=\"records\")}\n\n    except Exception as e:\n        logging.error(f\"Erro ao buscar produto: {e}\", exc_info=True)\n        return {\"error\": f\"Erro ao buscar dados: {e}\"}\n\n\n@tool\ndef get_product_stock(product_id: int) -> Dict[str, Any]:\n    \"\"\"Retorna dados de um produto em Filial_Madureira.\"\"\"\n    logging.info(f\"Buscando produto: {product_id}\")\n    try:\n        if not os.path.exists(FILIAL_MADUREIRA_PATH):\n            logging.error(f\"Arquivo n\u00e3o encontrado: {FILIAL_MADUREIRA_PATH}\")\n            return {\"error\": \"Fonte de dados n\u00e3o encontrada.\"}\n\n        df = pd.read_parquet(FILIAL_MADUREIRA_PATH)\n\n        # Procurar coluna de c\u00f3digo\n        codigo_col = None\n        if \"CODIGO\" in df.columns:\n            codigo_col = \"CODIGO\"\n        elif \"codigo\" in df.columns:\n            codigo_col = \"codigo\"\n\n        if not codigo_col:\n            return {\"error\": \"Coluna de c\u00f3digo n\u00e3o encontrada.\"}\n\n        df[codigo_col] = df[codigo_col].astype(str)\n        product_id_str = str(product_id)\n        product_info = df[df[codigo_col] == product_id_str]\n\n        if product_info.empty:\n            return {\"data\": f\"Produto n\u00e3o encontrado: {product_id}\"}\n\n        return {\"data\": product_info.to_dict(orient=\"records\")}\n\n    except Exception as e:\n        logging.error(f\"Erro ao buscar produto: {e}\", exc_info=True)\n        return {\"error\": f\"Erro ao buscar dados: {e}\"}\n\n\n@tool\ndef list_product_categories() -> Dict[str, Any]:\n    \"\"\"Lista categorias dispon\u00edveis em Filial_Madureira.\"\"\"\n    logging.info(\"Listando categorias...\")\n    try:\n        if not os.path.exists(FILIAL_MADUREIRA_PATH):\n            logging.error(f\"Arquivo n\u00e3o encontrado: {FILIAL_MADUREIRA_PATH}\")\n            return {\"error\": \"Fonte de dados n\u00e3o encontrada.\"}\n\n        df = pd.read_parquet(FILIAL_MADUREIRA_PATH)\n\n        # Procurar coluna de categoria\n        cat_col = None\n        for col in df.columns:\n            if \"categoria\" in col.lower() or \"category\" in col.lower():\n                cat_col = col\n                break\n\n        if not cat_col and \"CATEGORIA\" in df.columns:\n            cat_col = \"CATEGORIA\"\n\n        if not cat_col:\n            return {\"error\": \"Coluna de categoria n\u00e3o encontrada.\"}\n\n        categories = df[cat_col].unique().tolist()\n        return {\"data\": {\"categories\": categories}}\n\n    except Exception as e:\n        logging.error(f\"Erro ao listar categorias: {e}\", exc_info=True)\n        return {\"error\": f\"Erro: {e}\"}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3843, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5a0b1bf2-1986-4b95-82b2-90b4d31b46b1": {"__data__": {"id_": "5a0b1bf2-1986-4b95-82b2-90b4d31b46b1", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\mcp_sql_server_tools.py", "language": "python", "lines": 122, "filename": "mcp_sql_server_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\mcp_sql_server_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\mcp_sql_server_tools.py", "language": "python", "lines": 122, "filename": "mcp_sql_server_tools.py"}, "hash": "ebb3381e1bbc30d0b02eeb6c689844992a26df5328c4b28b826825c840b60240", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f0483fb3-a796-45d3-bc56-bd8df7f1bc3e", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\mcp_sql_server_tools.py", "language": "python", "lines": 122, "filename": "mcp_sql_server_tools.py"}, "hash": "2f3a43a38a384b2a5ee4f70c833ce486cf74549de4cca2d102b1dfff2c4a939e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# Lista de ferramentas\nsql_tools = [\n    get_product_data,\n    get_product_stock,\n    list_product_categories,\n]", "mimetype": "text/plain", "start_char_idx": 3846, "end_char_idx": 3958, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f8a3181a-92ca-4872-8773-c0558406f5c9": {"__data__": {"id_": "f8a3181a-92ca-4872-8773-c0558406f5c9", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\quick_response.py", "language": "python", "lines": 159, "filename": "quick_response.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\quick_response.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\quick_response.py", "language": "python", "lines": 159, "filename": "quick_response.py"}, "hash": "96bb5b38e1ed91e95264cba170bde009d79a5c001ca85893e73b8a4017e5fb9c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6123a6bc-6a11-4547-8b01-ed976f4a58bc", "node_type": "1", "metadata": {}, "hash": "7dfe8684a1ecab90e55def4ae9e5cf462a64fb15d2cb3468a14c3b2ddf9eea01", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nSistema de Resposta R\u00e1pida (Quick Response)\nResponde consultas simples SEM usar o LLM para performance m\u00e1xima.\n\nTempo de resposta: < 500ms\nTaxa de acerto: 95%+\n\"\"\"\n\nimport re\nimport logging\nfrom typing import Optional, Union\nimport polars as pl\n\nlogger = logging.getLogger(__name__)\n\n\nclass QuickResponseSystem:\n    \"\"\"Sistema de resposta r\u00e1pida para consultas simples.\"\"\"\n\n    def __init__(self, df: Union[pl.DataFrame, pl.LazyFrame]):\n        # \u2705 OTIMIZA\u00c7\u00c3O: Usar Polars LazyFrame para queries eficientes\n        if isinstance(df, pl.LazyFrame):\n            self.df = df\n        else:\n            self.df = df.lazy()\n        self.logger = logger\n        \n    def try_quick_response(self, query: str) -> Optional[str]:\n        \"\"\"\n        Tenta responder rapidamente sem LLM.\n\n        Args:\n            query: Pergunta do usu\u00e1rio\n\n        Returns:\n            Resposta formatada ou None se n\u00e3o conseguir responder\n        \"\"\"\n        query_lower = query.lower()\n\n        # Extrair c\u00f3digo do produto\n        codigo = self._extract_product_code(query_lower)\n        if not codigo:\n            return None\n\n        # \u2705 Buscar produto usando Polars (eficiente)\n        produto = self.df.filter(pl.col('PRODUTO') == codigo).collect()\n        if produto.height == 0:\n            return f\"\u274c Produto **{codigo}** n\u00e3o encontrado na base de dados.\"\n\n        produto_data = produto.row(0, named=True)\n        \n        # PRE\u00c7O\n        if any(word in query_lower for word in ['pre\u00e7o', 'preco', 'valor', 'custa', 'quanto']):\n            return self._format_price_response(codigo, produto_data)\n        \n        # ESTOQUE\n        if any(word in query_lower for word in ['estoque', 'saldo', 'quantidade', 'tem']):\n            return self._format_stock_response(codigo, produto_data)\n        \n        # FABRICANTE\n        if any(word in query_lower for word in ['fabricante', 'marca', 'quem fabrica']):\n            return self._format_manufacturer_response(codigo, produto_data)\n        \n        # NOME/DESCRI\u00c7\u00c3O\n        if any(word in query_lower for word in ['nome', 'descri\u00e7\u00e3o', 'descricao', 'o que \u00e9', 'qual \u00e9']):\n            return self._format_name_response(codigo, produto_data)\n        \n        # VENDAS\n        if any(word in query_lower for word in ['vendas', 'vendeu', 'venda']):\n            return self._format_sales_response(codigo, produto_data)\n        \n        return None  # Deixa o LLM processar\n    \n    def _extract_product_code(self, query: str) -> Optional[int]:\n        \"\"\"Extrai c\u00f3digo do produto da query.\"\"\"\n        # Padr\u00f5es: \"produto 123\", \"c\u00f3digo 123\", \"item 123\", \"123\"\n        patterns = [\n            r'produto\\s+(\\d+)',\n            r'c\u00f3digo\\s+(\\d+)',\n            r'codigo\\s+(\\d+)',\n            r'item\\s+(\\d+)',\n            r'\\b(\\d{4,})\\b',  # N\u00famero com 4+ d\u00edgitos\n        ]\n        \n        for pattern in patterns:\n            match = re.search(pattern, query)\n            if match:\n                try:\n                    return int(match.group(1))\n                except:\n                    continue\n        \n        return None\n    \n    def _format_price_response(self, codigo: int, produto: dict) -> str:\n        \"\"\"Formata resposta de pre\u00e7o.\"\"\"\n        try:\n            preco = float(produto['LIQUIDO_38'])\n            nome = str(produto.get('NOME', 'N/A'))[:50]\n            return f\"\ud83d\udcb0 O pre\u00e7o do produto **{codigo}** ({nome}) \u00e9 **R$ {preco:.2f}**.\"\n        except:\n            return f\"\u26a0\ufe0f Pre\u00e7o do produto **{codigo}** n\u00e3o dispon\u00edvel.\"\n\n    def _format_stock_response(self, codigo: int, produto: dict) -> str:\n        \"\"\"Formata resposta de estoque.\"\"\"", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3583, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "6123a6bc-6a11-4547-8b01-ed976f4a58bc": {"__data__": {"id_": "6123a6bc-6a11-4547-8b01-ed976f4a58bc", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\quick_response.py", "language": "python", "lines": 159, "filename": "quick_response.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\quick_response.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\quick_response.py", "language": "python", "lines": 159, "filename": "quick_response.py"}, "hash": "96bb5b38e1ed91e95264cba170bde009d79a5c001ca85893e73b8a4017e5fb9c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f8a3181a-92ca-4872-8773-c0558406f5c9", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\quick_response.py", "language": "python", "lines": 159, "filename": "quick_response.py"}, "hash": "997d815b0997f2edaae519a68d5f20610dbfd7c49adea68fdbb3e7911f827d3b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "try:\n            estoque = int(float(produto['ESTOQUE_UNE']))\n            nome = str(produto.get('NOME', 'N/A'))[:50]\n\n            if estoque > 100:\n                emoji = \"\u2705\"\n                status = \"Estoque bom\"\n            elif estoque > 10:\n                emoji = \"\u26a0\ufe0f\"\n                status = \"Estoque baixo\"\n            else:\n                emoji = \"\ud83d\udd34\"\n                status = \"Estoque cr\u00edtico\"\n\n            return f\"{emoji} O produto **{codigo}** ({nome}) tem **{estoque} unidades** em estoque. {status}.\"\n        except:\n            return f\"\u26a0\ufe0f Estoque do produto **{codigo}** n\u00e3o dispon\u00edvel.\"\n\n    def _format_manufacturer_response(self, codigo: int, produto: dict) -> str:\n        \"\"\"Formata resposta de fabricante.\"\"\"\n        try:\n            fabricante = str(produto['NOMEFABRICANTE'])\n            nome = str(produto.get('NOME', 'N/A'))[:50]\n            return f\"\ud83c\udfed O fabricante do produto **{codigo}** ({nome}) \u00e9 **{fabricante}**.\"\n        except:\n            return f\"\u26a0\ufe0f Fabricante do produto **{codigo}** n\u00e3o dispon\u00edvel.\"\n\n    def _format_name_response(self, codigo: int, produto: dict) -> str:\n        \"\"\"Formata resposta de nome/descri\u00e7\u00e3o.\"\"\"\n        try:\n            nome = str(produto['NOME'])\n            fabricante = str(produto.get('NOMEFABRICANTE', 'N/A'))\n            return f\"\ud83d\udce6 O produto **{codigo}** \u00e9: **{nome}** (Fabricante: {fabricante}).\"\n        except:\n            return f\"\u26a0\ufe0f Informa\u00e7\u00f5es do produto **{codigo}** n\u00e3o dispon\u00edveis.\"\n\n    def _format_sales_response(self, codigo: int, produto: dict) -> str:\n        \"\"\"Formata resposta de vendas.\"\"\"\n        try:\n            vendas_30d = float(produto.get('VENDA_30DD', 0))\n            nome = str(produto.get('NOME', 'N/A'))[:50]\n\n            if vendas_30d > 0:\n                return f\"\ud83d\udcca O produto **{codigo}** ({nome}) vendeu **{vendas_30d:.0f} unidades** nos \u00faltimos 30 dias.\"\n            else:\n                return f\"\ud83d\udcca O produto **{codigo}** ({nome}) n\u00e3o teve vendas nos \u00faltimos 30 dias.\"\n        except:\n            return f\"\u26a0\ufe0f Dados de vendas do produto **{codigo}** n\u00e3o dispon\u00edveis.\"\n\n\ndef create_quick_response_system(df: Union[pl.DataFrame, pl.LazyFrame]) -> QuickResponseSystem:\n    \"\"\"Factory function para criar o sistema de resposta r\u00e1pida.\"\"\"\n    return QuickResponseSystem(df)", "mimetype": "text/plain", "start_char_idx": 3592, "end_char_idx": 5868, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b73b4fe5-3127-4629-9e0a-a0d2506f1767": {"__data__": {"id_": "b73b4fe5-3127-4629-9e0a-a0d2506f1767", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\sql_server_tools.py", "language": "python", "lines": 357, "filename": "sql_server_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\sql_server_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\sql_server_tools.py", "language": "python", "lines": 357, "filename": "sql_server_tools.py"}, "hash": "0d7cdfb3a05103e3e035605f2e78ba02d4eaf1071674ee1e46ee700e8901c444", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "75e46973-2e0f-4855-bfae-411ccc0c8d8a", "node_type": "1", "metadata": {}, "hash": "fdc198942c19595e46e3658c6c26900c39b7180f2840d052ab7ba820f89648a6", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nFerramentas para executar consultas SQL Server atrav\u00e9s do agente.\nIntegra\u00e7\u00e3o direta com o banco de dados para respostas em tempo real.\n\"\"\"\n\nimport logging\nfrom typing import Dict, Any\nfrom langchain_core.tools import tool\nfrom app.core.database.database import get_db_manager\nfrom sqlalchemy import text\n\nlogger = logging.getLogger(__name__)\n\n\n@tool\ndef query_database(sql_query: str) -> Dict[str, Any]:\n    \"\"\"\n    Executa uma consulta SQL diretamente no banco de dados.\n\n    Args:\n        sql_query: Consulta SQL para executar\n\n    Returns:\n        Dicion\u00e1rio com os resultados ou erro\n    \"\"\"\n    logger.info(f\"Executando query: {sql_query}\")\n\n    try:\n        db_manager = get_db_manager()\n\n        with db_manager.get_connection() as conn:\n            result = conn.execute(text(sql_query))\n            rows = result.fetchall()\n            columns = result.keys() if rows else []\n\n            if not rows:\n                return {\n                    \"status\": \"success\",\n                    \"message\": \"Nenhum resultado encontrado\",\n                    \"data\": [],\n                }\n\n            # Converter ResultProxy para lista de dicts\n            data = [dict(zip(columns, row)) for row in rows]\n\n            return {\n                \"status\": \"success\",\n                \"message\": f\"{len(data)} registros encontrados\",\n                \"columns\": list(columns),\n                \"data\": data,\n                \"count\": len(data),\n            }\n\n    except Exception as e:\n        logger.error(f\"Erro ao executar query: {e}\", exc_info=True)\n        return {\n            \"status\": \"error\",\n            \"message\": f\"Erro ao executar consulta: {str(e)}\",\n            \"data\": [],\n        }\n\n\n@tool\ndef get_product_by_code(product_code: str) -> Dict[str, Any]:\n    \"\"\"\n    Busca um produto pelo c\u00f3digo na tabela ADMAT_OPCOM.\n\n    Args:\n        product_code: C\u00f3digo do produto\n\n    Returns:\n        Informa\u00e7\u00f5es do produto\n    \"\"\"\n    logger.info(f\"Buscando produto com c\u00f3digo: {product_code}\")\n\n    try:\n        db_manager = get_db_manager()\n        query = \"\"\"\n        SELECT TOP 1\n            CAST([C\u00d3DIGO] AS VARCHAR(50)) as codigo,\n            [NOME] as nome,\n            [PRE\u00c7O 38%] as preco,\n            [FABRICANTE] as fabricante,\n            [EMBALAGEM] as embalagem,\n            [CATEGORIA] as categoria,\n            [GRUPO] as grupo,\n            [SUBGRUPO] as subgrupo,\n            [EST# UNE] as estoque,\n            [ULTIMA_VENDA] as ultima_venda\n        FROM dbo.Admat_OPCOM\n        WHERE CAST([C\u00d3DIGO] AS VARCHAR(50)) = :codigo\n           OR [C\u00d3DIGO] = :codigo_int\n        \"\"\"\n\n        with db_manager.get_connection() as conn:\n            result = conn.execute(\n                text(query),\n                {\n                    \"codigo\": product_code,\n                    \"codigo_int\": int(product_code) if product_code.isdigit() else 0,\n                },\n            )\n            row = result.fetchone()\n\n            if not row:\n                return {\n                    \"status\": \"not_found\",\n                    \"message\": f\"Produto {product_code} n\u00e3o encontrado\",\n                }\n\n            columns = result.keys()\n            data = dict(zip(columns, row))\n\n            return {\"status\": \"success\", \"message\": \"Produto encontrado\", \"data\": data}\n\n    except Exception as e:\n        logger.error(f\"Erro ao buscar produto: {e}\", exc_info=True)\n        return {\"status\": \"error\", \"message\": f\"Erro ao buscar produto: {str(e)}\"}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3459, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "75e46973-2e0f-4855-bfae-411ccc0c8d8a": {"__data__": {"id_": "75e46973-2e0f-4855-bfae-411ccc0c8d8a", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\sql_server_tools.py", "language": "python", "lines": 357, "filename": "sql_server_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\sql_server_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\sql_server_tools.py", "language": "python", "lines": 357, "filename": "sql_server_tools.py"}, "hash": "0d7cdfb3a05103e3e035605f2e78ba02d4eaf1071674ee1e46ee700e8901c444", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b73b4fe5-3127-4629-9e0a-a0d2506f1767", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\sql_server_tools.py", "language": "python", "lines": 357, "filename": "sql_server_tools.py"}, "hash": "7b77fe33472d3a43aa75652d1e6322c69f15f398442d8ce816bc9d19304218f9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8179d88c-e69b-4d4a-bb74-4d40182d5525", "node_type": "1", "metadata": {}, "hash": "cf956c4533d1cab83e269d4a7f6bc8d848538639021415243216c58fc8066559", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "@tool\ndef search_products_by_name(product_name: str, limit: int = 10) -> Dict[str, Any]:\n    \"\"\"\n    Busca produtos pelo nome (parcial) na tabela ADMAT_OPCOM.\n\n    Args:\n        product_name: Nome ou parte do nome do produto\n        limit: N\u00famero m\u00e1ximo de resultados\n\n    Returns:\n        Lista de produtos encontrados\n    \"\"\"\n    logger.info(f\"Buscando produtos com nome contendo: {product_name}\")\n\n    try:\n        db_manager = get_db_manager()\n        query = f\"\"\"\n        SELECT TOP {limit}\n            CAST([C\u00d3DIGO] AS VARCHAR(50)) as codigo,\n            [NOME] as nome,\n            [PRE\u00c7O 38%] as preco,\n            [CATEGORIA] as categoria,\n            [EST# UNE] as estoque\n        FROM dbo.Admat_OPCOM\n        WHERE [NOME] LIKE :search_term\n        ORDER BY [NOME]\n        \"\"\"\n\n        with db_manager.get_connection() as conn:\n            result = conn.execute(text(query), {\"search_term\": f\"%{product_name}%\"})\n            rows = result.fetchall()\n            columns = result.keys() if rows else []\n\n            if not rows:\n                return {\n                    \"status\": \"not_found\",\n                    \"message\": f\"Nenhum produto encontrado com '{product_name}'\",\n                    \"data\": [],\n                }\n\n            data = [dict(zip(columns, row)) for row in rows]\n\n            return {\n                \"status\": \"success\",\n                \"message\": f\"{len(data)} produtos encontrados\",\n                \"data\": data,\n                \"count\": len(data),\n            }\n\n    except Exception as e:\n        logger.error(f\"Erro ao buscar produtos: {e}\", exc_info=True)\n        return {\n            \"status\": \"error\",\n            \"message\": f\"Erro ao buscar produtos: {str(e)}\",\n            \"data\": [],\n        }\n\n\n@tool\ndef get_products_by_category(category: str, limit: int = 20) -> Dict[str, Any]:\n    \"\"\"\n    Busca produtos por categoria.\n\n    Args:\n        category: Nome da categoria\n        limit: N\u00famero m\u00e1ximo de resultados\n\n    Returns:\n        Lista de produtos da categoria\n    \"\"\"\n    logger.info(f\"Buscando produtos da categoria: {category}\")\n\n    try:\n        db_manager = get_db_manager()\n        query = f\"\"\"\n        SELECT TOP {limit}\n            CAST([C\u00d3DIGO] AS VARCHAR(50)) as codigo,\n            [NOME] as nome,\n            [PRE\u00c7O 38%] as preco,\n            [CATEGORIA] as categoria,\n            [GRUPO] as grupo,\n            [EST# UNE] as estoque\n        FROM dbo.Admat_OPCOM\n        WHERE [CATEGORIA] = :category\n        ORDER BY [NOME]\n        \"\"\"\n\n        with db_manager.get_connection() as conn:\n            result = conn.execute(text(query), {\"category\": category})\n            rows = result.fetchall()\n            columns = result.keys() if rows else []\n\n            if not rows:\n                return {\n                    \"status\": \"not_found\",\n                    \"message\": f\"Nenhum produto encontrado na categoria '{category}'\",\n                    \"data\": [],\n                }\n\n            data = [dict(zip(columns, row)) for row in rows]\n\n            return {\n                \"status\": \"success\",\n                \"message\": f\"{len(data)} produtos encontrados\",\n                \"data\": data,\n                \"count\": len(data),\n            }\n\n    except Exception as e:\n        logger.error(f\"Erro ao buscar por categoria: {e}\", exc_info=True)\n        return {\n            \"status\": \"error\",\n            \"message\": f\"Erro ao buscar por categoria: {str(e)}\",\n            \"data\": [],\n        }", "mimetype": "text/plain", "start_char_idx": 3462, "end_char_idx": 6921, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8179d88c-e69b-4d4a-bb74-4d40182d5525": {"__data__": {"id_": "8179d88c-e69b-4d4a-bb74-4d40182d5525", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\sql_server_tools.py", "language": "python", "lines": 357, "filename": "sql_server_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\sql_server_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\sql_server_tools.py", "language": "python", "lines": 357, "filename": "sql_server_tools.py"}, "hash": "0d7cdfb3a05103e3e035605f2e78ba02d4eaf1071674ee1e46ee700e8901c444", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "75e46973-2e0f-4855-bfae-411ccc0c8d8a", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\sql_server_tools.py", "language": "python", "lines": 357, "filename": "sql_server_tools.py"}, "hash": "3c621077e2bd7bbf115a079df019b7b9437b7171c06280e4c68bf06c431d77f2", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "@tool\ndef get_top_selling_products(limit: int = 10) -> Dict[str, Any]:\n    \"\"\"\n    Retorna os produtos mais vendidos nos \u00faltimos 30 dias.\n\n    Args:\n        limit: N\u00famero m\u00e1ximo de resultados\n\n    Returns:\n        Lista dos produtos mais vendidos\n    \"\"\"\n    logger.info(f\"Buscando top {limit} produtos mais vendidos\")\n\n    try:\n        db_manager = get_db_manager()\n        query = f\"\"\"\n        SELECT TOP {limit}\n            CAST([C\u00d3DIGO] AS VARCHAR(50)) as codigo,\n            [NOME] as nome,\n            [VENDA 30D] as vendas_30d,\n            [PRE\u00c7O 38%] as preco,\n            [CATEGORIA] as categoria\n        FROM dbo.Admat_OPCOM\n        WHERE [VENDA 30D] > 0\n        ORDER BY [VENDA 30D] DESC\n        \"\"\"\n\n        with db_manager.get_connection() as conn:\n            result = conn.execute(text(query))\n            rows = result.fetchall()\n            columns = result.keys() if rows else []\n\n            if not rows:\n                return {\n                    \"status\": \"not_found\",\n                    \"message\": \"Nenhum produto com vendas encontrado\",\n                    \"data\": [],\n                }\n\n            data = [dict(zip(columns, row)) for row in rows]\n\n            return {\n                \"status\": \"success\",\n                \"message\": f\"{len(data)} produtos com vendas encontrados\",\n                \"data\": data,\n                \"count\": len(data),\n            }\n\n    except Exception as e:\n        logger.error(f\"Erro ao buscar produtos mais vendidos: {e}\", exc_info=True)\n        return {\n            \"status\": \"error\",\n            \"message\": f\"Erro ao buscar produtos: {str(e)}\",\n            \"data\": [],\n        }\n\n\n@tool\ndef get_product_stock(product_code: str) -> Dict[str, Any]:\n    \"\"\"\n    Retorna o estoque de um produto espec\u00edfico.\n\n    Args:\n        product_code: C\u00f3digo do produto\n\n    Returns:\n        Informa\u00e7\u00f5es de estoque\n    \"\"\"\n    logger.info(f\"Buscando estoque do produto: {product_code}\")\n\n    try:\n        db_manager = get_db_manager()\n        query = \"\"\"\n        SELECT TOP 1\n            CAST([C\u00d3DIGO] AS VARCHAR(50)) as codigo,\n            [NOME] as nome,\n            [EST# UNE] as estoque_unidades,\n            [CATEGORIA] as categoria,\n            [PRE\u00c7O 38%] as preco\n        FROM dbo.Admat_OPCOM\n        WHERE CAST([C\u00d3DIGO] AS VARCHAR(50)) = :codigo\n           OR [C\u00d3DIGO] = :codigo_int\n        \"\"\"\n\n        with db_manager.get_connection() as conn:\n            result = conn.execute(\n                text(query),\n                {\n                    \"codigo\": product_code,\n                    \"codigo_int\": int(product_code) if product_code.isdigit() else 0,\n                },\n            )\n            row = result.fetchone()\n\n            if not row:\n                return {\n                    \"status\": \"not_found\",\n                    \"message\": f\"Produto {product_code} n\u00e3o encontrado\",\n                }\n\n            columns = result.keys()\n            data = dict(zip(columns, row))\n\n            return {\"status\": \"success\", \"message\": \"Estoque encontrado\", \"data\": data}\n\n    except Exception as e:\n        logger.error(f\"Erro ao buscar estoque: {e}\", exc_info=True)\n        return {\"status\": \"error\", \"message\": f\"Erro ao buscar estoque: {str(e)}\"}\n\n\n# Lista de ferramentas SQL Server\nsql_server_tools = [\n    query_database,\n    get_product_by_code,\n    search_products_by_name,\n    get_products_by_category,\n    get_top_selling_products,\n    get_product_stock,\n]", "mimetype": "text/plain", "start_char_idx": 6924, "end_char_idx": 10355, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "62757858-327a-4b9b-9bbf-ce676510dc81": {"__data__": {"id_": "62757858-327a-4b9b-9bbf-ce676510dc81", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\une_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "hash": "6be71c03f1dbd133b8014d5fb2f91199903471679ebe934e02f7f588603f785a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d9a14ce9-69e7-47fd-ae7b-efec0ef36f30", "node_type": "1", "metadata": {}, "hash": "7dcd3d8e359a90cc240382a271e1bad989657e974ec672d1206b622e219da124", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nFerramentas LangChain para opera\u00e7\u00f5es UNE.\nImplementa regras de abastecimento, MC e pol\u00edtica de pre\u00e7os.\n\nEste m\u00f3dulo fornece ferramentas para:\n- C\u00e1lculo de necessidades de abastecimento por UNE\n- Consulta de MC (M\u00e9dia Comum) de produtos\n- C\u00e1lculo de pre\u00e7os finais aplicando pol\u00edtica de pre\u00e7os UNE\n\"\"\"\n\nfrom langchain_core.tools import tool\n\nimport pandas as pd\n\nimport os\n\nimport logging\n\nfrom typing import Dict, Any, List, Optional\n\nfrom functools import lru_cache\n\nfrom pathlib import Path\n\n# Validadores integrados (v3.0) - Ajustado para FastAPI\nfrom app.core.validators.schema_validator import SchemaValidator\nfrom app.core.utils.query_validator import validate_columns, handle_nulls, safe_filter\nfrom app.core.utils.error_handler import error_handler_decorator\n\nlogger = logging.getLogger(__name__)\n\n# Flag para usar HybridAdapter (SQL/Parquet autom\u00e1tico)\nUSE_HYBRID_ADAPTER = os.getenv(\"UNE_USE_HYBRID_ADAPTER\", \"true\").lower() == \"true\"\n\n# Mapeamento de colunas SQL Server \u2192 formato padr\u00e3o\nCOLUMN_MAPPING_SQL = {\n    'PRODUTO': 'codigo',\n    'NOME': 'nome_produto',\n    'UNE': 'une',\n    'ESTOQUE_UNE': 'estoque_atual',\n    'ESTOQUE_LV': 'linha_verde',\n    'MEDIA_CONSIDERADA_LV': 'mc',\n    'VENDA_30DD': 'venda_30_d',\n    'NOMESEGMENTO': 'nomesegmento',\n    'ESTOQUE_CD': 'estoque_cd', # Adicionado mapeamento para estoque_cd\n    'UNE_NOME': 'une_nome', # Added this for consistency\n    'NOMEFABRICANTE': 'nomefabricante', # Added this for consistency\n}\n\n# Mapeamento de colunas Parquet padr\u00e3o \u2192 formato padr\u00e3o\nCOLUMN_MAPPING_PARQUET = {\n    'estoque_lv': 'linha_verde',\n    'media_considerada_lv': 'mc',\n}\n\n@lru_cache(maxsize=1)\ndef _get_data_adapter():\n    \"\"\"Retorna adapter de dados (HybridAdapter ou Parquet direto) com cache\"\"\"\n    global USE_HYBRID_ADAPTER\n\n    if USE_HYBRID_ADAPTER:\n        try:\n            from app.infrastructure.data.hybrid_adapter import HybridDataAdapter\n            adapter = HybridDataAdapter()\n            logger.info(f\"Usando HybridAdapter - fonte: {adapter.current_source}\")\n            return adapter\n        except Exception as e:\n            logger.warning(f\"Erro ao inicializar HybridAdapter: {e}, usando Parquet direto\")\n            USE_HYBRID_ADAPTER = False\n\n    # Fallback: usar Parquet direto\n    PARQUET_PATH_EXTENDED = os.path.join(os.getcwd(), \"data\", \"parquet\", \"admmat_extended.parquet\")\n    PARQUET_PATH_DEFAULT = os.path.join(os.getcwd(), \"data\", \"parquet\", \"admmat.parquet\")\n\n    if os.path.exists(PARQUET_PATH_EXTENDED):\n        return {'type': 'parquet', 'path': PARQUET_PATH_EXTENDED, 'extended': True}\n    else:\n        return {'type': 'parquet', 'path': PARQUET_PATH_DEFAULT, 'extended': False}\n\ndef _normalize_dataframe(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"Normaliza DataFrame para ter colunas consistentes independente da fonte\"\"\"\n    # Verificar se precisa mapear colunas SQL\n    if 'PRODUTO' in df.columns:\n        # Dados vieram do SQL Server\n        for sql_col, std_col in COLUMN_MAPPING_SQL.items():\n            if sql_col in df.columns and std_col not in df.columns:\n                df[std_col] = df[sql_col]\n\n    # Verificar se precisa mapear colunas Parquet padr\u00e3o\n    for parquet_col, std_col in COLUMN_MAPPING_PARQUET.items():\n        if parquet_col in df.columns and std_col not in df.columns:\n            df[std_col] = df[parquet_col]\n\n    # Mapear colunas do Parquet para nomes padronizados\n    # (mapeamento reverso do que \u00e9 feito em _load_data)\n    if 'media_considerada_lv' in df.columns and 'mc' not in df.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3501, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d9a14ce9-69e7-47fd-ae7b-efec0ef36f30": {"__data__": {"id_": "d9a14ce9-69e7-47fd-ae7b-efec0ef36f30", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\une_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "hash": "6be71c03f1dbd133b8014d5fb2f91199903471679ebe934e02f7f588603f785a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "62757858-327a-4b9b-9bbf-ce676510dc81", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "hash": "7ca8315a64b04cdb381b5afaba7ff4f30966af28af4033c330622ef006848830", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "41fd96d5-44f4-478d-967f-8c644d2fdbf4", "node_type": "1", "metadata": {}, "hash": "1a814b310fb4a1189b69b4e618d88df85a811534211cb62ad500fd124b36f805", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "columns and 'mc' not in df.columns:\n        df['mc'] = df['media_considerada_lv']\n\n    if 'estoque_lv' in df.columns and 'linha_verde' not in df.columns:\n        df['linha_verde'] = df['estoque_lv']\n\n    if 'estoque_gondola_lv' in df.columns and 'estoque_gondola' not in df.columns:\n        df['estoque_gondola'] = df['estoque_gondola_lv']\n\n    return df\n\ndef _load_data(filters: Dict[str, Any] = None, columns: List[str] = None) -> pd.DataFrame:\n    \"\"\"\n    Carrega dados usando adapter apropriado (SQL ou Parquet) com valida\u00e7\u00e3o\n\n    Args:\n        filters: Filtros a aplicar (ex: {'une': 2586, 'codigo': 369947})\n        columns: Colunas espec\u00edficas a carregar (otimiza\u00e7\u00e3o)\n\n    Returns:\n        DataFrame normalizado e validado\n    \"\"\"\n    adapter = _get_data_adapter()\n\n    # Validar schema se for Parquet direto\n    if isinstance(adapter, dict):\n        validator = SchemaValidator()\n        # Pass the specific parquet file name to the validator\n        parquet_file_stem = Path(adapter['path']).stem\n        is_valid, errors = validator.validate_parquet_file(adapter['path'], table_name=parquet_file_stem)\n        if not is_valid:\n            logger.error(f\"Schema inv\u00e1lido: {errors}\")\n            raise ValueError(f\"Schema do arquivo Parquet inv\u00e1lido: {errors}\")\n\n    # Create reverse mappings (moved outside if columns block)\n    # PRIMEIRO: Mapeamentos padr\u00e3o Parquet (lowercase)\n    reverse_mapping = {v: k for k, v in COLUMN_MAPPING_PARQUET.items()}\n    # SEGUNDO: Mapeamentos SQL (Uppercase) - Sobrescreve anteriores para priorizar Uppercase (admmat.parquet)\n    for k, v in COLUMN_MAPPING_SQL.items():\n        reverse_mapping[v] = k\n\n    # Mapear COLUNAS solicitadas\n    parquet_cols_to_load = None\n    if columns:\n        parquet_cols_to_load = []\n        for col in columns:\n            if col in reverse_mapping:\n                parquet_cols_to_load.append(reverse_mapping[col])\n            elif col == 'linha_verde':\n                parquet_cols_to_load.append('ESTOQUE_LV')\n            elif col == 'mc':\n                parquet_cols_to_load.append('MEDIA_CONSIDERADA_LV')\n            elif col in ['estoque_gondola_lv', 'ESTOQUE_GONDOLA', 'estoque_gondola']:\n                parquet_cols_to_load.append('ESTOQUE_GONDOLA_LV')\n            else:\n                parquet_cols_to_load.append(col)\n        # Unique\n        parquet_cols_to_load = list(set([c for c in parquet_cols_to_load if c]))\n    \n    # Mapear FILTROS solicitados\n    duckdb_filters = {}\n    if filters:\n        for col, val in filters.items():\n            mapped_col = col\n            if col in reverse_mapping:\n                mapped_col = reverse_mapping[col]\n            elif col == 'linha_verde':\n                mapped_col = 'ESTOQUE_LV'\n            elif col == 'mc':\n                mapped_col = 'MEDIA_CONSIDERADA_LV'\n            \n            duckdb_filters[mapped_col] = val\n\n    try:\n        from app.infrastructure.data.duckdb_adapter import duckdb_adapter\n        logger.info(f\"\ud83d\ude80 DuckDB Load: Cols={len(parquet_cols_to_load) if parquet_cols_to_load else 'All'}, Filters={list(duckdb_filters.keys())}\")\n        \n        df = duckdb_adapter.load_data(\n            columns=parquet_cols_to_load,\n            filters=duckdb_filters\n        )\n        \n        logger.info(f\"\u2705 DuckDB carregou {len(df)} registros\")\n\n    except Exception as e:\n        logger.error(f\"Erro Cr\u00edtico no DuckDB: {e}\", exc_info=True)\n        # Fallback de emerg\u00eancia (apenas se DuckDB falhar, o que \u00e9 raro)\n        # Tentar ler com pandas puro sem filtros\n        logger.warning(\"\u26a0\ufe0f Tentando fallback para pd.read_parquet (lento)...\")\n        PARQUET_PATH_DEFAULT = os.path.join(os.getcwd(), \"data\", \"parquet\", \"admmat.parquet\")\n        df = pd.read_parquet(PARQUET_PATH_DEFAULT,", "mimetype": "text/plain", "start_char_idx": 3474, "end_char_idx": 7216, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "41fd96d5-44f4-478d-967f-8c644d2fdbf4": {"__data__": {"id_": "41fd96d5-44f4-478d-967f-8c644d2fdbf4", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\une_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "hash": "6be71c03f1dbd133b8014d5fb2f91199903471679ebe934e02f7f588603f785a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d9a14ce9-69e7-47fd-ae7b-efec0ef36f30", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "hash": "92029866abb2446a887e2d64a07c89c1a7e65e57589d411468789ddbd704c3a1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f9ad5787-cd9a-4268-8aaf-9dd8da2c81f2", "node_type": "1", "metadata": {}, "hash": "b1ab02a74e6655e2d8244db5140b5f8cb78380a3812a99a9d9298455b4777abd", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "parquet\")\n        df = pd.read_parquet(PARQUET_PATH_DEFAULT, columns=parquet_cols_to_load)\n        # Aplicar filtros manualmente\n        if duckdb_filters:\n            for col, val in duckdb_filters.items():\n                 if col in df.columns:\n                     if isinstance(val, list):\n                         df = df[df[col].isin(val)]\n                     else:\n                         df = df[df[col] == val]\n\n    # Normalizar colunas\n    df = _normalize_dataframe(df)\n\n    # Tratar nulls com validador (mais robusto)\n    for col in ['estoque_atual', 'linha_verde', 'mc', 'venda_30_d']:\n        if col in df.columns:\n            df = handle_nulls(df, col, strategy=\"fill\", fill_value=0)\n\n    # Converter tipos com seguran\u00e7a (usando pandas)\n    for col in ['estoque_atual', 'linha_verde', 'mc', 'venda_30_d']:\n        if col in df.columns:\n            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n\n    return df\n\n\n@tool\n@error_handler_decorator(\n    context_func=lambda une_id, segmento=None: {\"une_id\": une_id, \"segmento\": segmento, \"funcao\": \"calcular_abastecimento_une\"},\n    return_on_error={\"error\": \"Erro ao calcular abastecimento\", \"total_produtos\": 0, \"produtos\": []}\n)\ndef calcular_abastecimento_une(une_id: int, segmento: str = None) -> Dict[str, Any]:\n    \"\"\"\n    Calcula produtos que precisam de abastecimento em uma UNE.\n\n    Regra aplicada: ESTOQUE_UNE <= 50% LINHA_VERDE\n\n    Args:\n        une_id: ID da UNE (1-10)\n        segmento: Filtro opcional por segmento (ex: \"TECIDOS\", \"PAPELARIA\")\n\n    Returns:\n        dict com:\n        - total_produtos: int (total de produtos que precisam abastecimento)\n        - produtos: list[dict] (top 20 produtos ordenados por qtd_a_abastecer DESC)\n        - regra_aplicada: str (descri\u00e7\u00e3o da regra de abastecimento)\n        - une_id: int\n        - segmento: str (se aplicado)\n\n    Example:\n        >>> result = calcular_abastecimento_une(une_id=1, segmento=\"TECIDOS\")\n        >>> print(f\"Total produtos: {result['total_produtos']}\")\n    \"\"\"\n    # Valida\u00e7\u00e3o de inputs\n    if not isinstance(une_id, int) or une_id <= 0:\n        return {\"error\": \"une_id deve ser um inteiro positivo\"}\n\n    # Carregar dados com valida\u00e7\u00e3o integrada\n    logger.info(f\"Carregando dados de abastecimento para UNE {une_id}\")\n    df = _load_data(filters={'une': une_id})\n\n    # Verificar se dataframe n\u00e3o est\u00e1 vazio\n    if df.empty:\n        logger.warning(f\"Query retornou 0 linhas para UNE {une_id}\")\n        return {\n            \"error\": f\"Nenhum dado encontrado para UNE {une_id}\",\n            \"une_id\": une_id,\n            \"total_produtos\": 0,\n            \"produtos\": []\n        }\n\n    # Normalizar DataFrame (garantir mapeamento de colunas SQL -> padr\u00e3o)\n    df = _normalize_dataframe(df)\n\n    # Validar colunas necess\u00e1rias\n    required_cols = ['une', 'codigo', 'nome_produto', 'estoque_atual', 'linha_verde']\n    is_valid, missing = validate_columns(df, required_cols)\n    if not is_valid:\n        logger.error(f\"Colunas dispon\u00edveis: {list(df.columns)}\")\n        logger.error(f\"Colunas faltantes: {missing}\")\n        return {\n            \"error\": f\"Colunas ausentes ap\u00f3s normaliza\u00e7\u00e3o: {missing}\",\n            \"colunas_disponiveis\": list(df.columns),\n            \"une_id\": une_id\n        }\n\n    # Calcular colunas derivadas se n\u00e3o existirem\n    if 'precisa_abastecimento' not in df.columns:\n        logger.", "mimetype": "text/plain", "start_char_idx": 7156, "end_char_idx": 10519, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f9ad5787-cd9a-4268-8aaf-9dd8da2c81f2": {"__data__": {"id_": "f9ad5787-cd9a-4268-8aaf-9dd8da2c81f2", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\une_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "hash": "6be71c03f1dbd133b8014d5fb2f91199903471679ebe934e02f7f588603f785a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "41fd96d5-44f4-478d-967f-8c644d2fdbf4", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "hash": "f0575e15245f5d63e96ebcf0212a7af77c711893129716f2622bc306b6c6a8b2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "082afb91-c0cf-409a-b54b-1ea23be69480", "node_type": "1", "metadata": {}, "hash": "c19c8bcbc5216eeb5df75797327c19cff167159ffcaac1286a5adcc87481aa88", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "columns:\n        logger.info(\"Calculando coluna 'precisa_abastecimento' (n\u00e3o encontrada nos dados)\")\n        # Regra: ESTOQUE_UNE <= 50% LINHA_VERDE\n        df['precisa_abastecimento'] = (df['estoque_atual'] <= (df['linha_verde'] * 0.5))\n\n    if 'qtd_a_abastecer' not in df.columns:\n        logger.info(\"Calculando coluna 'qtd_a_abastecer' (n\u00e3o encontrada nos dados)\")\n        # Quantidade a abastecer = LINHA_VERDE - ESTOQUE_ATUAL (se positivo)\n        df['qtd_a_abastecer'] = (df['linha_verde'] - df['estoque_atual']).clip(lower=0)\n\n    # Filtrar por UNE com seguran\u00e7a\n    df_une = df[df['une'] == une_id]\n\n    if df_une.empty:\n        return {\n            \"error\": f\"Nenhum produto encontrado para UNE {une_id}\",\n            \"une_id\": une_id\n        }\n\n    # Filtrar por segmento (se fornecido)\n    if segmento:\n        if 'nomesegmento' in df_une.columns:\n            df_une = df_une[\n                df_une['nomesegmento'].str.contains(segmento, case=False, na=False)\n            ]\n            if df_une.empty:\n                return {\n                    \"error\": f\"Nenhum produto encontrado para segmento '{segmento}' na UNE {une_id}\",\n                    \"une_id\": une_id,\n                    \"segmento\": segmento\n                }\n        else:\n            logger.warning(\"Coluna 'nomesegmento' n\u00e3o encontrada no dataset\")\n\n    # Filtrar produtos que precisam abastecimento\n    # (coluna j\u00e1 foi calculada anteriormente se n\u00e3o existia)\n    df_abastecer = df_une[df_une['precisa_abastecimento'] == True].copy()\n\n    total_produtos = len(df_abastecer)\n\n    if total_produtos == 0:\n        return {\n            \"total_produtos\": 0,\n            \"produtos\": [],\n            \"regra_aplicada\": \"ESTOQUE_UNE <= 50% LINHA_VERDE\",\n            \"une_id\": une_id,\n            \"segmento\": segmento if segmento else \"Todos\",\n            \"mensagem\": \"Nenhum produto precisa de abastecimento no momento\"\n        }\n\n    # Ordenar por qtd_a_abastecer DESC e pegar top 20\n    df_abastecer = df_abastecer.sort_values('qtd_a_abastecer', ascending=False)\n    top_20 = df_abastecer.head(20)\n\n    # Preparar lista de produtos\n    produtos = []\n    for _, row in top_20.iterrows():\n        produto = {\n            \"codigo\": int(row['codigo']) if pd.notna(row['codigo']) else None,\n            \"nome_produto\": str(row['nome_produto']) if pd.notna(row['nome_produto']) else \"N/A\",\n            \"segmento\": str(row['nomesegmento']) if 'nomesegmento' in row and pd.notna(row['nomesegmento']) else \"N/A\",\n            \"estoque_atual\": float(row['estoque_atual']) if pd.notna(row['estoque_atual']) else 0.0,\n            \"linha_verde\": float(row['linha_verde']) if pd.notna(row['linha_verde']) else 0.0,\n            \"qtd_a_abastecer\": float(row['qtd_a_abastecer']) if pd.notna(row['qtd_a_abastecer']) else 0.0,\n            \"percentual_estoque\": round((float(row['estoque_atual']) / float(row['linha_verde']) * 100), 2) if pd.notna(row['linha_verde']) and row['linha_verde'] > 0 else 0.0\n        }\n        produtos.append(produto)\n\n    logger.info(f\"Encontrados {total_produtos} produtos para abastecimento na UNE {une_id}\")\n\n    return {\n        \"total_produtos\": total_produtos,\n        \"produtos\": produtos,\n        \"regra_aplicada\": \"ESTOQUE_UNE <= 50% LINHA_VERDE\",\n        \"une_id\": une_id,\n        \"segmento\": segmento if segmento else \"Todos\"\n    }", "mimetype": "text/plain", "start_char_idx": 10495, "end_char_idx": 13823, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "082afb91-c0cf-409a-b54b-1ea23be69480": {"__data__": {"id_": "082afb91-c0cf-409a-b54b-1ea23be69480", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\une_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "hash": "6be71c03f1dbd133b8014d5fb2f91199903471679ebe934e02f7f588603f785a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f9ad5787-cd9a-4268-8aaf-9dd8da2c81f2", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "hash": "1614d2f3d1e63bd7b2db2ffa5db9fc6cd6b15b52a41fb9e49c7083ff8efd44ee", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e32aece9-bd76-4b6f-b0f3-a9109da53fd3", "node_type": "1", "metadata": {}, "hash": "1e6b67d3a1c9ed8882f529e614bdc9f980c48cba338cdf0a190c8a92c270ab6b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"segmento\": segmento if segmento else \"Todos\"\n    }\n\n\n@tool\ndef calcular_mc_produto(produto_id: int, une_id: int) -> Dict[str, Any]:\n    \"\"\"\n    Retorna informa\u00e7\u00f5es de MC (M\u00e9dia Comum) de um produto em uma UNE espec\u00edfica.\n\n    A MC representa a m\u00e9dia de vendas do produto, usada para dimensionar\n    o estoque adequado em g\u00f4ndola.\n\n    Args:\n        produto_id: C\u00f3digo do produto\n        une_id: ID da UNE (1-10)\n\n    Returns:\n        dict com:\n        - produto_id: int\n        - nome: str\n        - segmento: str\n        - mc_calculada: float (M\u00e9dia Comum)\n        - estoque_atual: float\n        - linha_verde: float (estoque m\u00e1ximo)\n        - estoque_gondola: float (se existir na base)\n        - percentual_linha_verde: float (% do estoque em rela\u00e7\u00e3o \u00e0 linha verde)\n        - recomendacao: str (orienta\u00e7\u00e3o de abastecimento)\n\n    Example:\n        >>> result = calcular_mc_produto(produto_id=12345, une_id=1)\n        >>> print(f\"MC: {result['mc_calculada']}, Recomenda\u00e7\u00e3o: {result['recomendacao']}\")\n    \"\"\"\n    try:\n        # Valida\u00e7\u00e3o de inputs\n        if not isinstance(produto_id, int) or produto_id <= 0:\n            return {\"error\": \"produto_id deve ser um inteiro positivo\"}\n\n        if not isinstance(une_id, int) or une_id <= 0:\n            return {\"error\": \"une_id deve ser um inteiro positivo\"}\n\n        # Carregar dados usando _load_data() com filtros (padr\u00e3o refatorado)\n        logger.info(f\"Buscando MC do produto {produto_id} na UNE {une_id}\")\n        # CORRE\u00c7\u00c3O: Remover colunas ESTOQUE_GONDOLA/estoque_gondola que n\u00e3o existem no Parquet\n        # Usar estoque_gondola_lv que existe no Parquet\n        produto_df = _load_data(\n            filters={'codigo': produto_id, 'une': une_id},\n            columns=['codigo', 'nome_produto', 'une', 'mc', 'estoque_atual',\n                    'linha_verde', 'nomesegmento', 'estoque_gondola_lv']\n        )\n\n        if produto_df.empty:\n            return {\n                \"error\": f\"Produto {produto_id} n\u00e3o encontrado na UNE {une_id}\",\n                \"produto_id\": produto_id,\n                \"une_id\": une_id\n            }\n\n        # Pegar primeira linha (deve ser \u00fanica)\n        row = produto_df.iloc[0]\n\n        # Extrair dados\n        mc_calculada = float(row['mc']) if pd.notna(row['mc']) else 0.0\n        estoque_atual = float(row['estoque_atual']) if pd.notna(row['estoque_atual']) else 0.0\n        linha_verde = float(row['linha_verde']) if pd.notna(row['linha_verde']) else 0.0\n\n        # Estoque g\u00f4ndola (usar estoque_gondola_lv que existe no Parquet)\n        estoque_gondola = None\n        if 'estoque_gondola_lv' in row:\n            estoque_gondola = float(row['estoque_gondola_lv']) if pd.notna(row['estoque_gondola_lv']) else 0.0\n        elif 'ESTOQUE_GONDOLA' in row:\n            estoque_gondola = float(row['ESTOQUE_GONDOLA']) if pd.notna(row['ESTOQUE_GONDOLA']) else 0.0\n        elif 'estoque_gondola' in row:\n            estoque_gondola = float(row['estoque_gondola']) if pd.notna(row['estoque_gondola']) else 0.0\n\n        # Calcular percentual da linha verde\n        percentual_linha_verde = 0.0\n        if linha_verde > 0:\n            percentual_linha_verde = round((estoque_atual / linha_verde) * 100,", "mimetype": "text/plain", "start_char_idx": 13772, "end_char_idx": 16956, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e32aece9-bd76-4b6f-b0f3-a9109da53fd3": {"__data__": {"id_": "e32aece9-bd76-4b6f-b0f3-a9109da53fd3", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\une_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "hash": "6be71c03f1dbd133b8014d5fb2f91199903471679ebe934e02f7f588603f785a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "082afb91-c0cf-409a-b54b-1ea23be69480", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "hash": "54ab6caa0281ea391f0c20e729a266f6867a4f1fa442babc798e9a236bc47e95", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7e939a50-9468-4b1f-93d2-3723297d305d", "node_type": "1", "metadata": {}, "hash": "369619784142efde2e3c9a38ba7b24d4bf970fceee5b6ca3cc255d1c71dfec9b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2)\n\n        # Gerar recomenda\u00e7\u00e3o\n        recomendacao = \"Manter estoque atual\"\n\n        if estoque_gondola is not None and mc_calculada > estoque_gondola:\n            recomendacao = \"Aumentar ESTOQUE em g\u00f4ndola - MC superior ao estoque atual\"\n        elif percentual_linha_verde < 50:\n            recomendacao = \"URGENTE: Abastecer produto - Estoque abaixo de 50% da linha verde\"\n        elif percentual_linha_verde < 75:\n            recomendacao = \"ATEN\u00c7\u00c3O: Planejar abastecimento - Estoque entre 50% e 75% da linha verde\"\n        elif percentual_linha_verde > 100:\n            recomendacao = \"ALERTA: Estoque acima da linha verde - Verificar dimensionamento\"\n\n        resultado = {\n            \"produto_id\": int(produto_id),\n            \"une_id\": int(une_id),\n            \"nome\": str(row['nome_produto']) if pd.notna(row['nome_produto']) else \"N/A\",\n            \"segmento\": str(row['nomesegmento']) if 'nomesegmento' in row and pd.notna(row['nomesegmento']) else \"N/A\",\n            \"mc_calculada\": mc_calculada,\n            \"estoque_atual\": estoque_atual,\n            \"linha_verde\": linha_verde,\n            \"percentual_linha_verde\": percentual_linha_verde,\n            \"recomendacao\": recomendacao\n        }\n\n        # Adicionar estoque_gondola se existir\n        if estoque_gondola is not None:\n            resultado[\"estoque_gondola\"] = estoque_gondola\n\n        logger.info(f\"MC calculada para produto {produto_id}: {mc_calculada}\")\n\n        return resultado\n\n    except Exception as e:\n        logger.error(f\"Erro em calcular_mc_produto: {e}\", exc_info=True)\n        return {\"error\": f\"Erro ao calcular MC do produto: {str(e)}\"}\n\n\n@tool\ndef calcular_preco_final_une(valor_compra: float, ranking: int, forma_pagamento: str) -> Dict[str, Any]:\n    \"\"\"\n    Calcula pre\u00e7o final aplicando pol\u00edtica de pre\u00e7os UNE.\n\n    Regras de Tipo de Pre\u00e7o:\n    - Valor >= R$ 750,00 \u2192 Pre\u00e7o Atacado\n    - Valor < R$ 750,00 \u2192 Pre\u00e7o Varejo\n\n    Pol\u00edtica por Ranking:\n    - Ranking 0: Atacado 38%, Varejo 30%\n    - Ranking 1: Pre\u00e7o \u00fanico 38% (independente do valor)\n    - Ranking 2: Atacado 38%, Varejo 30%\n    - Ranking 3: Sem desconto (pre\u00e7o tabela)\n    - Ranking 4: Atacado 38%, Varejo 24%\n\n    Desconto por Forma de Pagamento:\n    - 'vista': 38%\n    - '30d': 36%\n    - '90d': 34%\n    - '120d': 30%\n\n    Args:\n        valor_compra: Valor total da compra em reais\n        ranking: Classifica\u00e7\u00e3o do produto (0-4)\n        forma_pagamento: Tipo de pagamento ('vista', '30d', '90d', '120d')\n\n    Returns:\n        dict com:\n        - valor_original: float\n        - tipo: str (\"Atacado\" ou \"Varejo\")\n        - ranking: int\n        - desconto_ranking: str (percentual aplicado pelo ranking)\n        - forma_pagamento: str\n        - desconto_pagamento: str (percentual por forma de pagamento)\n        - preco_final: float\n        - economia: float (valor economizado)\n        - detalhamento: str (explica\u00e7\u00e3o do c\u00e1lculo)\n\n    Example:\n        >>> result = calcular_preco_final_une(valor_compra=1000.0, ranking=0, forma_pagamento='vista')\n        >>> print(f\"Pre\u00e7o final: R$ {result['preco_final']:.2f}\")\n    \"\"\"\n    try:\n        # Valida\u00e7\u00e3o de inputs\n        if not isinstance(valor_compra, (int, float)) or valor_compra <= 0:\n            return {\"error\": \"valor_compra deve ser um n\u00famero positivo\"}\n\n        if not isinstance(ranking,", "mimetype": "text/plain", "start_char_idx": 16957, "end_char_idx": 20269, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7e939a50-9468-4b1f-93d2-3723297d305d": {"__data__": {"id_": "7e939a50-9468-4b1f-93d2-3723297d305d", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\une_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "hash": "6be71c03f1dbd133b8014d5fb2f91199903471679ebe934e02f7f588603f785a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e32aece9-bd76-4b6f-b0f3-a9109da53fd3", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "hash": "b1c9cd1215f32d976c901cc407e784e52c8077fa404a962b78cc39c4b0440393", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f0ee5031-178d-417e-b4c8-0256bd849e5c", "node_type": "1", "metadata": {}, "hash": "0b7f4970a40a239e88b9e419971aa5d8b08085a7ebf94ee9b920fd1db85a243f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "int) or ranking < 0 or ranking > 4:\n            return {\"error\": \"ranking deve ser um inteiro entre 0 e 4\"}\n\n        formas_validas = ['vista', '30d', '90d', '120d']\n        if forma_pagamento not in formas_validas:\n            return {\"error\": f\"forma_pagamento deve ser uma das op\u00e7\u00f5es: {', '.join(formas_validas)}\"}\n\n        valor_original = float(valor_compra)\n\n        # Determinar tipo de pre\u00e7o (Atacado ou Varejo)\n        tipo_preco = \"Atacado\" if valor_compra >= 750.0 else \"Varejo\"\n\n        # Definir desconto por ranking\n        desconto_ranking_percent = 0.0\n\n        if ranking == 0:\n            desconto_ranking_percent = 38.0 if tipo_preco == \"Atacado\" else 30.0\n        elif ranking == 1:\n            desconto_ranking_percent = 38.0  # Pre\u00e7o \u00fanico\n            tipo_preco = \"\u00danico\"  # Override para ranking 1\n        elif ranking == 2:\n            desconto_ranking_percent = 38.0 if tipo_preco == \"Atacado\" else 30.0\n        elif ranking == 3:\n            desconto_ranking_percent = 0.0  # Sem desconto\n        elif ranking == 4:\n            desconto_ranking_percent = 38.0 if tipo_preco == \"Atacado\" else 24.0\n\n        # Aplicar desconto do ranking\n        valor_apos_ranking = valor_original * (1 - desconto_ranking_percent / 100)\n\n        # Definir desconto por forma de pagamento\n        descontos_pagamento = {\n            'vista': 38.0,\n            '30d': 36.0,\n            '90d': 34.0,\n            '120d': 30.0\n        }\n\n        desconto_pagamento_percent = descontos_pagamento[forma_pagamento]\n\n        # Aplicar desconto de forma de pagamento sobre o valor ap\u00f3s desconto de ranking\n        valor_final = valor_apos_ranking * (1 - desconto_pagamento_percent / 100)\n\n        # Calcular economia total\n        economia = valor_original - valor_final\n\n        # Gerar detalhamento do c\u00e1lculo\n        detalhamento_partes = [\n            f\"Valor original: R$ {valor_original:.2f}\",\n            f\"Tipo de pre\u00e7o: {tipo_preco} (valor {'>=' if valor_compra >= 750 else '<'} R$ 750,00)\"\n        ]\n\n        if desconto_ranking_percent > 0:\n            detalhamento_partes.append(\n                f\"Desconto ranking {ranking}: {desconto_ranking_percent}% -> R$ {valor_apos_ranking:.2f}\"\n            )\n        else:\n            detalhamento_partes.append(\n                f\"Ranking {ranking}: Sem desconto (pre\u00e7o tabela)\"\n            )\n\n        detalhamento_partes.append(\n            f\"Desconto pagamento ({forma_pagamento}): {desconto_pagamento_percent}% -> R$ {valor_final:.2f}\"\n        )\n        detalhamento_partes.append(\n            f\"Economia total: R$ {economia:.2f} ({(economia/valor_original)*100:.2f}%)\"\n        )\n\n        detalhamento = \" | \".join(detalhamento_partes)\n\n        logger.info(\n            f\"Pre\u00e7o calculado: R$ {valor_original:.2f} -> R$ {valor_final:.2f} \"\n            f\"(Ranking {ranking}, {forma_pagamento})\"\n        )\n\n        return {\n            \"valor_original\": round(valor_original, 2),\n            \"tipo\": tipo_preco,\n            \"ranking\": ranking,\n            \"desconto_ranking\": f\"{desconto_ranking_percent}%\" if desconto_ranking_percent > 0 else \"Sem desconto\",\n            \"forma_pagamento\": forma_pagamento,\n            \"desconto_pagamento\": f\"{desconto_pagamento_percent}%\",\n            \"preco_final\": round(valor_final, 2),\n            \"economia\": round(economia, 2),\n            \"percentual_economia\": round((economia / valor_original) * 100, 2),\n            \"detalhamento\": detalhamento\n        }\n\n    except Exception as e:\n        logger.error(f\"Erro em calcular_preco_final_une: {e}\",", "mimetype": "text/plain", "start_char_idx": 20270, "end_char_idx": 23813, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f0ee5031-178d-417e-b4c8-0256bd849e5c": {"__data__": {"id_": "f0ee5031-178d-417e-b4c8-0256bd849e5c", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\une_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "hash": "6be71c03f1dbd133b8014d5fb2f91199903471679ebe934e02f7f588603f785a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7e939a50-9468-4b1f-93d2-3723297d305d", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "hash": "a05c096f7da64f88b6335ba7fce586ebbc456dfe5aa7ee5f1f33d5e0806a1e92", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e0ed09dc-b984-4e76-9419-03dad06b2817", "node_type": "1", "metadata": {}, "hash": "a6b66097176d0ef5932cd7e45b890f7cd96a1a4df9140528d42bef4672e9519d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "error(f\"Erro em calcular_preco_final_une: {e}\", exc_info=True)\n        return {\"error\": f\"Erro ao calcular pre\u00e7o final: {str(e)}\"}\n\n\n@tool\ndef validar_transferencia_produto(\n    produto_id: int,\n    une_origem: int,\n    une_destino: int,\n    quantidade: int\n) -> Dict[str, Any]:\n    \"\"\"\n    Valida se uma transfer\u00eancia de produto entre UNEs \u00e9 vi\u00e1vel e recomendada.\n\n    Aplica regras de neg\u00f3cio para verificar:\n    - Se UNE origem tem estoque suficiente\n    - Se UNE destino realmente precisa do produto\n    - Se a quantidade est\u00e1 dentro dos limites adequados\n    - Se a transfer\u00eancia \u00e9 priorit\u00e1ria baseada em linha verde e MC\n    - Incorpora a regra de ruptura cr\u00edtica (sem estoque no CD).\n\n    Args:\n        produto_id: C\u00f3digo do produto a transferir\n        une_origem: ID da UNE que vai enviar o produto\n        une_destino: ID da UNE que vai receber o produto\n        quantidade: Quantidade a transferir\n\n    Returns:\n        dict com:\n        - valido: bool (se a transfer\u00eancia \u00e9 v\u00e1lida)\n        - prioridade: str (\"URGENTE\", \"ALTA\", \"NORMAL\", \"BAIXA\", \"NAO_RECOMENDADA\")\n        - score_prioridade: float (0-100, quanto maior mais priorit\u00e1ria)\n        - motivo: str (justificativa da valida\u00e7\u00e3o)\n        - recomendacoes: list[str] (a\u00e7\u00f5es sugeridas)\n        ... e outros detalhes.\n    \"\"\"", "mimetype": "text/plain", "start_char_idx": 23766, "end_char_idx": 25059, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e0ed09dc-b984-4e76-9419-03dad06b2817": {"__data__": {"id_": "e0ed09dc-b984-4e76-9419-03dad06b2817", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\une_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "hash": "6be71c03f1dbd133b8014d5fb2f91199903471679ebe934e02f7f588603f785a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f0ee5031-178d-417e-b4c8-0256bd849e5c", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "hash": "37a85b65d620a7b2f9b6621ffc1e5666299b81c130538b3b2c0a17beffae13ca", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "87153257-9812-4e17-a765-40e05dda0340", "node_type": "1", "metadata": {}, "hash": "138fba15549fa96ca0061a4c14df03af1174a57db5883b88d2dfd0090822d9e7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "try:\n        # Valida\u00e7\u00e3o de inputs\n        if not isinstance(produto_id, int) or produto_id <= 0:\n            return {\"error\": \"produto_id deve ser um inteiro positivo\", \"valido\": False}\n        if not isinstance(une_origem, int) or une_origem <= 0:\n            return {\"error\": \"une_origem deve ser um inteiro positivo\", \"valido\": False}\n        if not isinstance(une_destino, int) or une_destino <= 0:\n            return {\"error\": \"une_destino deve ser um inteiro positivo\", \"valido\": False}\n        if une_origem == une_destino:\n            return {\"error\": \"UNE origem e destino n\u00e3o podem ser iguais\", \"valido\": False}\n        if not isinstance(quantidade, int) or quantidade <= 0:\n            return {\"error\": \"quantidade deve ser um inteiro positivo\", \"valido\": False}\n\n        logger.info(f\"Validando transfer\u00eancia: Produto {produto_id}, UNE {une_origem} -> {une_destino}, Qtd: {quantidade}\")\n\n        try:\n            # Carregar dados necess\u00e1rios, incluindo estoque_cd\n            colunas_necessarias = [\n                'codigo', 'nome_produto', 'une', 'estoque_atual', 'linha_verde',\n                'mc', 'venda_30_d', 'nomesegmento', 'estoque_cd'\n            ]\n            df = _load_data(filters={'codigo': produto_id}, columns=colunas_necessarias)\n            df = df[df['une'].isin([une_origem, une_destino])]\n        except Exception as e:\n            logger.error(f\"Erro ao carregar dados: {e}\")\n            return {\"error\": f\"Erro ao acessar dados: {str(e)}\", \"valido\": False}\n\n        # Dados da Origem\n        origem_df = df[df['une'] == une_origem]\n        if origem_df.empty:\n            return {\"valido\": False, \"motivo\": f\"Produto {produto_id} n\u00e3o encontrado na UNE origem {une_origem}\"}\n\n        # Dados do Destino\n        destino_df = df[df['une'] == une_destino]\n        if destino_df.empty:\n            return {\"valido\": False, \"motivo\": f\"Produto {produto_id} n\u00e3o encontrado na UNE destino {une_destino}\"}\n\n        origem = origem_df.iloc[0]\n        destino = destino_df.iloc[0]\n\n        # Extrair dados num\u00e9ricos com seguran\u00e7a\n        estoque_origem = float(origem.get('estoque_atual', 0))\n        linha_verde_origem = float(origem.get('linha_verde', 0))\n        estoque_destino = float(destino.get('estoque_atual', 0))\n        linha_verde_destino = float(destino.get('linha_verde', 0))\n        venda_30d_destino = float(destino.get('venda_30_d', 0))\n        mc_destino = float(destino.get('mc', 0))\n        estoque_cd = float(origem.get('estoque_cd', 0)) # Estoque do CD \u00e9 o mesmo para o produto\n\n        # --- Valida\u00e7\u00f5es de Bloqueio ---\n        if estoque_origem < quantidade:\n            return {\"valido\": False, \"motivo\": f\"Estoque insuficiente na origem.", "mimetype": "text/plain", "start_char_idx": 25064, "end_char_idx": 27753, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "87153257-9812-4e17-a765-40e05dda0340": {"__data__": {"id_": "87153257-9812-4e17-a765-40e05dda0340", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\une_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "hash": "6be71c03f1dbd133b8014d5fb2f91199903471679ebe934e02f7f588603f785a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e0ed09dc-b984-4e76-9419-03dad06b2817", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "hash": "cdba81270d70917d2443ed2c57b6dd9f2338a42467ca8eebcb0831e0af6fd96e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0800b633-5544-4836-970b-1b5629a6d124", "node_type": "1", "metadata": {}, "hash": "8d430def159b7a88b663335db4a6e324fff7aa61726c119d4dcb38eba242e8f5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Dispon\u00edvel: {estoque_origem:.0f}, Solicitado: {quantidade}\"}\n\n        estoque_origem_apos = estoque_origem - quantidade\n        perc_origem_apos = (estoque_origem_apos / linha_verde_origem * 100) if linha_verde_origem > 0 else 0.0\n        if perc_origem_apos < 50:\n            return {\"valido\": False, \"motivo\": f\"Transfer\u00eancia deixaria origem com estoque cr\u00edtico ({perc_origem_apos:.1f}% da linha verde)\"}\n\n        # --- C\u00e1lculo de Score de Prioridade ---\n        score_prioridade = 0.0\n        recomendacoes = []\n        \n        perc_origem = (estoque_origem / linha_verde_origem * 100) if linha_verde_origem > 0 else 0.0\n        perc_destino = (estoque_destino / linha_verde_destino * 100) if linha_verde_destino > 0 else 0.0\n\n        # Fator 1: Necessidade do destino (0-40 pontos)\n        if perc_destino < 25: score_prioridade += 40\n        elif perc_destino < 50: score_prioridade += 30\n        elif perc_destino < 75: score_prioridade += 20\n        else: score_prioridade += 5\n\n        # Fator 2: Excesso na origem (0-30 pontos)\n        if perc_origem > 150: score_prioridade += 30\n        elif perc_origem > 125: score_prioridade += 20\n        elif perc_origem > 100: score_prioridade += 10\n\n        # Fator 3: Demanda do destino (0-30 pontos)\n        if venda_30d_destino > 0:\n            dias_estoque_destino = estoque_destino / (venda_30d_destino / 30)\n            if dias_estoque_destino < 7: score_prioridade += 30\n            elif dias_estoque_destino < 15: score_prioridade += 20\n            elif dias_estoque_destino < 30: score_prioridade += 10\n        \n        # Fator 4: Ruptura Cr\u00edtica Sist\u00eamica (B\u00f4nus de 50 pontos)\n        if estoque_cd <= 0 and perc_destino < 75:\n            score_prioridade += 50\n            recomendacoes.append(\"ALERTA CR\u00cdTICO: Produto sem estoque no CD. Transfer\u00eancia de alta prioridade para evitar ruptura.\")\n\n        # --- Recomenda\u00e7\u00f5es Adicionais ---\n        pode_transferir = max(0, int(estoque_origem - linha_verde_origem)) if perc_origem > 100 else int(estoque_origem * 0.25)\n        pode_receber = max(0, int(linha_verde_destino - estoque_destino))\n        quantidade_recomendada = min(pode_transferir, pode_receber)\n        \n        if quantidade != quantidade_recomendada and quantidade_recomendada > 0:\n            recomendacoes.append(f\"Sugerimos transferir {quantidade_recomendada} unidades.\")\n        if perc_destino < 25:\n            recomendacoes.append(\"CR\u00cdTICO: Destino com estoque muito baixo.\")\n        if mc_destino > estoque_destino:\n            recomendacoes.append(\"MC do destino > estoque atual, indicando alta demanda.\")\n        if not recomendacoes:\n            recomendacoes.append(\"Transfer\u00eancia dentro dos padr\u00f5es normais.\")", "mimetype": "text/plain", "start_char_idx": 27754, "end_char_idx": 30454, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0800b633-5544-4836-970b-1b5629a6d124": {"__data__": {"id_": "0800b633-5544-4836-970b-1b5629a6d124", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\une_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "hash": "6be71c03f1dbd133b8014d5fb2f91199903471679ebe934e02f7f588603f785a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "87153257-9812-4e17-a765-40e05dda0340", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "hash": "957dc6b35fe08790f0b896b3e983a483d2691887db8738c604e0b981e2df0114", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1d273463-c8cc-458b-9768-df6140e41abe", "node_type": "1", "metadata": {}, "hash": "d060e5ab5bd0c1f4912041fafece764b9eb0dccb63e7d021f75664cbd4806aba", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "if not recomendacoes:\n            recomendacoes.append(\"Transfer\u00eancia dentro dos padr\u00f5es normais.\")\n\n        # --- Determinar Prioridade Final ---\n        if score_prioridade >= 90: prioridade = \"URGENTE\"\n        elif score_prioridade >= 70: prioridade = \"ALTA\"\n        elif score_prioridade >= 40: prioridade = \"NORMAL\"\n        else: prioridade = \"BAIXA\"\n\n        # --- Montar Resposta ---\n        resultado = {\n            \"valido\": True,\n            \"produto_id\": int(produto_id),\n            \"nome_produto\": str(origem.get('nome_produto', \"N/A\")),\n            \"prioridade\": prioridade,\n            \"score_prioridade\": round(score_prioridade, 2),\n            \"quantidade_recomendada\": int(quantidade_recomendada),\n            \"motivo\": f\"Transfer\u00eancia v\u00e1lida com prioridade {prioridade}\",\n            \"recomendacoes\": recomendacoes,\n            # ... (outros detalhes podem ser adicionados aqui)\n        }\n        return resultado\n\n    except Exception as e:\n        logger.error(f\"Erro em validar_transferencia_produto: {e}\", exc_info=True)\n        return {\"error\": f\"Erro ao validar transfer\u00eancia: {str(e)}\", \"valido\": False}\n\n\n@tool\ndef sugerir_transferencias_automaticas(limite: int = 20, une_origem_filtro: int = None, une_destino_id: int = None) -> Dict[str, Any]:\n    \"\"\"\n    Sugere transfer\u00eancias autom\u00e1ticas entre UNEs baseadas em regras de neg\u00f3cio.\n\n    Identifica oportunidades de balanceamento de estoque considerando:\n    - UNEs com excesso de estoque (>100% linha verde)\n    - UNEs com falta de estoque (<50% linha verde)\n    - MC (M\u00e9dia Comum) e hist\u00f3rico de vendas\n    - Prioriza\u00e7\u00e3o por criticidade\n\n    Args:\n        limite: N\u00famero m\u00e1ximo de sugest\u00f5es a retornar (default: 20)\n        une_origem_filtro: Filtrar sugest\u00f5es apenas desta UNE origem (opcional)\n\n    Returns:\n        dict com:\n        - total_sugestoes: int\n        - sugestoes: list[dict] (sugest\u00f5es ordenadas por prioridade)\n        - estatisticas: dict (resumo das sugest\u00f5es)\n\n    Cada sugest\u00e3o cont\u00e9m:\n        - produto_id: int\n        - nome_produto: str\n        - une_origem: int\n        - une_destino: int\n        - quantidade_sugerida: int\n        - prioridade: str\n        - score: float\n        - motivo: str\n        - beneficio_estimado: str\n\n    Example:\n        >>> result = sugerir_transferencias_automaticas(limite=10, une_origem_filtro=3116)\n        >>> for sug in result['sugestoes']:\n        ...     print(f\"{sug['nome_produto']}: UNE {sug['une_origem']} -> {sug['une_destino']}\")\n    \"\"\"\n    try:\n        if not isinstance(limite, int) or limite <= 0:\n            return {\"error\": \"limite deve ser um inteiro positivo\"}\n\n        if une_origem_filtro is not None and (not isinstance(une_origem_filtro, int) or une_origem_filtro <= 0):\n            return {\"error\": \"une_origem_filtro deve ser um inteiro positivo ou None\"}\n\n        logger.info(f\"Gerando sugest\u00f5es autom\u00e1ticas de transfer\u00eancias (limite: {limite})\")\n\n        try:\n            # OTIMIZA\u00c7\u00c3O: Usar PyArrow diretamente para carregar dataset completo de forma eficiente\n            import pyarrow.parquet as pq\n            from pathlib import Path\n\n            parquet_path = Path(os.getcwd()) / 'data' / 'parquet' / 'admmat_extended.parquet'\n\n            if not parquet_path.exists():\n                parquet_path = Path(os.getcwd()) / 'data' / 'parquet' / 'admmat.parquet'\n\n            # Carregar apenas colunas necess\u00e1rias (reduz I/O significativamente)\n            colunas_parquet = ['codigo', 'nome_produto', 'une', 'estoque_atual', 'estoque_lv',\n                              'media_considerada_lv', 'venda_30_d', 'nomesegmento']\n\n            logger.info(f\"Carregando dados do Parquet com PyArrow: {parquet_path}\")\n            table = pq.", "mimetype": "text/plain", "start_char_idx": 30355, "end_char_idx": 34058, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1d273463-c8cc-458b-9768-df6140e41abe": {"__data__": {"id_": "1d273463-c8cc-458b-9768-df6140e41abe", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\une_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "hash": "6be71c03f1dbd133b8014d5fb2f91199903471679ebe934e02f7f588603f785a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0800b633-5544-4836-970b-1b5629a6d124", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "hash": "17ebc45ebd0c9cf94f8d91544a1045b5ddab03b811a7bcaa5e482521bd579cc2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "62947953-7189-4748-9b39-49ad0621414d", "node_type": "1", "metadata": {}, "hash": "d72643119b8b50cbbacf9e3d75e5ddf423c3a177f20ba3757fb242024a74d5e0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "read_table(parquet_path, columns=colunas_parquet)\n            df = table.to_pandas()\n\n            # Normalizar nomes de colunas\n            df = df.rename(columns={\n                'estoque_lv': 'linha_verde',\n                'media_considerada_lv': 'mc'\n            })\n\n            # Converter colunas num\u00e9ricas (CR\u00cdTICO para evitar erros de compara\u00e7\u00e3o)\n            for col in ['estoque_atual', 'linha_verde', 'mc', 'venda_30_d']:\n                if col in df.columns:\n                    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n\n            logger.info(f\"Dados carregados: {len(df)} registros, {len(df['codigo'].unique())} produtos \u00fanicos\")\n\n        except Exception as e:\n            logger.error(f\"Erro ao carregar dados: {e}\")\n            return {\"error\": f\"Erro ao acessar dados: {str(e)}\"}\n\n        # Calcular percentual de linha verde para todos os produtos (VETORIZADO para performance)\n        df['perc_linha_verde'] = 0.0  # Inicializar com zero\n        mask = (df['linha_verde'] > 0)  # Apenas onde linha_verde > 0\n        df.loc[mask, 'perc_linha_verde'] = (df.loc[mask, 'estoque_atual'] / df.loc[mask, 'linha_verde'] * 100)\n\n        # Identificar UNEs com excesso (>100% linha verde)\n        df_excesso = df[df['perc_linha_verde'] > 100].copy()\n        logger.info(f\"Produtos com excesso (perc_linha_verde > 100): {len(df_excesso)}\")\n\n        # Identificar UNEs com falta (<75% linha verde)\n        df_falta = df[df['perc_linha_verde'] < 75].copy()\n        logger.info(f\"Produtos com falta (perc_linha_verde < 75): {len(df_falta)}\")\n\n        if df_excesso.empty or df_falta.empty:\n            logger.info(\"df_excesso ou df_falta est\u00e3o vazios, retornando 0 sugest\u00f5es.\")\n            return {\n                \"total_sugestoes\": 0,\n                \"sugestoes\": [],\n                \"mensagem\": \"N\u00e3o h\u00e1 oportunidades de transfer\u00eancia no momento\",\n                \"estatisticas\": {\n                    \"produtos_com_excesso\": len(df_excesso),\n                    \"produtos_com_falta\": len(df_falta)\n                }\n            }\n\n        sugestoes = []\n\n        # OTIMIZA\u00c7\u00c3O: Limitar busca apenas aos produtos mais cr\u00edticos para evitar timeout\n        # Ordenar por criticidade (menor percentual = mais cr\u00edtico)\n        produtos_criticos = df_falta.nsmallest(500, 'perc_linha_verde')['codigo'].unique()\n        logger.info(f\"Analisando {len(produtos_criticos)} produtos cr\u00edticos (top 500 por necessidade)\")\n\n        # Agrupar por produto para encontrar oportunidades\n        for produto_id in produtos_criticos:\n            # Early stopping: se j\u00e1 temos sugest\u00f5es suficientes, parar\n            if len(sugestoes) >= limite * 2:  # Coletar 2x o limite para ter op\u00e7\u00f5es ap\u00f3s ordena\u00e7\u00e3o\n                logger.info(f\"Limite de sugest\u00f5es atingido ({len(sugestoes)}), parando a gera\u00e7\u00e3o.\")\n                break\n\n            # Pegar todas as UNEs com excesso deste produto\n            produto_excesso = df_excesso[df_excesso['codigo'] == produto_id]\n\n            # Pegar todas as UNEs com falta deste produto\n            produto_falta = df_falta[df_falta['codigo'] == produto_id]\n\n            if produto_falta.empty:\n                continue\n\n            # Para cada UNE com excesso, encontrar melhor destino (limitar a 5 origens por produto)\n            for _, origem in produto_excesso.head(5).iterrows():\n                estoque_origem = float(origem['estoque_atual'])\n                linha_verde_origem = float(origem['linha_verde'])\n                une_origem = int(origem['une'])\n\n                # FILTRO: Se une_origem_filtro foi especificado,", "mimetype": "text/plain", "start_char_idx": 34058, "end_char_idx": 37630, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "62947953-7189-4748-9b39-49ad0621414d": {"__data__": {"id_": "62947953-7189-4748-9b39-49ad0621414d", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\une_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "hash": "6be71c03f1dbd133b8014d5fb2f91199903471679ebe934e02f7f588603f785a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1d273463-c8cc-458b-9768-df6140e41abe", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "hash": "766e3caa0de6d43a829ad15181e1992ce14c92a219395e41f020f90745fa4b7b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b53d8228-a69d-4ffe-88cd-2859cd2162ef", "node_type": "1", "metadata": {}, "hash": "d1e85d89411f6b931e076e687f35e3b5fc981db260c3f3de8af3d9a591b0ec05", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "pular UNEs diferentes\n                if une_origem_filtro is not None and une_origem != une_origem_filtro:\n                    continue\n\n                # Quantidade dispon\u00edvel para transferir (excesso)\n                qtd_disponivel = int(estoque_origem - linha_verde_origem)\n\n                if qtd_disponivel <= 0:\n                    continue\n\n                # Ordenar destinos por prioridade (menor percentual primeiro) e limitar a 3 destinos\n                for _, destino in produto_falta.sort_values('perc_linha_verde').head(3).iterrows():\n                    une_destino = int(destino['une'])\n\n                    if une_destino_id is not None and une_destino != une_destino_id:\n                        continue\n\n                    if une_origem == une_destino:\n                        continue\n\n                    estoque_destino = float(destino['estoque_atual'])\n                    linha_verde_destino = float(destino['linha_verde'])\n                    perc_destino = float(destino['perc_linha_verde'])\n                    mc_destino = float(destino['mc']) if pd.notna(destino['mc']) else 0.0\n                    venda_30d = float(destino['venda_30_d']) if pd.notna(destino['venda_30_d']) else 0.0\n\n                    # Quantidade necess\u00e1ria no destino\n                    qtd_necessaria = int(linha_verde_destino - estoque_destino)\n\n                    if qtd_necessaria <= 0:\n                        continue\n\n                    # Quantidade sugerida (m\u00ednimo entre dispon\u00edvel e necess\u00e1rio)\n                    qtd_sugerida = min(qtd_disponivel, qtd_necessaria)\n\n                    # Calcular score de prioridade\n                    score = 0.0\n\n                    # Fator 1: Criticidade do destino (0-50 pontos)\n                    if perc_destino < 25:\n                        score += 50\n                        prioridade = \"URGENTE\"\n                    elif perc_destino < 50:\n                        score += 35\n                        prioridade = \"ALTA\"\n                    elif perc_destino < 75:\n                        score += 20\n                        prioridade = \"NORMAL\"\n                    else:\n                        score += 10\n                        prioridade = \"BAIXA\"\n\n                    # Fator 2: Excesso na origem (0-25 pontos)\n                    perc_origem = float(origem['perc_linha_verde'])\n                    if perc_origem > 150:\n                        score += 25\n                    elif perc_origem > 125:\n                        score += 15\n                    elif perc_origem > 100:\n                        score += 10\n\n                    # Fator 3: Demanda do produto no destino (0-25 pontos)\n                    if venda_30d > 0:\n                        dias_estoque = estoque_destino / (venda_30d / 30)\n                        if dias_estoque < 7:\n                            score += 25\n                        elif dias_estoque < 15:\n                            score += 15\n                        elif dias_estoque < 30:\n                            score += 10\n\n                    # Gerar motivo\n                    motivo_partes = []\n                    if perc_destino < 50:\n                        motivo_partes.append(f\"Destino cr\u00edtico ({perc_destino:.1f}% LV)\")\n                    if perc_origem > 125:\n                        motivo_partes.append(f\"Origem com excesso ({perc_origem:.1f}% LV)\")\n                    if venda_30d > 0 and dias_estoque < 15:\n                        motivo_partes.append(f\"Alta demanda ({dias_estoque:.0f} dias estoque)\")\n\n                    motivo = \" | \".join(motivo_partes) if motivo_partes else \"Balanceamento de estoque\"\n\n                    # Calcular benef\u00edcio estimado\n                    melhoria_destino = (estoque_destino + qtd_sugerida) / linha_verde_destino * 100 if linha_verde_destino > 0 else 0\n                    beneficio = f\"Destino: {perc_destino:.1f}% -> {melhoria_destino:.1f}% da linha verde\"\n\n                    sugestao = {\n                        \"produto_id\": int(produto_id),\n                        \"nome_produto\": str(origem['nome_produto']) if pd.notna(origem['nome_produto']) else \"N/A\",\n                        \"segmento\": str(origem['nomesegmento']) if 'nomesegmento' in origem and pd.notna(origem['nomesegmento']) else \"N/A\",\n                        \"une_origem\": une_origem,\n                        \"une_destino\": une_destino,", "mimetype": "text/plain", "start_char_idx": 37631, "end_char_idx": 42007, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b53d8228-a69d-4ffe-88cd-2859cd2162ef": {"__data__": {"id_": "b53d8228-a69d-4ffe-88cd-2859cd2162ef", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\une_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "hash": "6be71c03f1dbd133b8014d5fb2f91199903471679ebe934e02f7f588603f785a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "62947953-7189-4748-9b39-49ad0621414d", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "hash": "9a77f9d0b98b4232f6a8689c519e1a889dce5317224e9591360b6973d1f25d91", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c4055a18-4955-4d21-b58e-e9a718e5ff20", "node_type": "1", "metadata": {}, "hash": "54bcf999c766233bd03d6de4ea55bc9fd11d738b13d11d6ba55633840d99b639", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"une_destino\": une_destino,\n                        \"quantidade_sugerida\": qtd_sugerida,\n                        \"prioridade\": prioridade,\n                        \"score\": round(score, 2),\n                        \"motivo\": motivo,\n                        \"beneficio_estimado\": beneficio,\n                        \"detalhes\": {\n                            \"origem\": {\n                                \"estoque\": estoque_origem,\n                                \"linha_verde\": linha_verde_origem,\n                                \"percentual\": round(perc_origem, 2)\n                            },\n                            \"destino\": {\n                                \"estoque\": estoque_destino,\n                                \"linha_verde\": linha_verde_destino,\n                                \"percentual\": round(perc_destino, 2),\n                                \"mc\": mc_destino,\n                                \"venda_30d\": venda_30d\n                            }\n                        }\n                    }\n\n                    sugestoes.append(sugestao)\n\n                    # Atualizar quantidade dispon\u00edvel\n                    qtd_disponivel -= qtd_sugerida\n                    if qtd_disponivel <= 0:\n                        break\n        logger.info(f\"Total de sugest\u00f5es geradas antes da ordena\u00e7\u00e3o e limite: {len(sugestoes)}\")\n\n        # Ordenar sugest\u00f5es por score (maior primeiro)\n        sugestoes_ordenadas = sorted(sugestoes, key=lambda x: x['score'], reverse=True)\n\n        # Limitar ao n\u00famero solicitado\n        sugestoes_final = sugestoes_ordenadas[:limite]\n\n        # Calcular estat\u00edsticas\n        total_sugestoes = len(sugestoes_final)\n        urgentes = len([s for s in sugestoes_final if s['prioridade'] == 'URGENTE'])\n        altas = len([s for s in sugestoes_final if s['prioridade'] == 'ALTA'])\n        normais = len([s for s in sugestoes_final if s['prioridade'] == 'NORMAL'])\n        baixas = len([s for s in sugestoes_final if s['prioridade'] == 'BAIXA'])\n        total_unidades = sum([s['quantidade_sugerida'] for s in sugestoes_final])\n\n        logger.info(f\"Geradas {total_sugestoes} sugest\u00f5es de transfer\u00eancia\")\n\n        return {\n            \"total_sugestoes\": total_sugestoes,\n            \"sugestoes\": sugestoes_final,\n            \"estatisticas\": {\n                \"total\": total_sugestoes,\n                \"urgentes\": urgentes,\n                \"altas\": altas,\n                \"normais\": normais,\n                \"baixas\": baixas,\n                \"total_unidades\": total_unidades,\n                \"produtos_unicos\": len(set([s['produto_id'] for s in sugestoes_final])),\n                \"unes_origem\": len(set([s['une_origem'] for s in sugestoes_final])),\n                \"unes_destino\": len(set([s['une_destino'] for s in sugestoes_final]))\n            }\n        }\n\n    except Exception as e:\n        logger.error(f\"Erro em sugerir_transferencias_automaticas: {e}\", exc_info=True)\n        return {\"error\": f\"Erro ao gerar sugest\u00f5es: {str(e)}\"}\n\n\n@tool\n@error_handler_decorator(\n    context_func=lambda une_id: {\"une_id\": une_id, \"funcao\": \"calcular_produtos_sem_vendas\"},\n    return_on_error={\"error\": \"Erro ao calcular produtos sem vendas\", \"total_produtos\": 0, \"produtos\": []}\n)\ndef calcular_produtos_sem_vendas(une_id: int, limite: int = 50, fabricante: str = None) -> Dict[str, Any]:\n    \"\"\"\n    Identifica produtos sem vendas (VENDA_30DD = 0) em uma UNE, com filtro opcional por fabricante.", "mimetype": "text/plain", "start_char_idx": 41980, "end_char_idx": 45409, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c4055a18-4955-4d21-b58e-e9a718e5ff20": {"__data__": {"id_": "c4055a18-4955-4d21-b58e-e9a718e5ff20", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\une_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "hash": "6be71c03f1dbd133b8014d5fb2f91199903471679ebe934e02f7f588603f785a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b53d8228-a69d-4ffe-88cd-2859cd2162ef", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "hash": "cfa99e3fe56825a54382d8e53e08665c8dac56e2fe9aae565a45ce0e7fabb5af", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3d831c33-df11-4e14-93b2-512f18f0a3c6", "node_type": "1", "metadata": {}, "hash": "e0e1588c8dc7c2b27cef397b7e6eda631dd52aafc3c5d804ed84c7274dfda8ce", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Esta ferramenta \u00e9 \u00fatil para:\n    - Identificar produtos sem giro\n    - Detectar itens parados em estoque\n    - Analisar a ruptura de um fabricante espec\u00edfico\n\n    Args:\n        une_id: ID da UNE (ex: 2586 para SCR, 261 para MAD)\n        limite: N\u00famero m\u00e1ximo de produtos a retornar (default: 50)\n        fabricante: Nome do fabricante para filtrar os resultados (opcional)\n\n    Returns:\n        dict com:\n        - total_produtos: int (total de produtos sem vendas)\n        - produtos: list[dict] (produtos sem vendas com estoque > 0)\n        - une_id: int\n        - criterio: str (descri\u00e7\u00e3o do filtro aplicado)\n\n    Example:\n        >>> result = calcular_produtos_sem_vendas(une_id=2586, limite=20, fabricante=\"KIT\")\n        >>> print(f\"Total: {result['total_produtos']} produtos sem vendas do fabricante KIT\")\n    \"\"\"\n    # Valida\u00e7\u00e3o de inputs\n    if not isinstance(une_id, int) or une_id <= 0:\n        return {\"error\": \"une_id deve ser um inteiro positivo\"}\n\n    if not isinstance(limite, int) or limite <= 0:\n        limite = 50\n\n    logger.info(f\"Buscando produtos sem vendas na UNE {une_id} para o fabricante {fabricante or 'Todos'}\")\n\n    # Construir filtros\n    filters = {'une': une_id}\n    if fabricante:\n        # Usar o nome real da coluna no Parquet\n        filters['NOMEFABRICANTE'] = fabricante.upper()\n\n    # Carregar dados da UNE\n    df = _load_data(\n        filters=filters,\n        columns=['codigo', 'nome_produto', 'une', 'estoque_atual', 'venda_30_d',\n                'linha_verde', 'nomesegmento', 'mc', 'NOMEFABRICANTE']\n    )\n\n    if df.empty:\n        logger.warning(f\"Nenhum dado encontrado para UNE {une_id} e fabricante {fabricante}\")\n        return {\n            \"error\": f\"Nenhum dado encontrado para UNE {une_id} com o filtro de fabricante '{fabricante}'\",\n            \"une_id\": une_id,\n            \"total_produtos\": 0,\n            \"produtos\": []\n        }\n\n    # Normalizar DataFrame\n    df = _normalize_dataframe(df)\n\n    # Filtrar produtos SEM vendas (venda_30_d = 0) mas COM estoque\n    df_sem_vendas = df[\n        (df['venda_30_d'] == 0) &\n        (df['estoque_atual'] > 0)\n    ].copy()\n\n    total_produtos = len(df_sem_vendas)\n\n    if total_produtos == 0:\n        return {\n            \"total_produtos\": 0,\n            \"produtos\": [],\n            \"une_id\": une_id,\n            \"criterio\": \"VENDA_30DD = 0 E ESTOQUE > 0\" + (f\" E NOMEFABRICANTE = '{fabricante.upper()}'\" if fabricante else \"\"),\n            \"mensagem\": \"Nenhum produto sem vendas encontrado com os filtros aplicados.\"", "mimetype": "text/plain", "start_char_idx": 45415, "end_char_idx": 47932, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "3d831c33-df11-4e14-93b2-512f18f0a3c6": {"__data__": {"id_": "3d831c33-df11-4e14-93b2-512f18f0a3c6", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\une_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "hash": "6be71c03f1dbd133b8014d5fb2f91199903471679ebe934e02f7f588603f785a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c4055a18-4955-4d21-b58e-e9a718e5ff20", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "hash": "5e9e3e38e95b64db2859c5d458e67c903ca7fd922c5e720ff5f9d662c88125ce", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9ce7b2f0-913f-4772-8319-ed275b8b2315", "node_type": "1", "metadata": {}, "hash": "a8646f4949a69ac8e74ddb69c45a843654f4d6b99c416bbcf53b675664fab710", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "}\n\n    # Ordenar por estoque (produtos com mais estoque parado = mais cr\u00edticos)\n    df_sem_vendas = df_sem_vendas.sort_values('estoque_atual', ascending=False)\n\n    # Limitar ao n\u00famero solicitado\n    top_produtos = df_sem_vendas.head(limite)\n\n    # Preparar lista de produtos\n    produtos = []\n    for _, row in top_produtos.iterrows():\n        produto = {\n            \"codigo\": int(row['codigo']) if pd.notna(row['codigo']) else None,\n            \"nome_produto\": str(row['nome_produto']) if pd.notna(row['nome_produto']) else \"N/A\",\n            \"segmento\": str(row['nomesegmento']) if 'nomesegmento' in row and pd.notna(row['nomesegmento']) else \"N/A\",\n            \"estoque_atual\": float(row['estoque_atual']) if pd.notna(row['estoque_atual']) else 0.0,\n            \"linha_verde\": float(row['linha_verde']) if pd.notna(row['linha_verde']) else 0.0,\n            \"venda_30d\": 0.0,  # Sempre zero (crit\u00e9rio da busca)\n            \"dias_sem_venda\": \"> 30 dias\"\n        }\n        produtos.append(produto)\n\n    logger.info(f\"Encontrados {total_produtos} produtos sem vendas na UNE {une_id} para o fabricante {fabricante or 'Todos'}\")\n\n    return {\n        \"total_produtos\": total_produtos,\n        \"produtos\": produtos,\n        \"une_id\": une_id,\n        \"criterio\": \"VENDA_30DD = 0 E ESTOQUE > 0\" + (f\" E NOMEFABRICANTE = '{fabricante.upper()}'\" if fabricante else \"\"),\n        \"limite_exibido\": len(produtos),\n        \"recomendacao\": \"Considere a\u00e7\u00f5es promocionais ou transfer\u00eancia para UNEs com demanda\" if total_produtos > 0 else None\n    }\n\n\n@tool\n@error_handler_decorator(\n    context_func=lambda: {\"funcao\": \"encontrar_rupturas_criticas\"},\n    return_on_error={\"error\": \"Erro ao encontrar rupturas cr\u00edticas\", \"total_criticos\": 0, \"produtos_criticos\": []}\n)\ndef encontrar_rupturas_criticas(limite: Optional[int] = 100) -> Dict[str, Any]:\n    \"\"\"\n    Identifica produtos em situa\u00e7\u00e3o de ruptura cr\u00edtica sist\u00eamica, ordenados por gravidade.\n\n    A regra de neg\u00f3cio para ruptura cr\u00edtica \u00e9:\n    1. O estoque no Centro de Distribui\u00e7\u00e3o (CD) \u00e9 zero ou negativo (estoque_cd <= 0).\n    2. O estoque na UNE (loja) est\u00e1 abaixo da linha verde (estoque_atual < linha_verde).\n\n    A lista \u00e9 ordenada para mostrar primeiro os produtos com \"Estoque Negativo Cr\u00edtico\"\n    e depois por 'percentual_cobertura' (do menor para o maior), que representa\n    o qu\u00e3o cheio o estoque est\u00e1 em rela\u00e7\u00e3o \u00e0 linha verde.\n\n    Args:\n        limite: N\u00famero m\u00e1ximo de produtos cr\u00edticos a retornar. Se None, retorna todos.", "mimetype": "text/plain", "start_char_idx": 47941, "end_char_idx": 50423, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9ce7b2f0-913f-4772-8319-ed275b8b2315": {"__data__": {"id_": "9ce7b2f0-913f-4772-8319-ed275b8b2315", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\une_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "hash": "6be71c03f1dbd133b8014d5fb2f91199903471679ebe934e02f7f588603f785a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3d831c33-df11-4e14-93b2-512f18f0a3c6", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "hash": "7ec547afdf7f194793b86d990df46cd42c10eec06564aba245aac399cf70502d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3c59032c-76b9-44ab-b1e2-56b73ac084d9", "node_type": "1", "metadata": {}, "hash": "c0f8ad266788e231c9c8eee40d6a6ac0d75d2e7e2dc1db4d30ccd8b67e70c2d6", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Se None, retorna todos.\n\n    Returns:\n        dict com:\n        - total_criticos: int (total de produtos em situa\u00e7\u00e3o cr\u00edtica)\n        - produtos_criticos: list[dict] (lista dos produtos, incluindo 'motivo_ruptura', 'alerta_de_estoque' e 'percentual_cobertura')\n        - criterio: str (descri\u00e7\u00e3o da regra aplicada)\n\n    Example:\n        >>> result = encontrar_rupturas_criticas(limite=10)\n        >>> print(f\"Total de produtos cr\u00edticos: {result['total_criticos']}\")\n    \"\"\"\n    try:\n        logger.info(f\"Buscando produtos em ruptura cr\u00edtica (limite: {limite})\")\n\n        # Carregar dados necess\u00e1rios de forma otimizada, incluindo venda_30_d\n        colunas_necessarias = [\n            'codigo', 'nome_produto', 'une', 'une_nome', 'estoque_atual',\n            'linha_verde', 'estoque_cd', 'nomesegmento', 'venda_30_d'\n        ]\n        \n        # Usar _load_data para abstrair a fonte de dados\n        df = _load_data(columns=colunas_necessarias)\n\n        if df.empty:\n            return {\n                \"total_criticos\": 0,\n                \"produtos_criticos\": [],\n                \"mensagem\": \"Nenhum dado de produto encontrado.\"\n            }\n\n        # Garantir que as colunas num\u00e9ricas s\u00e3o do tipo correto\n        for col in ['estoque_cd', 'estoque_atual', 'linha_verde', 'venda_30_d']:\n            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n\n        # Aplicar a regra de neg\u00f3cio\n        # 1. Estoque no CD <= 0\n        df_sem_estoque_cd = df[df['estoque_cd'] <= 0]\n\n        if df_sem_estoque_cd.empty:\n            return {\n                \"total_criticos\": 0,\n                \"produtos_criticos\": [],\n                \"mensagem\": \"Nenhum produto encontrado com estoque zerado no CD.\"\n            }\n\n        # 2. Estoque na UNE < Linha Verde\n        df_criticos = df_sem_estoque_cd[df_sem_estoque_cd['estoque_atual'] < df_sem_estoque_cd['linha_verde']].copy()\n\n        total_criticos = len(df_criticos)\n\n        if total_criticos == 0:\n            return {\n                \"total_criticos\": 0,\n                \"produtos_criticos\": [],\n                \"criterio\": \"estoque_cd <= 0 E estoque_atual < linha_verde\",\n                \"mensagem\": \"Nenhuma ruptura cr\u00edtica encontrada. Todas as UNEs com estoque abaixo da linha verde possuem cobertura no CD.\"", "mimetype": "text/plain", "start_char_idx": 50400, "end_char_idx": 52672, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "3c59032c-76b9-44ab-b1e2-56b73ac084d9": {"__data__": {"id_": "3c59032c-76b9-44ab-b1e2-56b73ac084d9", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\une_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "hash": "6be71c03f1dbd133b8014d5fb2f91199903471679ebe934e02f7f588603f785a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9ce7b2f0-913f-4772-8319-ed275b8b2315", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "hash": "afccbd26252147aa11b6c0272b0d5974b55603d60e1bd41d09b3ea09ef0304f1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0548c04f-e9b5-459a-a051-aca97df49241", "node_type": "1", "metadata": {}, "hash": "9f8efdc74c9c0e0cea110885cb91d7e5b52cb1a0c3eb637e2abe4b0de145b7b3", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "}\n\n        # Adicionar campos para alerta e ordena\u00e7\u00e3o\n        df_criticos['alerta_de_estoque'] = df_criticos['estoque_atual'].apply(\n            lambda x: \"Estoque Negativo Cr\u00edtico\" if x < 0 else \"Estoque Baixo\"\n        )\n        df_criticos['percentual_cobertura'] = df_criticos.apply(\n            lambda row: (row['estoque_atual'] / row['linha_verde'] * 100) if row['linha_verde'] > 0 else 0,\n            axis=1\n        )\n        \n        # Criar uma coluna tempor\u00e1ria para ordena\u00e7\u00e3o que prioriza os negativos\n        df_criticos['is_negativo'] = df_criticos['estoque_atual'].apply(lambda x: 1 if x < 0 else 0)\n\n        # Ordenar por status de alerta (negativos primeiro) e depois por percentual de cobertura\n        df_criticos = df_criticos.sort_values(\n            by=['is_negativo', 'percentual_cobertura'], \n            ascending=[False, True]\n        )\n\n        # Limitar ao n\u00famero solicitado, se um limite for fornecido\n        top_criticos = df_criticos\n        if limite is not None:\n            top_criticos = df_criticos.head(limite)\n\n        # Preparar lista de produtos\n        produtos = []\n        for _, row in top_criticos.iterrows():\n            # Determinar o motivo da ruptura\n            motivo_ruptura = \"Risco de Reposi\u00e7\u00e3o (Estoque CD Zerado)\"\n            if row['linha_verde'] < row['venda_30_d']:\n                motivo_ruptura = \"Planejamento Incorreto (Linha Verde < Vendas)\"\n\n            produto = {\n                \"codigo\": int(row['codigo']) if pd.notna(row['codigo']) else None,\n                \"nome_produto\": str(row['nome_produto']) if pd.notna(row['nome_produto']) else \"N/A\",\n                \"segmento\": str(row['nomesegmento']) if 'nomesegmento' in row and pd.notna(row['nomesegmento']) else \"N/A\",\n                \"une_afetada_id\": int(row['une']) if pd.notna(row['une']) else None,\n                \"une_afetada_nome\": str(row['une_nome']) if 'une_nome' in row and pd.notna(row['une_nome']) else \"N/A\",\n                \"alerta_de_estoque\": row['alerta_de_estoque'],\n                \"estoque_na_une\": float(row['estoque_atual']),\n                \"linha_verde_na_une\": float(row['linha_verde']),\n                \"percentual_cobertura\": round(row['percentual_cobertura'], 2),\n                \"venda_30_dias\": float(row['venda_30_d']),\n                \"necessidade_na_une\": float(row['linha_verde'] - row['estoque_atual']),\n                \"estoque_no_cd\": float(row['estoque_cd']),\n                \"motivo_ruptura\": motivo_ruptura\n            }\n            produtos.append(produto)\n\n        logger.info(f\"Encontradas {total_criticos} situa\u00e7\u00f5es de ruptura cr\u00edtica.\")\n\n        return {\n            \"total_criticos\": total_criticos,\n            \"produtos_criticos\": produtos,\n            \"criterio\": \"estoque_cd <= 0 E estoque_atual < linha_verde\",\n            \"limite_exibido\": len(produtos)\n        }\n\n    except Exception as e:\n        logger.error(f\"Erro em encontrar_rupturas_criticas: {e}\", exc_info=True)\n        return {\"error\": f\"Erro ao processar rupturas cr\u00edticas: {str(e)}\"}\n\n\n@tool\n@error_handler_decorator(\n    context_func=lambda une_id=None, produto_id=None, segmento=None, termo_busca=None: {\n        \"une_id\": une_id, \"produto_id\": produto_id, \"segmento\": segmento, \"termo_busca\": termo_busca, \"funcao\": \"consultar_dados_gerais\"\n    },\n    return_on_error={\"error\": \"Erro ao consultar dados gerais\", \"total_resultados\": 0, \"resultados\": []}\n)\ndef consultar_dados_gerais(\n    une_id: Optional[int] = None,\n    produto_id: Optional[int] = None,\n    segmento: Optional[str] = None,\n    termo_busca: Optional[str] = None,\n    limite: int = 20\n) -> Dict[str, Any]:\n    \"\"\"\n    Consulta dados gerais de produtos, estoque e vendas com filtros flex\u00edveis.", "mimetype": "text/plain", "start_char_idx": 52685, "end_char_idx": 56384, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0548c04f-e9b5-459a-a051-aca97df49241": {"__data__": {"id_": "0548c04f-e9b5-459a-a051-aca97df49241", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\une_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "hash": "6be71c03f1dbd133b8014d5fb2f91199903471679ebe934e02f7f588603f785a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3c59032c-76b9-44ab-b1e2-56b73ac084d9", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "hash": "03fc97ff2f11dcd08964bdf67c51654e33de3ffdbe5c46017f4c0d87107bdc6f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7a32339c-1917-4671-bccd-a5b1983affea", "node_type": "1", "metadata": {}, "hash": "e4c8ea76d5d0451ab59a81a80e26812e78f9367aa55aad9e834d87f04e9b61c9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Use esta ferramenta para responder perguntas gerais como:\n    - \"Qual o estoque do produto X na UNE Y?\"\n    - \"Quais produtos do segmento Z temos na UNE Y?\"\n    - \"Dados do produto 12345\"\n\n    Args:\n        une_id: ID da UNE (opcional)\n        produto_id: C\u00f3digo do produto (opcional)\n        segmento: Nome do segmento (opcional, ex: \"TECIDOS\")\n        termo_busca: Parte do nome do produto para busca (opcional)\n        limite: M\u00e1ximo de resultados (default: 20)\n\n    Returns:\n        dict com 'total_resultados' e lista de 'resultados'.\n    \"\"\"\n    logger.info(f\"Consultando dados gerais: une={une_id}, prod={produto_id}, seg={segmento}, busca={termo_busca}\")\n\n    filters = {}\n    if une_id:\n        filters['une'] = une_id\n    if produto_id:\n        filters['codigo'] = produto_id\n    \n    # Se tiver filtro de segmento, precisamos carregar e filtrar depois ou usar _load_data se suportar\n    # _load_data suporta filtro exato. Para contains (termo_busca), faremos via pandas.\n\n    try:\n        # Colunas relevantes para consulta geral\n        cols = [\n            'codigo', 'nome_produto', 'une', 'une_nome', 'estoque_atual', 'linha_verde', \n            'venda_30_d', 'mc', 'nomesegmento', 'estoque_cd', 'NOMEFABRICANTE'\n        ]\n        \n        # Otimiza\u00e7\u00e3o: se tiver ID ou UNE, filtrar na carga\n        df = _load_data(filters=filters if filters else None, columns=cols)\n        \n        if df.empty:\n            return {\"total_resultados\": 0, \"resultados\": [], \"mensagem\": \"Nenhum dado encontrado com os filtros iniciais.\"}\n\n        # Normalizar\n        df = _normalize_dataframe(df)\n        \n        # Filtros adicionais (pandas)\n        if segmento and 'nomesegmento' in df.columns:\n            df = df[df['nomesegmento'].str.contains(segmento, case=False, na=False)]\n        \n        if termo_busca and 'nome_produto' in df.columns:\n            df = df[df['nome_produto'].str.contains(termo_busca, case=False, na=False)]\n\n        total = len(df)\n        if total == 0:\n             return {\"total_resultados\": 0, \"resultados\": [], \"mensagem\": \"Nenhum dado encontrado ap\u00f3s filtros de texto.\"}", "mimetype": "text/plain", "start_char_idx": 56389, "end_char_idx": 58494, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7a32339c-1917-4671-bccd-a5b1983affea": {"__data__": {"id_": "7a32339c-1917-4671-bccd-a5b1983affea", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\une_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "hash": "6be71c03f1dbd133b8014d5fb2f91199903471679ebe934e02f7f588603f785a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0548c04f-e9b5-459a-a051-aca97df49241", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "hash": "a3f8dd56b3bb3d1c84efdfb2a70d7833b7b69825cad7fc236c6750687c717f22", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0277ad50-6a75-43a5-8ad2-db1db2a6384d", "node_type": "1", "metadata": {}, "hash": "40650f1b48fc92ac1818896ba1cd811992627de7e833d786d9fbd6e4595c8de3", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# Limitar e formatar\n        df_res = df.head(limite)\n        resultados = []\n        for _, row in df_res.iterrows():\n            item = {\n                \"codigo\": int(row['codigo']) if pd.notna(row.get('codigo')) else None,\n                \"nome\": str(row['nome_produto']) if pd.notna(row.get('nome_produto')) else \"N/A\",\n                \"une\": int(row['une']) if pd.notna(row.get('une')) else None,\n                \"estoque\": float(row['estoque_atual']) if pd.notna(row.get('estoque_atual')) else 0.0,\n                \"venda_30d\": float(row['venda_30_d']) if pd.notna(row.get('venda_30_d')) else 0.0,\n                \"linha_verde\": float(row['linha_verde']) if pd.notna(row.get('linha_verde')) else 0.0,\n                \"segmento\": str(row['nomesegmento']) if pd.notna(row.get('nomesegmento')) else \"N/A\"\n            }\n            # Adicionar campos extras se dispon\u00edveis\n            if 'estoque_cd' in row and pd.notna(row['estoque_cd']):\n                item['estoque_cd'] = float(row['estoque_cd'])\n            \n            resultados.append(item)\n\n        return {\n            \"total_resultados\": total,\n            \"resultados\": resultados,\n            \"limite_aplicado\": limite\n        }\n\n    except Exception as e:\n        logger.error(f\"Erro em consultar_dados_gerais: {e}\", exc_info=True)\n        return {\"error\": f\"Erro na consulta: {str(e)}\"}\n\n# Lista de ferramentas dispon\u00edveis para exporta\u00e7\u00e3o\n__all__ = [\n    'calcular_abastecimento_une',\n    'calcular_mc_produto',\n    'calcular_preco_final_une',\n    'validar_transferencia_produto',\n    'sugerir_transferencias_automaticas',\n    'calcular_produtos_sem_vendas',\n    'encontrar_rupturas_criticas',\n    'consultar_dados_gerais'\n]\n\n\n# -----------------------------------------------------------------------------\n# Compatibility wrapper functions (shims) expected by older tests/scripts\n# These provide a stable, high-level API (get_*) that returns the\n# standardized dict: {\"success\": bool, \"data\": ..., \"message\": str}\n# They call the existing implementations where possible or provide\n# safe fallbacks so test-collection/imports do not fail.\n# -----------------------------------------------------------------------------\n\n\ndef _standard_response(data=None, message: str = \"\", success: bool = True):\n    return {\"success\": success, \"data\": data if data is not None else [], \"message\": message}\n\n\ndef get_produtos_une(une_id: int):\n    \"\"\"Compat wrapper: retorna produtos para uma UNE.\n\n    Usa `_load_data` e devolve lista de registros normalizados.\n    \"\"\"\n    try:\n        if not isinstance(une_id, int) or une_id <= 0:\n            return _standard_response([], \"une_id inv\u00e1lido\", False)\n\n        df = _load_data(filters={\"une\": une_id})\n        records = df.to_dict(orient=\"records\") if not df.empty else []\n\n        return _standard_response(records, \"OK\", True)\n    except Exception as e:\n        logger.error(f\"Erro em get_produtos_une: {e}\", exc_info=True)\n        return _standard_response([], f\"Erro: {e}\", False)\n\n\ndef get_transferencias(une: int = None, data_inicio: str = None, data_fim: str = None, status: str = None):\n    \"\"\"Compat wrapper: retorna transferencias (usa sugerir_transferencias_automaticas como fallback).\"\"\"\n    try:\n        limite = 50\n        result = sugerir_transferencias_automaticas(limite=limite, une_origem_filtro=une)\n        sugestoes = result.get(\"sugestoes\") if isinstance(result, dict) else []\n        return _standard_response(sugestoes, \"OK\", True)\n    except Exception as e:\n        logger.error(f\"Erro em get_transferencias: {e}\", exc_info=True)\n        return _standard_response([], f\"Erro: {e}\", False)", "mimetype": "text/plain", "start_char_idx": 58504, "end_char_idx": 62123, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0277ad50-6a75-43a5-8ad2-db1db2a6384d": {"__data__": {"id_": "0277ad50-6a75-43a5-8ad2-db1db2a6384d", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\une_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "hash": "6be71c03f1dbd133b8014d5fb2f91199903471679ebe934e02f7f588603f785a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7a32339c-1917-4671-bccd-a5b1983affea", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools.py", "language": "python", "lines": 1545, "filename": "une_tools.py"}, "hash": "16975d1ec407eaa1cebc804ca57436aa4197d4c11ba9c82f73363bd7b799f6ed", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "def get_estoque_une(une_id: int):\n    try:\n        df = _load_data(filters={\"une\": une_id})\n        if df.empty:\n            return _standard_response([], \"Nenhum dado\", True)\n\n        total_estoque = int(df['estoque_atual'].fillna(0).sum()) if 'estoque_atual' in df.columns else 0\n        return _standard_response({\"une\": une_id, \"total_estoque\": total_estoque}, \"OK\", True)\n    except Exception as e:\n        logger.error(f\"Erro em get_estoque_une: {e}\", exc_info=True)\n        return _standard_response([], f\"Erro: {e}\", False)\n\n\ndef get_vendas_une(une_id: int):\n    try:\n        df = _load_data(filters={\"une\": une_id})\n        total_vendas = float(df['venda_30_d'].fillna(0).sum()) if 'venda_30_d' in df.columns else 0.0\n        return _standard_response({\"une\": une_id, \"total_vendas_30d\": total_vendas}, \"OK\", True)\n    except Exception as e:\n        logger.error(f\"Erro em get_vendas_une: {e}\", exc_info=True)\n        return _standard_response([], f\"Erro: {e}\", False)\n\n\ndef get_unes_disponiveis():\n    try:\n        df = _load_data()\n        if 'une' in df.columns:\n            unes = sorted(list(df['une'].dropna().unique()))\n        else:\n            unes = []\n        return _standard_response(unes, \"OK\", True)\n    except Exception as e:\n        logger.error(f\"Erro em get_unes_disponiveis: {e}\", exc_info=True)\n        return _standard_response([], f\"Erro: {e}\", False)\n\n\ndef get_preco_produto(une_id: int, produto_codigo: str):\n    try:\n        df = _load_data(filters={\"une\": une_id, \"codigo\": produto_codigo})\n        if df.empty:\n            return _standard_response({}, \"Produto n\u00e3o encontrado\", False)\n        row = df.iloc[0].to_dict()\n        preco = row.get('preco_venda') or row.get('preco') or 0.0\n        return _standard_response({\"produto\": produto_codigo, \"preco_venda\": float(preco)}, \"OK\", True)\n    except Exception as e:\n        logger.error(f\"Erro em get_preco_produto: {e}\", exc_info=True)\n        return _standard_response({}, f\"Erro: {e}\", False)\n\n\ndef get_total_vendas_une(une_id: int):\n    try:\n        df = _load_data(filters={\"une\": une_id})\n        total = float(df['venda_30_d'].fillna(0).sum()) if 'venda_30_d' in df.columns else 0.0\n        return _standard_response(total, \"OK\", True)\n    except Exception as e:\n        logger.error(f\"Erro em get_total_vendas_une: {e}\", exc_info=True)\n        return _standard_response(0, f\"Erro: {e}\", False)\n\n\ndef get_total_estoque_une(une_id: int):\n    try:\n        df = _load_data(filters={\"une\": une_id})\n        total = int(df['estoque_atual'].fillna(0).sum()) if 'estoque_atual' in df.columns else 0\n        return _standard_response(total, \"OK\", True)\n    except Exception as e:\n        logger.error(f\"Erro em get_total_estoque_une: {e}\", exc_info=True)\n        return _standard_response(0, f\"Erro: {e}\", False)\n\n\ndef health_check():\n    try:\n        base = os.path.join(os.getcwd(), 'data', 'parquet')\n        files = os.listdir(base) if os.path.exists(base) else []\n        expected = ['produtos.parquet', 'transferencias.parquet']\n        missing = [f for f in expected if f not in files]\n        status = {\"present_files\": files, \"missing_expected\": missing}\n        success = len(missing) == 0\n        return _standard_response(status, \"OK\" if success else \"Arquivos faltando\", success)\n    except Exception as e:\n        logger.error(f\"Erro em health_check: {e}\", exc_info=True)\n        return _standard_response({}, f\"Erro: {e}\", False)", "mimetype": "text/plain", "start_char_idx": 62126, "end_char_idx": 65558, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "385325ba-54d0-43a0-a6c5-d0a0d2ffdbff": {"__data__": {"id_": "385325ba-54d0-43a0-a6c5-d0a0d2ffdbff", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools_backup_old.py", "language": "python", "lines": 349, "filename": "une_tools_backup_old.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\une_tools_backup_old.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools_backup_old.py", "language": "python", "lines": 349, "filename": "une_tools_backup_old.py"}, "hash": "8147ecb1d0427740339c7cdd9bef0240314d9a5e92081d5b1d898a82d9e1e082", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "bdf78d43-d49d-45be-aad2-71162b6607f0", "node_type": "1", "metadata": {}, "hash": "0563e06a947f872e2529dbc30c58bf4fcaf353e2df14204966b4f44fe218aeb0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# backend/app/core/tools/une_tools.py\n\nfrom typing import Dict, Any, List, Optional\nfrom functools import lru_cache\n\n# Assuming HybridAdapter exists in infrastructure/data as per TASK_LIST\n# We will create a placeholder for it later if it doesn't exist\n# from ....infrastructure.data.hybrid_adapter import HybridAdapter\n# Placeholder for now\nclass HybridAdapter:\n    def __init__(self, parquet_dir: str = \"data/parquet\", sql_server_conn_str: Optional[str] = None):\n        print(f\"HybridAdapter initialized with parquet_dir={parquet_dir} and sql_server_conn_str={'<hidden>' if sql_server_conn_str else 'None'}\")\n        # Placeholder for actual data loading/connection\n        self.data = {} # Simulating loaded data\n        self.schema = {\n            \"une_id\": \"int\", \"produto_id\": \"int\", \"segmento\": \"str\",\n            \"media_considerada_lv\": \"float\", \"estoque_origem\": \"int\",\n            \"estoque_destino\": \"int\", \"linha_verde\": \"int\",\n            \"vendas_diarias\": \"float\", \"transferencias_pendentes\": \"int\",\n            \"criticidade\": \"str\" # URGENTE/ALTA/NORMAL\n        }\n\n    def fetch_data(self, filters: Dict[str, Any], columns: Optional[List[str]] = None) -> List[Dict]:\n        print(f\"Fetching data with filters: {filters}, columns: {columns}\")\n        # Simulate data fetching\n        # In a real scenario, this would query Parquet or SQL Server\n        # For now, return some dummy data that matches schema\n        dummy_data = [\n            {\"une_id\": 1, \"produto_id\": 101, \"segmento\": \"A\", \"media_considerada_lv\": 10.0, \"estoque_origem\": 50, \"estoque_destino\": 20, \"linha_verde\": 30, \"vendas_diarias\": 5.0, \"transferencias_pendentes\": 0, \"criticidade\": \"NORMAL\"},\n            {\"une_id\": 1, \"produto_id\": 102, \"segmento\": \"A\", \"media_considerada_lv\": 20.0, \"estoque_origem\": 10, \"estoque_destino\": 5, \"linha_verde\": 40, \"vendas_diarias\": 10.0, \"transferencias_pendentes\": 0, \"criticidade\": \"URGENTE\"},\n            {\"une_id\": 2, \"produto_id\": 101, \"segmento\": \"B\", \"media_considerada_lv\": 15.0, \"estoque_origem\": 100, \"estoque_destino\": 80, \"linha_verde\": 20, \"vendas_diarias\": 7.0, \"transferencias_pendentes\": 0, \"criticidade\": \"NORMAL\"},\n            {\"une_id\": 3, \"produto_id\": 103, \"segmento\": \"C\", \"media_considerada_lv\": 5.0, \"estoque_origem\": 5, \"estoque_destino\": 2, \"linha_verde\": 10, \"vendas_diarias\": 1.0, \"transferencias_pendentes\": 0, \"criticidade\": \"ALTA\"},\n        ]\n        \n        # Apply simple filtering for demonstration\n        filtered_data = []\n        for item in dummy_data:\n            match = True\n            for key, value in filters.items():\n                if key in item and item[key] != value:\n                    match = False\n                    break\n            if match:\n                filtered_data.append(item)\n        \n        if columns:\n            return [{col: item[col] for col in columns if col in item} for item in filtered_data]\n        return filtered_data\n    \n    def get_known_columns(self) -> Dict[str, str]:\n        return self.schema\n\n# Placeholder for @tool decorator\ndef tool(func):\n    def wrapper(*args, **kwargs):\n        print(f\"Tool '{func.__name__}' called with args: {args}, kwargs: {kwargs}\")\n        return func(*args, **kwargs)\n    return wrapper\n\n# --- Helper Functions (T3.2.2, T3.2.3, T3.2.4) ---\n\n@lru_cache(maxsize=1)\ndef _get_data_adapter() -> HybridAdapter:\n    \"\"\"\n    Returns a cached instance of HybridAdapter.\n    In a real scenario, configuration for parquet_dir and sql_server_conn_str\n    would come from settings.\n    \"\"\"", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3520, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "bdf78d43-d49d-45be-aad2-71162b6607f0": {"__data__": {"id_": "bdf78d43-d49d-45be-aad2-71162b6607f0", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools_backup_old.py", "language": "python", "lines": 349, "filename": "une_tools_backup_old.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\une_tools_backup_old.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools_backup_old.py", "language": "python", "lines": 349, "filename": "une_tools_backup_old.py"}, "hash": "8147ecb1d0427740339c7cdd9bef0240314d9a5e92081d5b1d898a82d9e1e082", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "385325ba-54d0-43a0-a6c5-d0a0d2ffdbff", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools_backup_old.py", "language": "python", "lines": 349, "filename": "une_tools_backup_old.py"}, "hash": "59c3a9978f8feddfef2e8ac6537c7cd65f8ed1daa51f881cb8758e0a1b6dab47", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9fb87a2b-bf2d-4a69-bf54-658c8f40f557", "node_type": "1", "metadata": {}, "hash": "63c62fd472d43616c95d2cdb703d96f42a9e846aa669f25cd7bc98233957e1e2", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# Placeholder: assuming data/parquet is standard, and SQL Server conn_str might be None for now\n    # We will expand this once settings.py is updated.\n    return HybridAdapter(parquet_dir=\"data/parquet\")\n\ndef _normalize_dataframe(df_data: List[Dict]) -> List[Dict]:\n    \"\"\"\n    Normalizes column names from SQL to Parquet conventions if necessary,\n    and ensures consistent data types.\n    Placeholder for actual normalization logic.\n    \"\"\"\n    # Example: if SQL had 'UNE_ID', convert to 'une_id'\n    normalized_data = []\n    for row in df_data:\n        new_row = {k.lower(): v for k, v in row.items()} # Simple lowercase normalization\n        normalized_data.append(new_row)\n    return normalized_data\n\ndef _load_data(filters: Dict[str, Any], columns: Optional[List[str]] = None) -> List[Dict]:\n    \"\"\"\n    Loads data using the HybridAdapter with given filters and columns.\n    Includes basic schema validation and error handling (placeholder).\n    \"\"\"\n    adapter = _get_data_adapter()\n    raw_data = adapter.fetch_data(filters, columns)\n    \n    # Placeholder for schema validation and recovery\n    valid_data = []\n    expected_schema = adapter.get_known_columns()\n    for row in raw_data:\n        # Simple validation: ensure all expected columns (if specified) are present\n        # and basic type checks\n        is_valid = True\n        if columns:\n            for col in columns:\n                if col not in row:\n                    print(f\"Warning: Column '{col}' missing in row: {row}\")\n                    is_valid = False\n                    break\n        if is_valid:\n            valid_data.append(row)\n            \n    return _normalize_dataframe(valid_data)\n\n# --- UNE Business Rules (T3.2.5) ---\n\n@tool\ndef calcular_abastecimento_une(une_id: int, segmento: Optional[str] = None, limite: int = 10) -> List[Dict]:\n    \"\"\"\n    Calcula a necessidade de abastecimento para uma UNE espec\u00edfica, opcionalmente por segmento.\n    Retorna os produtos com maior criticidade de abastecimento.\n    \"\"\"\n    print(f\"Calculating supply for UNE: {une_id}, Segmento: {segmento}, Limite: {limite}\")\n    \n    # Placeholder for fetching relevant data\n    filters = {\"une_id\": une_id}\n    if segmento:\n        filters[\"segmento\"] = segmento\n        \n    data = _load_data(filters)\n    \n    results = []\n    for row in data:\n        # Implementar c\u00e1lculo de criticidade de abastecimento (placeholder)\n        # Exemplo: (linha_verde - estoque_origem) / vendas_diarias\n        estoque = row.get(\"estoque_origem\", 0)\n        linha_verde = row.get(\"linha_verde\", 0)\n        vendas_diarias = row.get(\"vendas_diarias\", 1) # Avoid division by zero\n        \n        necessidade = linha_verde - estoque\n        dias_para_ruptura = necessidade / vendas_diarias if vendas_diarias > 0 else float('inf')\n\n        criticidade_abastecimento = \"NORMAL\"\n        if dias_para_ruptura < 5 and necessidade > 0: # Example rule\n            criticidade_abastecimento = \"URGENTE\"\n        elif dias_para_ruptura < 10 and necessidade > 0:\n            criticidade_abastecimento = \"ALTA\"\n\n        row[\"necessidade_abastecimento\"] = necessidade\n        row[\"dias_para_ruptura\"] = round(dias_para_ruptura, 2)\n        row[\"criticidade_abastecimento\"] = criticidade_abastecimento\n        results.append(row)\n\n    # Sort by criticidade_abastecimento (URGENTE > ALTA > NORMAL) and then necessidade\n    priority_order = {\"URGENTE\": 3, \"ALTA\": 2, \"NORMAL\": 1}\n    results.sort(key=lambda x: (priority_order.get(x.get(\"criticidade_abastecimento\"), 0), x.get(\"necessidade_abastecimento\", 0)), reverse=True)\n    \n    return results[:limite]\n\n\n@tool\ndef calcular_mc_produto(produto_id: int, une_id: int) -> Dict[str, Any]:\n    \"\"\"\n    Calcula a Margem de Contribui\u00e7\u00e3o (MC) para um produto espec\u00edfico em uma UNE.\n    A MC \u00e9 baseada na 'media_considerada_lv' ou na m\u00e9dia de vendas, conforme regras de neg\u00f3cio.\n    \"\"\"", "mimetype": "text/plain", "start_char_idx": 3525, "end_char_idx": 7394, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9fb87a2b-bf2d-4a69-bf54-658c8f40f557": {"__data__": {"id_": "9fb87a2b-bf2d-4a69-bf54-658c8f40f557", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools_backup_old.py", "language": "python", "lines": 349, "filename": "une_tools_backup_old.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\une_tools_backup_old.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools_backup_old.py", "language": "python", "lines": 349, "filename": "une_tools_backup_old.py"}, "hash": "8147ecb1d0427740339c7cdd9bef0240314d9a5e92081d5b1d898a82d9e1e082", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bdf78d43-d49d-45be-aad2-71162b6607f0", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools_backup_old.py", "language": "python", "lines": 349, "filename": "une_tools_backup_old.py"}, "hash": "3aced4c9ea99492ce97b3de93cd3f303f871bb5d01e85d743d239c1a79e6ac22", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c0d50bd7-8fbf-40c9-b1d5-f37507b1b994", "node_type": "1", "metadata": {}, "hash": "0df7c8a7e2092cb9fdc96fac83a47cca0ca010a3e2a20498e72d1aa7b6129945", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "print(f\"Calculating MC for Produto: {produto_id}, UNE: {une_id}\")\n    \n    data = _load_data({\"produto_id\": produto_id, \"une_id\": une_id}, columns=[\"media_considerada_lv\", \"vendas_diarias\"])\n    \n    if not data:\n        return {\"produto_id\": produto_id, \"une_id\": une_id, \"mc_calculada\": None, \"mensagem\": \"Dados n\u00e3o encontrados para o produto/UNE.\"}\n        \n    product_data = data[0]\n    media_considerada_lv = product_data.get(\"media_considerada_lv\")\n    vendas_diarias = product_data.get(\"vendas_diarias\")\n\n    mc_calculada = None\n    mensagem = \"C\u00e1lculo de MC n\u00e3o aplic\u00e1vel com os dados fornecidos.\"\n    \n    # Placeholder for actual MC calculation logic (T3.2.5)\n    # Exemplo: se media_considerada_lv existe, usa ela. Sen\u00e3o, usa vendas_diarias como base.\n    if media_considerada_lv is not None:\n        mc_calculada = media_considerada_lv * 0.25 # Exemplo: 25% de MC sobre a LV\n        mensagem = \"MC calculada com base na m\u00e9dia considerada LV.\"\n    elif vendas_diarias is not None:\n        mc_calculada = vendas_diarias * 0.20 # Exemplo: 20% de MC sobre vendas di\u00e1rias\n        mensagem = \"MC calculada com base na m\u00e9dia de vendas di\u00e1rias.\"\n\n    return {\n        \"produto_id\": produto_id,\n        \"une_id\": une_id,\n        \"mc_calculada\": round(mc_calculada, 2) if mc_calculada is not None else None,\n        \"mensagem\": mensagem\n    }\n\n@tool\ndef calcular_preco_final_une(produto_id: int, une_id: int) -> Dict[str, Any]:\n    \"\"\"\n    Calcula o pre\u00e7o final de venda para um produto em uma UNE espec\u00edfica,\n    considerando pol\u00edticas de precifica\u00e7\u00e3o (placeholder).\n    \"\"\"\n    print(f\"Calculating final price for Produto: {produto_id}, UNE: {une_id}\")\n    \n    data = _load_data({\"produto_id\": produto_id, \"une_id\": une_id}, columns=[\"media_considerada_lv\"])\n    \n    if not data:\n        return {\"produto_id\": produto_id, \"une_id\": une_id, \"preco_final\": None, \"mensagem\": \"Dados n\u00e3o encontrados para o produto/UNE.\"}\n        \n    product_data = data[0]\n    base_price = product_data.get(\"media_considerada_lv\") # Using LV as a base price placeholder\n    \n    preco_final = None\n    mensagem = \"N\u00e3o foi poss\u00edvel calcular o pre\u00e7o final.\"\n\n    if base_price is not None:\n        # Placeholder for complex pricing policies (T3.2.5)\n        # Exemplo: Adicionar 10% de margem e 5% de imposto\n        preco_final = base_price * 1.10 * 1.05\n        mensagem = \"Pre\u00e7o final calculado com base no pre\u00e7o base e pol\u00edticas internas.\"\n\n    return {\n        \"produto_id\": produto_id,\n        \"une_id\": une_id,\n        \"preco_final\": round(preco_final, 2) if preco_final is not None else None,\n        \"mensagem\": mensagem\n    }\n\n@tool\ndef validar_transferencia_produto(produto_id: int, une_origem: int, une_destino: int, quantidade: int) -> Dict[str, Any]:\n    \"\"\"\n    Valida se uma transfer\u00eancia de produto entre UNEs \u00e9 poss\u00edvel,\n    considerando estoque na origem, linha verde do destino, etc.\n    \"\"\"\n    print(f\"Validating transfer: Produto {produto_id} from UNE {une_origem} to UNE {une_destino}, Quantidade {quantidade}\")\n    \n    # Fetch data for origin and destination UNEs\n    origin_data = _load_data({\"produto_id\": produto_id, \"une_id\": une_origem}, columns=[\"estoque_origem\"])\n    dest_data = _load_data({\"produto_id\": produto_id, \"une_id\": une_destino}, columns=[\"linha_verde\", \"estoque_origem\", \"transferencias_pendentes\"])\n    \n    if not origin_data:\n        return {\"status\": \"falha\", \"mensagem\": f\"Dados da UNE de origem {une_origem} n\u00e3o encontrados para o produto {produto_id}.\"}", "mimetype": "text/plain", "start_char_idx": 7399, "end_char_idx": 10891, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c0d50bd7-8fbf-40c9-b1d5-f37507b1b994": {"__data__": {"id_": "c0d50bd7-8fbf-40c9-b1d5-f37507b1b994", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools_backup_old.py", "language": "python", "lines": 349, "filename": "une_tools_backup_old.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\une_tools_backup_old.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools_backup_old.py", "language": "python", "lines": 349, "filename": "une_tools_backup_old.py"}, "hash": "8147ecb1d0427740339c7cdd9bef0240314d9a5e92081d5b1d898a82d9e1e082", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9fb87a2b-bf2d-4a69-bf54-658c8f40f557", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools_backup_old.py", "language": "python", "lines": 349, "filename": "une_tools_backup_old.py"}, "hash": "47c182b2f8a5997a5dbabf929546182f2231dae954a732832bccf87280a084ee", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c2dcd50c-0af0-4117-85fb-e4e2c356e258", "node_type": "1", "metadata": {}, "hash": "e698cef6921f179c9577794b12a13bf5c8d9b3455c2a1d806b42b44042627319", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "if not dest_data:\n        return {\"status\": \"falha\", \"mensagem\": f\"Dados da UNE de destino {une_destino} n\u00e3o encontrados para o produto {produto_id}.\"}\n        \n    estoque_origem = origin_data[0].get(\"estoque_origem\", 0)\n    linha_verde_destino = dest_data[0].get(\"linha_verde\", 0)\n    estoque_destino_atual = dest_data[0].get(\"estoque_origem\", 0) # Using estoque_origem for current stock at destination\n    transferencias_pendentes = dest_data[0].get(\"transferencias_pendentes\", 0)\n\n    # Placeholder for validation rules (T3.2.5)\n    if estoque_origem < quantidade:\n        return {\"status\": \"falha\", \"mensagem\": f\"Estoque insuficiente na UNE de origem ({estoque_origem}) para transferir {quantidade} unidades.\"}\n    \n    # Check if destination would exceed Linea Verde after transfer + pending transfers\n    estoque_apos_transferencia = estoque_destino_atual + quantidade + transferencias_pendentes\n    if estoque_apos_transferencia > linha_verde_destino * 1.2: # Example: allow up to 20% over LV\n        return {\"status\": \"alerta\", \"mensagem\": f\"A transfer\u00eancia pode fazer a UNE de destino exceder significativamente a Linha Verde (LV={linha_verde_destino}). Estoque total ap\u00f3s transfer\u00eancia: {estoque_apos_transferencia}.\"}\n        \n    return {\"status\": \"sucesso\", \"mensagem\": \"Transfer\u00eancia validada e poss\u00edvel.\"}\n\n@tool\ndef sugerir_transferencias_automaticas(segmento: Optional[str] = None, une_origem_excluir: Optional[int] = None, limite: int = 5) -> List[Dict[str, Any]]:\n    \"\"\"\n    Sugere transfer\u00eancias autom\u00e1ticas baseadas em produtos com alta criticidade de ruptura\n    e disponibilidade em outras UNEs.\n    \"\"\"\n    print(f\"Suggesting automatic transfers for Segmento: {segmento}, Excluir UNE: {une_origem_excluir}, Limite: {limite}\")\n    \n    # Placeholder for identifying products in rupture (high criticality)\n    rupture_products = encontrar_rupturas_criticas(limite=limite*2) # Get more to filter\n    \n    suggestions = []\n    for prod_rupture in rupture_products:\n        product_id = prod_rupture[\"produto_id\"]\n        une_destino = prod_rupture[\"une_id\"]\n        \n        # Find potential origin UNEs\n        filters = {\"produto_id\": product_id}\n        if segmento:\n            filters[\"segmento\"] = segmento\n        if une_origem_excluir:\n            filters[\"une_id\"] = {\"$ne\": une_origem_excluir} # Placeholder for \"not equal\"\n            \n        all_unes_for_product = _load_data(filters, columns=[\"une_id\", \"estoque_origem\", \"linha_verde\"])\n        \n        for potential_origin in all_unes_for_product:\n            une_origem = potential_origin[\"une_id\"]\n            estoque_origem = potential_origin[\"estoque_origem\"]\n            \n            # Simple logic: if origin has enough stock and it's not the destination\n            if estoque_origem > prod_rupture.get(\"necessidade_abastecimento\", 0) and une_origem != une_destino:\n                # Validate the transfer (using the tool itself for consistency)\n                validation_result = validar_transferencia_produto(product_id, une_origem, une_destino, prod_rupture.get(\"necessidade_abastecimento\", 1))\n                \n                if validation_result[\"status\"] == \"sucesso\":\n                    suggestions.append({\n                        \"produto_id\": product_id,\n                        \"une_origem\": une_origem,\n                        \"une_destino\": une_destino,\n                        \"quantidade_sugerida\": prod_rupture.get(\"necessidade_abastecimento\", 1),\n                        \"mensagem\": validation_result[\"mensagem\"]\n                    })\n                    if len(suggestions) >= limite:\n                        break\n        if len(suggestions) >= limite:\n            break\n            \n    return suggestions[:limite]", "mimetype": "text/plain", "start_char_idx": 10896, "end_char_idx": 14629, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c2dcd50c-0af0-4117-85fb-e4e2c356e258": {"__data__": {"id_": "c2dcd50c-0af0-4117-85fb-e4e2c356e258", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools_backup_old.py", "language": "python", "lines": 349, "filename": "une_tools_backup_old.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\une_tools_backup_old.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools_backup_old.py", "language": "python", "lines": 349, "filename": "une_tools_backup_old.py"}, "hash": "8147ecb1d0427740339c7cdd9bef0240314d9a5e92081d5b1d898a82d9e1e082", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c0d50bd7-8fbf-40c9-b1d5-f37507b1b994", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\une_tools_backup_old.py", "language": "python", "lines": 349, "filename": "une_tools_backup_old.py"}, "hash": "fdc31e211b02fd415f15fbd62f07710f6c93666317fb50262373a796b74d9188", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "@tool\ndef encontrar_rupturas_criticas(limite: int = 5) -> List[Dict[str, Any]]:\n    \"\"\"\n    Identifica UNEs/produtos com maior probabilidade de ruptura cr\u00edtica,\n    baseado em estoque atual, linha verde e vendas di\u00e1rias.\n    \"\"\"\n    print(f\"Finding critical ruptures, Limite: {limite}\")\n    \n    data = _load_data({}) # Load all data for rupture analysis\n    \n    ruptures = []\n    for row in data:\n        estoque = row.get(\"estoque_origem\", 0)\n        linha_verde = row.get(\"linha_verde\", 0)\n        vendas_diarias = row.get(\"vendas_diarias\", 1) # Avoid division by zero\n        \n        # Placeholder for critical rupture logic (T3.2.5)\n        # Criticidade: URGENTE (estoque < 0.5 * LV e < 3 dias de venda)\n        # ALTA (estoque < LV e < 7 dias de venda)\n        \n        dias_cobertura = estoque / vendas_diarias if vendas_diarias > 0 else float('inf')\n        \n        criticidade = \"NORMAL\"\n        if estoque < (0.5 * linha_verde) and dias_cobertura < 3 and linha_verde > 0:\n            criticidade = \"URGENTE\"\n        elif estoque < linha_verde and dias_cobertura < 7 and linha_verde > 0:\n            criticidade = \"ALTA\"\n            \n        if criticidade in [\"URGENTE\", \"ALTA\"]:\n            row[\"dias_cobertura\"] = round(dias_cobertura, 2)\n            row[\"criticidade_ruptura\"] = criticidade\n            # Add a 'necessidade_abastecimento' for consistency with other tools\n            row[\"necessidade_abastecimento\"] = max(0, linha_verde - estoque)\n            ruptures.append(row)\n            \n    # Sort by criticidade_ruptura (URGENTE > ALTA) and then by necessidade_abastecimento\n    priority_order = {\"URGENTE\": 3, \"ALTA\": 2, \"NORMAL\": 1}\n    ruptures.sort(key=lambda x: (priority_order.get(x.get(\"criticidade_ruptura\"), 0), x.get(\"necessidade_abastecimento\", 0)), reverse=True)\n            \n    return ruptures[:limite]", "mimetype": "text/plain", "start_char_idx": 14632, "end_char_idx": 16474, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0cf02784-1747-4dad-b33a-398f712211ae": {"__data__": {"id_": "0cf02784-1747-4dad-b33a-398f712211ae", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\unified_data_tools.py", "language": "python", "lines": 329, "filename": "unified_data_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\unified_data_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\unified_data_tools.py", "language": "python", "lines": 329, "filename": "unified_data_tools.py"}, "hash": "34b5a0ff8cea7840dffcfd8871e4f93f2f6f4cf8de7d1c79b9c58ec34b1b05da", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "865602e3-ef29-44a4-b53a-cdb84e230443", "node_type": "1", "metadata": {}, "hash": "ed8ff2dc54e3aa362bf1adc583917a92c8a0ec3cca91bff2c3ba2fcd55d3250f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nFerramentas unificadas para acessar dados de Filial_Madureira.parquet\nEste arquivo foi refatorado para usar o DataSourceManager centralizado.\n\"\"\"\n\nimport logging\nfrom typing import Dict, Any, Optional, Union\nimport pandas as pd\nfrom langchain_core.tools import tool\n\n# Importa o gerenciador de dados centralizado\nfrom app.core.data_source_manager import get_data_manager\n\nlogger = logging.getLogger(__name__)\n\n\ndef _truncate_df_for_llm(df: pd.DataFrame, max_rows: int = 10) -> Dict[str, Any]:\n    \"\"\"Trunca o DataFrame e prepara a resposta para o LLM.\"\"\"\n    if df is None or df.empty:\n        return {\n            \"data\": [],\n            \"message\": \"Nenhum dado para exibir.\",\n            \"total_records\": 0\n        }\n    \n    total_records = len(df)\n    if total_records > max_rows:\n        return {\n            \"data\": df.head(max_rows).to_dict(orient=\"records\"),\n            \"message\": f\"Mostrando as primeiras {max_rows} de {total_records} linhas.\",\n            \"total_records\": total_records\n        }\n    return {\n        \"data\": df.to_dict(orient=\"records\"),\n        \"total_records\": total_records\n    }\n\n\n@tool\ndef listar_colunas_disponiveis() -> Dict[str, Any]:\n    \"\"\"\n    IMPORTANTE: Use esta ferramenta PRIMEIRO quando n\u00e3o souber quais colunas existem!\n    \n    Lista todas as colunas dispon\u00edveis na fonte de dados principal (Filial_Madureira.parquet)\n    com seus tipos de dados e exemplos de valores.\n    \n    Esta \u00e9 a \u00daNICA fonte de dados do sistema. N\u00e3o existe banco SQL ativo.\n    \n    Returns:\n        Dicion\u00e1rio com lista de colunas, tipos e exemplos de valores.\n    \"\"\"\n    logger.info(\"Listando colunas dispon\u00edveis via DataSourceManager\")\n    \n    try:\n        data_manager = get_data_manager()\n        source_info = data_manager.get_source_info()\n\n        if not source_info or source_info.get(\"status\") == \"sem_dados\":\n            return {\n                \"status\": \"error\",\n                \"message\": \"N\u00e3o foi poss\u00edvel carregar os dados atrav\u00e9s do DataSourceManager.\"\n            }\n\n        df = data_manager.get_data(limit=10) # Pega alguns dados para exemplos\n        if df.empty:\n             return {\n                \"status\": \"error\",\n                \"message\": \"Fonte de dados vazia.\"\n            }\n\n        colunas_info = []\n        for col, dtype in source_info.get(\"dtypes\", {}).items():\n            col_info = {\n                \"nome\": col,\n                \"tipo\": str(dtype),\n                \"exemplo\": str(df[col].iloc[0]) if not df.empty and col in df.columns and len(df) > 0 else \"N/A\",\n                \"valores_nulos\": int(df[col].isna().sum()) if col in df.columns else \"N/A\"\n            }\n            colunas_info.append(col_info)\n            \n        return {\n            \"status\": \"success\",\n            \"total_colunas\": source_info.get(\"shape\", (0,0))[1],\n            \"total_registros\": source_info.get(\"shape\", (0,0))[0],\n            \"colunas\": colunas_info,\n            \"arquivo\": source_info.get(\"file\"),\n            \"message\": f\"Encontradas {len(colunas_info)} colunas na fonte de dados.\"\n        }\n        \n    except Exception as e:\n        logger.error(f\"Erro ao listar colunas: {e}\", exc_info=True)\n        return {\n            \"status\": \"error\",\n            \"message\": f\"Erro: {str(e)}\"\n        }\n\n\n@tool\ndef consultar_dados(\n    coluna: Optional[str] = None,\n    valor: Optional[Union[str, int, float]] = None,  # \u2705 ACEITA string, int ou float\n    coluna_retorno: Optional[str] = None,\n    limite: int = 100\n) -> str:\n    \"\"\"\n    Consulta dados na fonte de dados Filial_Madureira.parquet.\n    \n    Use `listar_colunas_disponiveis` para ver as colunas.\n    \n    Args:\n        coluna: Nome da coluna para filtrar (opcional).\n        valor: Valor a buscar na coluna (aceita string, int ou float).\n        coluna_retorno: Coluna espec\u00edfica para retornar (opcional).\n        limite: Limite de registros (padr\u00e3o: 100).\n    \n    Returns:\n        Uma string formatada com os dados consultados ou uma mensagem de erro/n\u00e3o encontrado.\n    \"\"\"", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3991, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "865602e3-ef29-44a4-b53a-cdb84e230443": {"__data__": {"id_": "865602e3-ef29-44a4-b53a-cdb84e230443", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\unified_data_tools.py", "language": "python", "lines": 329, "filename": "unified_data_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\unified_data_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\unified_data_tools.py", "language": "python", "lines": 329, "filename": "unified_data_tools.py"}, "hash": "34b5a0ff8cea7840dffcfd8871e4f93f2f6f4cf8de7d1c79b9c58ec34b1b05da", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0cf02784-1747-4dad-b33a-398f712211ae", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\unified_data_tools.py", "language": "python", "lines": 329, "filename": "unified_data_tools.py"}, "hash": "39d275a42180da0655bd05e1bc6389a7da02b7396f178f30a513b17d42b260e6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "75bae677-5492-448e-9603-323e1e85d15e", "node_type": "1", "metadata": {}, "hash": "54523f3af828f7c1e5a48553b00bd3ae9f2a859e33be4ba9397a72e339bafb1a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "logger.info(f\"Consultando via DataSourceManager: coluna={coluna}, valor={valor}, coluna_retorno={coluna_retorno}, limite={limite}\")\n    \n    try:\n        data_manager = get_data_manager()\n        \n        # Se n\u00e3o houver filtro, retorna os primeiros dados\n        if not coluna or valor is None:\n            df_resultado = data_manager.get_data(limit=limite)\n        else:\n            # \u2705 Converte valor para string (aceita int, float ou string)\n            df_resultado = data_manager.search_data(column=coluna, value=str(valor), limit=limite)\n\n        if df_resultado is None or df_resultado.empty:\n            filtro_msg = f\" com filtro {coluna}='{valor}'\" if coluna and valor is not None else \"\"\n            return f\"Nenhum dado encontrado{filtro_msg}.\"\n\n        # Se coluna_retorno especificada, retornar apenas essa coluna\n        if coluna_retorno:\n            if coluna_retorno not in df_resultado.columns:\n                return f\"Coluna de retorno '{coluna_retorno}' n\u00e3o encontrada.\"\n            \n            if df_resultado.empty:\n                 return f\"Nenhum valor encontrado para '{coluna_retorno}' com o filtro especificado.\"\n\n            valor_retornado = df_resultado[coluna_retorno].iloc[0]\n            \n            if pd.isna(valor_retornado) or valor_retornado == '':\n                return f\"O valor para '{coluna_retorno}' no produto com {coluna}='{valor}' n\u00e3o foi encontrado ou est\u00e1 vazio.\"\n\n            # Formata\u00e7\u00e3o humanizada para casos comuns\n            coluna_upper = coluna.upper()\n            coluna_retorno_upper = coluna_retorno.upper()\n\n            # PRE\u00c7O DO PRODUTO\n            if coluna_upper == 'PRODUTO' and coluna_retorno_upper == 'LIQUIDO_38':\n                try:\n                    preco = float(valor_retornado)\n                    return f\"O pre\u00e7o do produto {valor} \u00e9 **R$ {preco:.2f}**.\"\n                except:\n                    return f\"O pre\u00e7o do produto {valor} \u00e9 R$ {valor_retornado}.\"\n\n            # CUSTO DO PRODUTO\n            elif coluna_upper == 'PRODUTO' and coluna_retorno_upper == 'ULTIMA_ENTRADA_CUSTO_CD':\n                try:\n                    custo = float(valor_retornado)\n                    return f\"O custo do produto {valor} \u00e9 **R$ {custo:.2f}**.\"\n                except:\n                    return f\"O custo do produto {valor} \u00e9 R$ {valor_retornado}.\"\n\n            # ESTOQUE DO PRODUTO\n            elif coluna_upper == 'PRODUTO' and coluna_retorno_upper == 'ESTOQUE_UNE':\n                try:\n                    estoque = int(valor_retornado)\n                    return f\"O produto {valor} tem **{estoque} unidades** em estoque.\"\n                except:\n                    return f\"O produto {valor} tem {valor_retornado} em estoque.\"\n\n            # NOME DO PRODUTO\n            elif coluna_upper == 'PRODUTO' and coluna_retorno_upper == 'NOME':\n                return f\"O produto {valor} \u00e9 **{valor_retornado}**.\"\n\n            # FABRICANTE DO PRODUTO\n            elif coluna_upper == 'PRODUTO' and coluna_retorno_upper == 'NOMEFABRICANTE':\n                return f\"O fabricante do produto {valor} \u00e9 **{valor_retornado}**.\"\n\n            # FALLBACK (caso gen\u00e9rico)\n            else:\n                return f\"O valor de {coluna_retorno} para {coluna}='{valor}' \u00e9 '{valor_retornado}'.\"\n        \n        # Retornar dados completos\n        response_data = _truncate_df_for_llm(df_resultado, max_rows=limite)\n        return f\"Consulta retornou {response_data['total_records']} registros. Primeiros resultados: {response_data['data']}\"\n        \n    except Exception as e:\n        logger.error(f\"Erro ao consultar dados: {e}\", exc_info=True)\n        return f\"Erro ao consultar dados: {str(e)}.\"", "mimetype": "text/plain", "start_char_idx": 3996, "end_char_idx": 7660, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "75bae677-5492-448e-9603-323e1e85d15e": {"__data__": {"id_": "75bae677-5492-448e-9603-323e1e85d15e", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\unified_data_tools.py", "language": "python", "lines": 329, "filename": "unified_data_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\unified_data_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\unified_data_tools.py", "language": "python", "lines": 329, "filename": "unified_data_tools.py"}, "hash": "34b5a0ff8cea7840dffcfd8871e4f93f2f6f4cf8de7d1c79b9c58ec34b1b05da", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "865602e3-ef29-44a4-b53a-cdb84e230443", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\unified_data_tools.py", "language": "python", "lines": 329, "filename": "unified_data_tools.py"}, "hash": "d9cbcc8478e41039a136e6c0d65ec7d87b0e3b7a221c4968554049dd944b6080", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "24511efe-6e77-4fc8-850c-9eeeae19df79", "node_type": "1", "metadata": {}, "hash": "dc9ea28493a90a4ff59e9fabe23e0b99ba9b83b4accc231ca3276423098e558e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "@tool\ndef buscar_produto(\n    codigo: Optional[str] = None,\n    nome: Optional[str] = None,\n    limite: int = 10\n) -> Dict[str, Any]:\n    \"\"\"\n    Busca produtos por c\u00f3digo ou nome usando o DataSourceManager.\n    \n    Args:\n        codigo: C\u00f3digo do produto (busca em 'CODIGO').\n        nome: Nome do produto (busca parcial em 'DESCRI\u00c7\u00c3O').\n        limite: N\u00famero m\u00e1ximo de resultados.\n    \n    Returns:\n        Dicion\u00e1rio com os produtos encontrados.\n    \"\"\"\n    logger.info(f\"Buscando produto via DataSourceManager: c\u00f3digo={codigo}, nome={nome}\")\n    \n    try:\n        data_manager = get_data_manager()\n        df_result = pd.DataFrame()\n        criterio = \"\"\n        valor_buscado = \"\"\n\n        if codigo:\n            df_result = data_manager.search_data(column='CODIGO', value=str(codigo).strip(), limit=limite)\n            criterio = \"c\u00f3digo\"\n            valor_buscado = codigo\n        elif nome:\n            df_result = data_manager.search_data(column='DESCRI\u00c7\u00c3O', value=nome, limit=limite)\n            criterio = \"nome\"\n            valor_buscado = nome\n        else:\n            return {\"status\": \"error\", \"message\": \"Informe c\u00f3digo ou nome do produto.\"}\n        \n        if df_result is None or df_result.empty:\n            return {\n                \"status\": \"not_found\",\n                \"message\": f\"Produto n\u00e3o encontrado com {criterio}='{valor_buscado}'.\"\n            }\n        \n        response_data = _truncate_df_for_llm(df_result, max_rows=limite)\n        \n        return {\n            \"status\": \"success\",\n            \"criterio_busca\": criterio,\n            \"valor_buscado\": valor_buscado,\n            \"colunas\": list(df_result.columns),\n            **response_data\n        }\n        \n    except Exception as e:\n        logger.error(f\"Erro ao buscar produto: {e}\", exc_info=True)\n        return {\"status\": \"error\", \"message\": f\"Erro: {str(e)}\"}", "mimetype": "text/plain", "start_char_idx": 7663, "end_char_idx": 9522, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "24511efe-6e77-4fc8-850c-9eeeae19df79": {"__data__": {"id_": "24511efe-6e77-4fc8-850c-9eeeae19df79", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\unified_data_tools.py", "language": "python", "lines": 329, "filename": "unified_data_tools.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\unified_data_tools.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\unified_data_tools.py", "language": "python", "lines": 329, "filename": "unified_data_tools.py"}, "hash": "34b5a0ff8cea7840dffcfd8871e4f93f2f6f4cf8de7d1c79b9c58ec34b1b05da", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "75bae677-5492-448e-9603-323e1e85d15e", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\tools\\unified_data_tools.py", "language": "python", "lines": 329, "filename": "unified_data_tools.py"}, "hash": "6617f9777d9d3ca2f8f8d7cbdb8f8bef5a5cb76ed550369273c18db48ecbdc9c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "@tool\ndef obter_estoque(\n    codigo_produto: Optional[str] = None,\n    nome_produto: Optional[str] = None\n) -> Dict[str, Any]:\n    \"\"\"\n    Obt\u00e9m informa\u00e7\u00f5es de estoque de um produto usando o DataSourceManager.\n    \n    Args:\n        codigo_produto: C\u00f3digo do produto.\n        nome_produto: Nome do produto.\n    \n    Returns:\n        Dados de estoque do produto.\n    \"\"\"\n    logger.info(f\"Consultando estoque via DataSourceManager: c\u00f3digo={codigo_produto}, nome={nome_produto}\")\n    \n    try:\n        data_manager = get_data_manager()\n        df_produto = pd.DataFrame()\n        criterio = \"\"\n\n        if codigo_produto:\n            df_produto = data_manager.search_data(column='CODIGO', value=str(codigo_produto).strip(), limit=1)\n            criterio = f\"c\u00f3digo={codigo_produto}\"\n        elif nome_produto:\n            df_produto = data_manager.search_data(column='DESCRI\u00c7\u00c3O', value=nome_produto, limit=1)\n            criterio = f\"nome contendo '{nome_produto}'\"\n        else:\n            return {\"status\": \"error\", \"message\": \"Informe c\u00f3digo ou nome do produto.\"}\n        \n        if df_produto is None or df_produto.empty:\n            return {\n                \"status\": \"not_found\",\n                \"message\": f\"Produto n\u00e3o encontrado com {criterio}.\"\n            }\n        \n        produto = df_produto.iloc[0]\n        \n        estoque_col = None\n        estoque_valor = 0\n        for col in ['QTD', 'SALDO', 'ESTOQUE']:\n            if col in df_produto.columns:\n                estoque_col = col\n                valor = produto.get(col)\n                if pd.notna(valor):\n                    estoque_valor = int(valor)\n                break\n        \n        info_produto = {\n            \"codigo\": str(produto.get('CODIGO', 'N/A')),\n            \"descricao\": str(produto.get('DESCRI\u00c7\u00c3O', 'N/A')),\n            \"estoque_coluna\": estoque_col,\n            \"estoque_valor\": estoque_valor,\n            \"fabricante\": str(produto.get('FABRICANTE', 'N/A')),\n            \"grupo\": str(produto.get('GRUPO', 'N/A'))\n        }\n        \n        return {\n            \"status\": \"success\",\n            \"criterio_busca\": criterio,\n            \"produto\": info_produto\n        }\n        \n    except Exception as e:\n        logger.error(f\"Erro ao obter estoque: {e}\", exc_info=True)\n        return {\"status\": \"error\", \"message\": f\"Erro: {str(e)}\"}\n\n\n# Lista de ferramentas unificadas - EXPORTA\u00c7\u00c3O IMPORTANTE\nunified_tools = [\n    listar_colunas_disponiveis,\n    consultar_dados,\n    buscar_produto,\n    obter_estoque,\n]", "mimetype": "text/plain", "start_char_idx": 9525, "end_char_idx": 12026, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e8bed705-17b2-4773-bb68-0f0bf2be4c06": {"__data__": {"id_": "e8bed705-17b2-4773-bb68-0f0bf2be4c06", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\verify_imports.py", "language": "python", "lines": 45, "filename": "verify_imports.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\verify_imports.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\verify_imports.py", "language": "python", "lines": 45, "filename": "verify_imports.py"}, "hash": "c814a22325fcb0f77bfbbe9a3d03cbe44abbc939b55e836b978b25e721bccdcd", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import importlib\n\n\"\"\"\nScript para verificar se as importa\u00e7\u00f5es funcionam corretamente.\n\"\"\"\n\n\ndef check_import(module_name):\n    try:\n        importlib.import_module(module_name)\n        print(f\"\u2713 Importa\u00e7\u00e3o de '{module_name}' bem-sucedida\")\n        return True\n    except ImportError as e:\n        print(f\"\u2717 Erro ao importar '{module_name}': {e}\")\n        return False\n\n\n# Lista de m\u00f3dulos para verificar\nmodules_to_check = [\n    \"langchain_core.messages\",\n\n    # \"langgraph.graph\",\n    \"langchain_community.utilities\",\n    \"sqlalchemy\",\n    \"dotenv\",\n]\n\nprint(\"Verificando importa\u00e7\u00f5es cr\u00edticas...\")\nall_passed = True\n\nfor module in modules_to_check:\n    if not check_import(module):\n        all_passed = False\n\nif all_passed:\n    print(\"\\nTodas as importa\u00e7\u00f5es funcionam corretamente!\")\n    print(\"Se voc\u00ea ainda v\u00ea erros no VS Code, tente:\")\n    print(\"1. Reiniciar o VS Code\")\n    print(\n        \"2. Selecionar o interpretador Python correto (Ctrl+Shift+P -> Python: Select Interpreter)\"\n    )\n    print(\"3. Verificar se o arquivo .vscode/settings.json foi criado corretamente\")\nelse:\n    print(\"\\nAlgumas importa\u00e7\u00f5es falharam. Verifique os erros acima.\")", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1155, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d95904f1-c546-4aee-99ba-7b526f88a907": {"__data__": {"id_": "d95904f1-c546-4aee-99ba-7b526f88a907", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\tools\\__init__.py", "language": "python", "lines": 1, "filename": "__init__.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\tools\\__init__.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\tools\\__init__.py", "language": "python", "lines": 1, "filename": "__init__.py"}, "hash": "9cf1be337c0f92a15a8759231532c8f78b212e7a952b39498987a2132a717380", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 0, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b3315497-d5a1-4a30-a1cc-3d412493e979": {"__data__": {"id_": "b3315497-d5a1-4a30-a1cc-3d412493e979", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\utils\\agent_cache.py", "language": "python", "lines": 199, "filename": "agent_cache.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\utils\\agent_cache.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\utils\\agent_cache.py", "language": "python", "lines": 199, "filename": "agent_cache.py"}, "hash": "8ec758f433940aa99815f332f7543ec56c9769164069b2d1fec37f3c9c7fc81a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5e35dcbc-e278-4905-ab31-404d2ccff1e2", "node_type": "1", "metadata": {}, "hash": "1bf731f7e5872fbec97c73eef74b7f3ee8da3b83418e11135e0c3784de59d5c8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nAgent Cache - Cache em mem\u00f3ria para resultados de ferramentas\nMelhoria 2024: Reduz lat\u00eancia em queries repetidas em at\u00e9 80%\n\"\"\"\n\nimport hashlib\nimport json\nimport logging\nfrom datetime import datetime, timedelta\nfrom typing import Any, Optional, Dict\nfrom functools import wraps\n\nlogger = logging.getLogger(__name__)", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 320, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5e35dcbc-e278-4905-ab31-404d2ccff1e2": {"__data__": {"id_": "5e35dcbc-e278-4905-ab31-404d2ccff1e2", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\utils\\agent_cache.py", "language": "python", "lines": 199, "filename": "agent_cache.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\utils\\agent_cache.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\utils\\agent_cache.py", "language": "python", "lines": 199, "filename": "agent_cache.py"}, "hash": "8ec758f433940aa99815f332f7543ec56c9769164069b2d1fec37f3c9c7fc81a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b3315497-d5a1-4a30-a1cc-3d412493e979", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\utils\\agent_cache.py", "language": "python", "lines": 199, "filename": "agent_cache.py"}, "hash": "3d4af27bdf987e044f7c66b1080b3a048c51f4dc362d29be4e2a8704f7aa6d9a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "28621ebf-0236-4cd6-a122-1656099df066", "node_type": "1", "metadata": {}, "hash": "bec741d0048fc67f1b7dfdb32ab508e823a172c6e6cda9566f145666fe1c43f7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "class AgentCache:\n    \"\"\"\n    Cache simples em mem\u00f3ria para resultados de ferramentas.\n    \n    Features:\n    - TTL configur\u00e1vel (padr\u00e3o: 5 minutos)\n    - Limpeza autom\u00e1tica de entradas expiradas\n    - Hash de argumentos para chave \u00fanica\n    - Thread-safe (b\u00e1sico)\n    \"\"\"\n    \n    def __init__(self, ttl_minutes: int = 5):\n        \"\"\"\n        Inicializa o cache.\n        \n        Args:\n            ttl_minutes: Tempo de vida das entradas em minutos\n        \"\"\"\n        self.cache: Dict[str, tuple[Any, datetime]] = {}\n        self.ttl = timedelta(minutes=ttl_minutes)\n        self.hits = 0\n        self.misses = 0\n        logger.info(f\"\u2705 AgentCache inicializado (TTL: {ttl_minutes} min)\")\n    \n    def _generate_key(self, tool_name: str, **kwargs) -> str:\n        \"\"\"\n        Gera chave \u00fanica baseada no nome da ferramenta e argumentos.\n        \n        Args:\n            tool_name: Nome da ferramenta\n            **kwargs: Argumentos da ferramenta\n            \n        Returns:\n            Hash MD5 da combina\u00e7\u00e3o\n        \"\"\"\n        # Serializar argumentos de forma determin\u00edstica\n        args_str = json.dumps(kwargs, sort_keys=True, default=str)\n        combined = f\"{tool_name}:{args_str}\"\n        return hashlib.md5(combined.encode()).hexdigest()\n    \n    def get(self, tool_name: str, **kwargs) -> Optional[Any]:\n        \"\"\"\n        Recupera valor do cache se existir e n\u00e3o estiver expirado.\n        \n        Args:\n            tool_name: Nome da ferramenta\n            **kwargs: Argumentos da ferramenta\n            \n        Returns:\n            Valor cacheado ou None se n\u00e3o encontrado/expirado\n        \"\"\"\n        key = self._generate_key(tool_name, **kwargs)\n        \n        if key in self.cache:\n            value, timestamp = self.cache[key]\n            \n            # Verificar se expirou\n            if datetime.now() - timestamp < self.ttl:\n                self.hits += 1\n                logger.info(f\"\ud83c\udfaf CACHE HIT: {tool_name} (hits: {self.hits}, misses: {self.misses})\")\n                return value\n            else:\n                # Remover entrada expirada\n                del self.cache[key]\n                logger.debug(f\"\u23f0 Cache expirado: {tool_name}\")\n        \n        self.misses += 1\n        logger.debug(f\"\u274c CACHE MISS: {tool_name} (hits: {self.hits}, misses: {self.misses})\")\n        return None\n    \n    def set(self, tool_name: str, value: Any, **kwargs) -> None:\n        \"\"\"\n        Armazena valor no cache.\n        \n        Args:\n            tool_name: Nome da ferramenta\n            value: Valor a ser cacheado\n            **kwargs: Argumentos da ferramenta\n        \"\"\"\n        key = self._generate_key(tool_name, **kwargs)\n        self.cache[key] = (value, datetime.now())\n        logger.debug(f\"\ud83d\udcbe Cache SET: {tool_name} (total entries: {len(self.cache)})\")\n    \n    def clear(self) -> None:\n        \"\"\"Limpa todo o cache.\"\"\"\n        self.cache.clear()\n        self.hits = 0\n        self.misses = 0\n        logger.info(\"\ud83d\uddd1\ufe0f  Cache limpo\")\n    \n    def cleanup_expired(self) -> int:\n        \"\"\"\n        Remove entradas expiradas do cache.\n        \n        Returns:\n            N\u00famero de entradas removidas\n        \"\"\"\n        now = datetime.now()\n        expired_keys = [\n            key for key, (_, timestamp) in self.cache.items()\n            if now - timestamp >= self.ttl\n        ]\n        \n        for key in expired_keys:\n            del self.cache[key]\n        \n        if expired_keys:\n            logger.info(f\"\ud83e\uddf9 Limpeza: {len(expired_keys)} entradas expiradas removidas\")\n        \n        return len(expired_keys)\n    \n    def get_stats(self) -> Dict[str, Any]:\n        \"\"\"\n        Retorna estat\u00edsticas do cache.\n        \n        Returns:\n            Dicion\u00e1rio com estat\u00edsticas\n        \"\"\"\n        total_requests = self.hits + self.misses\n        hit_rate = (self.hits / total_requests * 100) if total_requests > 0 else 0\n        \n        return {\n            \"total_entries\": len(self.cache),\n            \"hits\": self.hits,\n            \"misses\": self.misses,\n            \"hit_rate\": round(hit_rate, 2),\n            \"ttl_minutes\": self.ttl.total_seconds() / 60\n        }\n\n\n# Singleton global\n_agent_cache: Optional[AgentCache] = None", "mimetype": "text/plain", "start_char_idx": 323, "end_char_idx": 4501, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "28621ebf-0236-4cd6-a122-1656099df066": {"__data__": {"id_": "28621ebf-0236-4cd6-a122-1656099df066", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\utils\\agent_cache.py", "language": "python", "lines": 199, "filename": "agent_cache.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\utils\\agent_cache.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\utils\\agent_cache.py", "language": "python", "lines": 199, "filename": "agent_cache.py"}, "hash": "8ec758f433940aa99815f332f7543ec56c9769164069b2d1fec37f3c9c7fc81a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5e35dcbc-e278-4905-ab31-404d2ccff1e2", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\utils\\agent_cache.py", "language": "python", "lines": 199, "filename": "agent_cache.py"}, "hash": "3167d33190ab0910c175274223e95b085bd9661d3090c011f5007fa82bf2640f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# Singleton global\n_agent_cache: Optional[AgentCache] = None\n\n\ndef get_agent_cache(ttl_minutes: int = 5) -> AgentCache:\n    \"\"\"\n    Retorna inst\u00e2ncia singleton do cache.\n    \n    Args:\n        ttl_minutes: TTL em minutos (usado apenas na primeira chamada)\n        \n    Returns:\n        Inst\u00e2ncia do AgentCache\n    \"\"\"\n    global _agent_cache\n    if _agent_cache is None:\n        _agent_cache = AgentCache(ttl_minutes=ttl_minutes)\n    return _agent_cache\n\n\ndef cached_tool(ttl_minutes: int = 5):\n    \"\"\"\n    Decorator para cachear resultados de ferramentas.\n    \n    Usage:\n        @cached_tool(ttl_minutes=5)\n        @tool\n        def my_tool(arg1: str, arg2: int) -> Dict:\n            # ... expensive operation\n            return result\n    \n    Args:\n        ttl_minutes: Tempo de vida do cache em minutos\n    \"\"\"\n    def decorator(func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            cache = get_agent_cache(ttl_minutes)\n            tool_name = func.__name__\n            \n            # Tentar recuperar do cache\n            cached_result = cache.get(tool_name, **kwargs)\n            if cached_result is not None:\n                return cached_result\n            \n            # Executar fun\u00e7\u00e3o e cachear resultado\n            result = func(*args, **kwargs)\n            cache.set(tool_name, result, **kwargs)\n            \n            return result\n        \n        return wrapper\n    return decorator", "mimetype": "text/plain", "start_char_idx": 4441, "end_char_idx": 5867, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "29af04a2-e38f-4f46-bd10-351c6bd07267": {"__data__": {"id_": "29af04a2-e38f-4f46-bd10-351c6bd07267", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\utils\\cache_cleaner.py", "language": "python", "lines": 360, "filename": "cache_cleaner.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\utils\\cache_cleaner.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\utils\\cache_cleaner.py", "language": "python", "lines": 360, "filename": "cache_cleaner.py"}, "hash": "73774af184d72b5edd74bb878904865977b2995c9168d897de4e1723bec16ed6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0cff6f1e-39d2-48cf-984b-e1de7c1994cc", "node_type": "1", "metadata": {}, "hash": "fb6dd1b14a0740ed26c0b431e087080f5c0ba9f9fae7187a10d42958ae3e2d25", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nSistema Autom\u00e1tico de Limpeza de Cache\nAutor: Agent_Solution_BI (Adaptado para FastAPI)\nData: 2025-12-03\n\nEste m\u00f3dulo implementa limpeza autom\u00e1tica de caches para:\n- __pycache__ (bytecode Python)\n- data/cache (cache LLM responses)\n- data/cache_agent_graph (cache de grafos)\n- Versionamento autom\u00e1tico para invalida\u00e7\u00e3o de cache\n\nExecuta automaticamente no startup do FastAPI.\n\"\"\"\n\nimport os\nimport shutil\nimport logging\nimport hashlib\nimport json\nfrom datetime import datetime, timedelta\nfrom pathlib import Path\nfrom typing import Dict, List, Tuple\n\nlogger = logging.getLogger(__name__)\n\n\nclass CacheCleaner:\n    \"\"\"\n    Sistema centralizado de limpeza autom\u00e1tica de cache com versionamento.\n    \"\"\"\n\n    def __init__(self, base_path: str = None, max_age_days: int = 7):\n        \"\"\"\n        Inicializa o limpador de cache.\n\n        Args:\n            base_path: Diret\u00f3rio raiz do projeto (default: cwd)\n            max_age_days: Idade m\u00e1xima de arquivos de cache (default: 7 dias)\n        \"\"\"\n        self.base_path = Path(base_path or os.getcwd())\n        self.max_age_days = max_age_days\n        self.max_age_seconds = max_age_days * 24 * 3600\n\n        # Diret\u00f3rios de cache a serem gerenciados\n        self.cache_dirs = {\n            \"python_cache\": self.base_path / \"__pycache__\",\n            \"llm_cache\": self.base_path / \"data\" / \"cache\",\n            \"agent_graph_cache\": self.base_path / \"data\" / \"cache_agent_graph\",\n        }\n\n        # Arquivo de versionamento\n        self.version_file = self.base_path / \"data\" / \".cache_version\"\n\n        logger.info(f\"CacheCleaner inicializado - Base: {self.base_path}, Max Age: {max_age_days}d\")\n\n    def get_code_version_hash(self) -> str:\n        \"\"\"\n        \u2705 OTIMIZA\u00c7\u00c3O v2.2: Gera hash baseado apenas em arquivos cr\u00edticos (10-20 arquivos)\n        Reduz tempo de processamento de 500ms-1.5s para ~50-100ms (10x+ mais r\u00e1pido)\n\n        Returns:\n            Hash SHA256 dos arquivos Python cr\u00edticos (primeiros 12 caracteres)\n        \"\"\"\n        hasher = hashlib.sha256()\n\n        # \u2705 Lista de arquivos cr\u00edticos (altera\u00e7\u00f5es aqui realmente importam para cache)\n        critical_files = [\n            \"backend/main.py\",\n            \"backend/app/core/graph/agent.py\",\n            \"backend/app/core/llm_gemini_adapter.py\",\n            \"backend/app/core/agents/caculinha_bi_agent.py\",\n            \"backend/app/core/agents/code_gen_agent.py\",\n            \"backend/app/infrastructure/data/polars_dask_adapter.py\",\n            \"backend/app/infrastructure/data/hybrid_adapter.py\",\n            \"backend/app/core/tools/data_tools.py\",\n            \"backend/app/core/tools/une_tools.py\",\n            \"backend/app/core/cache.py\",\n            \"backend/app/core/utils/response_cache.py\"\n        ]\n\n        files_processed = 0\n        for relative_path in critical_files:\n            try:\n                full_path = self.base_path / relative_path\n                if full_path.exists():\n                    # Incluir caminho relativo e timestamp de modifica\u00e7\u00e3o\n                    hasher.update(relative_path.encode())\n                    stat = full_path.stat()\n                    hasher.update(str(stat.st_mtime).encode())\n                    files_processed += 1\n            except Exception as e:\n                logger.debug(f\"Arquivo n\u00e3o encontrado ou erro: {relative_path} - {e}\")\n                continue\n\n        logger.debug(f\"\u2705 Hash de vers\u00e3o gerado a partir de {files_processed} arquivos cr\u00edticos\")\n        version_hash = hasher.hexdigest()[:12]\n        return version_hash\n\n    def load_version_info(self) -> Dict:\n        \"\"\"\n        Carrega informa\u00e7\u00f5es de vers\u00e3o do cache.\n\n        Returns:\n            Dict com version_hash, last_cleaned, etc.\n        \"\"\"\n        if not self.version_file.exists():\n            return {}\n\n        try:\n            with open(self.version_file, 'r') as f:\n                return json.load(f)\n        except Exception as e:\n            logger.warning(f\"Erro ao carregar version info: {e}\")\n            return {}\n\n    def save_version_info(self, info: Dict):\n        \"\"\"\n        Salva informa\u00e7\u00f5es de vers\u00e3o do cache.\n\n        Args:\n            info: Dicion\u00e1rio com version_hash, last_cleaned, etc.\n        \"\"\"", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4188, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0cff6f1e-39d2-48cf-984b-e1de7c1994cc": {"__data__": {"id_": "0cff6f1e-39d2-48cf-984b-e1de7c1994cc", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\utils\\cache_cleaner.py", "language": "python", "lines": 360, "filename": "cache_cleaner.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\utils\\cache_cleaner.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\utils\\cache_cleaner.py", "language": "python", "lines": 360, "filename": "cache_cleaner.py"}, "hash": "73774af184d72b5edd74bb878904865977b2995c9168d897de4e1723bec16ed6", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "29af04a2-e38f-4f46-bd10-351c6bd07267", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\utils\\cache_cleaner.py", "language": "python", "lines": 360, "filename": "cache_cleaner.py"}, "hash": "979df02b0633eb98c8749ab2f6ccf9e01aac56773aee6100bb25f0b0f3b27846", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e96f435d-d657-44d4-aca1-8d417e131ddc", "node_type": "1", "metadata": {}, "hash": "a52f14fbb8fb8078f82c1c60578e25331f2c606f5b4a93cfc1851b9a59bfe37f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "try:\n            self.version_file.parent.mkdir(parents=True, exist_ok=True)\n            with open(self.version_file, 'w') as f:\n                json.dump(info, f, indent=2)\n        except Exception as e:\n            logger.error(f\"Erro ao salvar version info: {e}\")\n\n    def clean_pycache(self) -> Tuple[int, int]:\n        \"\"\"\n        Remove todos os diret\u00f3rios __pycache__ do projeto.\n\n        Returns:\n            (num_dirs_removed, total_size_mb)\n        \"\"\"\n        removed_count = 0\n        total_size = 0\n\n        try:\n            for pycache_dir in self.base_path.rglob(\"__pycache__\"):\n                try:\n                    # Calcular tamanho antes de remover\n                    for file in pycache_dir.rglob(\"*\"):\n                        if file.is_file():\n                            total_size += file.stat().st_size\n\n                    # Remover diret\u00f3rio\n                    shutil.rmtree(pycache_dir)\n                    removed_count += 1\n\n                except Exception as e:\n                    logger.warning(f\"Erro ao remover {pycache_dir}: {e}\")\n\n            size_mb = total_size / (1024 * 1024)\n            logger.info(f\"\u2705 Removidos {removed_count} diret\u00f3rios __pycache__ ({size_mb:.2f} MB)\")\n\n            return removed_count, size_mb\n\n        except Exception as e:\n            logger.error(f\"\u274c Erro na limpeza de __pycache__: {e}\")\n            return 0, 0\n\n    def clean_old_files(self, directory: Path, max_age_seconds: int = None) -> Tuple[int, int]:\n        \"\"\"\n        Remove arquivos antigos de um diret\u00f3rio.\n\n        Args:\n            directory: Diret\u00f3rio a limpar\n            max_age_seconds: Idade m\u00e1xima (default: self.max_age_seconds)\n\n        Returns:\n            (num_files_removed, total_size_mb)\n        \"\"\"\n        if not directory.exists():\n            return 0, 0\n\n        max_age = max_age_seconds or self.max_age_seconds\n        cutoff_time = datetime.now().timestamp() - max_age\n\n        removed_count = 0\n        total_size = 0\n\n        try:\n            for file in directory.rglob(\"*\"):\n                if not file.is_file():\n                    continue\n\n                try:\n                    # Verificar idade do arquivo\n                    file_mtime = file.stat().st_mtime\n\n                    if file_mtime < cutoff_time:\n                        file_size = file.stat().st_size\n                        total_size += file_size\n\n                        file.unlink()\n                        removed_count += 1\n\n                except Exception as e:\n                    logger.warning(f\"Erro ao remover {file}: {e}\")\n\n            size_mb = total_size / (1024 * 1024)\n\n            if removed_count > 0:\n                logger.info(f\"\u2705 Removidos {removed_count} arquivos antigos de {directory.name} ({size_mb:.2f} MB)\")\n\n            return removed_count, size_mb\n\n        except Exception as e:\n            logger.error(f\"\u274c Erro ao limpar {directory}: {e}\")\n            return 0, 0\n\n    def clean_all_cache(self, force: bool = False) -> Dict:\n        \"\"\"\n        Executa limpeza completa de todos os caches.\n\n        Args:\n            force: Se True, limpa tudo independente da vers\u00e3o\n\n        Returns:\n            Dict com estat\u00edsticas da limpeza\n        \"\"\"\n        logger.info(\"\ud83e\uddf9 Iniciando limpeza autom\u00e1tica de cache...\")\n\n        stats = {\n            \"timestamp\": datetime.now().isoformat(),\n            \"forced\": force,\n            \"pycache_removed\": 0,\n            \"pycache_size_mb\": 0,\n            \"old_files_removed\": 0,\n            \"old_files_size_mb\": 0,\n            \"cache_invalidated\": False,\n            \"previous_version\": None,\n            \"current_version\": None\n        }\n\n        # 1. Verificar versionamento\n        current_version = self.get_code_version_hash()\n        version_info = self.load_version_info()\n        previous_version = version_info.get(\"version_hash\")\n\n        stats[\"current_version\"] = current_version\n        stats[\"previous_version\"] = previous_version\n\n        # Se vers\u00e3o mudou, invalidar cache\n        if previous_version and previous_version != current_version:\n            logger.warning(f\"\ud83d\udd04 Vers\u00e3o do c\u00f3digo mudou: {previous_version} \u2192 {current_version}\")\n            logger.warning(\"\ud83e\uddf9 Invalidando TODOS os caches...\")\n            force = True\n            stats[\"cache_invalidated\"] = True\n\n        # 2.", "mimetype": "text/plain", "start_char_idx": 4197, "end_char_idx": 8507, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e96f435d-d657-44d4-aca1-8d417e131ddc": {"__data__": {"id_": "e96f435d-d657-44d4-aca1-8d417e131ddc", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\utils\\cache_cleaner.py", "language": "python", "lines": 360, "filename": "cache_cleaner.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\utils\\cache_cleaner.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\utils\\cache_cleaner.py", "language": "python", "lines": 360, "filename": "cache_cleaner.py"}, "hash": "73774af184d72b5edd74bb878904865977b2995c9168d897de4e1723bec16ed6", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0cff6f1e-39d2-48cf-984b-e1de7c1994cc", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\utils\\cache_cleaner.py", "language": "python", "lines": 360, "filename": "cache_cleaner.py"}, "hash": "f1a6924ada1f2bb84ea0daa43eebd217440bb78138d86c863e8449ed07399ce0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Limpar __pycache__ (sempre limpa)\n        pycache_count, pycache_size = self.clean_pycache()\n        stats[\"pycache_removed\"] = pycache_count\n        stats[\"pycache_size_mb\"] = round(pycache_size, 2)\n\n        # 3. Limpar arquivos antigos (ou tudo se force=True)\n        max_age = 0 if force else self.max_age_seconds\n\n        total_old_files = 0\n        total_old_size = 0\n\n        for cache_name, cache_dir in self.cache_dirs.items():\n            if cache_name == \"python_cache\":\n                continue  # J\u00e1 limpo acima\n\n            count, size = self.clean_old_files(cache_dir, max_age)\n            total_old_files += count\n            total_old_size += size\n\n        stats[\"old_files_removed\"] = total_old_files\n        stats[\"old_files_size_mb\"] = round(total_old_size, 2)\n\n        # 4. Salvar nova vers\u00e3o\n        new_version_info = {\n            \"version_hash\": current_version,\n            \"last_cleaned\": datetime.now().isoformat(),\n            \"max_age_days\": self.max_age_days,\n            \"stats\": stats\n        }\n\n        self.save_version_info(new_version_info)\n\n        # Log resumo\n        total_removed = stats[\"pycache_removed\"] + stats[\"old_files_removed\"]\n        total_size = stats[\"pycache_size_mb\"] + stats[\"old_files_size_mb\"]\n\n        logger.info(\"=\" * 80)\n        logger.info(\"\ud83d\udcca RESUMO DA LIMPEZA DE CACHE\")\n        logger.info(\"=\" * 80)\n        logger.info(f\"\ud83d\uddd1\ufe0f  Total de arquivos removidos: {total_removed}\")\n        logger.info(f\"\ud83d\udcbe Espa\u00e7o liberado: {total_size:.2f} MB\")\n        logger.info(f\"\ud83d\udd16 Vers\u00e3o do c\u00f3digo: {current_version}\")\n\n        if stats[\"cache_invalidated\"]:\n            logger.info(\"\ud83d\udd04 Cache invalidado (c\u00f3digo modificado)\")\n\n        logger.info(\"=\" * 80)\n\n        return stats\n\n    def clean_on_startup(self, force: bool = False):\n        \"\"\"\n        M\u00e9todo de conveni\u00eancia para executar no startup do FastAPI.\n\n        Args:\n            force: For\u00e7ar limpeza completa\n        \"\"\"\n        try:\n            stats = self.clean_all_cache(force=force)\n            return stats\n        except Exception as e:\n            logger.error(f\"\u274c Erro na limpeza de startup: {e}\", exc_info=True)\n            return None\n\n\ndef run_cache_cleanup(base_path: str = None, max_age_days: int = 7, force: bool = False) -> Dict:\n    \"\"\"\n    Fun\u00e7\u00e3o de conveni\u00eancia para executar limpeza de cache.\n\n    Args:\n        base_path: Diret\u00f3rio raiz do projeto\n        max_age_days: Idade m\u00e1xima de arquivos de cache\n        force: For\u00e7ar limpeza completa\n\n    Returns:\n        Dict com estat\u00edsticas da limpeza\n    \"\"\"\n    cleaner = CacheCleaner(base_path=base_path, max_age_days=max_age_days)\n    return cleaner.clean_on_startup(force=force)\n\n\nif __name__ == \"__main__\":\n    # Teste manual\n    import sys\n\n    # Configurar logging\n    logging.basicConfig(\n        level=logging.INFO,\n        format='%(levelname)s - %(name)s - %(message)s'\n    )\n\n    print(\"=\" * 80)\n    print(\"TESTE DO SISTEMA DE LIMPEZA DE CACHE\")\n    print(\"=\" * 80)\n\n    # Executar limpeza\n    stats = run_cache_cleanup(force=False)\n\n    if stats:\n        print(\"\\n[OK] Limpeza concluida com sucesso!\")\n        print(f\"\\nEstatisticas:\")\n        print(f\"  - Arquivos removidos: {stats['pycache_removed'] + stats['old_files_removed']}\")\n        print(f\"  - Espaco liberado: {stats['pycache_size_mb'] + stats['old_files_size_mb']:.2f} MB\")\n        print(f\"  - Versao: {stats['current_version']}\")\n    else:\n        print(\"\\n[ERRO] Erro na limpeza!\")\n        sys.exit(1)", "mimetype": "text/plain", "start_char_idx": 8508, "end_char_idx": 11959, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4118601c-e883-4008-9bad-54bd869bf6f2": {"__data__": {"id_": "4118601c-e883-4008-9bad-54bd869bf6f2", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\utils\\chart_saver.py", "language": "python", "lines": 54, "filename": "chart_saver.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\utils\\chart_saver.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\utils\\chart_saver.py", "language": "python", "lines": 54, "filename": "chart_saver.py"}, "hash": "ab463e10c7bbd7f5875cdc90b5cab35a96ed159b7f89b62b76d3bdf76fbe967d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import os\nimport json\nimport uuid\nfrom datetime import datetime\nfrom pathlib import Path\nimport logging\n\nlogger = logging.getLogger(__name__)\n\nDASHBOARD_DIR = \"data/dashboards\"\n\ndef save_chart(chart_json: str):\n    \"\"\"\n    Salva um gr\u00e1fico JSON em um arquivo no diret\u00f3rio de dashboards.\n\n    Args:\n        chart_json (str): A string JSON do gr\u00e1fico Plotly.\n    \"\"\"\n    try:\n        # Caminho h\u00edbrido Docker/Dev\n        docker_path = Path(\"/app/data/dashboards\")\n        dev_path = Path(__file__).parent.parent.parent.parent.parent / \"data\" / \"dashboards\"\n\n        dashboard_dir = docker_path if docker_path.parent.exists() else dev_path\n\n        # Garantir que o diret\u00f3rio de dashboards exista\n        os.makedirs(dashboard_dir, exist_ok=True)\n\n        # Extrair o t\u00edtulo do gr\u00e1fico do JSON para usar no nome do arquivo\n        chart_data = json.loads(chart_json) if isinstance(chart_json, str) else chart_json\n        title = chart_data.get(\"layout\", {}).get(\"title\", {}).get(\"text\", \"grafico-sem-titulo\")\n\n        # Limpar o t\u00edtulo para criar um nome de arquivo seguro\n        safe_title = \"\".join(c for c in title if c.isalnum() or c in (' ', '_')).rstrip()\n        safe_title = safe_title.replace(\" \", \"_\").lower()\n\n        # Criar um nome de arquivo \u00fanico\n        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n        unique_id = str(uuid.uuid4())[:8]\n        filename = f\"{timestamp}_{safe_title}_{unique_id}.json\"\n        filepath = os.path.join(dashboard_dir, filename)\n\n        # Salvar o arquivo\n        with open(filepath, \"w\", encoding=\"utf-8\") as f:\n            if isinstance(chart_json, str):\n                f.write(chart_json)\n            else:\n                json.dump(chart_json, f, ensure_ascii=False, indent=2)\n\n        logger.info(f\"Gr\u00e1fico salvo com sucesso em: {filepath}\")\n\n    except Exception as e:\n        logger.error(f\"Erro ao salvar o gr\u00e1fico: {e}\", exc_info=True)", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1902, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e44c79ee-0088-4d31-a65b-c7a4c805c24b": {"__data__": {"id_": "e44c79ee-0088-4d31-a65b-c7a4c805c24b", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\utils\\error_handler.py", "language": "python", "lines": 409, "filename": "error_handler.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\utils\\error_handler.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\utils\\error_handler.py", "language": "python", "lines": 409, "filename": "error_handler.py"}, "hash": "cac70a97617de1a482a2d5afce5e4935016460b39b5669d007560b98b276cd06", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "47898aaa-cd17-4258-b6f7-633031a7b66c", "node_type": "1", "metadata": {}, "hash": "2179da0ea91ba3575e5b52eb0152c6652cf505d9e77d476c1a9a1957f37c2d54", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nError Handler - Gerenciamento centralizado de erros.\n\nEste m\u00f3dulo fornece tratamento robusto e centralizado de erros\npara o sistema Agent Solution BI.\n\nFuncionalidades:\n- Captura de exce\u00e7\u00f5es espec\u00edficas (ParquetFileError, etc)\n- Logging estruturado com contexto completo\n- Mensagens user-friendly\n- Rastreamento de erros recorrentes\n\nAutor: Code Agent\nData: 2025-10-17\n\"\"\"\n\nimport logging\nimport traceback\nfrom typing import Dict, Any, Optional, Callable\nfrom datetime import datetime\nfrom pathlib import Path\nfrom functools import wraps\nimport json\n\nlogger = logging.getLogger(__name__)\n\n# Diret\u00f3rio para logs de erro\nERROR_LOG_DIR = Path(\"data/learning\")\nERROR_LOG_DIR.mkdir(parents=True, exist_ok=True)\n\n\nclass APIError(Exception):\n    \"\"\"Exce\u00e7\u00e3o customizada para erros da API\"\"\"\n    def __init__(self, message: str, status_code: int = 500, details: Optional[Dict[str, Any]] = None):\n        self.message = message\n        self.status_code = status_code\n        self.details = details or {}\n        super().__init__(self.message)", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1036, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "47898aaa-cd17-4258-b6f7-633031a7b66c": {"__data__": {"id_": "47898aaa-cd17-4258-b6f7-633031a7b66c", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\utils\\error_handler.py", "language": "python", "lines": 409, "filename": "error_handler.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\utils\\error_handler.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\utils\\error_handler.py", "language": "python", "lines": 409, "filename": "error_handler.py"}, "hash": "cac70a97617de1a482a2d5afce5e4935016460b39b5669d007560b98b276cd06", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e44c79ee-0088-4d31-a65b-c7a4c805c24b", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\utils\\error_handler.py", "language": "python", "lines": 409, "filename": "error_handler.py"}, "hash": "99cf628916ba5c96a1c022f9005008ad5f4a6f35de044c5e226f0e29b122893f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4b57f713-1bcc-46b0-b366-7665ebac3ff9", "node_type": "1", "metadata": {}, "hash": "22602ebb4db6e3962b37a4b25e240fe46d3af805484f3f6e6b3aa20cf2d7f533", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "class ErrorContext:\n    \"\"\"\n    Contexto de erro com informa\u00e7\u00f5es detalhadas.\n    \"\"\"\n\n    def __init__(\n        self,\n        error: Exception,\n        context: Dict[str, Any],\n        user_message: Optional[str] = None\n    ):\n        \"\"\"\n        Inicializa contexto de erro.\n\n        Args:\n            error: Exce\u00e7\u00e3o capturada\n            context: Dicion\u00e1rio com contexto (fun\u00e7\u00e3o, par\u00e2metros, etc)\n            user_message: Mensagem personalizada para o usu\u00e1rio\n        \"\"\"\n        self.error = error\n        self.error_type = type(error).__name__\n        self.error_message = str(error)\n        self.context = context\n        self.user_message = user_message or self._generate_user_message()\n        self.timestamp = datetime.now()\n        self.traceback = traceback.format_exc()\n\n    def _generate_user_message(self) -> str:\n        \"\"\"\n        Gera mensagem amig\u00e1vel baseada no tipo de erro.\n\n        Returns:\n            Mensagem formatada para o usu\u00e1rio\n        \"\"\"\n        error_messages = {\n            'FileNotFoundError': 'Arquivo de dados n\u00e3o encontrado. Verifique se os dados foram carregados.',\n            'PermissionError': 'Sem permiss\u00e3o para acessar o arquivo. Verifique as permiss\u00f5es do sistema.',\n            'KeyError': 'Campo n\u00e3o encontrado nos dados. Verifique os par\u00e2metros da consulta.',\n            'ValueError': 'Valor inv\u00e1lido encontrado. Verifique os dados de entrada.',\n            'TypeError': 'Tipo de dado incompat\u00edvel na opera\u00e7\u00e3o.',\n            'ParserError': 'Erro ao ler arquivo de dados. O arquivo pode estar corrompido.',\n            'MemoryError': 'Mem\u00f3ria insuficiente. Tente reduzir o volume de dados consultado.',\n            'TimeoutError': 'A opera\u00e7\u00e3o demorou muito tempo. Tente usar filtros mais espec\u00edficos.',\n            'ConnectionError': 'Erro de conex\u00e3o. Verifique a conectividade de rede.',\n            'OSError': 'Erro de sistema operacional ao acessar arquivos.',\n        }\n\n        base_message = error_messages.get(\n            self.error_type,\n            'Ocorreu um erro ao processar sua solicita\u00e7\u00e3o.'\n        )\n\n        return f\"{base_message}\"\n\n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"\n        Converte contexto para dicion\u00e1rio.\n\n        Returns:\n            Dict com informa\u00e7\u00f5es do erro\n        \"\"\"\n        return {\n            'timestamp': self.timestamp.isoformat(),\n            'error_type': self.error_type,\n            'error_message': self.error_message,\n            'user_message': self.user_message,\n            'context': self.context,\n            'traceback': self.traceback\n        }\n\n    def log(self, level: int = logging.ERROR):\n        \"\"\"\n        Registra erro no log.\n\n        Args:\n            level: N\u00edvel de log (logging.ERROR, logging.WARNING, etc)\n        \"\"\"\n        logger.log(\n            level,\n            f\"Erro {self.error_type}: {self.error_message}\\n\"\n            f\"Contexto: {json.dumps(self.context, indent=2)}\\n\"\n            f\"Traceback: {self.traceback}\"\n        )\n\n    def save_to_file(self):\n        \"\"\"\n        Salva erro em arquivo para an\u00e1lise posterior.\n        \"\"\"\n        try:\n            today = datetime.now().strftime('%Y%m%d')\n            error_file = ERROR_LOG_DIR / f\"error_log_{today}.jsonl\"\n\n            with open(error_file, 'a', encoding='utf-8') as f:\n                f.write(json.dumps(self.to_dict(), ensure_ascii=False) + '\\n')\n\n            logger.debug(f\"Erro salvo em {error_file}\")\n\n        except Exception as e:\n            logger.warning(f\"Erro ao salvar log de erro: {e}\")", "mimetype": "text/plain", "start_char_idx": 1039, "end_char_idx": 4547, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4b57f713-1bcc-46b0-b366-7665ebac3ff9": {"__data__": {"id_": "4b57f713-1bcc-46b0-b366-7665ebac3ff9", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\utils\\error_handler.py", "language": "python", "lines": 409, "filename": "error_handler.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\utils\\error_handler.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\utils\\error_handler.py", "language": "python", "lines": 409, "filename": "error_handler.py"}, "hash": "cac70a97617de1a482a2d5afce5e4935016460b39b5669d007560b98b276cd06", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "47898aaa-cd17-4258-b6f7-633031a7b66c", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\utils\\error_handler.py", "language": "python", "lines": 409, "filename": "error_handler.py"}, "hash": "f50ae843f8ac0aed9cce4b8587492eb1fbe1e21ea1f2224dec63c2e141215ee1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ff8cbf0c-9e91-4cff-bcb7-d343fed7f9f5", "node_type": "1", "metadata": {}, "hash": "0d778ad19470835fe8dc1500c05a42907d7c764e8895953bb70ac2495e3c558b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "class ErrorHandler:\n    \"\"\"\n    Gerenciador centralizado de erros.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"Inicializa o gerenciador de erros.\"\"\"\n        self.error_counts = {}\n        self.last_errors = []\n        self.max_last_errors = 100\n\n    def handle_error(\n        self,\n        error: Exception,\n        context: Dict[str, Any],\n        user_message: Optional[str] = None,\n        log_level: int = logging.ERROR,\n        save_to_file: bool = True\n    ) -> ErrorContext:\n        \"\"\"\n        Trata um erro de forma centralizada.\n\n        Args:\n            error: Exce\u00e7\u00e3o capturada\n            context: Contexto da opera\u00e7\u00e3o\n            user_message: Mensagem personalizada para usu\u00e1rio\n            log_level: N\u00edvel de log\n            save_to_file: Se deve salvar em arquivo\n\n        Returns:\n            ErrorContext com informa\u00e7\u00f5es do erro\n        \"\"\"\n        # Criar contexto de erro\n        error_ctx = ErrorContext(error, context, user_message)\n\n        # Registrar no log\n        error_ctx.log(log_level)\n\n        # Salvar em arquivo se necess\u00e1rio\n        if save_to_file:\n            error_ctx.save_to_file()\n\n        # Atualizar contadores\n        error_type = error_ctx.error_type\n        self.error_counts[error_type] = self.error_counts.get(error_type, 0) + 1\n\n        # Manter hist\u00f3rico de erros recentes\n        self.last_errors.append(error_ctx)\n        if len(self.last_errors) > self.max_last_errors:\n            self.last_errors.pop(0)\n\n        return error_ctx\n\n    def get_error_stats(self) -> Dict[str, Any]:\n        \"\"\"\n        Retorna estat\u00edsticas de erros.\n\n        Returns:\n            Dict com contadores e informa\u00e7\u00f5es de erros\n        \"\"\"\n        return {\n            'total_errors': sum(self.error_counts.values()),\n            'error_counts': self.error_counts,\n            'recent_errors_count': len(self.last_errors),\n            'most_common_error': max(self.error_counts.items(), key=lambda x: x[1])[0] if self.error_counts else None\n        }\n\n    def clear_stats(self):\n        \"\"\"Limpa estat\u00edsticas de erro.\"\"\"\n        self.error_counts.clear()\n        self.last_errors.clear()\n        logger.info(\"Estat\u00edsticas de erro limpas\")\n\n\n# Inst\u00e2ncia global\n_error_handler = ErrorHandler()\n\n\ndef handle_error(\n    error: Exception,\n    context: Dict[str, Any],\n    user_message: Optional[str] = None\n) -> ErrorContext:\n    \"\"\"\n    Fun\u00e7\u00e3o auxiliar para tratamento de erro.\n\n    Args:\n        error: Exce\u00e7\u00e3o\n        context: Contexto\n        user_message: Mensagem para usu\u00e1rio\n\n    Returns:\n        ErrorContext\n    \"\"\"\n    return _error_handler.handle_error(error, context, user_message)\n\n\ndef get_error_stats() -> Dict[str, Any]:\n    \"\"\"Retorna estat\u00edsticas de erros.\"\"\"\n    return _error_handler.get_error_stats()", "mimetype": "text/plain", "start_char_idx": 4550, "end_char_idx": 7300, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ff8cbf0c-9e91-4cff-bcb7-d343fed7f9f5": {"__data__": {"id_": "ff8cbf0c-9e91-4cff-bcb7-d343fed7f9f5", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\utils\\error_handler.py", "language": "python", "lines": 409, "filename": "error_handler.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\utils\\error_handler.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\utils\\error_handler.py", "language": "python", "lines": 409, "filename": "error_handler.py"}, "hash": "cac70a97617de1a482a2d5afce5e4935016460b39b5669d007560b98b276cd06", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4b57f713-1bcc-46b0-b366-7665ebac3ff9", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\utils\\error_handler.py", "language": "python", "lines": 409, "filename": "error_handler.py"}, "hash": "6269814eaf34359b5503fee6cf0e239d6bf7f14b442286eeec1038a240bddecc", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "dd00cab5-67b4-49c9-8125-6b9ae42ad12d", "node_type": "1", "metadata": {}, "hash": "0a9490e0e1949f52d70d6b8220629a11f8366f1d71e717dcad57707302055636", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "def error_handler_decorator(\n    context_func: Optional[Callable] = None,\n    user_message: Optional[str] = None,\n    return_on_error: Any = None\n):\n    \"\"\"\n    Decorador para tratamento autom\u00e1tico de erros.\n\n    Args:\n        context_func: Fun\u00e7\u00e3o que retorna contexto (recebe args, kwargs)\n        user_message: Mensagem personalizada para usu\u00e1rio\n        return_on_error: Valor a retornar em caso de erro\n\n    Example:\n        @error_handler_decorator(\n            context_func=lambda *args, **kwargs: {'function': 'my_func', 'args': args},\n            return_on_error={'success': False, 'data': []}\n        )\n        def my_function(param1, param2):\n            # c\u00f3digo que pode gerar erro\n            pass\n    \"\"\"\n    def decorator(func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            try:\n                return func(*args, **kwargs)\n\n            except Exception as e:\n                # Gerar contexto\n                if context_func:\n                    context = context_func(*args, **kwargs)\n                else:\n                    context = {\n                        'function': func.__name__,\n                        'args': str(args)[:200],  # Limitar tamanho\n                        'kwargs': str(kwargs)[:200]\n                    }\n\n                # Tratar erro\n                error_ctx = _error_handler.handle_error(e, context, user_message)\n\n                # Retornar valor padr\u00e3o ou re-raise\n                if return_on_error is not None:\n                    # Se return_on_error for um dict, adicionar mensagem de erro\n                    if isinstance(return_on_error, dict):\n                        result = return_on_error.copy()\n                        result['error'] = error_ctx.user_message\n                        result['error_type'] = error_ctx.error_type\n                        return result\n                    else:\n                        return return_on_error\n                else:\n                    raise\n\n        return wrapper\n    return decorator\n\n\ndef create_error_response(\n    error: Exception,\n    context: Dict[str, Any],\n    include_details: bool = False\n) -> Dict[str, Any]:\n    \"\"\"\n    Cria resposta padronizada de erro.\n\n    Args:\n        error: Exce\u00e7\u00e3o capturada\n        context: Contexto da opera\u00e7\u00e3o\n        include_details: Se deve incluir detalhes t\u00e9cnicos\n\n    Returns:\n        Dict com resposta de erro formatada\n    \"\"\"\n    error_ctx = _error_handler.handle_error(error, context)\n\n    response = {\n        'success': False,\n        'data': [],\n        'count': 0,\n        'message': error_ctx.user_message,\n        'error_type': error_ctx.error_type,\n        'timestamp': error_ctx.timestamp.isoformat()\n    }\n\n    if include_details:\n        response['error_details'] = {\n            'error_message': error_ctx.error_message,\n            'context': error_ctx.context\n        }\n\n    return response\n\n\n# Mapeamento de exce\u00e7\u00f5es espec\u00edficas do Parquet\nclass ParquetErrorHandler:\n    \"\"\"\n    Handler espec\u00edfico para erros relacionados a arquivos Parquet.\n    \"\"\"\n\n    @staticmethod\n    def handle_parquet_error(error: Exception, file_path: str) -> Dict[str, Any]:\n        \"\"\"\n        Trata erros espec\u00edficos de Parquet.\n\n        Args:\n            error: Exce\u00e7\u00e3o\n            file_path: Caminho do arquivo Parquet\n\n        Returns:\n            Dict com resposta de erro\n        \"\"\"\n        context = {\n            'operation': 'parquet_read',\n            'file_path': file_path,\n            'file_exists': Path(file_path).exists()\n        }\n\n        # Mensagens espec\u00edficas para erros Parquet\n        parquet_messages = {\n            'ArrowInvalid': 'Arquivo Parquet inv\u00e1lido ou corrompido.',\n            'ArrowIOError': 'Erro de I/O ao ler arquivo Parquet.',\n            'OSError': f'N\u00e3o foi poss\u00edvel acessar o arquivo: {file_path}',\n        }\n\n        error_type = type(error).__name__\n        user_message = parquet_messages.get(error_type)\n\n        return create_error_response(error, context, include_details=False)", "mimetype": "text/plain", "start_char_idx": 7303, "end_char_idx": 11306, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "dd00cab5-67b4-49c9-8125-6b9ae42ad12d": {"__data__": {"id_": "dd00cab5-67b4-49c9-8125-6b9ae42ad12d", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\utils\\error_handler.py", "language": "python", "lines": 409, "filename": "error_handler.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\utils\\error_handler.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\utils\\error_handler.py", "language": "python", "lines": 409, "filename": "error_handler.py"}, "hash": "cac70a97617de1a482a2d5afce5e4935016460b39b5669d007560b98b276cd06", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ff8cbf0c-9e91-4cff-bcb7-d343fed7f9f5", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\utils\\error_handler.py", "language": "python", "lines": 409, "filename": "error_handler.py"}, "hash": "e3ae05600b552150f4124866957f3c0c2ee8ae94668be49249d5c904b2e67421", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "if __name__ == \"__main__\":\n    # Teste b\u00e1sico do error handler\n    logging.basicConfig(level=logging.INFO)\n\n    # Teste 1: Erro simples\n    try:\n        raise ValueError(\"Teste de erro\")\n    except Exception as e:\n        error_ctx = handle_error(\n            e,\n            context={'function': 'test', 'param': 'value'}\n        )\n        print(f\"\\nMensagem para usu\u00e1rio: {error_ctx.user_message}\")\n\n    # Teste 2: Estat\u00edsticas\n    stats = get_error_stats()\n    print(f\"\\nEstat\u00edsticas: {stats}\")\n\n    # Teste 3: Decorador\n    @error_handler_decorator(\n        context_func=lambda x: {'param': x},\n        return_on_error={'success': False, 'data': []}\n    )\n    def test_function(param):\n        if param == 'error':\n            raise KeyError(\"Campo n\u00e3o encontrado\")\n        return {'success': True, 'data': [param]}\n\n    result = test_function('error')\n    print(f\"\\nResultado com erro: {result}\")\n\n    result = test_function('ok')\n    print(f\"Resultado sem erro: {result}\")", "mimetype": "text/plain", "start_char_idx": 11309, "end_char_idx": 12286, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "cc24b328-654f-4eb6-86bb-2cc798a7b147": {"__data__": {"id_": "cc24b328-654f-4eb6-86bb-2cc798a7b147", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\utils\\error_handler_backup.py", "language": "python", "lines": 116, "filename": "error_handler_backup.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\utils\\error_handler_backup.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\utils\\error_handler_backup.py", "language": "python", "lines": 116, "filename": "error_handler_backup.py"}, "hash": "af3df6f7885a3dbd73ffaa7af4e387a371df7e753f172974d8b523912e7f05e8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# backend/app/core/utils/error_handler.py\n\nimport functools\nimport logging\nfrom typing import Callable, Any, Dict\n\n# Configure basic logging for now. In a real app, this would be more sophisticated.\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\nlogger = logging.getLogger(__name__)\n\nclass APIError(Exception):\n    \"\"\"Custom exception for API-related errors.\"\"\"\n    def __init__(self, message: str, status_code: int = 500, details: Any = None):\n        super().__init__(message)\n        self.message = message\n        self.status_code = status_code\n        self.details = details\n\n    def to_dict(self) -> Dict[str, Any]:\n        return {\n            \"message\": self.message,\n            \"status_code\": self.status_code,\n            \"details\": self.details\n        }\n\ndef error_handler_decorator(func: Callable) -> Callable:\n    \"\"\"\n    Decorator for handling errors in FastAPI endpoints or core logic functions.\n    It logs the error in a structured format and returns a user-friendly APIError response.\n    \"\"\"\n    @functools.wraps(func)\n    async def wrapper(*args, **kwargs) -> Any:\n        try:\n            # If the original function is an async function, await it\n            if inspect.iscoroutinefunction(func):\n                return await func(*args, **kwargs)\n            else:\n                return func(*args, **kwargs)\n        except APIError as e:\n            # Custom APIError, log and re-raise (or return appropriate response)\n            logger.error(\n                \"API Error caught in %s: %s\",\n                func.__name__,\n                e.message,\n                exc_info=True,\n                extra={\"status_code\": e.status_code, \"details\": e.details}\n            )\n            raise e # Re-raise to be caught by FastAPI's exception handlers\n        except Exception as e:\n            # Catch all other unexpected errors\n            error_message = \"An unexpected error occurred.\"\n            status_code = 500\n            \n            # Attempt to extract a more specific message if available\n            if hasattr(e, 'detail'): # Common for HTTPException in FastAPI\n                error_message = e.detail\n            elif str(e):\n                error_message = str(e)\n\n            logger.error(\n                \"Unhandled exception in %s: %s\",\n                func.__name__,\n                error_message,\n                exc_info=True,\n                extra={\"original_exception_type\": type(e).__name__}\n            )\n            # You might want to return a standardized error response here,\n            # or raise a new APIError which FastAPI can then handle.\n            raise APIError(\n                message=f\"Internal Server Error: {error_message}\",\n                status_code=status_code,\n                details={\"function\": func.__name__, \"error_type\": type(e).__name__}\n            )\n    return wrapper\n\nimport inspect # Import inspect for checking coroutine function\n\n# Example usage (for demonstration, can be removed in final version)\nif __name__ == \"__main__\":\n    # Example functions to demonstrate the decorator\n    @error_handler_decorator\n    def my_sync_function(should_fail: bool):\n        if should_fail:\n            raise ValueError(\"Something went wrong in sync function!\")\n        return {\"status\": \"success\", \"data\": \"Sync data\"}\n\n    @error_handler_decorator\n    async def my_async_function(should_fail: bool):\n        if should_fail:\n            raise APIError(\"Custom API error in async function!\", status_code=400, details={\"code\": \"BAD_REQUEST\"})\n        return {\"status\": \"success\", \"data\": \"Async data\"}\n\n    # Test sync function\n    print(\"--- Testing Sync Function ---\")\n    try:\n        print(my_sync_function(False))\n        # print(my_sync_function(True)) # This would raise an APIError\n    except APIError as e:\n        print(f\"Caught APIError: {e.to_dict()}\")\n    except Exception as e:\n        print(f\"Caught unexpected exception: {e}\")\n\n    # Test async function (requires an async context to run)\n    print(\"\\n--- Testing Async Function ---\")\n    import asyncio\n    async def run_async_tests():\n        try:\n            print(await my_async_function(False))\n            # print(await my_async_function(True)) # This would raise an APIError\n        except APIError as e:\n            print(f\"Caught APIError: {e.to_dict()}\")\n        except Exception as e:\n            print(f\"Caught unexpected exception: {e}\")\n\n    asyncio.run(run_async_tests())", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4480, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "68952c1a-2574-4218-8627-81144f3e0f48": {"__data__": {"id_": "68952c1a-2574-4218-8627-81144f3e0f48", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\utils\\fast_path_detector.py", "language": "python", "lines": 74, "filename": "fast_path_detector.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\utils\\fast_path_detector.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\utils\\fast_path_detector.py", "language": "python", "lines": 74, "filename": "fast_path_detector.py"}, "hash": "b414a4980aa25ed7f21435c83abb75cfc5a4c912b96e10e380b30370959f0640", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# backend/app/core/utils/fast_path_detector.py\n\nimport re\nfrom typing import Optional\n\ndef detect_fast_path_query(query: str) -> Optional[str]:\n    \"\"\"\n    Detects if a query can be handled by a fast-path, bypassing complex agent orchestration. \n    \n    Fast-path queries are typically simple, direct requests that can be routed to a\n    specific tool or information retrieval mechanism without LLM reasoning steps.\n\n    Args:\n        query: The user's natural language query.\n\n    Returns:\n        The name of the target node/tool for the fast-path, or None if no fast-path is detected.\n    \"\"\"\n    query_lower = query.lower()\n\n    # Fast-path for UNE Operations\n    if \"abastecimento\" in query_lower or \\\n       \"mc produto\" in query_lower or \\\n       \"pre\u00e7o final\" in query_lower or \\\n       \"validar transfer\u00eancia\" in query_lower or \\\n       \"sugerir transfer\u00eancias\" in query_lower or \\\n       \"rupturas cr\u00edticas\" in query_lower:\n        # These queries can likely be routed directly to the specific UNE tools\n        # The CaculinhaBIAgent already handles this with its tool routing logic.\n        # This function could return a specific tool name to indicate a fast-path match.\n        if \"abastecimento\" in query_lower:\n            return \"calcular_abastecimento_une\"\n        elif \"mc produto\" in query_lower:\n            return \"calcular_mc_produto\"\n        elif \"pre\u00e7o final\" in query_lower:\n            return \"calcular_preco_final_une\"\n        elif \"validar transfer\u00eancia\" in query_lower:\n            return \"validar_transferencia_produto\"\n        elif \"sugerir transfer\u00eancias\" in query_lower:\n            return \"sugerir_transferencias_automaticas\"\n        elif \"rupturas cr\u00edticas\" in query_lower:\n            return \"encontrar_rupturas_criticas\"\n\n    # Fast-path for simple data retrieval/listing\n    if re.search(r\"mostre-me (as )?(dez )?(cinco )?(dez )?(ultimas |primeiras )?vendas\", query_lower) or \\\n       re.search(r\"listar (todos )?(os )?produtos\", query_lower):\n        # These might be handled by a direct database query tool or a simple data listing tool\n        return \"simple_data_listing_tool\"\n\n    # Fast-path for status/health checks\n    if \"status\" in query_lower or \"sa\u00fade\" in query_lower:\n        return \"status_check_tool\" # Example: an API endpoint for health\n\n    return None\n\nif __name__ == '__main__':\n    print(\"--- Testing Fast-Path Detector ---\")\n    \n    # UNE related queries\n    print(f\"Query: 'Qual o abastecimento da UNE 101?' -> Fast-path: {detect_fast_path_query('Qual o abastecimento da UNE 101?')}\")\n    print(f\"Query: 'Calcular MC do produto X' -> Fast-path: {detect_fast_path_query('Calcular MC do produto X')}\")\n    print(f\"Query: 'Validar transfer\u00eancia de 10 unidades' -> Fast-path: {detect_fast_path_query('Validar transfer\u00eancia de 10 unidades')}\")\n    print(f\"Query: 'Encontrar rupturas cr\u00edticas' -> Fast-path: {detect_fast_path_query('Encontrar rupturas cr\u00edticas')}\")\n\n    # Simple data retrieval\n    print(f\"Query: 'Mostre-me as \u00faltimas vendas' -> Fast-path: {detect_fast_path_query('Mostre-me as \u00faltimas vendas')}\")\n    print(f\"Query: 'Listar todos os produtos' -> Fast-path: {detect_fast_path_query('Listar todos os produtos')}\")\n\n    # Non-fast-path queries\n    print(f\"Query: 'Qual a correla\u00e7\u00e3o entre vendas e marketing?' -> Fast-path: {detect_fast_path_query('Qual a correla\u00e7\u00e3o entre vendas e marketing?')}\")\n    print(f\"Query: 'Quero um gr\u00e1fico complexo' -> Fast-path: {detect_fast_path_query('Quero um gr\u00e1fico complexo')}\")\n\n    print(\"\\nFast-path detection tests completed.\")", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3540, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8bb15477-2a99-4ab2-9324-3d47205c20fa": {"__data__": {"id_": "8bb15477-2a99-4ab2-9324-3d47205c20fa", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\utils\\field_mapper.py", "language": "python", "lines": 125, "filename": "field_mapper.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\utils\\field_mapper.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\utils\\field_mapper.py", "language": "python", "lines": 125, "filename": "field_mapper.py"}, "hash": "451b96040052323ee3a70f95c13815edadb45157036ed2b5ab97170348b8bab3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a0b35d7c-d9c5-42d3-bdee-01959a76702a", "node_type": "1", "metadata": {}, "hash": "8393636f9612ff7439429a40ad0b4f8f71a614f82d7c7ecf9c17f489fd235861", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# backend/app/core/utils/field_mapper.py\n\nimport json\nfrom typing import Any, Dict, List, Optional\n\nclass FieldMapper:\n    \"\"\"\n    Maps natural language terms to actual database field names using a catalog.\n    Also provides known fields for agents.\n    \"\"\"\n    def __init__(self, catalog_path: str = \"data/catalog_focused.json\"):\n        self.catalog_path = catalog_path\n        self.catalog = self._load_catalog(catalog_path)\n        self.reverse_catalog = {v: k for k, v in self.catalog.items()} # For mapping back if needed\n\n    def _load_catalog(self, catalog_path: str) -> Dict[str, Any]:\n        \"\"\"\n        Loads the catalog from a JSON file.\n        Placeholder implementation. In a real scenario, this would load a dynamic catalog.\n        \"\"\"\n        try:\n            with open(catalog_path, 'r', encoding='utf-8') as f:\n                # Assuming the catalog file has a structure that maps natural language\n                # terms to their corresponding database/parquet field names.\n                # Example: {\"unidade de negocio\": \"une_id\", \"produto\": \"produto_id\"}\n                data = json.load(f)\n                # Flatten or process the loaded data as needed\n                # For now, a simple direct mapping from a flat dict is assumed.\n                if isinstance(data, dict):\n                    # Simple example: if catalog is a direct mapping\n                    return {k.lower(): v for k, v in data.items()}\n                else:\n                    print(f\"Warning: Catalog file {catalog_path} has unexpected structure. Using default placeholder catalog.\")\n                    return self._get_default_placeholder_catalog()\n        except FileNotFoundError:\n            print(f\"Warning: Catalog file {catalog_path} not found. Using default placeholder catalog.\")\n            return self._get_default_placeholder_catalog()\n        except json.JSONDecodeError:\n            print(f\"Warning: Error decoding JSON from {catalog_path}. Using default placeholder catalog.\")\n            return self._get_default_placeholder_catalog()\n\n    def _get_default_placeholder_catalog(self) -> Dict[str, str]:\n        \"\"\"Default catalog if file not found or invalid.\"\"\"\n        return {\n            \"unidade de negocio\": \"une_id\",\n            \"produto\": \"produto_id\",\n            \"segmento de mercado\": \"segmento\",\n            \"margem de contribuicao\": \"media_considerada_lv\", # Example mapping\n            \"estoque\": \"estoque_origem\",\n            \"linha verde\": \"linha_verde\",\n            \"vendas diarias\": \"vendas_diarias\",\n            \"transferencias pendentes\": \"transferencias_pendentes\",\n            \"id da une\": \"une_id\", # common variations\n            \"id do produto\": \"produto_id\"\n        }\n\n    def map_term(self, natural_language_term: str) -> Optional[str]:\n        \"\"\"\n        Maps a natural language term to its corresponding database field name.\n        Performs a case-insensitive lookup.\n        \"\"\"\n        if not isinstance(natural_language_term, str):\n            return None\n        return self.catalog.get(natural_language_term.lower(), natural_language_term)\n\n    def get_known_fields(self) -> List[str]:\n        \"\"\"\n        Returns a list of all known natural language terms in the catalog.\n        \"\"\"\n        return list(self.catalog.keys())\n\n    def get_db_fields(self) -> List[str]:\n        \"\"\"\n        Returns a list of all known database field names in the catalog.\n        \"\"\"\n        return list(set(self.catalog.values()))\n\n    def suggest_correction(self, invalid_term: str) -> Optional[str]:\n        \"\"\"\n        Suggests a correction for an invalid term based on similarity.\n        Placeholder for a more advanced fuzzy matching implementation.\n        \"\"\"", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3707, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a0b35d7c-d9c5-42d3-bdee-01959a76702a": {"__data__": {"id_": "a0b35d7c-d9c5-42d3-bdee-01959a76702a", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\utils\\field_mapper.py", "language": "python", "lines": 125, "filename": "field_mapper.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\utils\\field_mapper.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\utils\\field_mapper.py", "language": "python", "lines": 125, "filename": "field_mapper.py"}, "hash": "451b96040052323ee3a70f95c13815edadb45157036ed2b5ab97170348b8bab3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8bb15477-2a99-4ab2-9324-3d47205c20fa", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\utils\\field_mapper.py", "language": "python", "lines": 125, "filename": "field_mapper.py"}, "hash": "ea5e89212abf524cf142c7e0deffea3b9f1b62f7488df0d8e74243684dd3a56a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Placeholder for a more advanced fuzzy matching implementation.\n        \"\"\"\n        # For now, a very simple suggestion (e.g., if it's close to a known field)\n        # Could use fuzzywuzzy or difflib for better matching\n        invalid_term_lower = invalid_term.lower()\n        for nl_term, db_field in self.catalog.items():\n            if invalid_term_lower in nl_term or nl_term in invalid_term_lower:\n                return nl_term # Return the natural language term as a suggestion\n        return None\n\nif __name__ == '__main__':\n    # Create a dummy catalog_focused.json for testing\n    dummy_catalog_path = \"data/catalog_focused.json\"\n    dummy_catalog_content = {\n        \"unidade de negocio\": \"une_id\",\n        \"produto\": \"produto_id\",\n        \"segmento\": \"segmento\",\n        \"quantidade estoque\": \"estoque_origem\"\n    }\n    # Ensure 'data' directory exists for this test\n    import os\n    if not os.path.exists(\"data\"):\n        os.makedirs(\"data\")\n    with open(dummy_catalog_path, 'w', encoding='utf-8') as f:\n        json.dump(dummy_catalog_content, f, indent=4)\n\n    print(\"--- Testing FieldMapper ---\")\n    mapper = FieldMapper()\n    \n    print(f\"Map 'Unidade de Negocio': {mapper.map_term('Unidade de Negocio')}\")\n    print(f\"Map 'PRODUTO': {mapper.map_term('PRODUTO')}\")\n    print(f\"Map 'segmento': {mapper.map_term('segmento')}\")\n    print(f\"Map 'quantidade em estoque': {mapper.map_term('quantidade em estoque')}\") # Should map to estoque_origem if it recognizes a close match\n\n    print(f\"Known fields: {mapper.get_known_fields()}\")\n    print(f\"DB fields: {mapper.get_db_fields()}\")\n\n    print(f\"Suggest for 'unidade': {mapper.suggest_correction('unidade')}\")\n    print(f\"Suggest for 'produt': {mapper.suggest_correction('produt')}\")\n    print(f\"Suggest for 'non_existent_field': {mapper.suggest_correction('non_existent_field')}\")\n\n    # Clean up dummy file\n    os.remove(dummy_catalog_path)\n    print(f\"Cleaned up dummy catalog: {dummy_catalog_path}\")", "mimetype": "text/plain", "start_char_idx": 3633, "end_char_idx": 5604, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9e384c65-3965-431a-8ab8-c790a273cf63": {"__data__": {"id_": "9e384c65-3965-431a-8ab8-c790a273cf63", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\utils\\query_history.py", "language": "python", "lines": 179, "filename": "query_history.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\utils\\query_history.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\utils\\query_history.py", "language": "python", "lines": 179, "filename": "query_history.py"}, "hash": "c8899e5d1173288cd1a41ce5b8d7ac6996c2af2ac03e14dbf9eb8806e4db85c3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d8e449e7-cd63-4e7e-b19c-27db8d1dab60", "node_type": "1", "metadata": {}, "hash": "9bfbf263307385180e67ca51050f699d8ea62d64810b05ad59405b82f3608e7b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# backend/app/core/utils/query_history.py\n\nimport json\nimport os\nfrom datetime import datetime\nfrom typing import Any, Dict, List, Optional\n\nclass QueryHistory:\n    \"\"\"\n    Manages user query history, persisting it to daily JSONL files.\n    Allows for searching and filtering of past queries.\n    (T1.3.3 from TASK_LIST)\n    \"\"\"\n    def __init__(self, history_dir: str = \"data/query_history\"):\n        self.history_dir = history_dir\n        os.makedirs(self.history_dir, exist_ok=True)\n        print(f\"QueryHistory initialized in {self.history_dir}\")\n\n    def _get_daily_file_path(self, date: Optional[datetime] = None) -> str:\n        \"\"\"Generates the file path for a given day.\"\"\"\n        if date is None:\n            date = datetime.now()\n        date_str = date.strftime(\"%Y-%m-%d\")\n        return os.path.join(self.history_dir, f\"queries_{date_str}.jsonl\")\n\n    def add_query(self, user_id: str, query: str, response: Dict[str, Any], timestamp: Optional[datetime] = None):\n        \"\"\"\n        Adds a new query entry to the daily history file.\n        \"\"\"\n        if timestamp is None:\n            timestamp = datetime.now()\n        \n        entry = {\n            \"timestamp\": timestamp.isoformat(),\n            \"user_id\": user_id,\n            \"query\": query,\n            \"response_summary\": self._summarize_response(response), # Store a summary, not full response\n            \"full_response_hash\": self._hash_response(response) # Hash of full response for integrity/lookup\n        }\n        file_path = self._get_daily_file_path(timestamp)\n        \n        try:\n            with open(file_path, \"a\", encoding=\"utf-8\") as f:\n                f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n            print(f\"Query added to history for user {user_id}.\")\n        except OSError as e:\n            print(f\"Error writing query history file {file_path}: {e}\")\n\n    def _summarize_response(self, response: Dict[str, Any]) -> str:\n        \"\"\"Creates a brief summary of the response for history logging.\"\"\"\n        if \"type\" in response:\n            if response[\"type\"] == \"text\" and \"text\" in response:\n                return response[\"text\"][:100] + (\"...\" if len(response[\"text\"]) > 100 else \"\")\n            if response[\"type\"] == \"tool_result\" and \"tool_name\" in response:\n                return f\"Tool result from {response['tool_name']}\"\n            if response[\"type\"] == \"code_result\" and \"result\" in response:\n                return \"Code execution result.\"\n        return json.dumps(response)[:100] + (\"...\" if len(json.dumps(response)) > 100 else \"\")\n\n    def _hash_response(self, response: Dict[str, Any]) -> str:\n        \"\"\"Generates a hash of the full response for later integrity checks or matching.\"\"\"\n        import hashlib\n        return hashlib.sha256(json.dumps(response, sort_keys=True).encode(\"utf-8\")).hexdigest()\n\n    def get_history(self, user_id: Optional[str] = None, start_date: Optional[datetime] = None, end_date: Optional[datetime] = None, limit: int = 100) -> List[Dict[str, Any]]:\n        \"\"\"\n        Retrieves query history for a user, within a date range, with an optional limit.\n        \"\"\"", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3128, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d8e449e7-cd63-4e7e-b19c-27db8d1dab60": {"__data__": {"id_": "d8e449e7-cd63-4e7e-b19c-27db8d1dab60", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\utils\\query_history.py", "language": "python", "lines": 179, "filename": "query_history.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\utils\\query_history.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\utils\\query_history.py", "language": "python", "lines": 179, "filename": "query_history.py"}, "hash": "c8899e5d1173288cd1a41ce5b8d7ac6996c2af2ac03e14dbf9eb8806e4db85c3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9e384c65-3965-431a-8ab8-c790a273cf63", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\utils\\query_history.py", "language": "python", "lines": 179, "filename": "query_history.py"}, "hash": "1485ed09ab5c4b6734509d105d1e35e0f368b2cb1657d6298efc8736543fc33a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8d1928ae-c73b-4672-a7ce-63d91c3d1ce5", "node_type": "1", "metadata": {}, "hash": "780e878249399df62a902f6f324f42f051167665313c6a159dda6471e9eaac73", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "history_records: List[Dict[str, Any]] = []\n\n        # Use reasonable defaults instead of datetime.min/max to avoid Windows issues\n        if start_date is None:\n            start_date = datetime(2020, 1, 1)  # Reasonable past date\n        if end_date is None:\n            end_date = datetime(2099, 12, 31)  # Reasonable future date\n\n        # Create date ranges with safe boundaries\n        end_date_upper = end_date.replace(hour=23, minute=59, second=59, microsecond=999999)\n        start_date_lower = start_date.replace(hour=0, minute=0, second=0, microsecond=0)\n\n        # Iterate through history files (simple scan, can be optimized with file naming convention)\n        for filename in sorted(os.listdir(self.history_dir), reverse=True): # Newest files first\n            if filename.startswith(\"queries_\") and filename.endswith(\".jsonl\"):\n                file_date_str = filename[8:18] # YYYY-MM-DD\n                try:\n                    file_date = datetime.strptime(file_date_str, \"%Y-%m-%d\")\n                except ValueError:\n                    continue  # Skip invalid filenames\n\n                if file_date > end_date_upper:\n                    continue\n                if file_date < start_date_lower:\n                    break # Assuming files are sorted, we can stop early\n\n                file_path = os.path.join(self.history_dir, filename)\n                try:\n                    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n                        for line in f:\n                            try:\n                                entry = json.loads(line)\n                                entry_timestamp = datetime.fromisoformat(entry[\"timestamp\"])\n\n                                if start_date <= entry_timestamp <= end_date:\n                                    if user_id is None or entry.get(\"user_id\") == user_id:\n                                        history_records.append(entry)\n                                        if len(history_records) >= limit:\n                                            return history_records # Return early if limit reached\n                            except json.JSONDecodeError:\n                                print(f\"Warning: Corrupt JSON line in {filename}: {line.strip()}\")\n                except OSError as e:\n                    print(f\"Error reading history file {file_path}: {e}\")\n        \n        return history_records[:limit]\n\n    def search_queries(self, user_id: Optional[str] = None, keyword: str = \"\", limit: int = 100) -> List[Dict[str, Any]]:\n        \"\"\"\n        Searches query history for entries containing a specific keyword.\n        \"\"\"\n        matching_records: List[Dict[str, Any]] = []\n        all_records = self.get_history(user_id=user_id, limit=None) # Get all relevant history first\n\n        keyword_lower = keyword.lower()\n        for entry in all_records:\n            if keyword_lower in entry.get(\"query\", \"\").lower() or \\\n               keyword_lower in entry.get(\"response_summary\", \"\").lower():\n                matching_records.append(entry)\n                if len(matching_records) >= limit:\n                    break\n        return matching_records\n\n# Example usage\nif __name__ == '__main__':\n    from app.config.settings import Settings\n    temp_settings = Settings()\n\n    # Ensure history directory exists for testing\n    os.makedirs(temp_settings.LEARNING_EXAMPLES_PATH, exist_ok=True) # Using LEARNING_EXAMPLES_PATH as temp history dir\n\n    history = QueryHistory(history_dir=temp_settings.LEARNING_EXAMPLES_PATH)\n\n    user1_id = \"test_user_1\"\n    user2_id = \"test_user_2\"\n\n    # Add some queries\n    history.add_query(user1_id, \"Vendas totais do produto A?\", {\"type\": \"text\", \"text\": \"Total de vendas: 100\"})\n    history.add_query(user1_id, \"Gr\u00e1fico de vendas por regi\u00e3o?\", {\"type\": \"chart\", \"chart_spec\": {\"data\": []}})\n    history.add_query(user2_id, \"Qual o estoque atual?\", {\"type\": \"text\", \"text\": \"Estoque: 500\"})\n    history.add_query(user1_id, \"Top 5 produtos?", "mimetype": "text/plain", "start_char_idx": 3137, "end_char_idx": 7110, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8d1928ae-c73b-4672-a7ce-63d91c3d1ce5": {"__data__": {"id_": "8d1928ae-c73b-4672-a7ce-63d91c3d1ce5", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\utils\\query_history.py", "language": "python", "lines": 179, "filename": "query_history.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\utils\\query_history.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\utils\\query_history.py", "language": "python", "lines": 179, "filename": "query_history.py"}, "hash": "c8899e5d1173288cd1a41ce5b8d7ac6996c2af2ac03e14dbf9eb8806e4db85c3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d8e449e7-cd63-4e7e-b19c-27db8d1dab60", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\utils\\query_history.py", "language": "python", "lines": 179, "filename": "query_history.py"}, "hash": "d664e5eb026484c4000ebd1440ab5165a744c702acc32933ba6fdac63043a267", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\", {\"type\": \"code_result\", \"result\": [{\"prod\": \"X\", \"val\": 50}]}\n)\n\n    print(\"\\n--- Testing get_history ---\")\n    all_history = history.get_history()\n    print(f\"All history ({len(all_history)} records):\")\n    for entry in all_history:\n        print(f\"  [{entry['timestamp']}] User {entry['user_id']}: {entry['query']} -> {entry['response_summary']}\")\n\n    user1_history = history.get_history(user_id=user1_id)\n    print(f\"\\nUser 1 history ({len(user1_history)} records):\")\n    for entry in user1_history:\n        print(f\"  [{entry['timestamp']}] User {entry['user_id']}: {entry['query']} -> {entry['response_summary']}\")\n\n    print(\"\\n--- Testing search_queries ---\")\n    search_results = history.search_queries(keyword=\"vendas\")\n    print(f\"Search 'vendas' ({len(search_results)} records):\")\n    for entry in search_results:\n        print(f\"  [{entry['timestamp']}] User {entry['user_id']}: {entry['query']} -> {entry['response_summary']}\")\n\n    search_user1_chart = history.search_queries(user_id=user1_id, keyword=\"gr\u00e1fico\")\n    print(f\"\\nSearch 'gr\u00e1fico' for User 1 ({len(search_user1_chart)} records):\")\n    for entry in search_user1_chart:\n        print(f\"  [{entry['timestamp']}] User {entry['user_id']}: {entry['query']} -> {entry['response_summary']}\")\n\n    # Clean up dummy files\n    for filename in os.listdir(temp_settings.LEARNING_EXAMPLES_PATH):\n        if filename.startswith(\"queries_\"):\n            os.remove(os.path.join(temp_settings.LEARNING_EXAMPLES_PATH, filename))\n    print(\"\\nCleaned up dummy history files.\")\n    print(\"\\nQueryHistory tests passed!\")", "mimetype": "text/plain", "start_char_idx": 7110, "end_char_idx": 8688, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7aa2b149-63e2-48fb-b8ca-5138e15c13ed": {"__data__": {"id_": "7aa2b149-63e2-48fb-b8ca-5138e15c13ed", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\utils\\query_validator.py", "language": "python", "lines": 362, "filename": "query_validator.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\utils\\query_validator.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\utils\\query_validator.py", "language": "python", "lines": 362, "filename": "query_validator.py"}, "hash": "778eb01314e93fc6278b03666695890b4e6a00f5250134c33ce548287e806d39", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e95fcc6f-a591-4093-af65-c3fa7fcebb4a", "node_type": "1", "metadata": {}, "hash": "84f5c16219fb3c5fbaf5f89da8fdd123a0a78dc01ebc669d6f15b7ef25da722b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nQuery Validator - Validador de queries Parquet.\n\nEste m\u00f3dulo fornece valida\u00e7\u00e3o robusta de queries antes da execu\u00e7\u00e3o,\nincluindo verifica\u00e7\u00e3o de colunas, tipos e timeout.\n\nFuncionalidades:\n- Valida\u00e7\u00e3o de colunas antes de filtrar\n- Tratamento de valores None/null\n- Timeout para queries longas\n- Mensagens de erro user-friendly\n\nAutor: Code Agent\nData: 2025-10-17\n\"\"\"\n\nimport logging\nimport signal\nfrom typing import List, Dict, Any, Optional, Callable\nfrom contextlib import contextmanager\nimport pandas as pd\n\nlogger = logging.getLogger(__name__)\n\n\nclass QueryTimeout(Exception):\n    \"\"\"Exce\u00e7\u00e3o levantada quando query excede timeout.\"\"\"\n    pass\n\n\nclass QueryValidator:\n    \"\"\"\n    Validador de queries com timeout e verifica\u00e7\u00e3o de integridade.\n    \"\"\"\n\n    def __init__(self, default_timeout: int = 30):\n        \"\"\"\n        Inicializa o validador.\n\n        Args:\n            default_timeout: Timeout padr\u00e3o em segundos\n        \"\"\"\n        self.default_timeout = default_timeout\n\n    @contextmanager\n    def timeout_context(self, seconds: int):\n        \"\"\"\n        Context manager para timeout de queries.\n\n        Args:\n            seconds: Tempo m\u00e1ximo de execu\u00e7\u00e3o em segundos\n\n        Raises:\n            QueryTimeout: Se a query exceder o tempo limite\n        \"\"\"\n        def timeout_handler(signum, frame):\n            raise QueryTimeout(f\"Query excedeu o tempo limite de {seconds} segundos\")\n\n        # Configurar handler (apenas em sistemas Unix-like)\n        try:\n            old_handler = signal.signal(signal.SIGALRM, timeout_handler)\n            signal.alarm(seconds)\n            try:\n                yield\n            finally:\n                signal.alarm(0)\n                signal.signal(signal.SIGALRM, old_handler)\n        except AttributeError:\n            # Windows n\u00e3o suporta SIGALRM, executar sem timeout\n            logger.warning(\"Timeout n\u00e3o suportado nesta plataforma\")\n            yield\n\n    def validate_columns_in_dataframe(\n        self,\n        df: pd.DataFrame,\n        required_columns: List[str],\n        table_name: str = \"DataFrame\"\n    ) -> tuple[bool, List[str]]:\n        \"\"\"\n        Valida se colunas existem no DataFrame.\n\n        Args:\n            df: DataFrame a validar\n            required_columns: Lista de colunas obrigat\u00f3rias\n            table_name: Nome da tabela (para mensagens de erro)\n\n        Returns:\n            Tupla (is_valid, missing_columns)\n        \"\"\"\n        df_columns = set(df.columns)\n        required_set = set(required_columns)\n\n        missing_columns = list(required_set - df_columns)\n\n        if missing_columns:\n            logger.error(\n                f\"Valida\u00e7\u00e3o falhou para '{table_name}': \"\n                f\"Colunas faltantes: {missing_columns}\"\n            )\n            return False, missing_columns\n\n        logger.debug(f\"Todas as colunas obrigat\u00f3rias presentes em '{table_name}'\")\n        return True, []\n\n    def validate_filter_column(\n        self,\n        df: pd.DataFrame,\n        column_name: str,\n        table_name: str = \"DataFrame\"\n    ) -> bool:\n        \"\"\"\n        Valida se uma coluna existe antes de aplicar filtro.\n\n        Args:\n            df: DataFrame\n            column_name: Nome da coluna\n            table_name: Nome da tabela\n\n        Returns:\n            True se a coluna existe\n        \"\"\"\n        if column_name not in df.columns:\n            logger.error(\n                f\"Coluna '{column_name}' n\u00e3o encontrada em '{table_name}'. \"\n                f\"Colunas dispon\u00edveis: {list(df.columns)}\"\n            )\n            return False\n\n        return True\n\n    def handle_null_values(\n        self,\n        df: pd.DataFrame,\n        column_name: str,\n        strategy: str = \"drop\",\n        fill_value: Any = None\n    ) -> pd.DataFrame:\n        \"\"\"\n        Trata valores nulos em uma coluna.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3797, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e95fcc6f-a591-4093-af65-c3fa7fcebb4a": {"__data__": {"id_": "e95fcc6f-a591-4093-af65-c3fa7fcebb4a", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\utils\\query_validator.py", "language": "python", "lines": 362, "filename": "query_validator.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\utils\\query_validator.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\utils\\query_validator.py", "language": "python", "lines": 362, "filename": "query_validator.py"}, "hash": "778eb01314e93fc6278b03666695890b4e6a00f5250134c33ce548287e806d39", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7aa2b149-63e2-48fb-b8ca-5138e15c13ed", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\utils\\query_validator.py", "language": "python", "lines": 362, "filename": "query_validator.py"}, "hash": "68843e8e2edc0542dcbeb9887763b464f0675e818a7dc049b6f95122ba1aa0a7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d39443ac-739d-491d-a0f5-8f9e0263ae00", "node_type": "1", "metadata": {}, "hash": "bf65dd79a5c21e1a2a89020accee829d3db681c2a8fc04b2235f87a7818de084", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Args:\n            df: DataFrame\n            column_name: Nome da coluna\n            strategy: Estrat\u00e9gia ('drop', 'fill', 'keep')\n            fill_value: Valor para preencher (se strategy='fill')\n\n        Returns:\n            DataFrame com valores nulos tratados\n        \"\"\"\n        if column_name not in df.columns:\n            logger.warning(f\"Coluna '{column_name}' n\u00e3o encontrada, retornando DataFrame original\")\n            return df\n\n        null_count = df[column_name].isna().sum()\n\n        if null_count > 0:\n            logger.info(f\"Encontrados {null_count} valores nulos em '{column_name}'\")\n\n            if strategy == \"drop\":\n                df = df.dropna(subset=[column_name])\n                logger.info(f\"Removidas {null_count} linhas com valores nulos\")\n\n            elif strategy == \"fill\":\n                if fill_value is None:\n                    # Estrat\u00e9gia padr\u00e3o baseada no tipo\n                    if df[column_name].dtype in ['float64', 'int64']:\n                        fill_value = 0\n                    else:\n                        fill_value = \"\"\n\n                df[column_name].fillna(fill_value, inplace=True)\n                logger.info(f\"Preenchidos {null_count} valores nulos com '{fill_value}'\")\n\n            elif strategy == \"keep\":\n                logger.info(f\"Mantendo {null_count} valores nulos\")\n\n        return df\n\n    def safe_filter(\n        self,\n        df: pd.DataFrame,\n        filter_func: Callable[[pd.DataFrame], pd.DataFrame],\n        error_message: str = \"Erro ao aplicar filtro\"\n    ) -> pd.DataFrame:\n        \"\"\"\n        Aplica filtro de forma segura com tratamento de erros.\n\n        Args:\n            df: DataFrame\n            filter_func: Fun\u00e7\u00e3o de filtro\n            error_message: Mensagem de erro personalizada\n\n        Returns:\n            DataFrame filtrado ou original em caso de erro\n        \"\"\"\n        try:\n            return filter_func(df)\n        except KeyError as e:\n            logger.error(f\"{error_message}: Coluna n\u00e3o encontrada - {e}\")\n            return df\n        except Exception as e:\n            logger.error(f\"{error_message}: {e}\")\n            return df\n\n    def execute_with_timeout(\n        self,\n        func: Callable,\n        timeout: Optional[int] = None,\n        *args,\n        **kwargs\n    ) -> Any:\n        \"\"\"\n        Executa fun\u00e7\u00e3o com timeout.\n\n        Args:\n            func: Fun\u00e7\u00e3o a executar\n            timeout: Tempo limite em segundos (usa default se None)\n            *args: Argumentos posicionais\n            **kwargs: Argumentos nomeados\n\n        Returns:\n            Resultado da fun\u00e7\u00e3o\n\n        Raises:\n            QueryTimeout: Se exceder o tempo limite\n        \"\"\"\n        if timeout is None:\n            timeout = self.default_timeout\n\n        try:\n            with self.timeout_context(timeout):\n                return func(*args, **kwargs)\n        except QueryTimeout as e:\n            logger.error(f\"Query timeout: {e}\")\n            raise\n\n    def validate_and_convert_types(\n        self,\n        df: pd.DataFrame,\n        column_types: Dict[str, str]\n    ) -> pd.DataFrame:\n        \"\"\"\n        Valida e converte tipos de colunas.\n\n        Args:\n            df: DataFrame\n            column_types: Dict {column_name: desired_type}\n                Tipos suportados: 'int', 'float', 'str', 'datetime'\n\n        Returns:\n            DataFrame com tipos convertidos\n        \"\"\"\n        df_copy = df.copy()\n\n        for column, desired_type in column_types.items():\n            if column not in df_copy.columns:\n                logger.warning(f\"Coluna '{column}' n\u00e3o encontrada para convers\u00e3o de tipo\")\n                continue\n\n            try:\n                if desired_type == 'int':\n                    df_copy[column] = pd.to_numeric(df_copy[column], errors='coerce').fillna(0).astype(int)\n\n                elif desired_type == 'float':\n                    df_copy[column] = pd.to_numeric(df_copy[column], errors='coerce').fillna(0.0)\n\n                elif desired_type == 'str':\n                    df_copy[column] = df_copy[column].astype(str).replace('nan', '')\n\n                elif desired_type == 'datetime':\n                    df_copy[column] = pd.to_datetime(df_copy[column], errors='coerce')\n\n                else:\n                    logger.warning(f\"Tipo desconhecido '{desired_type}' para coluna '{column}'\")\n\n                logger.debug(f\"Coluna '{column}' convertida para '{desired_type}'\")\n\n            except Exception as e:\n                logger.error(f\"Erro ao converter coluna '{column}' para '{desired_type}': {e}\")\n\n        return df_copy\n\n    def get_user_friendly_error(self, error: Exception) -> str:\n        \"\"\"\n        Converte exce\u00e7\u00e3o em mensagem user-friendly.", "mimetype": "text/plain", "start_char_idx": 3807, "end_char_idx": 8518, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d39443ac-739d-491d-a0f5-8f9e0263ae00": {"__data__": {"id_": "d39443ac-739d-491d-a0f5-8f9e0263ae00", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\utils\\query_validator.py", "language": "python", "lines": 362, "filename": "query_validator.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\utils\\query_validator.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\utils\\query_validator.py", "language": "python", "lines": 362, "filename": "query_validator.py"}, "hash": "778eb01314e93fc6278b03666695890b4e6a00f5250134c33ce548287e806d39", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e95fcc6f-a591-4093-af65-c3fa7fcebb4a", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\utils\\query_validator.py", "language": "python", "lines": 362, "filename": "query_validator.py"}, "hash": "7589da8c901d34f39aea6d8e5815e76aef88e9dbbb4710f53594aebf56208242", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Args:\n            error: Exce\u00e7\u00e3o capturada\n\n        Returns:\n            Mensagem de erro formatada para o usu\u00e1rio\n        \"\"\"\n        error_type = type(error).__name__\n\n        # Mapeamento de erros t\u00e9cnicos para mensagens amig\u00e1veis\n        error_messages = {\n            'FileNotFoundError': 'Arquivo de dados n\u00e3o encontrado. Verifique se os dados foram carregados corretamente.',\n            'PermissionError': 'Sem permiss\u00e3o para acessar o arquivo de dados.',\n            'KeyError': 'Coluna especificada n\u00e3o existe nos dados. Verifique os nomes das colunas.',\n            'ValueError': 'Valor inv\u00e1lido encontrado nos dados. Verifique os filtros aplicados.',\n            'TypeError': 'Tipo de dado incompat\u00edvel na opera\u00e7\u00e3o.',\n            'QueryTimeout': 'A consulta demorou muito tempo. Tente usar filtros mais espec\u00edficos.',\n            'ParserError': 'Erro ao ler o arquivo de dados. O arquivo pode estar corrompido.',\n            'MemoryError': 'Mem\u00f3ria insuficiente para processar a consulta. Reduza o volume de dados.',\n        }\n\n        # Retornar mensagem personalizada ou gen\u00e9rica\n        base_message = error_messages.get(error_type, 'Erro ao processar a consulta.')\n\n        return f\"{base_message} (Detalhes t\u00e9cnicos: {str(error)})\"\n\n\n# Inst\u00e2ncia global\n_validator = QueryValidator()\n\n\ndef safe_convert_types(df: pd.DataFrame, column_types: Dict[str, str]) -> pd.DataFrame:\n    \"\"\"Compat shim: nome legado esperado por alguns testes/scripts.\n\n    Encaminha para `validate_and_convert_types` do `QueryValidator`.\n    \"\"\"\n    return _validator.validate_and_convert_types(df, column_types)\n\n# Fun\u00e7\u00f5es auxiliares para uso direto\ndef validate_columns(df: pd.DataFrame, required_columns: List[str], table_name: str = \"DataFrame\") -> tuple[bool, List[str]]:\n    \"\"\"Valida colunas em DataFrame.\"\"\"\n    return _validator.validate_columns_in_dataframe(df, required_columns, table_name)\n\n\ndef handle_nulls(df: pd.DataFrame, column: str, strategy: str = \"drop\", fill_value: Any = None) -> pd.DataFrame:\n    \"\"\"Trata valores nulos.\"\"\"\n    return _validator.handle_null_values(df, column, strategy, fill_value)\n\n\ndef safe_filter(df: pd.DataFrame, filter_func: Callable, error_msg: str = \"Erro ao filtrar\") -> pd.DataFrame:\n    \"\"\"Aplica filtro com seguran\u00e7a.\"\"\"\n    return _validator.safe_filter(df, filter_func, error_msg)\n\n\ndef get_friendly_error(error: Exception) -> str:\n    \"\"\"Converte erro em mensagem amig\u00e1vel.\"\"\"\n    return _validator.get_user_friendly_error(error)\n\n\nif __name__ == \"__main__\":\n    # Testes b\u00e1sicos\n    logging.basicConfig(level=logging.INFO)\n\n    # Teste de valida\u00e7\u00e3o de colunas\n    df_test = pd.DataFrame({\n        'col1': [1, 2, 3],\n        'col2': ['a', 'b', 'c']\n    })\n\n    is_valid, missing = validate_columns(df_test, ['col1', 'col2', 'col3'])\n    print(f\"Valida\u00e7\u00e3o: {is_valid}, Faltantes: {missing}\")\n\n    # Teste de tratamento de nulos\n    df_test['col3'] = [1, None, 3]\n    df_clean = handle_nulls(df_test, 'col3', strategy='fill', fill_value=0)\n    print(f\"Nulos tratados: {df_clean['col3'].tolist()}\")", "mimetype": "text/plain", "start_char_idx": 8528, "end_char_idx": 11569, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ba089853-133b-4bbb-af47-9d3e17cbb42d": {"__data__": {"id_": "ba089853-133b-4bbb-af47-9d3e17cbb42d", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\utils\\response_cache.py", "language": "python", "lines": 158, "filename": "response_cache.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\utils\\response_cache.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\utils\\response_cache.py", "language": "python", "lines": 158, "filename": "response_cache.py"}, "hash": "87c571361a1f167bf00f1ee4ccd728d7b69ff159abaf3a678156c7c9d6745f3c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "942e8b74-74ec-400c-8e95-89a99229f4ec", "node_type": "1", "metadata": {}, "hash": "7fdaeb28b6d97d36ac27a071259bb41a8bfcdb2385225e66be5fcd9a5c4bd756", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# backend/app/core/utils/response_cache.py\n\nimport json\nimport os\nimport hashlib\nfrom datetime import datetime, timedelta\nfrom typing import Any, Dict, Optional\n\nfrom app.config.settings import settings\nimport re\n\nclass ResponseCache:\n    \"\"\"\n    Manages caching of LLM responses on disk with a configurable TTL.\n    Normalizes queries for better cache hit rates.\n    \"\"\"\n    def __init__(self, cache_dir: str = \"data/cache\", ttl_minutes: int = settings.CACHE_TTL_MINUTES):\n        self.cache_dir = cache_dir\n        os.makedirs(self.cache_dir, exist_ok=True)\n        self.ttl = timedelta(minutes=ttl_minutes)\n        print(f\"ResponseCache initialized in {self.cache_dir} with TTL {self.ttl}\")\n\n    def _get_cache_file_path(self, key: str) -> str:\n        \"\"\"Generates a file path for a given cache key.\"\"\"\n        return os.path.join(self.cache_dir, f\"{key}.json\")\n\n    def generate_key(self, query: str) -> str:\n        \"\"\"\n        Generates a cache key by normalizing the query and hashing it.\n        This ensures consistent keys for similar queries.\n        \"\"\"\n        normalized_query = self._normalize_query(query)\n        return hashlib.sha256(normalized_query.encode(\"utf-8\")).hexdigest()\n\n    def _normalize_query(self, query: str) -> str:\n        \"\"\"\n        Normalizes a query string for caching purposes.\n        Removes stopwords, standardizes spaces, lowercases, removes irrelevant punctuation.\n        (T6.1.3 from TASK_LIST, but implemented here as it's directly related to cache key generation)\n        \"\"\"\n        query_lower = query.lower()\n        # Example stopwords (expand as needed)\n        stopwords = [\"o\", \"a\", \"os\", \"as\", \"um\", \"uma\", \"uns\", \"umas\", \"de\", \"da\", \"do\", \"dos\", \"das\", \"em\", \"no\", \"na\", \"nos\", \"nas\", \"que\", \"e\", \"\u00e9\", \"para\", \"com\", \"por\"]\n        words = [word for word in query_lower.split() if word not in stopwords]\n        \n        normalized = \" \".join(words)\n        normalized = re.sub(r'[^\\w\\s]', '', normalized) # Remove punctuation (keep alphanumeric and space)\n        normalized = re.sub(r'\\s+', ' ', normalized).strip() # Standardize spaces\n        return normalized\n\n    def get(self, key: str) -> Optional[Dict[str, Any]]:\n        \"\"\"\n        Retrieves a cached response if it exists and is not expired.\n        \"\"\"\n        file_path = self._get_cache_file_path(key)\n        if os.path.exists(file_path):\n            try:\n                with open(file_path, \"r\", encoding=\"utf-8\") as f:\n                    cached_data = json.load(f)\n                \n                cached_time_str = cached_data.get(\"timestamp\")\n                if cached_time_str:\n                    cached_time = datetime.fromisoformat(cached_time_str)\n                    if datetime.now() - cached_time < self.ttl:\n                        print(f\"Cache hit for key: {key}\")\n                        return cached_data.get(\"response\")\n                    else:\n                        print(f\"Cache expired for key: {key}. Deleting...\")\n                        os.remove(file_path) # Clean up expired cache\n                else:\n                    print(f\"Cache data for key: {key} missing timestamp. Deleting...\")\n                    os.remove(file_path) # Invalid cache entry\n            except (json.JSONDecodeError, OSError) as e:\n                print(f\"Error reading or decoding cache file {file_path}: {e}. Deleting...\")\n                if os.path.exists(file_path):\n                    os.remove(file_path)\n        return None\n\n    def set(self, key: str, response: Dict[str, Any]):\n        \"\"\"\n        Stores a response in the cache with a timestamp.\n        \"\"\"\n        file_path = self._get_cache_file_path(key)\n        data_to_cache = {\n            \"timestamp\": datetime.now().isoformat(),\n            \"response\": response\n        }\n        try:\n            with open(file_path, \"w\", encoding=\"utf-8\") as f:\n                json.dump(data_to_cache, f, ensure_ascii=False, indent=4)\n            print(f\"Cache set for key: {key}\")\n        except OSError as e:\n            print(f\"Error writing cache file {file_path}: {e}\")\n\n    def clean_expired_cache(self):\n        \"\"\"\n        Cleans up expired cache files (T1.3.1 - cache_cleaner).\n        This method will be called by a separate cache cleaner utility in production,\n        but can be manually triggered or run periodically.\n        \"\"\"", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4334, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "942e8b74-74ec-400c-8e95-89a99229f4ec": {"__data__": {"id_": "942e8b74-74ec-400c-8e95-89a99229f4ec", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\utils\\response_cache.py", "language": "python", "lines": 158, "filename": "response_cache.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\utils\\response_cache.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\utils\\response_cache.py", "language": "python", "lines": 158, "filename": "response_cache.py"}, "hash": "87c571361a1f167bf00f1ee4ccd728d7b69ff159abaf3a678156c7c9d6745f3c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ba089853-133b-4bbb-af47-9d3e17cbb42d", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\utils\\response_cache.py", "language": "python", "lines": 158, "filename": "response_cache.py"}, "hash": "550bda7fd91b0217e03cfee11f9552c4aa3e6ad3f9dac8111b97327d09dcf8fc", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "for filename in os.listdir(self.cache_dir):\n            file_path = os.path.join(self.cache_dir, filename)\n            if filename.endswith(\".json\") and os.path.isfile(file_path):\n                try:\n                    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n                        cached_data = json.load(f)\n                    cached_time_str = cached_data.get(\"timestamp\")\n                    if cached_time_str:\n                        cached_time = datetime.fromisoformat(cached_time_str)\n                        if datetime.now() - cached_time >= self.ttl:\n                            os.remove(file_path)\n                            print(f\"Cleaned expired cache file: {filename}\")\n                    else:\n                        os.remove(file_path)\n                        print(f\"Cleaned invalid cache file (no timestamp): {filename}\")\n                except (json.JSONDecodeError, OSError) as e:\n                    print(f\"Error checking/cleaning cache file {file_path}: {e}. Removing.\")\n                    if os.path.exists(file_path):\n                        os.remove(file_path)\n\n# Example usage\nif __name__ == '__main__':\n    # Ensure cache directory exists for testing\n    os.makedirs(settings.LEARNING_FEEDBACK_PATH, exist_ok=True) # Assuming LEARNING_FEEDBACK_PATH is a good temp dir\n    cache = ResponseCache(cache_dir=settings.LEARNING_FEEDBACK_PATH, ttl_minutes=1) # 1 minute TTL for testing\n\n    test_query = \"Qual \u00e9 o total de vendas por produto para o segmento A?\"\n    test_response = {\"result\": [{\"product\": \"X\", \"sales\": 100}], \"chart_spec\": None}\n\n    key = cache.generate_key(test_query)\n    print(f\"\\nGenerated key for '{test_query}': {key}\")\n\n    # Test set\n    cache.set(key, test_response)\n    \n    # Test get (should hit)\n    retrieved = cache.get(key)\n    print(f\"Retrieved (should hit): {retrieved}\")\n    assert retrieved == test_response\n\n    # Test get (after expiration - manual simulation)\n    print(\"Waiting for cache to expire (1 minute)...\")\n    import time\n    time.sleep(65) # Wait a bit more than 1 minute\n\n    retrieved_expired = cache.get(key)\n    print(f\"Retrieved (should miss after expiration): {retrieved_expired}\")\n    assert retrieved_expired is None\n\n    # Test clean_expired_cache\n    cache.set(key, test_response) # Set again to have something to expire\n    time.sleep(65)\n    print(\"\\nRunning cache cleanup...\")\n    cache.clean_expired_cache()\n    assert cache.get(key) is None # Should be gone after cleanup\n\n    print(\"\\nResponseCache tests passed!\")", "mimetype": "text/plain", "start_char_idx": 4343, "end_char_idx": 6869, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "708d713d-8f58-4653-8f50-599df5e6201e": {"__data__": {"id_": "708d713d-8f58-4653-8f50-599df5e6201e", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\utils\\response_parser.py", "language": "python", "lines": 139, "filename": "response_parser.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\utils\\response_parser.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\utils\\response_parser.py", "language": "python", "lines": 139, "filename": "response_parser.py"}, "hash": "f87527406b4782961aef2b75055c75387b176ddbec542409cc63fc668af83a89", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nUtilit\u00e1rios para parsear e processar respostas do agente.\nDetecta gr\u00e1ficos, dataframes e textos nas respostas.\n\"\"\"\n\nimport json\nimport logging\nfrom typing import Dict, Any, Tuple\nimport plotly.graph_objects as go\n\nlogger = logging.getLogger(__name__)\n\n\ndef parse_agent_response(response: str) -> Tuple[str, Dict[str, Any]]:\n    \"\"\"\n    Parseia a resposta do agente e extrai dados estruturados.\n\n    Args:\n        response: String da resposta do agente\n\n    Returns:\n        Tupla (tipo, dados_processados)\n        Tipos: \"chart\", \"text\", \"error\"\n    \"\"\"\n    if not response:\n        return \"text\", {\"output\": \"Nenhuma resposta recebida.\"}\n\n    response_lower = response.lower()\n\n    # Detectar se cont\u00e9m informa\u00e7\u00f5es de gr\u00e1fico\n    if any(\n        keyword in response_lower\n        for keyword in [\n            \"gr\u00e1fico\",\n            \"grafico\",\n            \"chart\",\n            \"plotly\",\n            \"chart_data\",\n            \"chart_type\",\n            \"visualiza\",\n        ]\n    ):\n        logger.debug(\"Detectada resposta tipo gr\u00e1fico\")\n        return _extract_chart_from_response(response)\n\n    # Caso contr\u00e1rio, retornar como texto\n    logger.debug(\"Resposta processada como texto\")\n    return \"text\", {\"output\": response}\n\n\ndef _extract_chart_from_response(response: str) -> Tuple[str, Dict[str, Any]]:\n    \"\"\"\n    Extrai dados de gr\u00e1fico de uma resposta de ferramenta.\n\n    Args:\n        response: String contendo dados do gr\u00e1fico\n\n    Returns:\n        Tupla (tipo, figura_plotly ou erro)\n    \"\"\"\n    try:\n        # Tentar parsear como JSON\n        if response.startswith(\"{\"):\n            data = json.loads(response)\n        else:\n            # Se n\u00e3o for JSON puro, tomar o primeiro JSON encontrado\n            import re\n\n            json_match = re.search(r\"\\{.*\\}\", response, re.DOTALL)\n            if json_match:\n                data = json.loads(json_match.group())\n            else:\n                return \"text\", {\"output\": response}\n\n        # Verificar se \u00e9 resposta de ferramenta de gr\u00e1fico\n        if \"chart_data\" in data and \"status\" in data:\n            if data.get(\"status\") == \"success\":\n                try:\n                    # chart_data j\u00e1 vem como JSON string de Plotly\n                    chart_json = data[\"chart_data\"]\n                    if isinstance(chart_json, str):\n                        chart_json = json.loads(chart_json)\n\n                    # Converter JSON para figura Plotly\n                    fig = go.Figure(chart_json)\n\n                    logger.info(\n                        f\"Gr\u00e1fico tipo '{data.get('chart_type', 'unknown')}' \"\n                        f\"extra\u00eddo com sucesso\"\n                    )\n\n                    return \"chart\", {\n                        \"output\": fig,\n                        \"summary\": data.get(\"summary\", {}),\n                        \"chart_type\": data.get(\"chart_type\", \"unknown\"),\n                    }\n\n                except Exception as e:\n                    logger.warning(f\"Erro ao processar chart_data: {e}\")\n                    # Retornar como texto se falhar\n                    summary = data.get(\"summary\", {})\n                    msg = \"Gr\u00e1fico gerado com sucesso.\\n\\n**Sum\u00e1rio:**\\n\"\n                    for key, value in summary.items():\n                        msg += f\"- **{key}**: {value}\\n\"\n                    return \"text\", {\"output\": msg}\n\n            else:\n                error_msg = data.get(\"message\", \"Erro ao gerar gr\u00e1fico\")\n                logger.warning(f\"Gr\u00e1fico retornou erro: {error_msg}\")\n                return \"text\", {\"output\": f\"\u274c {error_msg}\"}\n\n        # Se n\u00e3o tem estrutura de gr\u00e1fico, retornar como texto\n        return \"text\", {\"output\": response}\n\n    except json.JSONDecodeError:\n        logger.debug(\"Resposta n\u00e3o \u00e9 JSON, retornando como texto\")\n        return \"text\", {\"output\": response}\n    except Exception as e:\n        logger.error(f\"Erro ao extrair gr\u00e1fico: {e}\", exc_info=True)\n        return \"text\", {\"output\": response}\n\n\ndef detect_dataframe_response(response: Any) -> bool:\n    \"\"\"\n    Detecta se a resposta \u00e9 um DataFrame.\n\n    Args:\n        response: Resposta a verificar\n\n    Returns:\n        True se for DataFrame, False caso contr\u00e1rio\n    \"\"\"\n    try:\n        import pandas as pd\n\n        return isinstance(response, pd.DataFrame)\n    except Exception:\n        return False", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4316, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1d8f7810-9424-44c6-9cfb-9c616bb62f33": {"__data__": {"id_": "1d8f7810-9424-44c6-9cfb-9c616bb62f33", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\utils\\response_validator.py", "language": "python", "lines": 234, "filename": "response_validator.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\utils\\response_validator.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\utils\\response_validator.py", "language": "python", "lines": 234, "filename": "response_validator.py"}, "hash": "7451285ad96adcaa7f1fb8d5512ac4c05a3dfa1a650c438933376af1c3a17530", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1d02909b-c274-477c-9a35-0dde32df4bb4", "node_type": "1", "metadata": {}, "hash": "121a5355c65d62e1a926b979d7099717259e1fa622613298ee8ea03f6f4e36a6", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nResponse Validator - Valida respostas do agente para detectar erros e alucina\u00e7\u00f5es\nUsa t\u00e9cnicas de verifica\u00e7\u00e3o para melhorar precis\u00e3o\n\"\"\"\n\nimport logging\nimport re\nfrom typing import Dict, Any, Optional, List, Tuple\nfrom dataclasses import dataclass\n\nlogger = logging.getLogger(__name__)\n\n\n@dataclass\nclass ValidationResult:\n    \"\"\"Resultado da valida\u00e7\u00e3o de resposta.\"\"\"\n    is_valid: bool\n    confidence: float  # 0.0 a 1.0\n    issues: List[str]\n    suggestions: List[str]\n    corrected_response: Optional[str] = None\n\n\nclass ResponseValidator:\n    \"\"\"\n    Valida respostas do ChatBI para detectar:\n    - Alucina\u00e7\u00f5es (dados inventados)\n    - Inconsist\u00eancias num\u00e9ricas\n    - Refer\u00eancias a dados inexistentes\n    - Erros de formata\u00e7\u00e3o\n    \"\"\"\n    \n    # Colunas reais do admmat.parquet\n    VALID_COLUMNS = {\n        \"id\", \"UNE\", \"PRODUTO\", \"TIPO\", \"UNE_NOME\", \"NOME\", \"EMBALAGEM\",\n        \"NOMESEGMENTO\", \"NOMECATEGORIA\", \"NOMEFABRICANTE\", \"SITUACAO\",\n        \"ESTOQUE_UNE\", \"ESTOQUE_LV\", \"ESTOQUE_CD\", \"VENDA_30DD\",\n        \"PRECO_VENDA\", \"PRECO_CUSTO\", \"PICKLIST_SITUACAO\",\n        \"ULTIMA_VENDA_DATA_UNE\", \"created_at\", \"updated_at\"\n    }\n    \n    # Palavras que indicam poss\u00edvel alucina\u00e7\u00e3o\n    HALLUCINATION_INDICATORS = [\n        \"possivelmente\", \"provavelmente\", \"talvez\", \"n\u00e3o tenho certeza\",\n        \"acredito que\", \"parece que\", \"pode ser\", \"imagino que\"\n    ]\n    \n    # Padr\u00f5es de erro conhecidos\n    ERROR_PATTERNS = [\n        r\"erro\\s+ao\\s+consultar\",\n        r\"n\u00e3o\\s+foi\\s+poss\u00edvel\",\n        r\"falha\\s+na\\s+consulta\",\n        r\"coluna.*n\u00e3o\\s+encontrada\",\n        r\"dados\\s+n\u00e3o\\s+encontrados\",\n    ]\n    \n    def __init__(self):\n        self.validation_count = 0\n        self.error_count = 0\n    \n    def validate(self, response: Dict[str, Any], query: str = \"\") -> ValidationResult:\n        \"\"\"\n        Valida uma resposta do agente.\n        \n        Args:\n            response: Resposta do agente\n            query: Pergunta original do usu\u00e1rio\n            \n        Returns:\n            ValidationResult com status e detalhes\n        \"\"\"\n        self.validation_count += 1\n        issues = []\n        suggestions = []\n        confidence = 1.0\n        \n        # Extrair texto da resposta\n        response_text = self._extract_text(response)\n        \n        # 1. Verificar se resposta est\u00e1 vazia\n        if not response_text or len(response_text.strip()) < 10:\n            issues.append(\"Resposta muito curta ou vazia\")\n            suggestions.append(\"Reformule a pergunta de forma mais espec\u00edfica\")\n            confidence -= 0.5\n        \n        # 2. Verificar indicadores de alucina\u00e7\u00e3o\n        hallucination_score = self._check_hallucination(response_text)\n        if hallucination_score > 0.3:\n            issues.append(f\"Poss\u00edvel incerteza detectada (score: {hallucination_score:.2f})\")\n            suggestions.append(\"Verifique os dados retornados\")\n            confidence -= hallucination_score * 0.3\n        \n        # 3. Verificar padr\u00f5es de erro\n        if self._has_error_pattern(response_text):\n            issues.append(\"Padr\u00e3o de erro detectado na resposta\")\n            suggestions.append(\"Verifique os par\u00e2metros da consulta\")\n            confidence -= 0.3\n        \n        # 4. Validar refer\u00eancias a colunas\n        invalid_cols = self._check_column_references(response_text)\n        if invalid_cols:\n            issues.append(f\"Refer\u00eancias a colunas possivelmente inv\u00e1lidas: {', '.join(invalid_cols)}\")\n            suggestions.append(f\"Colunas v\u00e1lidas incluem: UNE, PRODUTO, NOME, ESTOQUE_UNE, VENDA_30DD\")\n            confidence -= 0.2\n        \n        # 5.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3592, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1d02909b-c274-477c-9a35-0dde32df4bb4": {"__data__": {"id_": "1d02909b-c274-477c-9a35-0dde32df4bb4", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\utils\\response_validator.py", "language": "python", "lines": 234, "filename": "response_validator.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\utils\\response_validator.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\utils\\response_validator.py", "language": "python", "lines": 234, "filename": "response_validator.py"}, "hash": "7451285ad96adcaa7f1fb8d5512ac4c05a3dfa1a650c438933376af1c3a17530", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1d8f7810-9424-44c6-9cfb-9c616bb62f33", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\utils\\response_validator.py", "language": "python", "lines": 234, "filename": "response_validator.py"}, "hash": "a3b5c7ec5edeb1ff485ccdc2b4b62370aaa609aa06e2e2dc3e8ceab359d556a8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Verificar consist\u00eancia num\u00e9rica\n        numeric_issues = self._check_numeric_consistency(response_text)\n        if numeric_issues:\n            issues.extend(numeric_issues)\n            confidence -= 0.1 * len(numeric_issues)\n        \n        # Garantir que confidence est\u00e1 entre 0 e 1\n        confidence = max(0.0, min(1.0, confidence))\n        \n        is_valid = len(issues) == 0 and confidence >= 0.7\n        \n        if not is_valid:\n            self.error_count += 1\n            logger.warning(f\"Resposta inv\u00e1lida: {issues}\")\n        \n        return ValidationResult(\n            is_valid=is_valid,\n            confidence=confidence,\n            issues=issues,\n            suggestions=suggestions\n        )\n    \n    def _extract_text(self, response: Dict[str, Any]) -> str:\n        \"\"\"Extrai texto da resposta do agente.\"\"\"\n        if isinstance(response, str):\n            return response\n        \n        # Tentar diferentes formatos de resposta\n        text = response.get(\"result\", \"\")\n        if isinstance(text, dict):\n            text = text.get(\"mensagem\", \"\") or str(text)\n        elif not isinstance(text, str):\n            text = str(text)\n        \n        return text\n    \n    def _check_hallucination(self, text: str) -> float:\n        \"\"\"Verifica indicadores de alucina\u00e7\u00e3o.\"\"\"\n        text_lower = text.lower()\n        count = 0\n        \n        for indicator in self.HALLUCINATION_INDICATORS:\n            if indicator in text_lower:\n                count += 1\n        \n        # Normalizar score\n        return min(1.0, count / 3)\n    \n    def _has_error_pattern(self, text: str) -> bool:\n        \"\"\"Verifica padr\u00f5es de erro conhecidos.\"\"\"\n        text_lower = text.lower()\n        \n        for pattern in self.ERROR_PATTERNS:\n            if re.search(pattern, text_lower):\n                return True\n        \n        return False\n    \n    def _check_column_references(self, text: str) -> List[str]:\n        \"\"\"Verifica refer\u00eancias a colunas potencialmente inv\u00e1lidas.\"\"\"\n        # Buscar padr\u00f5es que parecem nomes de colunas\n        pattern = r'\\b([A-Z][A-Z0-9_]{2,30})\\b'\n        matches = re.findall(pattern, text)\n        \n        invalid = []\n        for match in matches:\n            # Ignorar palavras comuns que n\u00e3o s\u00e3o colunas\n            if match in {\"OK\", \"NULL\", \"TRUE\", \"FALSE\", \"AND\", \"OR\", \"NOT\"}:\n                continue\n            \n            # Verificar se parece uma coluna mas n\u00e3o est\u00e1 na lista v\u00e1lida\n            if \"_\" in match or match.isupper():\n                if match not in self.VALID_COLUMNS:\n                    invalid.append(match)\n        \n        return invalid[:3]  # Limitar a 3 para n\u00e3o poluir\n    \n    def _check_numeric_consistency(self, text: str) -> List[str]:\n        \"\"\"Verifica consist\u00eancia de valores num\u00e9ricos.\"\"\"\n        issues = []\n        \n        # Buscar n\u00fameros muito grandes que podem ser erros\n        pattern = r'\\b(\\d{10,})\\b'\n        large_numbers = re.findall(pattern, text)\n        \n        for num in large_numbers:\n            if len(num) > 15:\n                issues.append(f\"N\u00famero muito grande detectado: pode ser erro\")\n                break\n        \n        # Buscar valores negativos onde n\u00e3o deveria haver\n        if re.search(r'estoque.*-\\d+|vendas.*-\\d+', text.lower()):\n            issues.append(\"Valor negativo detectado em campo que deveria ser positivo\")\n        \n        return issues\n    \n    def get_stats(self) -> Dict[str, Any]:\n        \"\"\"Retorna estat\u00edsticas de valida\u00e7\u00e3o.\"\"\"\n        error_rate = (self.error_count / self.validation_count * 100) if self.validation_count > 0 else 0\n        \n        return {\n            \"total_validations\": self.validation_count,\n            \"total_errors\": self.error_count,\n            \"error_rate\": f\"{error_rate:.1f}%\",\n            \"valid_columns_count\": len(self.VALID_COLUMNS),\n        }\n\n\n# Inst\u00e2ncia global\n_validator: Optional[ResponseValidator] = None\n\n\ndef get_validator() -> ResponseValidator:\n    \"\"\"Retorna inst\u00e2ncia singleton do validador.\"\"\"\n    global _validator\n    if _validator is None:\n        _validator = ResponseValidator()\n    return _validator\n\n\ndef validate_response(response: Dict[str, Any], query: str = \"\") -> ValidationResult:\n    \"\"\"Valida resposta do agente.\"\"\"\n    return get_validator().validate(response, query)\n\n\ndef validator_stats() -> Dict[str, Any]:\n    \"\"\"Retorna estat\u00edsticas do validador.\"\"\"\n    return get_validator().get_stats()", "mimetype": "text/plain", "start_char_idx": 3593, "end_char_idx": 8005, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "15dc9f6f-6531-40b6-9aa3-cb64abd60217": {"__data__": {"id_": "15dc9f6f-6531-40b6-9aa3-cb64abd60217", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\utils\\semantic_cache.py", "language": "python", "lines": 244, "filename": "semantic_cache.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\utils\\semantic_cache.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\utils\\semantic_cache.py", "language": "python", "lines": 244, "filename": "semantic_cache.py"}, "hash": "a2fce3c96d949a30bdbb2a00a508ba586a07a4df14fb328f9ac9e9efb1395332", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4404a5ce-abbf-4134-9cf1-711c7690c95a", "node_type": "1", "metadata": {}, "hash": "149028f13f30d852ec18412f8f60b02e268e135a459ed5add97d909ba9853d56", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nSemantic Cache - Cache inteligente baseado em similaridade sem\u00e2ntica\nPermite respostas instant\u00e2neas para perguntas similares\n\"\"\"\n\nimport hashlib\nimport json\nimport logging\nimport os\nimport time\nfrom pathlib import Path\nfrom typing import Dict, Any, Optional, Tuple\n\nlogger = logging.getLogger(__name__)\n\n\nclass SemanticCache:\n    \"\"\"\n    Cache sem\u00e2ntico para respostas do ChatBI.\n    \n    Caracter\u00edsticas:\n    - Hash baseado em normaliza\u00e7\u00e3o da query\n    - TTL configur\u00e1vel\n    - Persist\u00eancia em disco\n    - Estat\u00edsticas de hit/miss\n    \"\"\"\n    \n    def __init__(\n        self, \n        cache_dir: str = \"data/cache/semantic\",\n        ttl_minutes: int = 360,  # 6 horas\n        max_entries: int = 1000\n    ):\n        self.cache_dir = Path(cache_dir)\n        self.cache_dir.mkdir(parents=True, exist_ok=True)\n        self.ttl_seconds = ttl_minutes * 60\n        self.max_entries = max_entries\n        \n        # Estat\u00edsticas\n        self.hits = 0\n        self.misses = 0\n        \n        # Index em mem\u00f3ria para busca r\u00e1pida\n        self._index: Dict[str, Dict[str, Any]] = {}\n        self._load_index()\n        \n        logger.info(f\"SemanticCache inicializado: {cache_dir}, TTL={ttl_minutes}min\")\n    \n    def _normalize_query(self, query: str) -> str:\n        \"\"\"Normaliza query para melhor matching.\"\"\"\n        # Converter para min\u00fasculas\n        normalized = query.lower().strip()\n        \n        # Remover pontua\u00e7\u00e3o desnecess\u00e1ria\n        for char in \"?!.,;:\":\n            normalized = normalized.replace(char, \"\")\n        \n        # Normalizar espa\u00e7os m\u00faltiplos\n        normalized = \" \".join(normalized.split())\n        \n        return normalized\n    \n    def _generate_key(self, query: str) -> str:\n        \"\"\"Gera chave hash para a query normalizada.\"\"\"\n        normalized = self._normalize_query(query)\n        return hashlib.md5(normalized.encode('utf-8')).hexdigest()\n    \n    def _load_index(self):\n        \"\"\"Carrega \u00edndice do disco.\"\"\"\n        index_file = self.cache_dir / \"index.json\"\n        if index_file.exists():\n            try:\n                with open(index_file, 'r', encoding='utf-8') as f:\n                    self._index = json.load(f)\n                logger.info(f\"Cache index carregado: {len(self._index)} entradas\")\n            except Exception as e:\n                logger.error(f\"Erro ao carregar cache index: {e}\")\n                self._index = {}\n    \n    def _save_index(self):\n        \"\"\"Salva \u00edndice no disco.\"\"\"\n        index_file = self.cache_dir / \"index.json\"\n        try:\n            with open(index_file, 'w', encoding='utf-8') as f:\n                json.dump(self._index, f, ensure_ascii=False, indent=2)\n        except Exception as e:\n            logger.error(f\"Erro ao salvar cache index: {e}\")\n    \n    def get(self, query: str) -> Optional[Dict[str, Any]]:\n        \"\"\"\n        Busca resposta em cache.\n        \n        Args:\n            query: Pergunta do usu\u00e1rio\n            \n        Returns:\n            Resposta cacheada ou None se n\u00e3o encontrada/expirada\n        \"\"\"\n        key = self._generate_key(query)\n        \n        if key not in self._index:\n            self.misses += 1\n            return None\n        \n        entry = self._index[key]\n        \n        # Verificar TTL\n        if time.time() - entry.get(\"timestamp\", 0) > self.ttl_seconds:\n            # Expirado - remover\n            self._remove_entry(key)\n            self.misses += 1\n            logger.debug(f\"Cache expirado para: {query[:50]}...\")\n            return None\n        \n        # Cache hit!\n        self.hits += 1\n        logger.info(f\"Cache HIT para: {query[:50]}... (hits={self.hits})\")\n        \n        # Carregar resposta do arquivo\n        cache_file = self.cache_dir / f\"{key}.json\"\n        if cache_file.exists():\n            try:\n                with open(cache_file, 'r', encoding='utf-8') as f:\n                    return json.load(f)\n            except Exception as e:\n                logger.error(f\"Erro ao ler cache file: {e}\")\n                return None\n        \n        return None\n    \n    def set(self, query: str, response: Dict[str, Any]) -> bool:\n        \"\"\"\n        Armazena resposta em cache.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4147, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4404a5ce-abbf-4134-9cf1-711c7690c95a": {"__data__": {"id_": "4404a5ce-abbf-4134-9cf1-711c7690c95a", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\utils\\semantic_cache.py", "language": "python", "lines": 244, "filename": "semantic_cache.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\utils\\semantic_cache.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\utils\\semantic_cache.py", "language": "python", "lines": 244, "filename": "semantic_cache.py"}, "hash": "a2fce3c96d949a30bdbb2a00a508ba586a07a4df14fb328f9ac9e9efb1395332", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "15dc9f6f-6531-40b6-9aa3-cb64abd60217", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\utils\\semantic_cache.py", "language": "python", "lines": 244, "filename": "semantic_cache.py"}, "hash": "fdd61c9c6b4a92e54920ec70aae6d1307ecd4652a0d038122e2681d025fb795a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Args:\n            query: Pergunta do usu\u00e1rio\n            response: Resposta a cachear\n            \n        Returns:\n            True se armazenado com sucesso\n        \"\"\"\n        key = self._generate_key(query)\n        \n        # Verificar limite de entradas\n        if len(self._index) >= self.max_entries:\n            self._cleanup_oldest()\n        \n        # Atualizar \u00edndice\n        self._index[key] = {\n            \"query\": query,\n            \"normalized\": self._normalize_query(query),\n            \"timestamp\": time.time(),\n        }\n        \n        # Salvar resposta em arquivo\n        cache_file = self.cache_dir / f\"{key}.json\"\n        try:\n            with open(cache_file, 'w', encoding='utf-8') as f:\n                json.dump(response, f, ensure_ascii=False, indent=2)\n            \n            self._save_index()\n            logger.debug(f\"Cache SET para: {query[:50]}...\")\n            return True\n        except Exception as e:\n            logger.error(f\"Erro ao salvar cache: {e}\")\n            return False\n    \n    def _remove_entry(self, key: str):\n        \"\"\"Remove entrada do cache.\"\"\"\n        if key in self._index:\n            del self._index[key]\n            \n        cache_file = self.cache_dir / f\"{key}.json\"\n        if cache_file.exists():\n            cache_file.unlink()\n        \n        self._save_index()\n    \n    def _cleanup_oldest(self, remove_count: int = 100):\n        \"\"\"Remove entradas mais antigas.\"\"\"\n        if not self._index:\n            return\n        \n        # Ordenar por timestamp\n        sorted_entries = sorted(\n            self._index.items(),\n            key=lambda x: x[1].get(\"timestamp\", 0)\n        )\n        \n        # Remover as mais antigas\n        for key, _ in sorted_entries[:remove_count]:\n            self._remove_entry(key)\n        \n        logger.info(f\"Cache cleanup: removidas {remove_count} entradas antigas\")\n    \n    def clear(self):\n        \"\"\"Limpa todo o cache.\"\"\"\n        for key in list(self._index.keys()):\n            self._remove_entry(key)\n        self._index = {}\n        self._save_index()\n        logger.info(\"Cache limpo completamente\")\n    \n    def get_stats(self) -> Dict[str, Any]:\n        \"\"\"Retorna estat\u00edsticas do cache.\"\"\"\n        total = self.hits + self.misses\n        hit_rate = (self.hits / total * 100) if total > 0 else 0\n        \n        return {\n            \"entries\": len(self._index),\n            \"hits\": self.hits,\n            \"misses\": self.misses,\n            \"hit_rate\": f\"{hit_rate:.1f}%\",\n            \"cache_dir\": str(self.cache_dir),\n        }\n\n\n# Inst\u00e2ncia global do cache\n_semantic_cache: Optional[SemanticCache] = None\n\n\ndef get_semantic_cache() -> SemanticCache:\n    \"\"\"Retorna inst\u00e2ncia singleton do cache.\"\"\"\n    global _semantic_cache\n    if _semantic_cache is None:\n        _semantic_cache = SemanticCache()\n    return _semantic_cache\n\n\n# Fun\u00e7\u00f5es de conveni\u00eancia\ndef cache_get(query: str) -> Optional[Dict[str, Any]]:\n    \"\"\"Busca resposta em cache.\"\"\"\n    return get_semantic_cache().get(query)\n\n\ndef cache_set(query: str, response: Dict[str, Any]) -> bool:\n    \"\"\"Armazena resposta em cache.\"\"\"\n    return get_semantic_cache().set(query, response)\n\n\ndef cache_stats() -> Dict[str, Any]:\n    \"\"\"Retorna estat\u00edsticas do cache.\"\"\"\n    return get_semantic_cache().get_stats()", "mimetype": "text/plain", "start_char_idx": 4165, "end_char_idx": 7452, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "3c0703a9-f889-4804-b180-8951fd9e6f3d": {"__data__": {"id_": "3c0703a9-f889-4804-b180-8951fd9e6f3d", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\utils\\serializers.py", "language": "python", "lines": 179, "filename": "serializers.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\utils\\serializers.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\utils\\serializers.py", "language": "python", "lines": 179, "filename": "serializers.py"}, "hash": "0496d65f8691200b0a6bed3d976b43b9b729417deb4166cb9091a3faea40e936", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a90a9bac-f436-483a-8340-aea1491b2fc0", "node_type": "1", "metadata": {}, "hash": "97d2e052f66aaac2e56e588dee5e41c1e62aa09c56ac90cc313a9796845d3b11", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nUtilit\\u00e1rios de serializa\\u00e7\\u00e3o para tipos complexos Python/SQLAlchemy.\nResolve erros como \"Object of type MapComposite is not JSON serializable\".\n\"\"\"\nimport json\nimport logging\nfrom typing import Any, Dict, List\nfrom datetime import datetime, date\nfrom decimal import Decimal\nimport pandas as pd\nimport numpy as np\n\nlogger = logging.getLogger(__name__)", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 368, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a90a9bac-f436-483a-8340-aea1491b2fc0": {"__data__": {"id_": "a90a9bac-f436-483a-8340-aea1491b2fc0", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\utils\\serializers.py", "language": "python", "lines": 179, "filename": "serializers.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\utils\\serializers.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\utils\\serializers.py", "language": "python", "lines": 179, "filename": "serializers.py"}, "hash": "0496d65f8691200b0a6bed3d976b43b9b729417deb4166cb9091a3faea40e936", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3c0703a9-f889-4804-b180-8951fd9e6f3d", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\utils\\serializers.py", "language": "python", "lines": 179, "filename": "serializers.py"}, "hash": "f1bd1363572c9f2f5620b465ef43c5c5c7e18e0cbe43d02a370fd8ee2b27b86a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "206fd156-f82c-4487-868e-c230dd5b50e6", "node_type": "1", "metadata": {}, "hash": "4f30fb54a9418150e1fa8e764e21afe812c447a3b530b8de7dbfec0ba65a4119", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "class TypeConverter:\n    \"\"\"Conversor gen\\u00e9rico de tipos para serializa\\u00e7\\u00e3o JSON.\"\"\"\n\n    @staticmethod\n    def convert(obj: Any) -> Any:\n        \"\"\"\n        Converte qualquer objeto para formato JSON-serializ\\u00e1vel.\n\n        Trata casos especiais:\n        - SQLAlchemy Row / MapComposite\n        - Tipos numpy (int64, float64, etc.)\n        - Tipos pandas (Timestamp, Timedelta)\n        - Datetime, Decimal, bytes\n        - Objetos gen\\u00e9ricos com __dict__\n\n        Args:\n            obj: Objeto a ser convertido\n\n        Returns:\n            Objeto serializ\\u00e1vel em JSON\n        \"\"\"\n\n        # SQLAlchemy Row / MapComposite - CRIT\\u00cdCO para resolver o erro\n        if hasattr(obj, '_mapping'):\n            return dict(obj._mapping)\n\n        # Listas e tuplas\n        if isinstance(obj, (list, tuple)):\n            return [TypeConverter.convert(item) for item in obj]\n\n        # Dicion\\u00e1rios\n        if isinstance(obj, dict):\n            return {k: TypeConverter.convert(v) for k, v in obj.items()}\n\n        # Tipos primitivos j\\u00e1 serializ\\u00e1veis\n        if isinstance(obj, (int, float, bool, str, type(None))):\n            return obj\n\n        # Tipos numpy\n        if isinstance(obj, np.integer):\n            return int(obj)\n        if isinstance(obj, np.floating):\n            val = float(obj)\n            return None if (np.isnan(val) or np.isinf(val)) else val\n        if isinstance(obj, np.ndarray):\n            return obj.tolist()\n        if isinstance(obj, np.bool_):\n            return bool(obj)\n\n        # Tipos pandas\n        if isinstance(obj, pd.Timestamp):\n            return obj.isoformat()\n        if isinstance(obj, pd.Timedelta):\n            return str(obj)\n        if pd.isna(obj):\n            return None\n\n        # Tipos datetime\n        if isinstance(obj, (datetime, date)):\n            return obj.isoformat()\n\n        # Decimal\n        if isinstance(obj, Decimal):\n            return float(obj)\n\n        # Bytes\n        if isinstance(obj, bytes):\n            return obj.decode('utf-8', errors='ignore')\n\n        # Sets\n        if isinstance(obj, set):\n            return list(obj)\n\n        # Objetos gen\\u00e9ricos com __dict__\n        if hasattr(obj, '__dict__') and not isinstance(obj, type):\n            return {k: TypeConverter.convert(v)\n                   for k, v in obj.__dict__.items()\n                   if not k.startswith('_')}\n\n        # \\u00daltimo recurso: converter para string\n        logger.warning(f\"Tipo desconhecido {type(obj)}: {obj}, convertendo para string\")\n        return str(obj)\n\n    @staticmethod\n    def to_json(obj: Any, **kwargs) -> str:\n        \"\"\"\n        Converte objeto para string JSON de forma segura.\n\n        Args:\n            obj: Objeto a ser convertido\n            **kwargs: Argumentos adicionais para json.dumps\n\n        Returns:\n            String JSON\n        \"\"\"\n        try:\n            converted = TypeConverter.convert(obj)\n            if 'ensure_ascii' not in kwargs:\n                kwargs['ensure_ascii'] = False\n            return json.dumps(converted, **kwargs)\n        except Exception as e:\n            logger.error(f\"Falha na convers\\u00e3o JSON: {e}\", exc_info=True)\n            return json.dumps({\"error\": f\"Serializa\\u00e7\\u00e3o falhou: {str(e)}\"}, ensure_ascii=False)\n\n    @staticmethod\n    def from_query_rows(rows: List[Any]) -> List[Dict[str, Any]]:\n        \"\"\"\n        Converte linhas de resultado de query para lista de dicion\\u00e1rios.\n        Especialmente \\u00fatil para resultados SQLAlchemy.\n\n        Args:\n            rows: Lista de Row objects ou dicts\n\n        Returns:\n            Lista de dicion\\u00e1rios JSON-serializ\\u00e1veis\n        \"\"\"\n        results = []\n        for row in rows:\n            if hasattr(row, '_mapping'):\n                # SQLAlchemy Row com _mapping\n                results.append(TypeConverter.convert(dict(row._mapping)))\n            elif isinstance(row, dict):\n                # J\\u00e1 \\u00e9 dict, mas pode conter tipos n\\u00e3o-serializ\\u00e1veis\n                results.append(TypeConverter.convert(row))\n            else:\n                # Tentar converter diretamente\n                results.append(TypeConverter.convert(row))\n\n        return results", "mimetype": "text/plain", "start_char_idx": 371, "end_char_idx": 4594, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "206fd156-f82c-4487-868e-c230dd5b50e6": {"__data__": {"id_": "206fd156-f82c-4487-868e-c230dd5b50e6", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\utils\\serializers.py", "language": "python", "lines": 179, "filename": "serializers.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\utils\\serializers.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\utils\\serializers.py", "language": "python", "lines": 179, "filename": "serializers.py"}, "hash": "0496d65f8691200b0a6bed3d976b43b9b729417deb4166cb9091a3faea40e936", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a90a9bac-f436-483a-8340-aea1491b2fc0", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\utils\\serializers.py", "language": "python", "lines": 179, "filename": "serializers.py"}, "hash": "0d43cf2acc3cd1372c05ed70c017bb58d942cba11a51e10f761de586fc9f7ab8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "def safe_json_dumps(obj: Any, **kwargs) -> str:\n    \"\"\"\n    Wrapper para TypeConverter.to_json() para compatibilidade com c\\u00f3digo existente.\n\n    Args:\n        obj: Objeto a ser convertido\n        **kwargs: Argumentos para json.dumps\n\n    Returns:\n        String JSON\n    \"\"\"\n    return TypeConverter.to_json(obj, **kwargs)\n\n\ndef convert_mapcomposite(obj: Any) -> Any:\n    \"\"\"\n    Converte recursivamente objetos MapComposite para dict.\n    Fun\\u00e7\\u00e3o auxiliar para compatibilidade com c\\u00f3digo existente.\n\n    Args:\n        obj: Objeto a ser convertido\n\n    Returns:\n        Objeto com MapComposite convertido\n    \"\"\"\n    if hasattr(obj, '_mapping'):\n        return dict(obj._mapping)\n    elif isinstance(obj, dict):\n        return {k: convert_mapcomposite(v) for k, v in obj.items()}\n    elif isinstance(obj, list):\n        return [convert_mapcomposite(item) for item in obj]\n    return obj", "mimetype": "text/plain", "start_char_idx": 4597, "end_char_idx": 5502, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b226e07b-8734-490a-9b84-fe9b3a3e031b": {"__data__": {"id_": "b226e07b-8734-490a-9b84-fe9b3a3e031b", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\utils\\session_manager.py", "language": "python", "lines": 57, "filename": "session_manager.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\utils\\session_manager.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\utils\\session_manager.py", "language": "python", "lines": 57, "filename": "session_manager.py"}, "hash": "568775c628c6c9f076e742053015a03812fe7a2a5b485d10be3d81c27eecf64a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import json\nimport os\nimport logging\nfrom typing import List, Dict, Any\nfrom pathlib import Path\n\nlogger = logging.getLogger(__name__)\n\nclass SessionManager:\n    def __init__(self, storage_dir: str = \"data/sessions\"):\n        self.storage_dir = Path(storage_dir)\n        self.storage_dir.mkdir(parents=True, exist_ok=True)\n\n    def _get_file_path(self, session_id: str) -> Path:\n        return self.storage_dir / f\"{session_id}.json\"\n\n    def get_history(self, session_id: str) -> List[Dict[str, str]]:\n        \"\"\"Retrieves chat history for a given session ID.\"\"\"\n        file_path = self._get_file_path(session_id)\n        if not file_path.exists():\n            return []\n        \n        try:\n            with open(file_path, 'r', encoding='utf-8') as f:\n                data = json.load(f)\n                return data.get(\"history\", [])\n        except Exception as e:\n            logger.error(f\"Error reading session {session_id}: {e}\")\n            return []\n\n    def add_message(self, session_id: str, role: str, content: str):\n        \"\"\"Adds a message to the session history.\"\"\"\n        file_path = self._get_file_path(session_id)\n        history = self.get_history(session_id)\n        \n        history.append({\"role\": role, \"content\": content})\n        \n        # Limit history length to prevent context window explosion (e.g., last 20 messages)\n        # This is a basic optimization. RAG/Summarization would be better for long term.\n        if len(history) > 20:\n            history = history[-20:]\n\n        try:\n            with open(file_path, 'w', encoding='utf-8') as f:\n                json.dump({\"history\": history}, f, ensure_ascii=False, indent=2)\n        except Exception as e:\n            logger.error(f\"Error saving session {session_id}: {e}\")\n\n    def clear_session(self, session_id: str):\n        \"\"\"Deletes a session file.\"\"\"\n        file_path = self._get_file_path(session_id)\n        if file_path.exists():\n            try:\n                os.remove(file_path)\n            except Exception as e:\n                logger.error(f\"Error clearing session {session_id}: {e}\")", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2094, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a78c429f-eb14-4827-bded-1e9ed23bed4f": {"__data__": {"id_": "a78c429f-eb14-4827-bded-1e9ed23bed4f", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\utils\\__init__.py", "language": "python", "lines": 2, "filename": "__init__.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\utils\\__init__.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\utils\\__init__.py", "language": "python", "lines": 2, "filename": "__init__.py"}, "hash": "0446435eee3a78d18e2c49c18d55ee844a6e7d4e640efb0da313762c14696c12", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# Utils module", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 14, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "eb87491b-64b0-426e-b221-09e49323f382": {"__data__": {"id_": "eb87491b-64b0-426e-b221-09e49323f382", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\validators\\schema_validator.py", "language": "python", "lines": 397, "filename": "schema_validator.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\validators\\schema_validator.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\validators\\schema_validator.py", "language": "python", "lines": 397, "filename": "schema_validator.py"}, "hash": "c226472c193f365792fa8e202d99cdd7c528e3b2f80f92752c596ca0af27cf65", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "fee77b69-66d5-4194-ba7b-923360233275", "node_type": "1", "metadata": {}, "hash": "572fb734eec27fb59652a367fc390e6fe9d97b9ab0a40bec42619773f66bd74e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nSchemaValidator - Validador de schemas Parquet.\n\nEste m\u00f3dulo fornece valida\u00e7\u00e3o robusta de schemas Parquet contra\no cat\u00e1logo de dados corporativo (catalog_focused.json).\n\nFuncionalidades:\n- Valida\u00e7\u00e3o de tipos de dados\n- Detec\u00e7\u00e3o de incompatibilidades de schema\n- Mensagens de erro contextualizadas\n- Verifica\u00e7\u00e3o de colunas obrigat\u00f3rias\n\nAutor: Code Agent\nData: 2025-10-17\n\"\"\"\n\nimport json\nimport logging\nimport os\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Tuple, Any\nimport pyarrow as pa\nimport pyarrow.parquet as pq\n\nlogger = logging.getLogger(__name__)\n\n\nclass SchemaValidator:\n    \"\"\"\n    Validador de schemas Parquet contra cat\u00e1logo corporativo.\n\n    Attributes:\n        catalog (Dict): Cat\u00e1logo de dados carregado do JSON\n        catalog_path (Path): Caminho para o arquivo de cat\u00e1logo\n    \"\"\"\n\n    # Mapeamento de tipos Parquet para tipos Python/Pandas\n    TYPE_MAPPING = {\n        'int64': ['int64', 'int32', 'int16', 'int8'],\n        'float64': ['float64', 'float32', 'double'],\n        'string': ['string', 'large_string', 'utf8'],\n        'date': ['date32', 'date64'],\n        'datetime': ['timestamp[ns]', 'timestamp[us]', 'timestamp[ms]'],\n        'bool': ['bool'],\n    }\n\n    def __init__(self, catalog_path: Optional[str] = None):\n        \"\"\"\n        Inicializa o validador de schema.\n\n        Args:\n            catalog_path: Caminho para catalog_focused.json (opcional)\n        \"\"\"\n        if catalog_path is None:\n            # Tentar localizar o cat\u00e1logo em v\u00e1rios locais poss\u00edveis\n            possible_paths = [\n                Path(os.getcwd()) / \"data\" / \"catalog_focused.json\", # Root execution\n                Path(os.getcwd()) / \"backend\" / \"data\" / \"catalog_focused.json\", # Outside backend\n                Path(__file__).parent.parent.parent.parent.parent / \"data\" / \"catalog_focused.json\", # Relative to file\n                Path(__file__).parent.parent.parent / \"data\" / \"catalog_focused.json\", # Old fallback\n            ]\n            \n            for path in possible_paths:\n                if path.exists():\n                    catalog_path = path\n                    break\n            \n            # Fallback se nenhum existir (vai falhar no load, mas pelo menos tentou)\n            if catalog_path is None:\n                catalog_path = possible_paths[0]\n\n        self.catalog_path = Path(catalog_path)\n        # self.catalog = self._load_catalog() # Adiar carregamento para evitar crash na init se arquivo n\u00e3o existir\n        # Melhor: Tentar carregar, se falhar, logar warning e usar catalogo vazio\n        try:\n            self.catalog: Any = self._load_catalog()\n        except FileNotFoundError:\n            logger.warning(f\"Cat\u00e1logo n\u00e3o encontrado em {self.catalog_path}. Valida\u00e7\u00e3o de schema ser\u00e1 ignorada.\")\n            self.catalog = []\n\n    def _load_catalog(self) -> Dict:\n        \"\"\"\n        Carrega o cat\u00e1logo de dados do arquivo JSON.\n\n        Returns:\n            Dict contendo o cat\u00e1logo de dados\n\n        Raises:\n            FileNotFoundError: Se o cat\u00e1logo n\u00e3o existir\n            json.JSONDecodeError: Se o JSON for inv\u00e1lido\n        \"\"\"\n        try:\n            with open(self.catalog_path, 'r', encoding='utf-8') as f:\n                catalog = json.load(f)\n            logger.info(f\"Cat\u00e1logo carregado: {self.catalog_path}\")\n            return catalog\n        except FileNotFoundError:\n            logger.error(f\"Cat\u00e1logo n\u00e3o encontrado: {self.catalog_path}\")\n            raise\n        except json.JSONDecodeError as e:\n            logger.error(f\"Erro ao decodificar cat\u00e1logo JSON: {e}\")\n            raise\n\n    def validate_parquet_file(self, parquet_path: str, table_name: Optional[str] = None) -> Tuple[bool, List[str]]:\n        \"\"\"\n        Valida um arquivo Parquet contra o cat\u00e1logo.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3767, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "fee77b69-66d5-4194-ba7b-923360233275": {"__data__": {"id_": "fee77b69-66d5-4194-ba7b-923360233275", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\validators\\schema_validator.py", "language": "python", "lines": 397, "filename": "schema_validator.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\validators\\schema_validator.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\validators\\schema_validator.py", "language": "python", "lines": 397, "filename": "schema_validator.py"}, "hash": "c226472c193f365792fa8e202d99cdd7c528e3b2f80f92752c596ca0af27cf65", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "eb87491b-64b0-426e-b221-09e49323f382", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\validators\\schema_validator.py", "language": "python", "lines": 397, "filename": "schema_validator.py"}, "hash": "bf7036dc22d2d1cc1e8b14fc3d328d8cc82ccc8ef7603d2a1465bc50a1e00bae", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "74e18685-4e32-4ab1-9d5c-7b5c5c8cdb0f", "node_type": "1", "metadata": {}, "hash": "33d6126c3fd791d8f1c671b7789f6d02adc234c59c14a138dc81e0ee31817794", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Args:\n            parquet_path: Caminho para o arquivo Parquet\n            table_name: Nome da tabela no cat\u00e1logo (inferido do arquivo se None)\n\n        Returns:\n            Tupla (is_valid, errors) onde:\n                - is_valid: True se schema v\u00e1lido\n                - errors: Lista de mensagens de erro\n        \"\"\"\n        errors = []\n\n        try:\n            # Carregar schema do Parquet\n            parquet_file = pq.ParquetFile(parquet_path)\n            parquet_schema = parquet_file.schema_arrow\n\n            # Inferir nome da tabela se n\u00e3o fornecido\n            if table_name is None:\n                table_name = Path(parquet_path).stem\n\n            # Buscar schema esperado no cat\u00e1logo\n            expected_schema = self._get_expected_schema(table_name)\n            if expected_schema is None:\n                errors.append(f\"Tabela '{table_name}' n\u00e3o encontrada no cat\u00e1logo\")\n                return False, errors\n\n            # Validar colunas\n            column_errors = self._validate_columns(parquet_schema, expected_schema, table_name)\n            errors.extend(column_errors)\n\n            # Validar tipos\n            type_errors = self._validate_types(parquet_schema, expected_schema, table_name)\n            errors.extend(type_errors)\n\n            is_valid = len(errors) == 0\n\n            if is_valid:\n                logger.info(f\"Schema v\u00e1lido para '{table_name}': {parquet_path}\")\n            else:\n                logger.warning(f\"Schema inv\u00e1lido para '{table_name}': {len(errors)} erros encontrados\")\n\n            return is_valid, errors\n\n        except Exception as e:\n            error_msg = f\"Erro ao validar arquivo Parquet '{parquet_path}': {str(e)}\"\n            logger.error(error_msg)\n            errors.append(error_msg)\n            return False, errors\n\n    def _get_expected_schema(self, table_name: str) -> Optional[Dict]:\n        \"\"\"\n        Obt\u00e9m o schema esperado do cat\u00e1logo para uma tabela.\n\n        Args:\n            table_name: Nome da tabela\n\n        Returns:\n            Dict com schema esperado ou None se n\u00e3o encontrado\n        \"\"\"\n        # Normalizar nome da tabela buscada\n        search_name = table_name.lower().replace('_', '').replace('-', '')\n        \n        # Handle List structure (Current format of catalog_focused.json)\n        if isinstance(self.catalog, list):\n            for table_info in self.catalog:\n                file_name = table_info.get(\"file_name\", \"\")\n                if not file_name:\n                    continue\n                    \n                # Extrair nome base do arquivo (ex: \"admatao.parquet\" -> \"admatao\")\n                catalog_table_name = Path(file_name).stem.lower().replace('_', '').replace('-', '')\n                \n                # Match exato\n                if catalog_table_name == search_name:\n                    return table_info\n                \n                # Match aproximado espec\u00edfico para admmat/admatao\n                if (search_name == \"admmat\" and \"admat\" in catalog_table_name) or \\\n                   (search_name == \"admatao\" and \"admmat\" in catalog_table_name):\n                    return table_info\n                    \n            return None\n\n        # Handle Dict structure (Legacy format support)\n        elif isinstance(self.catalog, dict):\n            # Tentar encontrar a tabela no cat\u00e1logo\n            for table_key, table_info in self.catalog.items():\n                # Normalizar nomes (remover prefixos, sufixos)\n                normalized_key = table_key.lower().replace('_', '').replace('-', '')\n\n                if normalized_key == search_name or table_key.lower() == table_name.lower():\n                    return table_info\n\n        return None\n\n    def _validate_columns(self, parquet_schema: pa.Schema, expected_schema: Dict, table_name: str) -> List[str]:\n        \"\"\"\n        Valida se as colunas esperadas est\u00e3o presentes no Parquet.", "mimetype": "text/plain", "start_char_idx": 3777, "end_char_idx": 7653, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "74e18685-4e32-4ab1-9d5c-7b5c5c8cdb0f": {"__data__": {"id_": "74e18685-4e32-4ab1-9d5c-7b5c5c8cdb0f", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\validators\\schema_validator.py", "language": "python", "lines": 397, "filename": "schema_validator.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\validators\\schema_validator.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\validators\\schema_validator.py", "language": "python", "lines": 397, "filename": "schema_validator.py"}, "hash": "c226472c193f365792fa8e202d99cdd7c528e3b2f80f92752c596ca0af27cf65", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fee77b69-66d5-4194-ba7b-923360233275", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\validators\\schema_validator.py", "language": "python", "lines": 397, "filename": "schema_validator.py"}, "hash": "e3e55baa913e0cb94613a527efe843ffd908f1360b01a2f61bacdf368d707b5f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ef3fd107-8fe2-413d-8e67-1ca870095783", "node_type": "1", "metadata": {}, "hash": "cac9bbf2c58682fdbb693d99174901bfd23a7c1aeb4d30cb994cdd5d2809b468", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Args:\n            parquet_schema: Schema do arquivo Parquet\n            expected_schema: Schema esperado do cat\u00e1logo\n            table_name: Nome da tabela\n\n        Returns:\n            Lista de erros encontrados\n        \"\"\"\n        errors = []\n\n        # Obter colunas do Parquet\n        parquet_columns = set(parquet_schema.names)\n\n        # Obter colunas esperadas do cat\u00e1logo\n        expected_columns = set(expected_schema.get('columns', {}).keys())\n\n        # Verificar colunas faltantes (esperadas mas n\u00e3o presentes)\n        missing_columns = expected_columns - parquet_columns\n        if missing_columns:\n            errors.append(\n                f\"Tabela '{table_name}': Colunas faltantes: {sorted(missing_columns)}\"\n            )\n\n        # Verificar colunas extras (presentes mas n\u00e3o esperadas) - apenas warning\n        extra_columns = parquet_columns - expected_columns\n        if extra_columns:\n            logger.warning(\n                f\"Tabela '{table_name}': Colunas extras encontradas: {sorted(extra_columns)}\"\n            )\n\n        return errors\n\n    def _validate_types(self, parquet_schema: pa.Schema, expected_schema: Dict, table_name: str) -> List[str]:\n        \"\"\"\n        Valida se os tipos de dados s\u00e3o compat\u00edveis.\n\n        Args:\n            parquet_schema: Schema do arquivo Parquet\n            expected_schema: Schema esperado do cat\u00e1logo\n            table_name: Nome da tabela\n\n        Returns:\n            Lista de erros de incompatibilidade de tipos\n        \"\"\"\n        errors = []\n\n        expected_columns = expected_schema.get('columns', {})\n\n        for field in parquet_schema:\n            column_name = field.name\n\n            # Ignorar colunas n\u00e3o definidas no cat\u00e1logo\n            if column_name not in expected_columns:\n                continue\n\n            expected_type = expected_columns[column_name].get('type', 'string')\n            parquet_type = str(field.type)\n\n            # Verificar compatibilidade de tipos\n            if not self._is_type_compatible(parquet_type, expected_type):\n                errors.append(\n                    f\"Tabela '{table_name}', coluna '{column_name}': \"\n                    f\"Tipo incompat\u00edvel. Esperado: {expected_type}, \"\n                    f\"Encontrado: {parquet_type}\"\n                )\n\n        return errors\n\n    def _is_type_compatible(self, parquet_type: str, expected_type: str) -> bool:\n        \"\"\"\n        Verifica se um tipo Parquet \u00e9 compat\u00edvel com o tipo esperado.\n\n        Args:\n            parquet_type: Tipo do Parquet (ex: 'int64', 'string')\n            expected_type: Tipo esperado do cat\u00e1logo\n\n        Returns:\n            True se os tipos s\u00e3o compat\u00edveis\n        \"\"\"\n        # Normalizar tipos\n        parquet_type_lower = parquet_type.lower()\n        expected_type_lower = expected_type.lower()\n\n        # Verificar igualdade direta\n        if parquet_type_lower == expected_type_lower:\n            return True\n\n        # Verificar mapeamentos de tipos compat\u00edveis\n        for base_type, compatible_types in self.TYPE_MAPPING.items():\n            if expected_type_lower in compatible_types or expected_type_lower == base_type:\n                if parquet_type_lower in compatible_types or parquet_type_lower == base_type:\n                    return True\n\n        # Tipos num\u00e9ricos s\u00e3o geralmente compat\u00edveis entre si\n        numeric_types = ['int', 'float', 'double', 'decimal']\n        if any(nt in parquet_type_lower for nt in numeric_types) and \\\n           any(nt in expected_type_lower for nt in numeric_types):\n            return True\n\n        return False\n\n    def get_table_schema(self, table_name: str) -> Optional[Dict]:\n        \"\"\"\n        Retorna o schema esperado para uma tabela do cat\u00e1logo.\n\n        Args:\n            table_name: Nome da tabela\n\n        Returns:\n            Dict com schema da tabela ou None se n\u00e3o encontrada\n        \"\"\"\n        return self._get_expected_schema(table_name)\n\n    def list_required_columns(self, table_name: str) -> List[str]:\n        \"\"\"\n        Lista as colunas obrigat\u00f3rias de uma tabela.\n\n        Args:\n            table_name: Nome da tabela\n\n        Returns:\n            Lista de nomes de colunas obrigat\u00f3rias\n        \"\"\"\n        schema = self._get_expected_schema(table_name)\n        if schema is None:\n            return []\n\n        return list(schema.get('columns', {}).keys())\n\n    def validate_query_columns(self, table_name: str, query_columns: List[str]) -> Tuple[bool, List[str]]:\n        \"\"\"\n        Valida se as colunas de uma query existem no schema.", "mimetype": "text/plain", "start_char_idx": 7663, "end_char_idx": 12183, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ef3fd107-8fe2-413d-8e67-1ca870095783": {"__data__": {"id_": "ef3fd107-8fe2-413d-8e67-1ca870095783", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\validators\\schema_validator.py", "language": "python", "lines": 397, "filename": "schema_validator.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\validators\\schema_validator.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\validators\\schema_validator.py", "language": "python", "lines": 397, "filename": "schema_validator.py"}, "hash": "c226472c193f365792fa8e202d99cdd7c528e3b2f80f92752c596ca0af27cf65", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "74e18685-4e32-4ab1-9d5c-7b5c5c8cdb0f", "node_type": "1", "metadata": {"file_path": "backend\\app\\core\\validators\\schema_validator.py", "language": "python", "lines": 397, "filename": "schema_validator.py"}, "hash": "32b9b7c4712b96d3c0a3f85ab12a9445aa6ecfd847ea741313305933eefc3099", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Args:\n            table_name: Nome da tabela\n            query_columns: Lista de colunas usadas na query\n\n        Returns:\n            Tupla (is_valid, invalid_columns)\n        \"\"\"\n        schema = self._get_expected_schema(table_name)\n        if schema is None:\n            logger.warning(f\"Tabela '{table_name}' n\u00e3o encontrada no cat\u00e1logo\")\n            return True, []  # Assumir v\u00e1lido se tabela n\u00e3o est\u00e1 catalogada\n\n        valid_columns = set(schema.get('columns', {}).keys())\n        query_columns_set = set(query_columns)\n\n        invalid_columns = query_columns_set - valid_columns\n\n        is_valid = len(invalid_columns) == 0\n\n        return is_valid, list(invalid_columns)\n\n\n# Fun\u00e7\u00e3o auxiliar para valida\u00e7\u00e3o r\u00e1pida\ndef validate_parquet_schema(parquet_path: str, catalog_path: Optional[str] = None) -> Tuple[bool, List[str]]:\n    \"\"\"\n    Fun\u00e7\u00e3o auxiliar para valida\u00e7\u00e3o r\u00e1pida de schema Parquet.\n\n    Args:\n        parquet_path: Caminho para o arquivo Parquet\n        catalog_path: Caminho para o cat\u00e1logo (opcional)\n\n    Returns:\n        Tupla (is_valid, errors)\n    \"\"\"\n    validator = SchemaValidator(catalog_path)\n    return validator.validate_parquet_file(parquet_path)\n\n\nif __name__ == \"__main__\":\n    # Teste b\u00e1sico do validador\n    logging.basicConfig(level=logging.INFO)\n\n    # Exemplo de uso\n    validator = SchemaValidator()\n\n    # Validar arquivo de exemplo\n    test_file = Path(__file__).parent.parent.parent / \"data\" / \"parquet\" / \"produtos.parquet\"\n    if test_file.exists():\n        is_valid, errors = validator.validate_parquet_file(str(test_file))\n        print(f\"\\nValida\u00e7\u00e3o de {test_file.name}:\")\n        print(f\"V\u00e1lido: {is_valid}\")\n        if errors:\n            print(\"Erros:\")\n            for error in errors:\n                print(f\"  - {error}\")\n    else:\n        print(f\"Arquivo de teste n\u00e3o encontrado: {test_file}\")", "mimetype": "text/plain", "start_char_idx": 12193, "end_char_idx": 14046, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "34e2c144-8bf7-49f6-93ff-13184e2c87f4": {"__data__": {"id_": "34e2c144-8bf7-49f6-93ff-13184e2c87f4", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\visualization\\advanced_charts.py", "language": "python", "lines": 107, "filename": "advanced_charts.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\visualization\\advanced_charts.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\visualization\\advanced_charts.py", "language": "python", "lines": 107, "filename": "advanced_charts.py"}, "hash": "26fbe7f779069d1b5b83cc98f9fb0514597ca3265a33f5f5bede5ea448fb9474", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nM\u00f3dulo de Gr\u00e1ficos Avan\u00e7ados para Business Intelligence\nVers\u00e3o simplificada para Agent Solution BI\n\"\"\"\n\nimport pandas as pd\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport logging\n\nlogger = logging.getLogger(__name__)\n\n\nclass AdvancedChartGenerator:\n    \"\"\"Gerador de gr\u00e1ficos avan\u00e7ados para an\u00e1lises de neg\u00f3cio.\"\"\"\n\n    def __init__(self):\n        \"\"\"Inicializa o gerador de gr\u00e1ficos.\"\"\"\n        self.color_palette = {\n            \"primary\": \"#1f77b4\",\n            \"secondary\": \"#ff7f0e\",\n            \"success\": \"#2ca02c\",\n            \"warning\": \"#d62728\",\n            \"info\": \"#9467bd\",\n        }\n\n    def create_product_ranking_chart(\n        self, df: pd.DataFrame, limit: int = 10, chart_type: str = \"horizontal_bar\"\n    ) -> go.Figure:\n        \"\"\"\n        Cria gr\u00e1fico de ranking de produtos.\n\n        Args:\n            df: DataFrame com dados de produtos\n            limit: N\u00famero de produtos no ranking\n            chart_type: Tipo do gr\u00e1fico\n\n        Returns:\n            Figura Plotly\n        \"\"\"\n        try:\n            # Assumir que df tem colunas relevantes\n            if df.empty:\n                logger.warning(\"DataFrame vazio para criar gr\u00e1fico\")\n                return go.Figure()\n\n            fig = px.bar(\n                df.head(limit),\n                title=f\"Top {limit} Produtos\",\n                color_discrete_sequence=[self.color_palette[\"primary\"]],\n            )\n\n            fig.update_layout(\n                template=\"plotly_white\",\n                showlegend=True,\n                height=500,\n            )\n\n            return fig\n\n        except Exception as e:\n            logger.error(f\"Erro ao criar gr\u00e1fico: {e}\")\n            return go.Figure()\n\n    def create_time_series_chart(self, df: pd.DataFrame) -> go.Figure:\n        \"\"\"Cria gr\u00e1fico de s\u00e9rie temporal.\"\"\"\n        try:\n            fig = px.line(\n                df,\n                title=\"Evolu\u00e7\u00e3o Temporal\",\n                markers=True,\n                color_discrete_sequence=[self.color_palette[\"secondary\"]],\n            )\n\n            fig.update_layout(\n                template=\"plotly_white\",\n                showlegend=True,\n                height=500,\n            )\n\n            return fig\n\n        except Exception as e:\n            logger.error(f\"Erro ao criar gr\u00e1fico temporal: {e}\")\n            return go.Figure()\n\n    def create_pie_chart(self, df: pd.DataFrame) -> go.Figure:\n        \"\"\"Cria gr\u00e1fico de pizza.\"\"\"\n        try:\n            fig = px.pie(\n                df,\n                title=\"Distribui\u00e7\u00e3o\",\n                hole=0.3,\n            )\n\n            fig.update_layout(\n                template=\"plotly_white\",\n                showlegend=True,\n                height=500,\n            )\n\n            return fig\n\n        except Exception as e:\n            logger.error(f\"Erro ao criar gr\u00e1fico de pizza: {e}\")\n            return go.Figure()", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2887, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2f5962ad-5033-43fa-93ec-82ef82d3a86e": {"__data__": {"id_": "2f5962ad-5033-43fa-93ec-82ef82d3a86e", "embedding": null, "metadata": {"file_path": "backend\\app\\core\\visualization\\__init__.py", "language": "python", "lines": 2, "filename": "__init__.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\core\\visualization\\__init__.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\core\\visualization\\__init__.py", "language": "python", "lines": 2, "filename": "__init__.py"}, "hash": "08476213480c33d54e9ec65bc063de139587a1dfc546d3adadc5ab60fb1994eb", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# Visualization module", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 22, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e05210ae-c769-4b40-90a3-7aa5885ce41c": {"__data__": {"id_": "e05210ae-c769-4b40-90a3-7aa5885ce41c", "embedding": null, "metadata": {"file_path": "backend\\app\\infrastructure\\data\\base.py", "language": "python", "lines": 34, "filename": "base.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\infrastructure\\data\\base.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\infrastructure\\data\\base.py", "language": "python", "lines": 34, "filename": "base.py"}, "hash": "dd35592a09cb43165668ddef14c70b0ec0c5ee6c3facff956d7fff1270e37385", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nDatabase Adapter Interface\nAbstract Base Class for database adapters (Strategy Interface).\nAdapted for Async/FastAPI.\n\"\"\"\n\nfrom abc import ABC, abstractmethod\nfrom typing import Any, Dict, List\n\nclass DatabaseAdapter(ABC):\n    \"\"\"\n    Abstract Base Class for database adapters.\n    Defines the common contract for all database connectivity.\n    \"\"\"\n    @abstractmethod\n    async def connect(self) -> None:\n        \"\"\"Establishes a connection to the database.\"\"\"\n        pass\n\n    @abstractmethod\n    async def disconnect(self) -> None:\n        \"\"\"Closes the database connection.\"\"\"\n        pass\n\n    @abstractmethod\n    async def execute_query(self, query: Any) -> Any:\n        \"\"\"Executes a query and returns the results.\"\"\"\n        pass\n\n    @abstractmethod\n    async def get_schema(self) -> Any:\n        \"\"\"Returns the database schema information.\"\"\"\n        pass", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 870, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7149ff09-2905-4593-90e7-db6da39ed0b0": {"__data__": {"id_": "7149ff09-2905-4593-90e7-db6da39ed0b0", "embedding": null, "metadata": {"file_path": "backend\\app\\infrastructure\\data\\dependency.py", "language": "python", "lines": 25, "filename": "dependency.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\infrastructure\\data\\dependency.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\infrastructure\\data\\dependency.py", "language": "python", "lines": 25, "filename": "dependency.py"}, "hash": "e5f91be7ef0944b73ac4b814274669870bcadab8c1e460106f457c3e86dfef8a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nData Adapter Dependency\nProvides the HybridDataAdapter instance to API endpoints.\n\"\"\"\n\nfrom typing import Annotated\nfrom fastapi import Depends, Request\n\nfrom app.infrastructure.data.hybrid_adapter import HybridDataAdapter\n\ndef get_data_adapter(request: Request) -> HybridDataAdapter:\n    \"\"\"\n    Dependency to get the HybridDataAdapter instance from app state.\n    The adapter is initialized in main.py lifespan.\n    \"\"\"\n    if not hasattr(request.app.state, \"data_adapter\"):\n        # Fallback if not initialized (e.g. during tests)\n        # But ideally should be initialized in lifespan\n        request.app.state.data_adapter = HybridDataAdapter()\n        \n    return request.app.state.data_adapter\n\n# Type alias for easier usage in endpoints\nDataAdapter = Annotated[HybridDataAdapter, Depends(get_data_adapter)]", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 820, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "eb208ab1-05cd-4df6-809c-a9269ffc51e3": {"__data__": {"id_": "eb208ab1-05cd-4df6-809c-a9269ffc51e3", "embedding": null, "metadata": {"file_path": "backend\\app\\infrastructure\\data\\duckdb_adapter.py", "language": "python", "lines": 177, "filename": "duckdb_adapter.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\infrastructure\\data\\duckdb_adapter.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\infrastructure\\data\\duckdb_adapter.py", "language": "python", "lines": 177, "filename": "duckdb_adapter.py"}, "hash": "094d1d2b2f0635842d19ed789c725e860a7dc85c9358c3a2559a82d70c728d63", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a188f464-6e85-415e-927f-f813a4b43719", "node_type": "1", "metadata": {}, "hash": "43fbbb5ca362c93821cbbfe17ab15fb947f1a4b39da47610167bb59dc674adef", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import duckdb\nimport os\nimport pandas as pd\nimport logging\nfrom pathlib import Path\nfrom typing import Optional, List, Dict, Any, Union\n\nlogger = logging.getLogger(__name__)\n\nclass DuckDBAdapter:\n    \"\"\"\n    Adapter for querying Parquet files using DuckDB.\n    Follows Singleton pattern to manage connection efficiently (though DuckDB is fast to connect).\n    \"\"\"\n    _instance = None\n    \n    def __new__(cls):\n        if cls._instance is None:\n            cls._instance = super(DuckDBAdapter, cls).__new__(cls)\n            cls._instance._initialize()\n        return cls._instance\n    \n    def _initialize(self):\n        self.connection = duckdb.connect(database=':memory:')\n        self._setup_macros()\n        logger.info(\"DuckDBAdapter initialized (In-Memory)\")\n\n    def _setup_macros(self):\n        \"\"\"Setup reusable macros or settings\"\"\"\n        # Example: set threads if needed\n        # self.connection.execute(\"PRAGMA threads=4\")\n        pass\n\n    def _get_parquet_path(self, extended: bool = False) -> str:\n        \"\"\"Resolve absolute path to parquet file\"\"\"\n        # TODO: Get from settings\n        base_dir = Path(os.getcwd())\n        if extended:\n             path = base_dir / \"data\" / \"parquet\" / \"admmat_extended.parquet\"\n             if path.exists():\n                 return str(path)\n        \n        path = base_dir / \"data\" / \"parquet\" / \"admmat.parquet\"\n        if not path.exists():\n             # Fallback for tests path structure\n             path = base_dir / \"backend\" / \"data\" / \"parquet\" / \"admmat.parquet\"\n        \n        return str(path).replace(\"\\\\\", \"/\") # DuckDB prefers forward slashes or escaped backslashes\n\n    def query(self, sql: str, params: Optional[Union[List, Dict]] = None) -> pd.DataFrame:\n        \"\"\"\n        Execute raw SQL query and return Pandas DataFrame.\n        \"\"\"\n        try:\n            # If params provided, use them safely (DuckDB supports binding)\n            # However, for 'FROM' clauses with dynamic paths, we handled path in python.\n            if params:\n                 return self.connection.execute(sql, params).df()\n            else:\n                 return self.connection.execute(sql).df()\n        except Exception as e:\n            logger.error(f\"DuckDB Query Error: {e} | SQL: {sql}\")\n            raise e\n\n    def load_data(self, \n                  columns: Optional[List[str]] = None, \n                  filters: Optional[Dict[str, Any]] = None,\n                  limit: Optional[int] = None,\n                  order_by: Optional[str] = None) -> pd.DataFrame:\n        \"\"\"\n        Optimized data loader that builds SQL dynamically.\n        Replaces 'pd.read_parquet' with predicate pushdown.\n        \"\"\"\n        parquet_file = self._get_parquet_path()\n        \n        # 1. Select clause\n        cols_str = \"*\"\n        if columns:\n            # Sanitize column names just in case\n            cols_str = \", \".join([f'\"{c}\"' for c in columns])\n        \n        query_parts = [f\"SELECT {cols_str} FROM '{parquet_file}'\"]\n        \n        # 2. Where clause (Predicate Pushdown)\n        params = []\n        if filters:\n            conditions = []\n            for col, val in filters.items():\n                if isinstance(val, list):\n                    # IN clause: col IN (?, ?, ?)\n                    placeholders = \", \".join([\"?\" for _ in val])\n                    conditions.append(f'\"{col}\" IN ({placeholders})')\n                    params.extend(val)\n                else:\n                    # Equality\n                    conditions.append(f'\"{col}\" = ?')\n                    params.append(val)\n            \n            if conditions:\n                query_parts.append(\"WHERE \" + \" AND \".join(conditions))\n        \n        # 3. Order By\n        if order_by:\n             query_parts.append(f\"ORDER BY {order_by}\")\n\n        # 4. Limit\n        if limit:\n            query_parts.append(f\"LIMIT {limit}\")\n            \n        sql = \" \".join(query_parts)\n        # logger.debug(f\"DuckDB Load SQL: {sql} | Params: {params}\")\n        \n        return self.query(sql, params)\n\n    def execute_aggregation(self, \n                          agg_col: str, \n                          agg_func: str, \n                          group_by: Optional[List[str]] = None,\n                          filters: Optional[Dict[str, Any]] = None,\n                          limit: int = 50) -> pd.DataFrame:\n        \"\"\"\n        Perform fast aggregation directly in DuckDB.\n        \"\"\"", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4435, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a188f464-6e85-415e-927f-f813a4b43719": {"__data__": {"id_": "a188f464-6e85-415e-927f-f813a4b43719", "embedding": null, "metadata": {"file_path": "backend\\app\\infrastructure\\data\\duckdb_adapter.py", "language": "python", "lines": 177, "filename": "duckdb_adapter.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\infrastructure\\data\\duckdb_adapter.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\infrastructure\\data\\duckdb_adapter.py", "language": "python", "lines": 177, "filename": "duckdb_adapter.py"}, "hash": "094d1d2b2f0635842d19ed789c725e860a7dc85c9358c3a2559a82d70c728d63", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "eb208ab1-05cd-4df6-809c-a9269ffc51e3", "node_type": "1", "metadata": {"file_path": "backend\\app\\infrastructure\\data\\duckdb_adapter.py", "language": "python", "lines": 177, "filename": "duckdb_adapter.py"}, "hash": "293a3d8b5053369130ef92f0e75d6c2711c0622644c7e539c4f169651c96a408", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "parquet_file = self._get_parquet_path()\n        \n        # Validations\n        valid_aggs = {'sum', 'avg', 'min', 'max', 'count', 'count_distinct'}\n        if agg_func not in valid_aggs:\n            raise ValueError(f\"Invalid aggregation: {agg_func}\")\n            \n        sql_agg = f\"{agg_func}({agg_col})\"\n        if agg_func == 'count_distinct':\n             sql_agg = f\"count(DISTINCT {agg_col})\"\n        \n        select_clause = f\"{sql_agg} as valor\"\n        group_clause = \"\"\n        \n        if group_by:\n            group_cols = \", \".join([f'\"{c}\"' for c in group_by])\n            select_clause = f\"{group_cols}, {select_clause}\"\n            group_clause = f\"GROUP BY {group_cols}\"\n            \n        query_parts = [f\"SELECT {select_clause} FROM '{parquet_file}'\"]\n        \n        # Filters\n        params = []\n        if filters:\n            conditions = []\n            for col, val in filters.items():\n                if isinstance(val, list):\n                    placeholders = \", \".join([\"?\" for _ in val])\n                    conditions.append(f'\"{col}\" IN ({placeholders})')\n                    params.extend(val)\n                elif isinstance(val, str) and \"%\" in val: # LIKE support\n                     conditions.append(f'\"{col}\" LIKE ?')\n                     params.append(val)\n                else:\n                    conditions.append(f'\"{col}\" = ?')\n                    params.append(val)\n            \n            if conditions:\n                query_parts.append(\"WHERE \" + \" AND \".join(conditions))\n                \n        if group_clause:\n            query_parts.append(group_clause)\n            \n        # Order by aggregated value desc\n        query_parts.append(\"ORDER BY valor DESC\")\n        \n        query_parts.append(f\"LIMIT {limit}\")\n        \n        sql = \" \".join(query_parts)\n        return self.query(sql, params)\n\n# Global instance\nduckdb_adapter = DuckDBAdapter()", "mimetype": "text/plain", "start_char_idx": 4444, "end_char_idx": 6353, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ed2c99d0-fc50-4077-98b9-d9e7975cbed8": {"__data__": {"id_": "ed2c99d0-fc50-4077-98b9-d9e7975cbed8", "embedding": null, "metadata": {"file_path": "backend\\app\\infrastructure\\data\\hybrid_adapter.py", "language": "python", "lines": 125, "filename": "hybrid_adapter.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\infrastructure\\data\\hybrid_adapter.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\infrastructure\\data\\hybrid_adapter.py", "language": "python", "lines": 125, "filename": "hybrid_adapter.py"}, "hash": "202aa4c1224859ae66d5543d49f6c71d3800342d89ea8c50ad5c87d2aaf27ef6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f8a2635f-d21b-4981-a0c5-d932171b425a", "node_type": "1", "metadata": {}, "hash": "ec8e108137aa8d08ad2a7f9fdf8d56d498ab78922a690ab1a25168b05bd35a72", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nHybridDataAdapter: Adaptador h\u00edbrido com fallback autom\u00e1tico e inteligente.\nVers\u00e3o Async para FastAPI.\n\nPrioridade:\n1. SQL Server (se USE_SQL_SERVER=true e conex\u00e3o OK)\n2. Parquet (fallback sempre dispon\u00edvel)\n\"\"\"\n\nimport logging\nimport os\nimport asyncio\nfrom typing import Any, Dict, List, Optional\n\nfrom app.infrastructure.data.base import DatabaseAdapter\nfrom app.infrastructure.data.sql_server_adapter import SQLServerAdapter\nfrom app.infrastructure.data.parquet_adapter import ParquetAdapter\nfrom app.config.settings import settings\n\nlogger = logging.getLogger(__name__)\n\nclass HybridDataAdapter(DatabaseAdapter):\n    \"\"\"\n    Adapter h\u00edbrido com fallback autom\u00e1tico.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"Inicializa adapter com configura\u00e7\u00f5es do settings.py\"\"\"\n        # Flags de controle\n        self.use_sql_server = settings.USE_SQL_SERVER\n        self.sql_timeout = settings.SQL_SERVER_TIMEOUT\n        self.fallback_enabled = settings.FALLBACK_TO_PARQUET\n\n        # Status de conex\u00e3o\n        self.sql_available = False\n        self.current_source = \"parquet\"  # default seguro\n\n        # Adapters\n        self.sql_adapter: Optional[SQLServerAdapter] = None\n        self.parquet_adapter: Optional[ParquetAdapter] = None\n\n        # Inicializar adapters\n        self._init_adapters()\n\n        logger.info(f\"HybridDataAdapter inicializado - Fonte Inicial: {self.current_source}\")\n\n    def _init_adapters(self):\n        \"\"\"Inicializa adapters.\"\"\"\n        # 1. Inicializar Parquet (sempre necess\u00e1rio como fallback)\n        # Usar configura\u00e7\u00e3o centralizada do settings.py\n        parquet_path = settings.PARQUET_FILE_PATH\n        logger.info(f\"\ud83d\udcc2 Usando arquivo Parquet: {parquet_path}\")\n        self.parquet_adapter = ParquetAdapter(parquet_path)\n\n        # 2. Inicializar SQL Server se habilitado\n        if self.use_sql_server:\n            try:\n                # Settings j\u00e1 deve ter a string de conex\u00e3o configurada\n                self.sql_adapter = SQLServerAdapter(settings)\n                self.current_source = \"sql_server\" # Tentativa inicial\n            except Exception as e:\n                logger.error(f\"Erro ao configurar SQL Server Adapter: {e}\")\n                self.sql_available = False\n                self.current_source = \"parquet\"\n        else:\n            self.current_source = \"parquet\"\n\n    async def connect(self) -> None:\n        \"\"\"Tenta conectar ao SQL Server e define a fonte prim\u00e1ria com base na disponibilidade.\"\"\"\n        if self.use_sql_server and self.sql_adapter:\n            try:\n                # Tentar conectar com timeout\n                await asyncio.wait_for(self.sql_adapter.connect(), timeout=self.sql_timeout)\n                self.sql_available = True\n                self.current_source = \"sql_server\"\n                logger.info(\"\u2705 Conectado ao SQL Server. Fonte de dados definida como SQL Server.\")\n            except (asyncio.TimeoutError, Exception) as e:\n                logger.warning(f\"\u26a0\ufe0f Falha ao conectar SQL Server: {e}. Fallback para Parquet ativado.\")\n                self.sql_available = False\n                self.current_source = \"parquet\"\n        else:\n            self.current_source = \"parquet\"\n        \n        # Parquet \"conecta\" (lazy) para estar pronto para fallback\n        await self.parquet_adapter.connect()\n\n    async def disconnect(self) -> None:\n        if self.sql_adapter:\n            await self.sql_adapter.disconnect()\n        if self.parquet_adapter:\n            await self.parquet_adapter.disconnect()\n\n    async def execute_query(self, query_filters: Dict[str, Any], **kwargs) -> List[Dict[str, Any]]:\n        \"\"\"\n        Executa query com fallback autom\u00e1tico: SQL Server -> Parquet.\n        \"\"\"", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3687, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f8a2635f-d21b-4981-a0c5-d932171b425a": {"__data__": {"id_": "f8a2635f-d21b-4981-a0c5-d932171b425a", "embedding": null, "metadata": {"file_path": "backend\\app\\infrastructure\\data\\hybrid_adapter.py", "language": "python", "lines": 125, "filename": "hybrid_adapter.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\infrastructure\\data\\hybrid_adapter.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\infrastructure\\data\\hybrid_adapter.py", "language": "python", "lines": 125, "filename": "hybrid_adapter.py"}, "hash": "202aa4c1224859ae66d5543d49f6c71d3800342d89ea8c50ad5c87d2aaf27ef6", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ed2c99d0-fc50-4077-98b9-d9e7975cbed8", "node_type": "1", "metadata": {"file_path": "backend\\app\\infrastructure\\data\\hybrid_adapter.py", "language": "python", "lines": 125, "filename": "hybrid_adapter.py"}, "hash": "23ffe6adc3421917279bca353c1be4ad52cf40a4b9aa188480d305458790528a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "result = []\n        used_source = self.current_source\n\n        # Tentar SQL Server primeiro se for a fonte atual\n        if self.current_source == \"sql_server\" and self.sql_adapter:\n            try:\n                # SQL Adapter deve suportar a mesma interface ou kwargs\n                result = await self.sql_adapter.execute_query(query_filters, **kwargs)\n                return result\n            except Exception as e:\n                logger.error(f\"\u274c Erro na consulta SQL Server: {e}\")\n                if self.fallback_enabled:\n                    logger.info(\"\ud83d\udd04 Tentando fallback para Parquet...\")\n                    used_source = \"parquet\"\n                    # N\u00e3o alteramos self.current_source permanentemente aqui, apenas para esta query\n                    # ou poder\u00edamos alterar se quis\u00e9ssemos \"downgrade\" autom\u00e1tico\n                else:\n                    raise e\n        \n        # Executar no Parquet (se for a fonte atual ou fallback)\n        if used_source == \"parquet\" and self.parquet_adapter:\n            return await self.parquet_adapter.execute_query(query_filters, **kwargs)\n        \n        return []\n\n    async def get_schema(self) -> str:\n        \"\"\"Retorna schema do Parquet.\"\"\"\n        return await self.parquet_adapter.get_schema()", "mimetype": "text/plain", "start_char_idx": 3696, "end_char_idx": 4960, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "3dad3227-5cb1-4c8c-9e28-18ad1166f9b1": {"__data__": {"id_": "3dad3227-5cb1-4c8c-9e28-18ad1166f9b1", "embedding": null, "metadata": {"file_path": "backend\\app\\infrastructure\\data\\parquet_adapter.py", "language": "python", "lines": 39, "filename": "parquet_adapter.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\infrastructure\\data\\parquet_adapter.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\infrastructure\\data\\parquet_adapter.py", "language": "python", "lines": 39, "filename": "parquet_adapter.py"}, "hash": "90c536260c8b796d63ea8d73ea2507d3d7b28efd0ba210c87237929f935c2962", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nParquetAdapter: Adaptador para arquivos Parquet.\nVers\u00e3o Async para FastAPI.\n\"\"\"\n\nimport logging\nfrom typing import Any, Dict, List, Optional\n\nfrom app.infrastructure.data.base import DatabaseAdapter\nfrom app.infrastructure.data.polars_dask_adapter import PolarsDaskAdapter\n\nlogger = logging.getLogger(__name__)\n\nclass ParquetAdapter(DatabaseAdapter):\n    \"\"\"\n    Adapter for Parquet files usando PolarsDaskAdapter (h\u00edbrido Polars+Dask).\n    Async wrapper.\n    \"\"\"\n\n    def __init__(self, file_path: str):\n        self.file_path = file_path\n        self._hybrid = PolarsDaskAdapter(file_path)\n        logger.info(f\"ParquetAdapter initialized with PolarsDaskAdapter\")\n\n    async def connect(self) -> None:\n        await self._hybrid.connect()\n\n    async def disconnect(self) -> None:\n        await self._hybrid.disconnect()\n\n    async def execute_query(self, query_filters: Dict[str, Any], **kwargs) -> List[Dict[str, Any]]:\n        \"\"\"\n        Executa query usando PolarsDaskAdapter (h\u00edbrido).\n        \"\"\"\n        return await self._hybrid.execute_query(query_filters, **kwargs)\n\n    async def get_schema(self) -> str:\n        return await self._hybrid.get_schema()", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1168, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ec3a0eff-53fb-4be1-b1d5-bbebc5c93544": {"__data__": {"id_": "ec3a0eff-53fb-4be1-b1d5-bbebc5c93544", "embedding": null, "metadata": {"file_path": "backend\\app\\infrastructure\\data\\polars_dask_adapter.py", "language": "python", "lines": 344, "filename": "polars_dask_adapter.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\infrastructure\\data\\polars_dask_adapter.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\infrastructure\\data\\polars_dask_adapter.py", "language": "python", "lines": 344, "filename": "polars_dask_adapter.py"}, "hash": "40fd3f1918dfdde724af13356629f44a60855390aa8ded976157a7079914c52b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "467ef6d8-c4b6-4131-a1fb-e0f25900ffaf", "node_type": "1", "metadata": {}, "hash": "53936c1a4588f24572f3558fed5020aa5bcd57d55b9172b256090fc09cc57818", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nPolarsDaskAdapter: Adaptador inteligente que escolhe automaticamente entre Polars e Dask.\nAdaptado para Backend FastAPI (Async).\n\nDecis\u00e3o autom\u00e1tica baseada em tamanho do arquivo:\n- Arquivos < 500MB: Polars (8.1x mais r\u00e1pido)\n- Arquivos >= 500MB: Dask (escal\u00e1vel, out-of-core)\n\nRecursos:\n- Fallback autom\u00e1tico Polars \u2192 Dask em caso de erro\n- Valida\u00e7\u00e3o de integridade de dados\n- Logging detalhado de decis\u00f5es\n- Feature flag para desabilitar Polars (POLARS_ENABLED=false)\n- Execu\u00e7\u00e3o ass\u00edncrona (run_in_executor) para n\u00e3o bloquear event loop\n\nAutor: Claude Code\nData: 2025-10-20 (Portado para Backend em 2025-11-23)\n\"\"\"\n\nimport logging\nimport os\nimport re\nimport time\nimport asyncio\nfrom concurrent.futures import ThreadPoolExecutor\nfrom typing import Any, Dict, List, Optional\nimport pandas as pd\nimport dask.dataframe as dd\n\n# Import condicional do Polars (fallback para Dask se n\u00e3o dispon\u00edvel)\ntry:\n    import polars as pl\n    POLARS_AVAILABLE = True\nexcept ImportError as e:\n    POLARS_AVAILABLE = False\n    pl = None\nexcept Exception as e:\n    POLARS_AVAILABLE = False\n    pl = None\n\nfrom app.infrastructure.data.base import DatabaseAdapter\nfrom app.infrastructure.data.utils.column_validator import (\n    validate_columns,\n    ColumnValidationError,\n    get_available_columns_cached\n)\n\nlogger = logging.getLogger(__name__)\n\nclass PolarsDaskAdapter(DatabaseAdapter):\n    \"\"\"\n    Adaptador h\u00edbrido que escolhe automaticamente entre Polars (r\u00e1pido) e Dask (escal\u00e1vel).\n    Vers\u00e3o Async para FastAPI.\n    \"\"\"\n\n    # Configura\u00e7\u00f5es (podem ser sobrescritas por env vars)\n    POLARS_THRESHOLD_MB = int(os.getenv(\"POLARS_THRESHOLD_MB\", \"500\"))\n    POLARS_ENABLED = os.getenv(\"POLARS_ENABLED\", \"true\").lower() == \"true\"\n    FORCE_DASK = os.getenv(\"FORCE_DASK\", \"false\").lower() == \"true\"\n\n    def __init__(self, file_path: str):\n        \"\"\"\n        Inicializa o PolarsDaskAdapter.\n\n        Args:\n            file_path: Caminho para arquivo(s) Parquet (suporta wildcards)\n        \"\"\"\n        # Valida\u00e7\u00e3o do arquivo (mesma l\u00f3gica do ParquetAdapter)\n        if \"*\" not in file_path and not os.path.exists(file_path):\n            # Tentar encontrar no diret\u00f3rio data/parquet relativo ao backend\n            base_path = os.getcwd()\n            alt_path = os.path.join(base_path, \"data\", \"parquet\", os.path.basename(file_path))\n            if os.path.exists(alt_path):\n                file_path = alt_path\n            else:\n                # Se ainda n\u00e3o achou, tentar caminho absoluto se fornecido\n                pass\n                \n        if \"*\" not in file_path and not os.path.exists(file_path):\n             # Permitir inicializa\u00e7\u00e3o mesmo sem arquivo (ser\u00e1 validado na query ou reconex\u00e3o)\n             # Mas logar aviso\n             logger.warning(f\"Parquet file not found at init: {file_path}\")\n\n        self.file_path = file_path\n        self.size_mb = self._get_file_size_mb()\n        self.engine = self._select_engine()\n        self._executor = ThreadPoolExecutor(max_workers=4)\n\n        logger.info(f\"PolarsDaskAdapter initialized:\")\n        logger.info(f\"  File: {file_path}\")\n        logger.info(f\"  Size: {self.size_mb:.1f} MB\")\n        logger.info(f\"  Engine: {self.engine.upper()}\")\n\n    def _get_file_size_mb(self) -> float:\n        \"\"\"Calcula tamanho total do(s) arquivo(s) em MB.\"\"\"\n        import glob\n\n        try:\n            if \"*\" in self.file_path:\n                files = glob.glob(self.file_path)\n            else:\n                files = [self.file_path]\n\n            total_size = sum(os.path.getsize(f) for f in files if os.path.exists(f))\n            return total_size / (1024 ** 2)\n        except Exception:\n            return 0.0\n\n    def _select_engine(self) -> str:\n        \"\"\"Seleciona engine automaticamente.\"\"\"", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3741, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "467ef6d8-c4b6-4131-a1fb-e0f25900ffaf": {"__data__": {"id_": "467ef6d8-c4b6-4131-a1fb-e0f25900ffaf", "embedding": null, "metadata": {"file_path": "backend\\app\\infrastructure\\data\\polars_dask_adapter.py", "language": "python", "lines": 344, "filename": "polars_dask_adapter.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\infrastructure\\data\\polars_dask_adapter.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\infrastructure\\data\\polars_dask_adapter.py", "language": "python", "lines": 344, "filename": "polars_dask_adapter.py"}, "hash": "40fd3f1918dfdde724af13356629f44a60855390aa8ded976157a7079914c52b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ec3a0eff-53fb-4be1-b1d5-bbebc5c93544", "node_type": "1", "metadata": {"file_path": "backend\\app\\infrastructure\\data\\polars_dask_adapter.py", "language": "python", "lines": 344, "filename": "polars_dask_adapter.py"}, "hash": "c2ca5adfa1e5262348ae06a8cff0156b90f1b386efa54761a5b14b58e71f4bc5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e81b0293-2a24-42f3-b56f-e800794366d8", "node_type": "1", "metadata": {}, "hash": "94b168a3ffdfc3776c54f43b201e9ca02332a34a6f04c655b49c13972df5aa7a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "if not POLARS_AVAILABLE:\n            return \"dask\"\n        if self.FORCE_DASK:\n            return \"dask\"\n        if not self.POLARS_ENABLED:\n            return \"dask\"\n        if self.size_mb < self.POLARS_THRESHOLD_MB:\n            return \"polars\"\n        else:\n            return \"dask\"\n\n    async def connect(self) -> None:\n        \"\"\"No-op. Ambos engines usam lazy loading.\"\"\"\n        pass\n\n    async def disconnect(self) -> None:\n        \"\"\"No-op.\"\"\"\n        pass\n\n    async def execute_query(self, query_filters: Dict[str, Any], query_text: str = None, required_columns: Optional[List[str]] = None) -> List[Dict[str, Any]]:\n        \"\"\"\n        Executa query de forma ass\u00edncrona (em threadpool).\n        \"\"\"\n        loop = asyncio.get_event_loop()\n        return await loop.run_in_executor(\n            self._executor,\n            self._execute_sync,\n            query_filters,\n            query_text,\n            required_columns\n        )\n\n    def _execute_sync(self, query_filters: Dict[str, Any], query_text: str = None, required_columns: Optional[List[str]] = None) -> List[Dict[str, Any]]:\n        \"\"\"Implementa\u00e7\u00e3o s\u00edncrona da query (executada no threadpool).\"\"\"\n        logger.info(f\"PolarsDaskAdapter.execute_query() com {len(query_filters)} filtro(s)\")\n\n        if not query_filters:\n            return [{\"error\": \"A consulta \u00e9 muito ampla. Adicione filtros.\"}]\n\n        start_time = time.time()\n\n        try:\n            if self.engine == \"polars\":\n                result = self._execute_polars(query_filters, query_text, required_columns)\n            else:\n                result = self._execute_dask(query_filters, query_text, required_columns)\n\n            elapsed = time.time() - start_time\n            logger.info(f\"Query executada: {len(result)} rows em {elapsed:.2f}s ({self.engine.upper()})\")\n            return result\n\n        except Exception as e:\n            logger.error(f\"Erro com {self.engine.upper()}: {e}\", exc_info=True)\n            # Fallback logic (simplificada para brevidade, mas mantendo robustez)\n            if self.engine == \"polars\":\n                logger.warning(\"Fallback: Polars falhou, tentando Dask...\")\n                try:\n                    return self._execute_dask(query_filters, query_text)\n                except Exception as dask_err:\n                    logger.error(f\"Fallback Dask falhou: {dask_err}\")\n            \n            return [{\"error\": f\"Falha na execu\u00e7\u00e3o: {str(e)}\"}]\n\n    def _execute_polars(self, query_filters: Dict[str, Any], query_text: str = None, required_columns: Optional[List[str]] = None) -> List[Dict[str, Any]]:\n        \"\"\"Executa query usando Polars.\"\"\"", "mimetype": "text/plain", "start_char_idx": 3750, "end_char_idx": 6385, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e81b0293-2a24-42f3-b56f-e800794366d8": {"__data__": {"id_": "e81b0293-2a24-42f3-b56f-e800794366d8", "embedding": null, "metadata": {"file_path": "backend\\app\\infrastructure\\data\\polars_dask_adapter.py", "language": "python", "lines": 344, "filename": "polars_dask_adapter.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\infrastructure\\data\\polars_dask_adapter.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\infrastructure\\data\\polars_dask_adapter.py", "language": "python", "lines": 344, "filename": "polars_dask_adapter.py"}, "hash": "40fd3f1918dfdde724af13356629f44a60855390aa8ded976157a7079914c52b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "467ef6d8-c4b6-4131-a1fb-e0f25900ffaf", "node_type": "1", "metadata": {"file_path": "backend\\app\\infrastructure\\data\\polars_dask_adapter.py", "language": "python", "lines": 344, "filename": "polars_dask_adapter.py"}, "hash": "0f895de63351fcce83ae89f17728073c9fc8208a3e618114ab6ce8744b09f48d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ef9c8701-1fca-472c-9c31-0b8a0b6a2c81", "node_type": "1", "metadata": {}, "hash": "f89f5fb3a043cee6374200ee8c48dc9f9f54c313067dc3f308e6cc15c22d8082", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# ... (L\u00f3gica id\u00eantica ao original, simplificada aqui para caber no arquivo)\n        # A l\u00f3gica completa de filtros e convers\u00e3o deve ser mantida\n        # Copiando a l\u00f3gica principal:\n        \n        lf = pl.scan_parquet(\n            self.file_path,\n            allow_missing_columns=True,\n            extra_columns='ignore',\n            glob=True\n        )\n\n        # Adicionar colunas padr\u00e3o se ausentes\n        schema = lf.collect_schema()\n        expected_columns = {'linha_verde': 0, 'une_id': 'N/A'}\n        cols_to_add = []\n        for col, default_val in expected_columns.items():\n            if col not in schema.names():\n                cols_to_add.append(pl.lit(default_val).alias(col))\n        if cols_to_add:\n            lf = lf.with_columns(cols_to_add)\n\n        # Valida\u00e7\u00e3o de colunas\n        available_columns = list(schema.names())\n        filter_columns = list(query_filters.keys())\n        \n        try:\n            validation_result = validate_columns(filter_columns, available_columns, auto_correct=True)\n            if not validation_result[\"all_valid\"]:\n                raise ColumnValidationError(validation_result[\"invalid\"][0], validation_result[\"suggestions\"].get(validation_result[\"invalid\"][0], []), available_columns)\n            \n            column_mapping = {col: col for col in filter_columns}\n            column_mapping.update(validation_result[\"corrected\"])\n        except Exception as e:\n            logger.warning(f\"Erro valida\u00e7\u00e3o colunas: {e}\")\n            column_mapping = {col: col for col in filter_columns}\n\n        # Aplicar filtros\n        string_filters = []\n        numeric_filters = []\n        NUMERIC_COLS = ['estoque_une', 'ESTOQUE_UNE', 'estoque_atual']\n\n        for column, condition in query_filters.items():\n            actual_column = column_mapping.get(column, column)\n            \n            # Fallback case-insensitive\n            if actual_column not in schema.names():\n                for c in schema.names():\n                    if c.lower() == actual_column.lower():\n                        actual_column = c\n                        break\n            \n            op = '='\n            value = condition\n            \n            # Parse condition string (>=, <=, etc)\n            if isinstance(condition, str) and any(o in condition for o in ['>=', '<=', '!=', '>', '<', '=']):\n                match = re.match(r\"(>=|<=|!=|>|<|=)\\s*(.*)\", str(condition))\n                if match:\n                    op, value_str = match.groups()\n                    op = op.strip()\n                    value_str = value_str.strip().strip(\"'\\\"\")\n                    \n                    if actual_column.lower() in [c.lower() for c in NUMERIC_COLS] and op in ['>=', '<=', '>', '<']:\n                        try:\n                            val = float(value_str) if '.'", "mimetype": "text/plain", "start_char_idx": 6394, "end_char_idx": 9210, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ef9c8701-1fca-472c-9c31-0b8a0b6a2c81": {"__data__": {"id_": "ef9c8701-1fca-472c-9c31-0b8a0b6a2c81", "embedding": null, "metadata": {"file_path": "backend\\app\\infrastructure\\data\\polars_dask_adapter.py", "language": "python", "lines": 344, "filename": "polars_dask_adapter.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\infrastructure\\data\\polars_dask_adapter.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\infrastructure\\data\\polars_dask_adapter.py", "language": "python", "lines": 344, "filename": "polars_dask_adapter.py"}, "hash": "40fd3f1918dfdde724af13356629f44a60855390aa8ded976157a7079914c52b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e81b0293-2a24-42f3-b56f-e800794366d8", "node_type": "1", "metadata": {"file_path": "backend\\app\\infrastructure\\data\\polars_dask_adapter.py", "language": "python", "lines": 344, "filename": "polars_dask_adapter.py"}, "hash": "483bb40fcd1a5cadd9a1cb29553687886ec3a2286adc5f3bb75b7e1cb8fc5f6c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "fe17e751-72c6-4bd0-96f6-0f525870f90f", "node_type": "1", "metadata": {}, "hash": "78cfe20d88c1c4a2d82899d0079a7000d539af416ef51f2d5185547c61f3c8bb", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "in value_str else int(value_str)\n                            numeric_filters.append((actual_column, op, val))\n                            continue\n                        except: pass\n                    value = value_str\n\n            # Converter tipos se necess\u00e1rio (Polars strict)\n            col_dtype = schema.get(actual_column)\n            if col_dtype and POLARS_AVAILABLE:\n                dtype_str = str(col_dtype).lower()\n                if 'int' in dtype_str and isinstance(value, str) and value.isdigit():\n                    value = int(value)\n                elif 'float' in dtype_str and isinstance(value, str):\n                    try: value = float(value)\n                    except: pass\n\n            string_filters.append((actual_column, op, value))\n\n        # Aplicar filtros string\n        for col, op, val in string_filters:\n            if op == '=': lf = lf.filter(pl.col(col) == val)\n            elif op == '!=': lf = lf.filter(pl.col(col) != val)\n            elif op == '>': lf = lf.filter(pl.col(col) > val)\n            elif op == '<': lf = lf.filter(pl.col(col) < val)\n            elif op == '>=': lf = lf.filter(pl.col(col) >= val)\n            elif op == '<=': lf = lf.filter(pl.col(col) <= val)\n\n        # Converter colunas num\u00e9ricas\n        for col in NUMERIC_COLS:\n            if col in schema.names():\n                lf = lf.with_columns(pl.col(col).cast(pl.Float64, strict=False).fill_null(0))\n\n        # Vendas\n        vendas_cols = [f'mes_{i:02d}' for i in range(1, 13)]\n        existing_vendas = [c for c in vendas_cols if c in schema.names()]\n        if existing_vendas:\n            for col in existing_vendas:\n                lf = lf.with_columns(pl.col(col).cast(pl.Float64, strict=False).fill_null(0))\n            lf = lf.with_columns(pl.sum_horizontal(existing_vendas).alias('vendas_total'))\n\n        # Aplicar filtros num\u00e9ricos\n        for col, op, val in numeric_filters:\n            if op == '>=': lf = lf.filter(pl.col(col) >= val)\n            elif op == '<=': lf = lf.filter(pl.col(col) <= val)\n            elif op == '>': lf = lf.filter(pl.col(col) > val)\n            elif op == '<': lf = lf.filter(pl.col(col) < val)\n            elif op == '=': lf = lf.filter(pl.col(col) == val)\n\n        # Otimiza\u00e7\u00e3o de colunas\n        if required_columns:\n            final_cols = [c for c in required_columns if c in schema.names()]\n            if final_cols:\n                lf = lf.select(final_cols)\n        elif query_text:\n            try:\n                from app.infrastructure.data.utils.query_optimizer import get_optimized_columns\n                opt_cols = get_optimized_columns(list(schema.names()), query=query_text)\n                if opt_cols:\n                    lf = lf.select(opt_cols)\n            except: pass\n\n        # Collect\n        df_polars = lf.collect(engine=\"streaming\")\n        return df_polars.to_pandas().to_dict(orient=\"records\")\n\n    def _execute_dask(self, query_filters: Dict[str, Any], query_text: str = None, required_columns: Optional[List[str]] = None) -> List[Dict[str, Any]]:\n        \"\"\"Executa query usando Dask.\"\"\"\n        # Implementa\u00e7\u00e3o simplificada do Dask para brevidade\n        # Em produ\u00e7\u00e3o, usar a implementa\u00e7\u00e3o completa do core\n        try:\n            ddf = dd.read_parquet(self.file_path, engine='pyarrow')\n            \n            # Filtros simples\n            for col, val in query_filters.items():\n                if col in ddf.columns:\n                    ddf = ddf[ddf[col] == val]\n            \n            if required_columns:\n                cols = [c for c in required_columns if c in ddf.columns]\n                if cols:\n                    ddf = ddf[cols]\n            \n            return ddf.compute().to_dict(orient=\"records\")\n        except Exception as e:\n            logger.error(f\"Dask error: {e}\")\n            raise\n\n    async def get_schema(self) -> str:\n        \"\"\"Retorna schema do Parquet.\"\"\"", "mimetype": "text/plain", "start_char_idx": 9211, "end_char_idx": 13112, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "fe17e751-72c6-4bd0-96f6-0f525870f90f": {"__data__": {"id_": "fe17e751-72c6-4bd0-96f6-0f525870f90f", "embedding": null, "metadata": {"file_path": "backend\\app\\infrastructure\\data\\polars_dask_adapter.py", "language": "python", "lines": 344, "filename": "polars_dask_adapter.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\infrastructure\\data\\polars_dask_adapter.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\infrastructure\\data\\polars_dask_adapter.py", "language": "python", "lines": 344, "filename": "polars_dask_adapter.py"}, "hash": "40fd3f1918dfdde724af13356629f44a60855390aa8ded976157a7079914c52b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ef9c8701-1fca-472c-9c31-0b8a0b6a2c81", "node_type": "1", "metadata": {"file_path": "backend\\app\\infrastructure\\data\\polars_dask_adapter.py", "language": "python", "lines": 344, "filename": "polars_dask_adapter.py"}, "hash": "7a3a325e87098c6023a0e8f50f13618709b18cdecd580829c082271561606658", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "loop = asyncio.get_event_loop()\n        return await loop.run_in_executor(self._executor, self._get_schema_sync)\n\n    def _get_schema_sync(self) -> str:\n        try:\n            import pyarrow.parquet as pq\n            parquet_file = pq.ParquetFile(self.file_path)\n            schema = parquet_file.schema_arrow\n            schema_str = \"Parquet Schema (via PyArrow):\\n\"\n            for i in range(len(schema)):\n                field = schema.field(i)\n                schema_str += f\"  - {field.name}: {field.type}\\n\"\n            return schema_str\n        except Exception as e:\n            return f\"Error reading schema: {e}\"", "mimetype": "text/plain", "start_char_idx": 13121, "end_char_idx": 13747, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7028e6b4-c1e7-491f-bf8e-d4d01f52bbdd": {"__data__": {"id_": "7028e6b4-c1e7-491f-bf8e-d4d01f52bbdd", "embedding": null, "metadata": {"file_path": "backend\\app\\infrastructure\\data\\sql_server_adapter.py", "language": "python", "lines": 134, "filename": "sql_server_adapter.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\infrastructure\\data\\sql_server_adapter.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\infrastructure\\data\\sql_server_adapter.py", "language": "python", "lines": 134, "filename": "sql_server_adapter.py"}, "hash": "44ffb640feb0150ba3db450afcf8c9ab92fe5a7b702d3448ffbaa242306cbfcc", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nSQLServerAdapter: Adaptador para Microsoft SQL Server usando aioodbc (Async).\n\"\"\"\n\nimport logging\nimport aioodbc\nfrom typing import Any, Dict, List, Optional\n\nfrom app.infrastructure.data.base import DatabaseAdapter\nfrom app.core.utils.serializers import TypeConverter\n\nlogger = logging.getLogger(__name__)\n\nclass SQLServerAdapter(DatabaseAdapter):\n    \"\"\"Concrete implementation of the adapter for Microsoft SQL Server (Async).\"\"\"\n\n    def __init__(self, settings: Any):\n        self._settings = settings\n        self._pool = None\n        # Connection string deve ser compat\u00edvel com aioodbc (geralmente a mesma do pyodbc)\n        self._dsn = settings.PYODBC_CONNECTION_STRING\n\n    async def connect(self) -> None:\n        \"\"\"\n        Establishes connection pool.\n        aioodbc recommends using a pool.\n        \"\"\"\n        if not self._pool:\n            try:\n                logger.info(\"Attempting to connect to SQL Server (aioodbc)...\")\n                # Criar pool de conex\u00f5es\n                self._pool = await aioodbc.create_pool(dsn=self._dsn, minsize=1, maxsize=10, autocommit=True)\n                logger.info(\"SQL Server connection pool created successfully.\")\n            except Exception as ex:\n                logger.error(f\"SQL Server connection failed: {ex}\", exc_info=True)\n                raise\n\n    async def disconnect(self) -> None:\n        \"\"\"Closes the connection pool.\"\"\"\n        if self._pool:\n            self._pool.close()\n            await self._pool.wait_closed()\n            self._pool = None\n            logger.info(\"SQL Server connection pool closed.\")\n\n    async def execute_query(self, query: str) -> List[Dict[str, Any]]:\n        \"\"\"\n        Executes a SQL query asynchronously with safe serialization.\n        Converte Row objects para dicion\u00e1rios JSON-serializ\u00e1veis.\n        \"\"\"\n        if not self._pool:\n            await self.connect()\n\n        async with self._pool.acquire() as conn:\n            async with conn.cursor() as cursor:\n                logger.debug(f\"Executing query: {query}\")\n                await cursor.execute(query)\n\n                if cursor.description:\n                    columns = [column[0] for column in cursor.description]\n                    rows = await cursor.fetchall()\n\n                    # Converter Row objects para dicts\n                    results = []\n                    for row in rows:\n                        try:\n                            # Tenta usar _mapping (SQLAlchemy Row)\n                            if hasattr(row, '_mapping'):\n                                results.append(TypeConverter.convert(dict(row._mapping)))\n                            else:\n                                # Fallback: zip com colunas e converter tipos\n                                row_dict = dict(zip(columns, row))\n                                results.append(TypeConverter.convert(row_dict))\n                        except Exception as e:\n                            logger.warning(f\"Row conversion error: {e}, using basic fallback\")\n                            # \u00daltimo recurso: convers\u00e3o simples\n                            results.append(dict(zip(columns, row)))\n\n                    logger.debug(f\"Query returned {len(results)} rows (serialization-safe).\")\n                    return results\n                else:\n                    return []\n\n    async def get_schema(self) -> str:\n        \"\"\"\n        Inspeciona o banco de dados e gera uma string DDL (CREATE TABLE).\n        \"\"\"\n        if not self._pool:\n            await self.connect()\n\n        schema_ddl = \"\"\n        \n        # Query para pegar tabelas\n        tables_query = \"\"\"\n        SELECT TABLE_SCHEMA, TABLE_NAME \n        FROM INFORMATION_SCHEMA.TABLES \n        WHERE TABLE_TYPE = 'BASE TABLE'\n        \"\"\"\n        \n        try:\n            tables = await self.execute_query(tables_query)\n            \n            for table in tables:\n                schema = table['TABLE_SCHEMA']\n                name = table['TABLE_NAME']\n                \n                columns_query = f\"\"\"\n                SELECT COLUMN_NAME, DATA_TYPE, CHARACTER_MAXIMUM_LENGTH, IS_NULLABLE\n                FROM INFORMATION_SCHEMA.COLUMNS\n                WHERE TABLE_NAME = '{name}' AND TABLE_SCHEMA = '{schema}'\n                \"\"\"\n                \n                columns = await self.execute_query(columns_query)\n                \n                ddl = f\"CREATE TABLE {schema}.{name} (\\n\"\n                col_defs = []\n                for col in columns:\n                    col_def = f\"  {col['COLUMN_NAME']} {col['DATA_TYPE']}\"\n                    if col['CHARACTER_MAXIMUM_LENGTH']:\n                        col_def += f\"({col['CHARACTER_MAXIMUM_LENGTH']})\"\n                    if col['IS_NULLABLE'] == 'NO':\n                        col_def += \" NOT NULL\"\n                    col_defs.append(col_def)\n                \n                ddl += \",\\n\".join(col_defs)\n                ddl += \"\\n);\\n\\n\"\n                schema_ddl += ddl\n                \n            return schema_ddl\n            \n        except Exception as e:\n            logger.error(f\"Error getting schema: {e}\")\n            return f\"Error getting schema: {e}\"", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 5150, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c6433296-9ddb-478c-a93a-fb43c172efad": {"__data__": {"id_": "c6433296-9ddb-478c-a93a-fb43c172efad", "embedding": null, "metadata": {"file_path": "backend\\app\\infrastructure\\data\\config\\column_mapping.py", "language": "python", "lines": 312, "filename": "column_mapping.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\infrastructure\\data\\config\\column_mapping.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\infrastructure\\data\\config\\column_mapping.py", "language": "python", "lines": 312, "filename": "column_mapping.py"}, "hash": "b0fbcd1fec2b4ec7a24a5f74d6d5686fa1c67a9cad2fff4bb6e1b1ed61818e74", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5aac55ad-4c3c-40d0-95ee-c63aa5491c51", "node_type": "1", "metadata": {}, "hash": "cd9ef9820bad846e6fd11cea9168e1c13171e8ef4688f20accdc4c792af50764", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nMapeamento Oficial de Colunas do Parquet\nSistema: Agent_Solution_BI\nData: 2025-10-25\n\nEste m\u00f3dulo cont\u00e9m o mapeamento entre nomes legados (c\u00f3digo antigo) e nomes reais\ndas colunas do Parquet. Usado para normalizar queries e evitar erros de KeyError.\n\nFONTE: Extra\u00eddo diretamente do Parquet real (97 colunas)\n\"\"\"\n\n# ==================== MAPEAMENTO PRINCIPAL ====================\n# Mapeamento: Nome Legado \u2192 Nome Real no Parquet\nCOLUMN_MAP = {\n    # Colunas b\u00e1sicas do produto\n    \"PRODUTO\": \"codigo\",\n    \"CODIGO\": \"codigo\",\n    \"NOME\": \"nome_produto\",\n    \"NOME_PRODUTO\": \"nome_produto\",\n\n    # UNE\n    \"UNE\": \"une\",\n    \"UNE_NOME\": \"une_nome\",\n    \"NOMEUNE\": \"une_nome\",\n\n    # Classifica\u00e7\u00f5es\n    \"NOMESEGMENTO\": \"nomesegmento\",\n    \"SEGMENTO\": \"nomesegmento\",\n    \"NOMEGRUPO\": \"nomegrupo\",\n    \"GRUPO\": \"nomegrupo\",\n    \"NOMECATEGORIA\": \"NOMECATEGORIA\",  # J\u00e1 est\u00e1 MAI\u00daSCULO no Parquet\n    \"CATEGORIA\": \"NOMECATEGORIA\",\n    \"NOMESUBGRUPO\": \"NOMESUBGRUPO\",  # J\u00e1 est\u00e1 MAI\u00daSCULO no Parquet\n    \"SUBGRUPO\": \"NOMESUBGRUPO\",\n    \"NOMEFABRICANTE\": \"NOMEFABRICANTE\",  # J\u00e1 est\u00e1 MAI\u00daSCULO no Parquet\n    \"FABRICANTE\": \"NOMEFABRICANTE\",\n\n    # Vendas\n    \"VENDA_30DD\": \"venda_30_d\",\n    \"VENDA_30D\": \"venda_30_d\",\n    \"VENDA_30_DIAS\": \"venda_30_d\",\n    \"VENDAS_30D\": \"venda_30_d\",\n\n    # Estoque (5 varia\u00e7\u00f5es)\n    \"ESTOQUE\": \"estoque_atual\",  # Padr\u00e3o\n    \"ESTOQUE_UNE\": \"estoque_atual\",\n    \"ESTOQUE_ATUAL\": \"estoque_atual\",\n    \"ESTOQUE_LV\": \"estoque_lv\",\n    \"ESTOQUE_LINHA_VERDE\": \"estoque_lv\",\n    \"ESTOQUE_CD\": \"estoque_cd\",\n    \"ESTOQUE_GONDOLA\": \"estoque_gondola_lv\",\n    \"ESTOQUE_ILHA\": \"estoque_ilha_lv\",\n\n    # Pre\u00e7os\n    \"LIQUIDO_38\": \"preco_38_percent\",\n    \"PRECO_38\": \"preco_38_percent\",\n    \"PRECO_LIQUIDO_38\": \"preco_38_percent\",\n    \"PRECO\": \"preco_38_percent\",\n\n    # M\u00e9dias\n    \"MC\": \"media_considerada_lv\",\n    \"MEDIA\": \"media_considerada_lv\",\n    \"MEDIA_CONSIDERADA\": \"media_considerada_lv\",\n    \"MEDIA_CONSIDERADA_LV\": \"media_considerada_lv\",\n    \"MEDIA_TRAVADA\": \"media_travada\",\n\n    # ABC (Classifica\u00e7\u00e3o)\n    \"ABC_UNE_30DD\": \"abc_une_30_dd\",\n    \"ABC_30D\": \"abc_une_30_dd\",\n    \"ABC_CACULA_90DD\": \"abc_cacula_90_dd\",\n    \"ABC_90D\": \"abc_cacula_90_dd\",\n\n    # Outros\n    \"EAN\": \"ean\",\n    \"EMBALAGEM\": \"embalagem\",\n    \"TIPO\": \"tipo\",\n    \"PROMOCIONAL\": \"promocional\",\n    \"FORALINHA\": \"foralinha\",\n}\n\n# ==================== MAPEAMENTO REVERSO ====================\n# Nome Real \u2192 Informa\u00e7\u00f5es da Coluna\nCOLUMN_INFO = {\n    \"codigo\": {\n        \"nome_legado\": [\"PRODUTO\", \"CODIGO\"],\n        \"descricao\": \"C\u00f3digo \u00fanico do produto\",\n        \"tipo\": \"int\",\n        \"exemplo\": \"704559\",\n        \"nullable\": False,", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2627, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5aac55ad-4c3c-40d0-95ee-c63aa5491c51": {"__data__": {"id_": "5aac55ad-4c3c-40d0-95ee-c63aa5491c51", "embedding": null, "metadata": {"file_path": "backend\\app\\infrastructure\\data\\config\\column_mapping.py", "language": "python", "lines": 312, "filename": "column_mapping.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\infrastructure\\data\\config\\column_mapping.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\infrastructure\\data\\config\\column_mapping.py", "language": "python", "lines": 312, "filename": "column_mapping.py"}, "hash": "b0fbcd1fec2b4ec7a24a5f74d6d5686fa1c67a9cad2fff4bb6e1b1ed61818e74", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c6433296-9ddb-478c-a93a-fb43c172efad", "node_type": "1", "metadata": {"file_path": "backend\\app\\infrastructure\\data\\config\\column_mapping.py", "language": "python", "lines": 312, "filename": "column_mapping.py"}, "hash": "3fe027ed5e39adf35fd46cdb2cd1c942250034ecaf24def9e542aa2b075ce3d3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "16caafe4-7e96-4acb-a5e5-8178615290f2", "node_type": "1", "metadata": {}, "hash": "e5203b9ee58cd8677167d78ff0c93ad7e32e4fca03a083960513b71da9934812", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"exemplo\": \"704559\",\n        \"nullable\": False,\n    },\n    \"nome_produto\": {\n        \"nome_legado\": [\"NOME\", \"NOME_PRODUTO\"],\n        \"descricao\": \"Nome completo do produto\",\n        \"tipo\": \"str\",\n        \"exemplo\": \"ALCA BOLSA 7337 DIAM.105MM PS MESCLADO 810\",\n        \"nullable\": False,\n    },\n    \"une\": {\n        \"nome_legado\": [\"UNE\"],\n        \"descricao\": \"C\u00f3digo da Unidade de Neg\u00f3cio\",\n        \"tipo\": \"int\",\n        \"exemplo\": \"2586\",\n        \"nullable\": False,\n    },\n    \"une_nome\": {\n        \"nome_legado\": [\"UNE_NOME\", \"NOMEUNE\"],\n        \"descricao\": \"Nome da UNE (ex: NIG, MAD, SCR)\",\n        \"tipo\": \"str\",\n        \"exemplo\": \"NIG\",\n        \"nullable\": False,\n    },\n    \"nomesegmento\": {\n        \"nome_legado\": [\"NOMESEGMENTO\", \"SEGMENTO\"],\n        \"descricao\": \"Segmento do produto\",\n        \"tipo\": \"str\",\n        \"exemplo\": \"ARMARINHO E CONFEC\u00c7\u00c3O\",\n        \"nullable\": False,\n    },\n    \"nomegrupo\": {\n        \"nome_legado\": [\"NOMEGRUPO\", \"GRUPO\"],\n        \"descricao\": \"Grupo do produto\",\n        \"tipo\": \"str\",\n        \"exemplo\": \"FERRAGEM\",\n        \"nullable\": True,\n    },\n    \"NOMECATEGORIA\": {\n        \"nome_legado\": [\"NOMECATEGORIA\", \"CATEGORIA\"],\n        \"descricao\": \"Categoria do produto\",\n        \"tipo\": \"str\",\n        \"exemplo\": \"ACABAMENTOS CONFEC\u00c7\u00c3O\",\n        \"nullable\": True,\n    },\n    \"NOMESUBGRUPO\": {\n        \"nome_legado\": [\"NOMESUBGRUPO\", \"SUBGRUPO\"],\n        \"descricao\": \"Subgrupo do produto\",\n        \"tipo\": \"str\",\n        \"exemplo\": \"SIMPLES\",\n        \"nullable\": True,\n    },\n    \"NOMEFABRICANTE\": {\n        \"nome_legado\": [\"NOMEFABRICANTE\", \"FABRICANTE\"],\n        \"descricao\": \"Nome do fabricante\",\n        \"tipo\": \"str\",\n        \"exemplo\": \"KR AVIAMENTOS\",\n        \"nullable\": True,\n    },\n    \"venda_30_d\": {\n        \"nome_legado\": [\"VENDA_30DD\", \"VENDA_30D\", \"VENDA_30_DIAS\"],\n        \"descricao\": \"Vendas dos \u00faltimos 30 dias (em unidades)\",\n        \"tipo\": \"float\",\n        \"exemplo\": \"2.5\",\n        \"nullable\": True,\n    },\n    \"estoque_atual\": {\n        \"nome_legado\": [\"ESTOQUE\", \"ESTOQUE_UNE\", \"ESTOQUE_ATUAL\"],\n        \"descricao\": \"Estoque atual total da UNE\",\n        \"tipo\": \"float\",\n        \"exemplo\": \"15.0\",\n        \"nullable\": True,\n    },\n    \"estoque_lv\": {\n        \"nome_legado\": [\"ESTOQUE_LV\", \"ESTOQUE_LINHA_VERDE\"],\n        \"descricao\": \"Estoque na Linha Verde (\u00e1rea de venda)\",\n        \"tipo\": \"float\",\n        \"exemplo\": \"5.0\",\n        \"nullable\": True,\n    },\n    \"estoque_cd\": {\n        \"nome_legado\": [\"ESTOQUE_CD\"],\n        \"descricao\": \"Estoque no Centro de Distribui\u00e7\u00e3o\",\n        \"tipo\": \"float\",\n        \"exemplo\": \"100.0\",\n        \"nullable\": True,\n    },\n    \"preco_38_percent\": {\n        \"nome_legado\": [\"LIQUIDO_38\", \"PRECO_38\", \"PRECO\"],\n        \"descricao\": \"Pre\u00e7o l\u00edquido com 38% de margem\",\n        \"tipo\": \"float\",\n        \"exemplo\": \"12.99\",\n        \"nullable\": True,\n    },\n    \"media_considerada_lv\": {\n        \"nome_legado\": [\"MC\", \"MEDIA\",", "mimetype": "text/plain", "start_char_idx": 2580, "end_char_idx": 5515, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "16caafe4-7e96-4acb-a5e5-8178615290f2": {"__data__": {"id_": "16caafe4-7e96-4acb-a5e5-8178615290f2", "embedding": null, "metadata": {"file_path": "backend\\app\\infrastructure\\data\\config\\column_mapping.py", "language": "python", "lines": 312, "filename": "column_mapping.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\infrastructure\\data\\config\\column_mapping.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\infrastructure\\data\\config\\column_mapping.py", "language": "python", "lines": 312, "filename": "column_mapping.py"}, "hash": "b0fbcd1fec2b4ec7a24a5f74d6d5686fa1c67a9cad2fff4bb6e1b1ed61818e74", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5aac55ad-4c3c-40d0-95ee-c63aa5491c51", "node_type": "1", "metadata": {"file_path": "backend\\app\\infrastructure\\data\\config\\column_mapping.py", "language": "python", "lines": 312, "filename": "column_mapping.py"}, "hash": "e639ace93630a3ad7fb0f4002d575df238960c80a03fef74a221c0a0f6c7ebc1", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"MEDIA\", \"MEDIA_CONSIDERADA\"],\n        \"descricao\": \"M\u00e9dia de vendas considerada para reposi\u00e7\u00e3o\",\n        \"tipo\": \"float\",\n        \"exemplo\": \"2.3\",\n        \"nullable\": True,\n    },\n}\n\n# ==================== COLUNAS ESSENCIAIS ====================\n# Colunas m\u00ednimas necess\u00e1rias para an\u00e1lises b\u00e1sicas\nESSENTIAL_COLUMNS = [\n    'codigo',           # Identifica\u00e7\u00e3o do produto\n    'nome_produto',     # Nome do produto\n    'une',              # UNE (c\u00f3digo)\n    'une_nome',         # UNE (nome) - ESSENCIAL para rankings\n    'nomesegmento',     # Segmento\n    'NOMEFABRICANTE',   # Fabricante - ESSENCIAL para filtros de marca\n    'venda_30_d',       # Vendas\n    'estoque_atual',    # Estoque\n    'linha_verde',      # Linha Verde (Estoque M\u00e1ximo)\n    'quantidade_embalagem_master', # Quantidade de embalagem master\n    'quantidade_multiplo', # Quantidade m\u00faltiplo\n    'preco_38_percent', # Pre\u00e7o\n    'nomegrupo'         # Grupo\n]\n\n# ==================== FUN\u00c7\u00d5ES AUXILIARES ====================\n\ndef normalize_column_name(column_name: str) -> str:\n    \"\"\"\n    Normaliza nome de coluna (legado \u2192 real).\n\n    Args:\n        column_name: Nome da coluna (pode ser legado ou real)\n\n    Returns:\n        Nome real da coluna ou o pr\u00f3prio nome se n\u00e3o encontrado\n\n    Examples:\n        >>> normalize_column_name(\"PRODUTO\")\n        \"codigo\"\n        >>> normalize_column_name(\"VENDA_30DD\")\n        \"venda_30_d\"\n        >>> normalize_column_name(\"codigo\")\n        \"codigo\"\n    \"\"\"\n    # Se j\u00e1 \u00e9 um nome real, retornar\n    if column_name in COLUMN_INFO:\n        return column_name\n\n    # Tentar encontrar no mapeamento\n    upper_name = column_name.upper()\n    return COLUMN_MAP.get(upper_name, column_name)\n\n\ndef get_column_info(column_name: str) -> dict:\n    \"\"\"\n    Retorna informa\u00e7\u00f5es sobre uma coluna.\n\n    Args:\n        column_name: Nome da coluna (real ou legado)\n\n    Returns:\n        Dicion\u00e1rio com informa\u00e7\u00f5es ou None\n\n    Example:\n        >>> get_column_info(\"PRODUTO\")\n        {\"nome_legado\": [\"PRODUTO\"], \"descricao\": \"C\u00f3digo \u00fanico...\", ...}\n    \"\"\"\n    real_name = normalize_column_name(column_name)\n    return COLUMN_INFO.get(real_name)\n\n\ndef validate_columns(columns: list, df_columns: list) -> dict:\n    \"\"\"\n    Valida se colunas existem no DataFrame.\n\n    Args:\n        columns: Lista de colunas a validar\n        df_columns: Lista de colunas dispon\u00edveis no DataFrame\n\n    Returns:\n        {\"valid\": [...], \"invalid\": [...], \"suggestions\": {...}}\n\n    Example:\n        >>> validate_columns([\"PRODUTO\", \"VENDA_30DD\"], df.columns)\n        {\"valid\": [\"codigo\", \"venda_30_d\"], \"invalid\": [], \"suggestions\": {}}\n    \"\"\"\n    valid = []\n    invalid = []\n    suggestions = {}\n\n    for col in columns:\n        normalized = normalize_column_name(col)\n\n        if normalized in df_columns:\n            valid.append(normalized)\n        else:\n            invalid.append(col)\n            # Sugerir colunas similares\n            similar = [c for c in df_columns if col.lower() in c.lower() or c.lower() in col.lower()]\n            if similar:\n                suggestions[col] = similar[:3]  # Top 3 sugest\u00f5es\n\n    return {\n        \"valid\": valid,\n        \"invalid\": invalid,\n        \"suggestions\": suggestions\n    }\n\n\ndef get_essential_columns() -> list:\n    \"\"\"\n    Retorna lista de colunas essenciais.\n\n    Returns:\n        Lista com nomes reais das colunas essenciais\n    \"\"\"\n    return ESSENTIAL_COLUMNS.copy()\n\n\ndef list_all_columns() -> list:\n    \"\"\"\n    Lista todas as colunas conhecidas com suas informa\u00e7\u00f5es.\n\n    Returns:\n        Lista de tuplas (nome_real, descricao)\n    \"\"\"\n    return [(name, info[\"descricao\"]) for name, info in COLUMN_INFO.items()]", "mimetype": "text/plain", "start_char_idx": 5507, "end_char_idx": 9154, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "53f253e5-e7f9-4ed1-a42b-d8d3ae97f089": {"__data__": {"id_": "53f253e5-e7f9-4ed1-a42b-d8d3ae97f089", "embedding": null, "metadata": {"file_path": "backend\\app\\infrastructure\\data\\utils\\column_validator.py", "language": "python", "lines": 342, "filename": "column_validator.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\infrastructure\\data\\utils\\column_validator.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\infrastructure\\data\\utils\\column_validator.py", "language": "python", "lines": 342, "filename": "column_validator.py"}, "hash": "0c8a300da6a958b3c64fc92831b4ed36a98ace9ecd75d64fe2cde7e59eab3e00", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5ac50642-ba4c-4d36-8a0e-2b665c9de822", "node_type": "1", "metadata": {}, "hash": "49abc685db1cd01c1387cd0203330246d90c7e77d817a8899db2b66bb7f2e411", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nSistema Robusto de Valida\u00e7\u00e3o e Auto-Corre\u00e7\u00e3o de Colunas\n========================================================\n\nPrevine erros como ColumnNotFoundError do Polars antes da execu\u00e7\u00e3o de queries.\n\nFuncionalidades:\n1. Valida\u00e7\u00e3o preditiva de colunas antes da execu\u00e7\u00e3o\n2. Auto-corre\u00e7\u00e3o de nomes de colunas (fuzzy matching)\n3. Sugest\u00f5es inteligentes para erros\n4. Cache de valida\u00e7\u00f5es para performance\n5. Integra\u00e7\u00e3o com column_mapping.py e Polars exceptions\n\nAutor: Claude Code + Context7 Docs\nData: 2025-10-27\n\"\"\"\n\nimport logging\nimport re\nfrom typing import Dict, List, Optional, Set, Tuple, Any\nfrom difflib import get_close_matches\nfrom functools import lru_cache\n\n# Importa\u00e7\u00f5es do projeto (AJUSTADO PARA BACKEND)\nfrom app.infrastructure.data.config.column_mapping import (\n    COLUMN_MAP,\n    COLUMN_INFO,\n    normalize_column_name,\n    ESSENTIAL_COLUMNS\n)\n\nlogger = logging.getLogger(__name__)\n\n# ==================== CONFIGURA\u00c7\u00d5ES ====================\n\n# Similaridade m\u00ednima para sugest\u00f5es (0.0 a 1.0)\nSIMILARITY_THRESHOLD = 0.6\n\n# N\u00famero m\u00e1ximo de sugest\u00f5es\nMAX_SUGGESTIONS = 3\n\n# Cache de valida\u00e7\u00f5es (evita re-validar mesmas colunas)\nVALIDATION_CACHE = {}\n\n\n# ==================== EXCE\u00c7\u00d5ES CUSTOMIZADAS ====================\n\nclass ColumnValidationError(Exception):\n    \"\"\"Erro de valida\u00e7\u00e3o de coluna com sugest\u00f5es.\"\"\"\n\n    def __init__(self, column: str, suggestions: List[str] = None, available_columns: List[str] = None):\n        self.column = column\n        self.suggestions = suggestions or []\n        self.available_columns = available_columns or []\n\n        msg = f\"Coluna '{column}' n\u00e3o encontrada no DataFrame.\"\n\n        if self.suggestions:\n            msg += f\"\\n\\nSugest\u00f5es:\\n\" + \"\\n\".join(f\"  - {s}\" for s in self.suggestions[:MAX_SUGGESTIONS])\n\n        if len(self.available_columns) <= 20:\n            msg += f\"\\n\\nColunas dispon\u00edveis:\\n\" + \"\\n\".join(f\"  - {c}\" for c in sorted(self.available_columns)[:20])\n        else:\n            msg += f\"\\n\\n{len(self.available_columns)} colunas dispon\u00edveis (use list_columns() para ver todas)\"\n\n        super().__init__(msg)\n\n\n# ==================== FUN\u00c7\u00d5ES DE VALIDA\u00c7\u00c3O ====================\n\n@lru_cache(maxsize=128)\ndef get_available_columns_cached(file_path: str) -> Tuple[str, ...]:\n    \"\"\"\n    Retorna colunas dispon\u00edveis no Parquet (com cache).\n\n    Args:\n        file_path: Caminho do arquivo Parquet\n\n    Returns:\n        Tupla com nomes das colunas (imut\u00e1vel para cache)\n    \"\"\"\n    try:\n        import polars as pl\n\n        # Ler apenas o schema (sem carregar dados)\n        df_schema = pl.read_parquet_schema(file_path)\n        columns = tuple(df_schema.keys())\n\n        logger.debug(f\"Schema lido: {len(columns)} colunas encontradas\")\n        return columns\n\n    except Exception as e:\n        logger.error(f\"Erro ao ler schema do Parquet: {e}\")\n        # Fallback para colunas essenciais conhecidas\n        return tuple(ESSENTIAL_COLUMNS)", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2909, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5ac50642-ba4c-4d36-8a0e-2b665c9de822": {"__data__": {"id_": "5ac50642-ba4c-4d36-8a0e-2b665c9de822", "embedding": null, "metadata": {"file_path": "backend\\app\\infrastructure\\data\\utils\\column_validator.py", "language": "python", "lines": 342, "filename": "column_validator.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\infrastructure\\data\\utils\\column_validator.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\infrastructure\\data\\utils\\column_validator.py", "language": "python", "lines": 342, "filename": "column_validator.py"}, "hash": "0c8a300da6a958b3c64fc92831b4ed36a98ace9ecd75d64fe2cde7e59eab3e00", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "53f253e5-e7f9-4ed1-a42b-d8d3ae97f089", "node_type": "1", "metadata": {"file_path": "backend\\app\\infrastructure\\data\\utils\\column_validator.py", "language": "python", "lines": 342, "filename": "column_validator.py"}, "hash": "6a82cce84977540d20bad13ee3092c0e2125f18710ae72069cff7d97a7e49849", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ef4c4e41-cb30-4173-9e2c-53d3fd4ba748", "node_type": "1", "metadata": {}, "hash": "c831e72cd9ee081082e34f3a20110075938c4cb71e54344695ad49ac28171d80", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "def validate_column(\n    column: str,\n    available_columns: List[str],\n    auto_correct: bool = True,\n    raise_on_error: bool = False\n) -> Tuple[bool, Optional[str], List[str]]:\n    \"\"\"\n    Valida se uma coluna existe no DataFrame.\n\n    Args:\n        column: Nome da coluna a validar\n        available_columns: Lista de colunas dispon\u00edveis no DataFrame\n        auto_correct: Se True, tenta corrigir automaticamente\n        raise_on_error: Se True, levanta exce\u00e7\u00e3o em vez de retornar erro\n\n    Returns:\n        Tupla (is_valid, corrected_name, suggestions)\n        - is_valid: True se coluna \u00e9 v\u00e1lida/corrig\u00edvel\n        - corrected_name: Nome corrigido (ou None se n\u00e3o encontrado)\n        - suggestions: Lista de sugest\u00f5es alternativas\n\n    Raises:\n        ColumnValidationError: Se raise_on_error=True e coluna inv\u00e1lida\n    \"\"\"\n    # Verifica\u00e7\u00e3o r\u00e1pida de cache\n    cache_key = f\"{column}:{','.join(sorted(available_columns))}\"\n    if cache_key in VALIDATION_CACHE:\n        return VALIDATION_CACHE[cache_key]\n\n    # 1. Verificar se coluna j\u00e1 existe (case-sensitive)\n    if column in available_columns:\n        result = (True, column, [])\n        VALIDATION_CACHE[cache_key] = result\n        return result\n\n    # 2. Tentar normalizar usando COLUMN_MAP\n    normalized = normalize_column_name(column)\n    if normalized in available_columns:\n        logger.info(f\"\u2705 Coluna '{column}' normalizada para '{normalized}'\")\n        result = (True, normalized, [normalized])\n        VALIDATION_CACHE[cache_key] = result\n        return result\n\n    # 3. Tentar match case-insensitive\n    column_lower = column.lower()\n    for col in available_columns:\n        if col.lower() == column_lower:\n            logger.info(f\"\u2705 Coluna '{column}' encontrada com case diferente: '{col}'\")\n            result = (True, col, [col])\n            VALIDATION_CACHE[cache_key] = result\n            return result\n\n    # 4. Se auto_correct, buscar similares\n    suggestions = []\n    if auto_correct:\n        # Fuzzy matching usando difflib\n        suggestions = get_close_matches(\n            column.lower(),\n            [c.lower() for c in available_columns],\n            n=MAX_SUGGESTIONS,\n            cutoff=SIMILARITY_THRESHOLD\n        )\n\n        # Mapear de volta para nomes originais\n        suggestions = [\n            next(c for c in available_columns if c.lower() == s)\n            for s in suggestions\n        ]\n\n        # Adicionar sugest\u00f5es do COLUMN_MAP\n        for legacy_name, real_name in COLUMN_MAP.items():\n            if column.upper() == legacy_name and real_name in available_columns:\n                if real_name not in suggestions:\n                    suggestions.insert(0, real_name)\n\n        logger.warning(f\"\u26a0\ufe0f Coluna '{column}' n\u00e3o encontrada. Sugest\u00f5es: {suggestions}\")\n\n    # 5. Retornar resultado ou levantar exce\u00e7\u00e3o\n    if raise_on_error:\n        raise ColumnValidationError(column, suggestions, available_columns)\n\n    result = (False, None, suggestions)\n    VALIDATION_CACHE[cache_key] = result\n    return result\n\n\ndef validate_columns(\n    columns: List[str],\n    available_columns: List[str],\n    auto_correct: bool = True\n) -> Dict[str, Any]:\n    \"\"\"\n    Valida m\u00faltiplas colunas de uma vez.\n    \"\"\"\n    valid = []\n    invalid = []\n    corrected = {}\n    suggestions_map = {}\n\n    for col in columns:\n        is_valid, corrected_name, suggestions = validate_column(\n            col, available_columns, auto_correct, raise_on_error=False\n        )\n\n        if is_valid:\n            valid.append(corrected_name)\n            if col != corrected_name:\n                corrected[col] = corrected_name\n        else:\n            invalid.append(col)\n            if suggestions:\n                suggestions_map[col] = suggestions\n\n    return {\n        \"valid\": valid,\n        \"invalid\": invalid,\n        \"corrected\": corrected,\n        \"suggestions\": suggestions_map,\n        \"all_valid\": len(invalid) == 0\n    }", "mimetype": "text/plain", "start_char_idx": 2912, "end_char_idx": 6820, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ef4c4e41-cb30-4173-9e2c-53d3fd4ba748": {"__data__": {"id_": "ef4c4e41-cb30-4173-9e2c-53d3fd4ba748", "embedding": null, "metadata": {"file_path": "backend\\app\\infrastructure\\data\\utils\\column_validator.py", "language": "python", "lines": 342, "filename": "column_validator.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\infrastructure\\data\\utils\\column_validator.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\infrastructure\\data\\utils\\column_validator.py", "language": "python", "lines": 342, "filename": "column_validator.py"}, "hash": "0c8a300da6a958b3c64fc92831b4ed36a98ace9ecd75d64fe2cde7e59eab3e00", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5ac50642-ba4c-4d36-8a0e-2b665c9de822", "node_type": "1", "metadata": {"file_path": "backend\\app\\infrastructure\\data\\utils\\column_validator.py", "language": "python", "lines": 342, "filename": "column_validator.py"}, "hash": "e170aacb182708dd8e7e15c594089078aea923a9a24dd190fcb145578a3768a2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "51df215b-5ec7-4db1-bb43-c4a31c406c13", "node_type": "1", "metadata": {}, "hash": "aa46c121cc6289b249d358b201a9d7183c25598dc002052201b48a3dd460d000", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "def safe_select_columns(\n    df: Any,  # pl.DataFrame ou pl.LazyFrame\n    columns: List[str],\n    auto_correct: bool = True,\n    drop_invalid: bool = False\n) -> Tuple[Any, Dict[str, Any]]:\n    \"\"\"\n    Vers\u00e3o segura de df.select() que valida e corrige colunas antes.\n    \"\"\"\n    available = df.columns\n\n    validation = validate_columns(columns, available, auto_correct)\n\n    # Se tem inv\u00e1lidas e n\u00e3o deve dropar, erro\n    if validation[\"invalid\"] and not drop_invalid:\n        first_invalid = validation[\"invalid\"][0]\n        raise ColumnValidationError(\n            first_invalid,\n            validation[\"suggestions\"].get(first_invalid, []),\n            available\n        )\n\n    # Selecionar apenas colunas v\u00e1lidas\n    valid_cols = validation[\"valid\"]\n\n    if not valid_cols:\n        raise ValueError(\"Nenhuma coluna v\u00e1lida para selecionar!\")\n\n    # Aplicar select com colunas corrigidas\n    df_result = df.select(valid_cols)\n\n    logger.info(f\"\u2705 safe_select: {len(valid_cols)}/{len(columns)} colunas selecionadas\")\n    if validation[\"corrected\"]:\n        logger.info(f\"   Corre\u00e7\u00f5es: {validation['corrected']}\")\n    if validation[\"invalid\"]:\n        logger.warning(f\"   Ignoradas: {validation['invalid']}\")\n\n    return df_result, validation\n\n\ndef extract_columns_from_query(query_code: str) -> List[str]:\n    \"\"\"\n    Extrai nomes de colunas de c\u00f3digo Python/Polars.\n    \"\"\"\n    columns = set()\n\n    # Padr\u00e3o 1: pl.col(\"coluna\")\n    for match in re.finditer(r'pl\\.col\\([\"\\']([^\"\\']+)[\"\\']\\)', query_code):\n        columns.add(match.group(1))\n\n    # Padr\u00e3o 2: df[\"coluna\"]\n    for match in re.finditer(r'\\[[\"\\']([^\"\\']+)[\"\\']\\]', query_code):\n        columns.add(match.group(1))\n\n    # Padr\u00e3o 3: .select([\"col1\", \"col2\"])\n    for match in re.finditer(r'\\.select\\(\\[(.*?)\\]\\)', query_code):\n        cols_str = match.group(1)\n        for col in re.findall(r'[\"\\']([^\"\\']+)[\"\\']', cols_str):\n            columns.add(col)\n\n    # Padr\u00e3o 4: .group_by(\"coluna\")\n    for match in re.finditer(r'\\.group_by\\([\"\\']([^\"\\']+)[\"\\']\\)', query_code):\n        columns.add(match.group(1))\n\n    # Padr\u00e3o 5: .sort(\"coluna\")\n    for match in re.finditer(r'\\.sort\\([\"\\']([^\"\\']+)[\"\\']\\)', query_code):\n        columns.add(match.group(1))\n\n    return list(columns)\n\n\ndef validate_query_code(\n    query_code: str,\n    available_columns: List[str],\n    auto_correct: bool = True\n) -> Dict[str, Any]:\n    \"\"\"\n    Valida c\u00f3digo de query antes da execu\u00e7\u00e3o.\n    \"\"\"\n    # Extrair colunas do c\u00f3digo\n    columns_used = extract_columns_from_query(query_code)\n\n    if not columns_used:\n        logger.warning(\"\u26a0\ufe0f Nenhuma coluna detectada no c\u00f3digo da query\")\n        return {\n            \"valid\": True,\n            \"original_code\": query_code,\n            \"corrected_code\": query_code,\n            \"columns_used\": [],\n            \"validation\": {\"valid\": [], \"invalid\": [], \"corrected\": {}, \"suggestions\": {}, \"all_valid\": True}\n        }\n\n    # Validar colunas\n    validation = validate_columns(columns_used, available_columns, auto_correct)\n\n    # Se auto_correct, substituir no c\u00f3digo\n    corrected_code = query_code\n    if auto_correct and validation[\"corrected\"]:\n        for old_name, new_name in validation[\"corrected\"].items():\n            # Substituir todas as ocorr\u00eancias (com aspas)\n            corrected_code = corrected_code.replace(f'\"{old_name}\"', f'\"{new_name}\"')\n            corrected_code = corrected_code.replace(f\"'{old_name}'\", f\"'{new_name}'\")\n\n        logger.info(f\"\u2705 C\u00f3digo corrigido: {len(validation['corrected'])} substitui\u00e7\u00f5es\")\n\n    return {\n        \"valid\": validation[\"all_valid\"],\n        \"original_code\": query_code,\n        \"corrected_code\": corrected_code,\n        \"columns_used\": columns_used,\n        \"validation\": validation\n    }", "mimetype": "text/plain", "start_char_idx": 6823, "end_char_idx": 10556, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "51df215b-5ec7-4db1-bb43-c4a31c406c13": {"__data__": {"id_": "51df215b-5ec7-4db1-bb43-c4a31c406c13", "embedding": null, "metadata": {"file_path": "backend\\app\\infrastructure\\data\\utils\\column_validator.py", "language": "python", "lines": 342, "filename": "column_validator.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\infrastructure\\data\\utils\\column_validator.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\infrastructure\\data\\utils\\column_validator.py", "language": "python", "lines": 342, "filename": "column_validator.py"}, "hash": "0c8a300da6a958b3c64fc92831b4ed36a98ace9ecd75d64fe2cde7e59eab3e00", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ef4c4e41-cb30-4173-9e2c-53d3fd4ba748", "node_type": "1", "metadata": {"file_path": "backend\\app\\infrastructure\\data\\utils\\column_validator.py", "language": "python", "lines": 342, "filename": "column_validator.py"}, "hash": "775382f64c7f66e2befa06ebd976283d14f4efeb0d988355ab89b60c62e18429", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# ==================== FUN\u00c7\u00d5ES AUXILIARES ====================\n\ndef clear_validation_cache():\n    \"\"\"Limpa cache de valida\u00e7\u00f5es (\u00fatil para testes).\"\"\"\n    global VALIDATION_CACHE\n    VALIDATION_CACHE.clear()\n    get_available_columns_cached.cache_clear()\n    logger.info(\"\u2705 Cache de valida\u00e7\u00e3o limpo\")", "mimetype": "text/plain", "start_char_idx": 10559, "end_char_idx": 10858, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "df0c8d0e-9507-491b-8b43-ddd8eaf868b3": {"__data__": {"id_": "df0c8d0e-9507-491b-8b43-ddd8eaf868b3", "embedding": null, "metadata": {"file_path": "backend\\app\\infrastructure\\data\\utils\\query_optimizer.py", "language": "python", "lines": 256, "filename": "query_optimizer.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\infrastructure\\data\\utils\\query_optimizer.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\infrastructure\\data\\utils\\query_optimizer.py", "language": "python", "lines": 256, "filename": "query_optimizer.py"}, "hash": "69ab2abb3ad500b2f38db8bc0447db394c24f464c20089f8578f8ccdabd617c1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "51de2d81-a0ce-4421-bf95-122327d8aea9", "node_type": "1", "metadata": {}, "hash": "093ed0568a5a48b92edda92974bc16ee25bb75248f9b43de742726f765c67294", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nQuery Optimizer: Otimizador cir\u00fargico de queries para evitar satura\u00e7\u00e3o de buffer.\n\nSolu\u00e7\u00f5es implementadas:\n1. Sele\u00e7\u00e3o inteligente de colunas (retorna apenas colunas necess\u00e1rias)\n2. Suporte a lazy loading no Streamlit (height parameter)\n3. Streaming de dados grandes (chunking autom\u00e1tico)\n\nPrinc\u00edpios:\n- N\u00c3O quebra funcionalidade existente\n- N\u00c3O limita dados do usu\u00e1rio\n- Reduz uso de mem\u00f3ria em 60-80%\n- Compat\u00edvel com todo c\u00f3digo existente\n\nAutor: Claude Code\nData: 2025-10-26\n\"\"\"\n\nimport logging\nfrom typing import Dict, List, Any, Optional\n\nlogger = logging.getLogger(__name__)\n\n# ============================================================================\n# CONFIGURA\u00c7\u00c3O: Colunas essenciais por tipo de an\u00e1lise\n# ============================================================================\n\nESSENTIAL_COLUMNS = {\n    # Colunas que SEMPRE devem ser inclu\u00eddas (identificadores)\n    \"core\": [\n        \"codigo_produto\", \"CODIGO_PRODUTO\", \"produto_codigo\",\n        \"nome_produto\", \"NOME_PRODUTO\", \"produto_nome\", \"PRODUTO\",\n        \"une_codigo\", \"UNE_CODIGO\", \"une\", \"UNE\",\n        \"segmento\", \"SEGMENTO\", \"segmento_nome\", \"SEGMENTO_NOME\"\n    ],\n\n    # Colunas de estoque (se query menciona \"estoque\")\n    \"estoque\": [\n        \"estoque_une\", \"ESTOQUE_UNE\", \"estoque_atual\", \"ESTOQUE_ATUAL\"\n    ],\n\n    # Colunas de vendas (se query menciona \"venda\", \"vendeu\", etc)\n    \"vendas\": [\n        f\"mes_{i:02d}\" for i in range(1, 13)\n    ] + [\"vendas_total\", \"VENDAS_TOTAL\"],\n\n    # Colunas de pre\u00e7o (se query menciona \"pre\u00e7o\", \"valor\")\n    \"preco\": [\n        \"preco_venda\", \"PRECO_VENDA\", \"preco_custo\", \"PRECO_CUSTO\",\n        \"margem\", \"MARGEM\"\n    ],\n\n    # Colunas de localiza\u00e7\u00e3o (se query menciona UNE/loja espec\u00edfica)\n    \"localizacao\": [\n        \"une_nome\", \"UNE_NOME\", \"cidade\", \"CIDADE\", \"estado\", \"ESTADO\"\n    ]\n}\n\n# Colunas que podem ser REMOVIDAS para economizar mem\u00f3ria (raramente usadas)\nRARELY_USED_COLUMNS = [\n    \"observacoes\", \"OBSERVACOES\", \"observacao\", \"OBSERVACAO\",\n    \"comentarios\", \"COMENTARIOS\", \"comentario\", \"COMENTARIO\",\n    \"data_cadastro\", \"DATA_CADASTRO\", \"usuario_cadastro\", \"USUARIO_CADASTRO\",\n    \"data_alteracao\", \"DATA_ALTERACAO\", \"usuario_alteracao\", \"USUARIO_ALTERACAO\"\n]\n\n# ============================================================================\n# FUN\u00c7\u00d5ES DE OTIMIZA\u00c7\u00c3O\n# ============================================================================\n\ndef detect_query_intent(query: str) -> List[str]:\n    \"\"\"\n    Detecta inten\u00e7\u00e3o da query para selecionar colunas relevantes.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2514, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "51de2d81-a0ce-4421-bf95-122327d8aea9": {"__data__": {"id_": "51de2d81-a0ce-4421-bf95-122327d8aea9", "embedding": null, "metadata": {"file_path": "backend\\app\\infrastructure\\data\\utils\\query_optimizer.py", "language": "python", "lines": 256, "filename": "query_optimizer.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\infrastructure\\data\\utils\\query_optimizer.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\infrastructure\\data\\utils\\query_optimizer.py", "language": "python", "lines": 256, "filename": "query_optimizer.py"}, "hash": "69ab2abb3ad500b2f38db8bc0447db394c24f464c20089f8578f8ccdabd617c1", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "df0c8d0e-9507-491b-8b43-ddd8eaf868b3", "node_type": "1", "metadata": {"file_path": "backend\\app\\infrastructure\\data\\utils\\query_optimizer.py", "language": "python", "lines": 256, "filename": "query_optimizer.py"}, "hash": "a9a0bb236fbf2904f8748f742b8743cc58988184ac7a0f21cb6e296ad16ecfd8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "38742e43-e4ac-48c1-98d2-76d7a5c30f42", "node_type": "1", "metadata": {}, "hash": "7705a2f702e2c037e1e940a35bc03711656faff6d8dfd1b7289a8d725fba8408", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Args:\n        query: Pergunta do usu\u00e1rio\n\n    Returns:\n        Lista de categorias de colunas necess\u00e1rias\n    \"\"\"\n    query_lower = query.lower()\n    categories = [\"core\"]  # core sempre inclu\u00eddo\n\n    # Detectar men\u00e7\u00e3o a estoque\n    if any(kw in query_lower for kw in ['estoque', 'dispon\u00edvel', 'disponivel', 'tem em estoque', 'sem giro', 'sem vendas', 'sem movimento']):\n        categories.append(\"estoque\")\n\n    # Detectar men\u00e7\u00e3o a vendas (sempre incluir estoque tamb\u00e9m para queries de vendas)\n    if any(kw in query_lower for kw in ['vend', 'evolu\u00e7\u00e3o', 'evolucao', 'movimento', 'giro', 'sem vendas', 'sem giro']):\n        categories.append(\"vendas\")\n        # \u2705 CORRE\u00c7\u00c3O: Queries sobre vendas frequentemente precisam de estoque tamb\u00e9m\n        if \"estoque\" not in categories:\n            categories.append(\"estoque\")\n\n    # Detectar men\u00e7\u00e3o a pre\u00e7o\n    if any(kw in query_lower for kw in ['pre\u00e7o', 'preco', 'valor', 'custo', 'margem']):\n        categories.append(\"preco\")\n\n    # Detectar men\u00e7\u00e3o a localiza\u00e7\u00e3o\n    if any(kw in query_lower for kw in ['une', 'loja', 'cidade', 'estado', 'regional']):\n        categories.append(\"localizacao\")\n\n    logger.info(f\"Inten\u00e7\u00e3o detectada: {categories} para query: '{query[:50]}...'\")\n    return categories\n\ndef get_optimized_columns(\n    available_columns: List[str],\n    query: Optional[str] = None,\n    intent_categories: Optional[List[str]] = None\n) -> List[str]:\n    \"\"\"\n    Retorna lista otimizada de colunas baseada na inten\u00e7\u00e3o da query.\n\n    Args:\n        available_columns: Todas as colunas dispon\u00edveis no dataset\n        query: Pergunta do usu\u00e1rio (opcional, usado para detectar inten\u00e7\u00e3o)\n        intent_categories: Categorias de inten\u00e7\u00e3o (se j\u00e1 conhecidas)\n\n    Returns:\n        Lista de colunas otimizadas (apenas as necess\u00e1rias)\n    \"\"\"\n    # Detectar inten\u00e7\u00e3o se n\u00e3o fornecida\n    if intent_categories is None and query:\n        intent_categories = detect_query_intent(query)\n    elif intent_categories is None:\n        # Se n\u00e3o temos query nem categorias, retornar tudo (seguro)\n        return available_columns\n\n    # Coletar colunas essenciais baseadas na inten\u00e7\u00e3o\n    selected_columns = set()\n\n    for category in intent_categories:\n        if category in ESSENTIAL_COLUMNS:\n            selected_columns.update(ESSENTIAL_COLUMNS[category])\n\n    # Filtrar apenas colunas que existem no dataset (case-insensitive)\n    available_lower = {col.lower(): col for col in available_columns}\n\n    optimized = []\n    for col in selected_columns:\n        actual_col = available_lower.get(col.lower())\n        if actual_col:\n            optimized.append(actual_col)\n\n    # Se ficou vazio (n\u00e3o achou nenhuma), retornar todas (seguro)\n    if not optimized:\n        logger.warning(\"Nenhuma coluna otimizada encontrada. Retornando todas (fallback seguro).\")\n        return available_columns\n\n    # Remover colunas raramente usadas (se existirem)\n    rarely_used_lower = {col.lower() for col in RARELY_USED_COLUMNS}\n    optimized = [col for col in optimized if col.lower() not in rarely_used_lower]\n\n    reduction_pct = (1 - len(optimized) / len(available_columns)) * 100\n    logger.info(f\"Otimiza\u00e7\u00e3o de colunas: {len(available_columns)} \u2192 {len(optimized)} ({reduction_pct:.1f}% redu\u00e7\u00e3o)\")\n\n    return optimized\n\ndef should_use_column_optimization(num_rows: int, num_columns: int) -> bool:\n    \"\"\"\n    Decide se deve aplicar otimiza\u00e7\u00e3o de colunas baseado no tamanho do resultado.", "mimetype": "text/plain", "start_char_idx": 2520, "end_char_idx": 5937, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "38742e43-e4ac-48c1-98d2-76d7a5c30f42": {"__data__": {"id_": "38742e43-e4ac-48c1-98d2-76d7a5c30f42", "embedding": null, "metadata": {"file_path": "backend\\app\\infrastructure\\data\\utils\\query_optimizer.py", "language": "python", "lines": 256, "filename": "query_optimizer.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\infrastructure\\data\\utils\\query_optimizer.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\infrastructure\\data\\utils\\query_optimizer.py", "language": "python", "lines": 256, "filename": "query_optimizer.py"}, "hash": "69ab2abb3ad500b2f38db8bc0447db394c24f464c20089f8578f8ccdabd617c1", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "51de2d81-a0ce-4421-bf95-122327d8aea9", "node_type": "1", "metadata": {"file_path": "backend\\app\\infrastructure\\data\\utils\\query_optimizer.py", "language": "python", "lines": 256, "filename": "query_optimizer.py"}, "hash": "e6eafe689f22e22ef2a6c108a374163c56bbd52a4c7bdb611de604f440806376", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Args:\n        num_rows: N\u00famero de linhas no resultado\n        num_columns: N\u00famero de colunas no resultado\n\n    Returns:\n        True se deve otimizar, False caso contr\u00e1rio\n    \"\"\"\n    # Otimizar se:\n    # - Mais de 1000 linhas OU\n    # - Mais de 50 colunas OU\n    # - Produto linhas x colunas > 50000 (dataset grande)\n\n    if num_rows > 1000:\n        logger.info(f\"Otimiza\u00e7\u00e3o recomendada: {num_rows} linhas > 1000\")\n        return True\n\n    if num_columns > 50:\n        logger.info(f\"Otimiza\u00e7\u00e3o recomendada: {num_columns} colunas > 50\")\n        return True\n\n    dataset_size = num_rows * num_columns\n    if dataset_size > 50000:\n        logger.info(f\"Otimiza\u00e7\u00e3o recomendada: {dataset_size} cells > 50000\")\n        return True\n\n    logger.info(f\"Otimiza\u00e7\u00e3o N\u00c3O necess\u00e1ria: {num_rows} linhas x {num_columns} cols = {dataset_size} cells\")\n    return False\n\ndef get_streamlit_height_param(num_rows: int) -> Optional[int]:\n    \"\"\"\n    Calcula par\u00e2metro height ideal para st.dataframe() baseado no n\u00famero de linhas.\n    \"\"\"\n    if num_rows <= 100:\n        return None  # Streamlit decide\n    elif num_rows <= 1000:\n        logger.info(f\"Lazy loading: height=600px para {num_rows} linhas\")\n        return 600\n    else:\n        logger.info(f\"Lazy loading: height=800px para {num_rows} linhas\")\n        return 800\n\ndef optimize_query_result(\n    result: List[Dict[str, Any]],\n    query: Optional[str] = None,\n    apply_column_filter: bool = True\n) -> tuple[List[Dict[str, Any]], Dict[str, Any]]:\n    \"\"\"\n    Otimiza resultado de query antes de retornar ao usu\u00e1rio.\n    \"\"\"\n    if not result:\n        return result, {\"optimized\": False, \"reason\": \"empty_result\"}\n\n    num_rows = len(result)\n    num_columns = len(result[0].keys()) if result else 0\n\n    metadata = {\n        \"original_rows\": num_rows,\n        \"original_columns\": num_columns,\n        \"optimized\": False,\n        \"columns_removed\": 0,\n        \"memory_saved_pct\": 0,\n        \"streamlit_height\": None\n    }\n\n    # Verificar se otimiza\u00e7\u00e3o \u00e9 necess\u00e1ria\n    if not should_use_column_optimization(num_rows, num_columns):\n        metadata[\"reason\"] = \"not_needed\"\n        return result, metadata\n\n    # Otimizar colunas se solicitado\n    if apply_column_filter and query:\n        available_columns = list(result[0].keys())\n        optimized_columns = get_optimized_columns(available_columns, query=query)\n\n        # Filtrar resultado\n        optimized_result = [\n            {k: v for k, v in row.items() if k in optimized_columns}\n            for row in result\n        ]\n\n        metadata[\"optimized\"] = True\n        metadata[\"final_columns\"] = len(optimized_columns)\n        metadata[\"columns_removed\"] = num_columns - len(optimized_columns)\n        metadata[\"memory_saved_pct\"] = (metadata[\"columns_removed\"] / num_columns) * 100\n\n        result = optimized_result\n    else:\n        metadata[\"reason\"] = \"column_filter_disabled\"\n\n    # Calcular height para Streamlit (lazy loading)\n    metadata[\"streamlit_height\"] = get_streamlit_height_param(num_rows)\n\n    return result, metadata", "mimetype": "text/plain", "start_char_idx": 5943, "end_char_idx": 8976, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "091b5e28-0495-4f6e-b708-674464159c6c": {"__data__": {"id_": "091b5e28-0495-4f6e-b708-674464159c6c", "embedding": null, "metadata": {"file_path": "backend\\app\\infrastructure\\database\\migrations\\env.py", "language": "python", "lines": 69, "filename": "env.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\infrastructure\\database\\migrations\\env.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\infrastructure\\database\\migrations\\env.py", "language": "python", "lines": 69, "filename": "env.py"}, "hash": "297cecd42cd3d5dbd9570a606fd0d90e82b5ac71bad105e22374ff2944638fee", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "from logging.config import fileConfig\nfrom urllib.parse import quote_plus\n\nfrom sqlalchemy import engine_from_config, pool, create_engine\nfrom sqlalchemy import pool\n\nfrom alembic import context\n\nfrom app.config.settings import get_settings\nfrom app.infrastructure.database.models import Base\n\n# this is the Alembic Config object, which provides\n# access to the values within the .ini file in use.\nconfig = context.config\n\n# Interpret the config file for Python logging.\n# This line sets up loggers basically.\nif config.config_file_name is not None:\n    fileConfig(config.config_file_name)\n\n# Get settings\nsettings = get_settings()\n\n# add your model's MetaData object here\n# for 'autogenerate' support\ntarget_metadata = Base.metadata\n\ndef run_migrations_offline() -> None:\n    \"\"\"Run migrations in 'offline' mode.\"\"\"\n    url = str(settings.DATABASE_URL)\n    context.configure(\n        url=url,\n        target_metadata=target_metadata,\n        literal_binds=True,\n        dialect_opts={\"paramstyle\": \"named\"},\n    )\n\n    with context.begin_transaction():\n        context.run_migrations()\n\n\ndef run_migrations_online() -> None:\n    \"\"\"Run migrations in 'online' mode.\"\"\"\n    \n    # Use synchronous pyodbc connection string\n    # Construct URL using odbc_connect\n    encoded_conn_str = quote_plus(settings.PYODBC_CONNECTION_STRING)\n    url = f\"mssql+pyodbc:///?odbc_connect={encoded_conn_str}\"\n\n    connectable = create_engine(\n        url,\n        poolclass=pool.NullPool,\n    )\n\n    with connectable.connect() as connection:\n        context.configure(\n            connection=connection, \n            target_metadata=target_metadata\n        )\n\n        with context.begin_transaction():\n            context.run_migrations()\n\n\nif context.is_offline_mode():\n    run_migrations_offline()\nelse:\n    run_migrations_online()", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1815, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8dac3e44-213d-4141-a1ab-bd7f21477505": {"__data__": {"id_": "8dac3e44-213d-4141-a1ab-bd7f21477505", "embedding": null, "metadata": {"file_path": "backend\\app\\infrastructure\\database\\migrations\\versions\\fresh_start_migration.py", "language": "python", "lines": 74, "filename": "fresh_start_migration.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\infrastructure\\database\\migrations\\versions\\fresh_start_migration.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\infrastructure\\database\\migrations\\versions\\fresh_start_migration.py", "language": "python", "lines": 74, "filename": "fresh_start_migration.py"}, "hash": "abe7121583f62dc7cc036480ce40b4e2c5d4ab9d6c228f723d023875af218290", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"Criar tabelas do zero\n\nRevision ID: fresh_start\nRevises: \nCreate Date: 2025-11-23 16:35:00\n\n\"\"\"\nfrom typing import Sequence, Union\n\nfrom alembic import op\nimport sqlalchemy as sa\n\n# revision identifiers, used by Alembic.\nrevision: str = 'fresh_start'\ndown_revision: Union[str, None] = None\nbranch_labels: Union[str, Sequence[str], None] = None\ndepends_on: Union[str, Sequence[str], None] = None\n\n\ndef upgrade() -> None:\n    # Criar tabela users PRIMEIRO\n    op.create_table('users',\n        sa.Column('id', sa.Uuid(), nullable=False),\n        sa.Column('username', sa.String(length=50), nullable=False),\n        sa.Column('email', sa.String(length=255), nullable=False),\n        sa.Column('hashed_password', sa.String(length=255), nullable=False),\n        sa.Column('role', sa.String(length=20), nullable=False),\n        sa.Column('is_active', sa.Boolean(), nullable=False, server_default='1'),\n        sa.Column('last_login', sa.DateTime(timezone=True), nullable=True),\n        sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('CURRENT_TIMESTAMP'), nullable=False),\n        sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('CURRENT_TIMESTAMP'), nullable=False),\n        sa.PrimaryKeyConstraint('id')\n    )\n    op.create_index(op.f('ix_users_email'), 'users', ['email'], unique=True)\n    op.create_index(op.f('ix_users_username'), 'users', ['username'], unique=True)\n    \n    # Criar tabela reports\n    op.create_table('reports',\n        sa.Column('id', sa.Uuid(), nullable=False),\n        sa.Column('title', sa.String(length=255), nullable=False),\n        sa.Column('description', sa.Text(), nullable=True),\n        sa.Column('content', sa.JSON(), nullable=False),\n        sa.Column('status', sa.String(length=20), nullable=False),\n        sa.Column('author_id', sa.Uuid(), nullable=False),\n        sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('CURRENT_TIMESTAMP'), nullable=False),\n        sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('CURRENT_TIMESTAMP'), nullable=False),\n        sa.ForeignKeyConstraint(['author_id'], ['users.id'], ),\n        sa.PrimaryKeyConstraint('id')\n    )\n    \n    # Criar tabela audit_logs\n    op.create_table('audit_logs',\n        sa.Column('id', sa.Uuid(), nullable=False),\n        sa.Column('user_id', sa.Uuid(), nullable=False),\n        sa.Column('action', sa.String(length=100), nullable=False),\n        sa.Column('resource', sa.String(length=100), nullable=False),\n        sa.Column('details', sa.JSON(), nullable=True),\n        sa.Column('ip_address', sa.String(length=45), nullable=False),\n        sa.Column('timestamp', sa.DateTime(timezone=True), server_default=sa.text('CURRENT_TIMESTAMP'), nullable=False),\n        sa.Column('status', sa.String(length=20), nullable=False),\n        sa.ForeignKeyConstraint(['user_id'], ['users.id'], ),\n        sa.PrimaryKeyConstraint('id')\n    )\n    op.create_index(op.f('ix_audit_logs_timestamp'), 'audit_logs', ['timestamp'], unique=False)\n\n\ndef downgrade() -> None:\n    op.drop_index(op.f('ix_audit_logs_timestamp'), table_name='audit_logs')\n    op.drop_table('audit_logs')\n    op.drop_table('reports')\n    op.drop_index(op.f('ix_users_username'), table_name='users')\n    op.drop_index(op.f('ix_users_email'), table_name='users')\n    op.drop_table('users')", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3349, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "867fc1a1-d047-4c06-9cc4-6f0935324800": {"__data__": {"id_": "867fc1a1-d047-4c06-9cc4-6f0935324800", "embedding": null, "metadata": {"file_path": "backend\\app\\infrastructure\\database\\models\\admmatao.py", "language": "python", "lines": 123, "filename": "admmatao.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\infrastructure\\database\\models\\admmatao.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\infrastructure\\database\\models\\admmatao.py", "language": "python", "lines": 123, "filename": "admmatao.py"}, "hash": "9d929c4e5a9b743d2966a06d8b15f1a0d96152c2cf3aea49192b21a1f398960e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "28456f1a-bf84-4d4f-aa05-20175d5411c9", "node_type": "1", "metadata": {}, "hash": "cf66ab66ca5b7ecdc0057eff56d00d6d374c38f7f658becd49298979906b9800", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "from sqlalchemy import Column, Integer, String, Float, DateTime, BigInteger\nfrom sqlalchemy.sql import func\nfrom app.config.database import Base\n\nclass Admmatao(Base):\n    __tablename__ = \"admmatao\"\n\n    id = Column(BigInteger, primary_key=True, index=True)\n    une = Column(BigInteger, index=True)\n    produto = Column(BigInteger)\n    tipo = Column(BigInteger)\n    une_nome = Column(String(255))\n    nome = Column(String(255))\n    embalagem = Column(String(255))\n    nomesegmento = Column(String(255))\n    nomecategoria = Column(String(255))\n    nomegrupo = Column(String(255))\n    nomesubgrupo = Column(String(255))\n    nomefabricante = Column(String(255))\n    ean = Column(String(50))\n    promocional = Column(String(50))\n    foralinha = Column(String(50))\n    \n    # M\u00e9tricas e Dados Adicionais\n    liquido_38 = Column(Float)\n    qtde_emb_master = Column(Float)\n    qtde_emb_multiplo = Column(Float)\n    \n    # Curvas ABC\n    abc_une_mes_04 = Column(String(10))\n    abc_une_mes_03 = Column(String(10))\n    abc_une_mes_02 = Column(String(10))\n    abc_une_mes_01 = Column(String(10))\n    abc_une_30dd = Column(String(10))\n    abc_cacula_90dd = Column(String(10))\n    abc_une_30xabc_cacula_90dd = Column(String(10))\n    \n    # Vendas Mensais\n    mes_12 = Column(Float)\n    mes_11 = Column(Float)\n    mes_10 = Column(Float)\n    mes_09 = Column(Float)\n    mes_08 = Column(Float)\n    mes_07 = Column(Float)\n    mes_06 = Column(Float)\n    mes_05 = Column(Float)\n    mes_04 = Column(Float)\n    mes_03 = Column(Float)\n    mes_02 = Column(Float)\n    mes_01 = Column(Float)\n    mes_parcial = Column(Float)\n    \n    # Semanas Anteriores\n    semana_anterior_5 = Column(Float)\n    freq_semana_anterior_5 = Column(Float)\n    qtde_semana_anterior_5 = Column(Float)\n    media_semana_anterior_5 = Column(Float)\n    \n    semana_anterior_4 = Column(Float)\n    freq_semana_anterior_4 = Column(Float)\n    qtde_semana_anterior_4 = Column(Float)\n    media_semana_anterior_4 = Column(Float)\n    \n    semana_anterior_3 = Column(Float)\n    freq_semana_anterior_3 = Column(Float)\n    qtde_semana_anterior_3 = Column(Float)\n    media_semana_anterior_3 = Column(Float)\n    \n    semana_anterior_2 = Column(Float)\n    freq_semana_anterior_2 = Column(Float)\n    qtde_semana_anterior_2 = Column(Float)\n    media_semana_anterior_2 = Column(Float)\n    \n    semana_atual = Column(Float)\n    freq_semana_atual = Column(Float)\n    qtde_semana_atual = Column(Float)\n    media_semana_atual = Column(Float)\n    \n    # Outros Indicadores\n    venda_30dd = Column(Float)\n    media_considerada_lv = Column(Float)\n    estoque_cd = Column(Float)\n    ultima_entrada_data_cd = Column(DateTime)\n    ultima_entrada_qtde_cd = Column(Float)\n    ultima_entrada_custo_cd = Column(Float)\n    estoque_une = Column(Float)\n    ultimo_inventario_une = Column(DateTime)\n    ultima_entrada_data_une = Column(DateTime)\n    ultima_entrada_qtde_une = Column(Float)\n    estoque_lv = Column(Float)\n    estoque_gondola_lv =", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2958, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "28456f1a-bf84-4d4f-aa05-20175d5411c9": {"__data__": {"id_": "28456f1a-bf84-4d4f-aa05-20175d5411c9", "embedding": null, "metadata": {"file_path": "backend\\app\\infrastructure\\database\\models\\admmatao.py", "language": "python", "lines": 123, "filename": "admmatao.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\infrastructure\\database\\models\\admmatao.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\infrastructure\\database\\models\\admmatao.py", "language": "python", "lines": 123, "filename": "admmatao.py"}, "hash": "9d929c4e5a9b743d2966a06d8b15f1a0d96152c2cf3aea49192b21a1f398960e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "867fc1a1-d047-4c06-9cc4-6f0935324800", "node_type": "1", "metadata": {"file_path": "backend\\app\\infrastructure\\database\\models\\admmatao.py", "language": "python", "lines": 123, "filename": "admmatao.py"}, "hash": "5c2b50cc89b72779b056a5d75f1a874f2bac8d1ff270b8445d5ad55ea6081c66", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "estoque_lv = Column(Float)\n    estoque_gondola_lv = Column(Float)\n    estoque_ilha_lv = Column(Float)\n    exposicao_minima = Column(Float)\n    exposicao_minima_une = Column(Float)\n    exposicao_maxima_une = Column(Float)\n    leadtime_lv = Column(Float)\n    ponto_pedido_lv = Column(Float)\n    media_travada = Column(Float)\n    endereco_reserva = Column(String(255))\n    endereco_linha = Column(String(255))\n    solicitacao_pendente = Column(String(255))\n    solicitacao_pendente_data = Column(DateTime)\n    solicitacao_pendente_qtde = Column(Float)\n    solicitacao_pendente_situacao = Column(String(255))\n    ultima_venda_data_une = Column(DateTime)\n    picklist = Column(String(255))\n    picklist_situacao = Column(String(255))\n    picklist_conferencia = Column(String(255))\n    ultimo_volume = Column(String(255))\n    volume_qtde = Column(Float)\n    romaneio_solicitacao = Column(String(255))\n    romaneio_envio = Column(String(255))\n    nota = Column(String(255))\n    serie = Column(String(255))\n    nota_emissao = Column(DateTime)\n    freq_ult_sem = Column(Float)\n    \n    created_at = Column(DateTime(timezone=True), server_default=func.now())\n    updated_at = Column(DateTime(timezone=True), onupdate=func.now())\n\n    def __repr__(self):\n        return f\"<Admmatao(id={self.id}, produto='{self.nome}')>\"", "mimetype": "text/plain", "start_char_idx": 2907, "end_char_idx": 4216, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5beb76f3-0ed7-4ae6-b28e-8a1cb924af59": {"__data__": {"id_": "5beb76f3-0ed7-4ae6-b28e-8a1cb924af59", "embedding": null, "metadata": {"file_path": "backend\\app\\infrastructure\\database\\models\\audit_log.py", "language": "python", "lines": 38, "filename": "audit_log.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\infrastructure\\database\\models\\audit_log.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\infrastructure\\database\\models\\audit_log.py", "language": "python", "lines": 38, "filename": "audit_log.py"}, "hash": "9e3a54b59ae3749b8fb7b9dfd8ee40add6ac7f8534a84f467015428cde4c0ccc", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nAudit Log Model\nSQLAlchemy model for audit_logs table\n\"\"\"\n\nimport uuid\nfrom datetime import datetime\n\nfrom sqlalchemy import DateTime, ForeignKey, String, Text, JSON, Uuid\nfrom sqlalchemy.orm import Mapped, mapped_column\nfrom sqlalchemy.sql import func\n\nfrom app.config.database import Base\n\n\nclass AuditLog(Base):\n    \"\"\"Audit log database model\"\"\"\n\n    __tablename__ = \"audit_logs\"\n\n    id: Mapped[uuid.UUID] = mapped_column(\n        Uuid(as_uuid=True), primary_key=True, default=uuid.uuid4\n    )\n    user_id: Mapped[uuid.UUID] = mapped_column(\n        Uuid(as_uuid=True), ForeignKey(\"users.id\"), nullable=False\n    )\n    action: Mapped[str] = mapped_column(String(100), nullable=False)\n    resource: Mapped[str] = mapped_column(String(100), nullable=False)\n    details: Mapped[dict | None] = mapped_column(JSON, nullable=True)\n    ip_address: Mapped[str] = mapped_column(String(45), nullable=False)\n    timestamp: Mapped[datetime] = mapped_column(\n        DateTime(timezone=True), server_default=func.now(), nullable=False, index=True\n    )\n    status: Mapped[str] = mapped_column(String(20), nullable=False)\n\n    def __repr__(self) -> str:\n        return f\"<AuditLog(id={self.id}, action={self.action}, resource={self.resource})>\"", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1238, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "127cfc0e-6c09-4997-8383-203cb5f5c8ee": {"__data__": {"id_": "127cfc0e-6c09-4997-8383-203cb5f5c8ee", "embedding": null, "metadata": {"file_path": "backend\\app\\infrastructure\\database\\models\\report.py", "language": "python", "lines": 43, "filename": "report.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\infrastructure\\database\\models\\report.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\infrastructure\\database\\models\\report.py", "language": "python", "lines": 43, "filename": "report.py"}, "hash": "a48d217b4a87e24be42006ff7eb5957421bee67c0317c43cbe0173adb27f56d4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nReport Model\nSQLAlchemy model for reports table\n\"\"\"\n\nimport uuid\nfrom datetime import datetime\n\nfrom sqlalchemy import DateTime, ForeignKey, String, Text, JSON, Uuid\nfrom sqlalchemy.orm import Mapped, mapped_column, relationship\nfrom sqlalchemy.sql import func\n\nfrom app.config.database import Base\n\n\nclass Report(Base):\n    \"\"\"Report database model\"\"\"\n\n    __tablename__ = \"reports\"\n\n    id: Mapped[uuid.UUID] = mapped_column(\n        Uuid(as_uuid=True), primary_key=True, default=uuid.uuid4\n    )\n    title: Mapped[str] = mapped_column(String(255), nullable=False)\n    description: Mapped[str | None] = mapped_column(Text, nullable=True)\n    content: Mapped[dict] = mapped_column(JSON, nullable=False)  # TipTap JSON\n    status: Mapped[str] = mapped_column(String(20), nullable=False, default=\"draft\")\n    author_id: Mapped[uuid.UUID] = mapped_column(\n        Uuid(as_uuid=True), ForeignKey(\"users.id\"), nullable=False\n    )\n    created_at: Mapped[datetime] = mapped_column(\n        DateTime(timezone=True), server_default=func.now(), nullable=False\n    )\n    updated_at: Mapped[datetime] = mapped_column(\n        DateTime(timezone=True), server_default=func.now(), onupdate=func.now(), nullable=False\n    )\n\n    # Relationships\n    author: Mapped[\"User\"] = relationship(\"User\", lazy=\"selectin\")\n\n    def __repr__(self) -> str:\n        return f\"<Report(id={self.id}, title={self.title}, status={self.status})>\"", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1416, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "842b4f51-ef40-4e18-9462-4624cb9ec442": {"__data__": {"id_": "842b4f51-ef40-4e18-9462-4624cb9ec442", "embedding": null, "metadata": {"file_path": "backend\\app\\infrastructure\\database\\models\\shared_conversation.py", "language": "python", "lines": 70, "filename": "shared_conversation.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\infrastructure\\database\\models\\shared_conversation.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\infrastructure\\database\\models\\shared_conversation.py", "language": "python", "lines": 70, "filename": "shared_conversation.py"}, "hash": "de596955dcef93fb1100b1e4302317cf59bf30b34a55f10c69b087b2a9286595", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nShared Conversation Model\nSQLAlchemy model for shared conversations\n\"\"\"\n\nimport uuid\nfrom datetime import datetime, timedelta\nimport json\n\nfrom sqlalchemy import Boolean, DateTime, String, Uuid, Text\nfrom sqlalchemy.orm import Mapped, mapped_column\nfrom sqlalchemy.sql import func\n\nfrom app.config.database import Base\n\n\nclass SharedConversation(Base):\n    \"\"\"Shared conversation database model for public conversation links\"\"\"\n\n    __tablename__ = \"shared_conversations\"\n\n    id: Mapped[uuid.UUID] = mapped_column(\n        Uuid(as_uuid=True), primary_key=True, default=uuid.uuid4\n    )\n    share_id: Mapped[str] = mapped_column(\n        String(32), unique=True, nullable=False, index=True\n    )\n    session_id: Mapped[str] = mapped_column(String(255), nullable=False, index=True)\n    user_id: Mapped[uuid.UUID] = mapped_column(Uuid(as_uuid=True), nullable=False)\n    title: Mapped[str] = mapped_column(String(255), nullable=True)\n    messages: Mapped[str] = mapped_column(Text, nullable=False)  # JSON string\n    is_active: Mapped[bool] = mapped_column(Boolean, default=True, nullable=False)\n    expires_at: Mapped[datetime | None] = mapped_column(\n        DateTime(timezone=True), nullable=True\n    )\n    view_count: Mapped[int] = mapped_column(default=0, nullable=False)\n    created_at: Mapped[datetime] = mapped_column(\n        DateTime(timezone=True), server_default=func.now(), nullable=False\n    )\n    updated_at: Mapped[datetime] = mapped_column(\n        DateTime(timezone=True), server_default=func.now(), onupdate=func.now(), nullable=False\n    )\n\n    def __repr__(self) -> str:\n        return f\"<SharedConversation(share_id={self.share_id}, session_id={self.session_id})>\"\n\n    @property\n    def messages_list(self) -> list[dict]:\n        \"\"\"Converte a string JSON de messages para uma lista Python.\"\"\"\n        try:\n            return json.loads(self.messages) if self.messages else []\n        except (json.JSONDecodeError, TypeError):\n            return []\n\n    @messages_list.setter\n    def messages_list(self, messages: list[dict]):\n        \"\"\"Define messages a partir de uma lista Python, convertendo para string JSON.\"\"\"\n        self.messages = json.dumps(messages) if messages is not None else \"[]\"\n\n    @property\n    def is_expired(self) -> bool:\n        \"\"\"Check if the shared conversation has expired.\"\"\"\n        if self.expires_at is None:\n            return False\n        return datetime.now(self.expires_at.tzinfo) > self.expires_at\n\n    def increment_view_count(self):\n        \"\"\"Increment the view counter.\"\"\"\n        self.view_count += 1", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2567, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e47efd9b-8969-4296-9ae8-4e57d1874c6c": {"__data__": {"id_": "e47efd9b-8969-4296-9ae8-4e57d1874c6c", "embedding": null, "metadata": {"file_path": "backend\\app\\infrastructure\\database\\models\\user.py", "language": "python", "lines": 54, "filename": "user.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\infrastructure\\database\\models\\user.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\infrastructure\\database\\models\\user.py", "language": "python", "lines": 54, "filename": "user.py"}, "hash": "325d51f0eda5a9359737d359422e6522067a8acefa89abd183249328de33107f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nUser Model\nSQLAlchemy model for users table\n\"\"\"\n\nimport uuid\nfrom datetime import datetime\nimport json # Adicionado para manipula\u00e7\u00e3o de JSON string\n\nfrom sqlalchemy import Boolean, DateTime, String, Uuid, Text # Adicionado Text\nfrom sqlalchemy.orm import Mapped, mapped_column\nfrom sqlalchemy.sql import func\n\nfrom app.config.database import Base\n\n\nclass User(Base):\n    \"\"\"User database model\"\"\"\n\n    __tablename__ = \"users\"\n\n    id: Mapped[uuid.UUID] = mapped_column(\n        Uuid(as_uuid=True), primary_key=True, default=uuid.uuid4\n    )\n    username: Mapped[str] = mapped_column(String(50), unique=True, nullable=False, index=True)\n    email: Mapped[str] = mapped_column(String(255), unique=True, nullable=False, index=True)\n    hashed_password: Mapped[str] = mapped_column(String(255), nullable=False)\n    role: Mapped[str] = mapped_column(String(20), nullable=False, default=\"viewer\")\n    is_active: Mapped[bool] = mapped_column(Boolean, default=True, nullable=False)\n    allowed_segments: Mapped[str] = mapped_column(Text, nullable=False, default=\"[]\") # Armazenar como JSON string\n    last_login: Mapped[datetime | None] = mapped_column(DateTime(timezone=True), nullable=True)\n    created_at: Mapped[datetime] = mapped_column(\n        DateTime(timezone=True), server_default=func.now(), nullable=False\n    )\n    updated_at: Mapped[datetime] = mapped_column(\n        DateTime(timezone=True), server_default=func.now(), onupdate=func.now(), nullable=False\n    )\n\n    def __repr__(self) -> str:\n        return f\"<User(id={self.id}, username={self.username}, role={self.role})>\"\n\n    @property\n    def segments_list(self) -> list[str]:\n        \"\"\"Converte a string JSON de allowed_segments para uma lista Python.\"\"\"\n        try:\n            return json.loads(self.allowed_segments) if self.allowed_segments else []\n        except (json.JSONDecodeError, TypeError):\n            return []\n\n    @segments_list.setter\n    def segments_list(self, segments: list[str]):\n        \"\"\"Define allowed_segments a partir de uma lista Python, convertendo para string JSON.\"\"\"\n        self.allowed_segments = json.dumps(segments) if segments is not None else \"[]\"", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2156, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0e1052cc-8e88-4dff-8a8f-296df91f7a74": {"__data__": {"id_": "0e1052cc-8e88-4dff-8a8f-296df91f7a74", "embedding": null, "metadata": {"file_path": "backend\\app\\infrastructure\\database\\models\\user_preference.py", "language": "python", "lines": 51, "filename": "user_preference.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\infrastructure\\database\\models\\user_preference.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\infrastructure\\database\\models\\user_preference.py", "language": "python", "lines": 51, "filename": "user_preference.py"}, "hash": "f21a055fcac15d4bd80a169733a99e6109413ed5a4163ef45e8768a7953ac97f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nUser Preference Model\nSQLAlchemy model for user preferences and memory\n\"\"\"\n\nimport uuid\nfrom datetime import datetime\n\nfrom sqlalchemy import DateTime, String, Uuid, Text\nfrom sqlalchemy.orm import Mapped, mapped_column\nfrom sqlalchemy.sql import func\n\nfrom app.config.database import Base\n\n\nclass UserPreference(Base):\n    \"\"\"User preference model for storing user-specific preferences and memory\"\"\"\n\n    __tablename__ = \"user_preferences\"\n\n    id: Mapped[uuid.UUID] = mapped_column(\n        Uuid(as_uuid=True), primary_key=True, default=uuid.uuid4\n    )\n    user_id: Mapped[uuid.UUID] = mapped_column(\n        Uuid(as_uuid=True), nullable=False, index=True\n    )\n    key: Mapped[str] = mapped_column(String(100), nullable=False, index=True)\n    value: Mapped[str] = mapped_column(Text, nullable=False)\n    context: Mapped[str | None] = mapped_column(Text, nullable=True)  # Additional context\n    created_at: Mapped[datetime] = mapped_column(\n        DateTime(timezone=True), server_default=func.now(), nullable=False\n    )\n    updated_at: Mapped[datetime] = mapped_column(\n        DateTime(timezone=True), server_default=func.now(), onupdate=func.now(), nullable=False\n    )\n\n    def __repr__(self) -> str:\n        return f\"<UserPreference(user_id={self.user_id}, key={self.key})>\"\n\n    # Common preference keys\n    class Keys:\n        \"\"\"Common preference key constants\"\"\"\n        PREFERRED_CHART_TYPE = \"preferred_chart_type\"  # bar, line, pie, scatter\n        PREFERRED_DATA_FORMAT = \"preferred_data_format\"  # table, chart, both\n        LANGUAGE = \"language\"  # pt-BR, en-US\n        THEME = \"theme\"  # light, dark\n        COMPANY_NAME = \"company_name\"\n        BUSINESS_SEGMENT = \"business_segment\"\n        ANALYSIS_FOCUS = \"analysis_focus\"  # sales, inventory, finance\n        NOTIFICATION_ENABLED = \"notification_enabled\"  # true, false", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1848, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "50e72066-40de-4301-8a08-dbc7fa7741c7": {"__data__": {"id_": "50e72066-40de-4301-8a08-dbc7fa7741c7", "embedding": null, "metadata": {"file_path": "backend\\app\\infrastructure\\database\\models\\__init__.py", "language": "python", "lines": 15, "filename": "__init__.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\infrastructure\\database\\models\\__init__.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\infrastructure\\database\\models\\__init__.py", "language": "python", "lines": 15, "filename": "__init__.py"}, "hash": "d378deb691d6ac857b6d44836e3d38f8524c3c02e8fe21bd26cbab14eb2d18f1", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nDatabase Models\nExport all models for easy imports\n\"\"\"\n\nfrom app.config.database import Base\nfrom app.infrastructure.database.models.audit_log import AuditLog\nfrom app.infrastructure.database.models.report import Report\nfrom app.infrastructure.database.models.user import User\nfrom app.infrastructure.database.models.admmatao import Admmatao\nfrom app.infrastructure.database.models.shared_conversation import SharedConversation\nfrom app.infrastructure.database.models.user_preference import UserPreference\n\n__all__ = [\"Base\", \"User\", \"Report\", \"AuditLog\", \"Admmatao\", \"SharedConversation\", \"UserPreference\"]", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 611, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "23dad50c-1ef4-4195-83ca-bf22fb6fc8a0": {"__data__": {"id_": "23dad50c-1ef4-4195-83ca-bf22fb6fc8a0", "embedding": null, "metadata": {"file_path": "backend\\app\\schemas\\analytics.py", "language": "python", "lines": 55, "filename": "analytics.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\schemas\\analytics.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\schemas\\analytics.py", "language": "python", "lines": 55, "filename": "analytics.py"}, "hash": "32b645bf03ede9236c28a3ffc5fd052cdef00931c9c1c97c9382a88e5342d42a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nAnalytics Schemas\nPydantic schemas for Analytics API\n\"\"\"\n\nfrom datetime import date\nfrom typing import Literal\n\nfrom pydantic import BaseModel, Field\n\n\nclass AnalyticsFilter(BaseModel):\n    \"\"\"Analytics filter parameters\"\"\"\n\n    date_start: date | None = None\n    date_end: date | None = None\n    category: str | None = None\n    segment: str | None = None\n    min_value: float | None = None\n    max_value: float | None = None\n\n\nclass AnalyticsData(BaseModel):\n    \"\"\"Analytics data point\"\"\"\n\n    id: str\n    date: str\n    category: str\n    value: float\n    growth: float | None = None\n    metadata: dict | None = None\n\n\nclass AnalyticsMetric(BaseModel):\n    \"\"\"Analytics metric\"\"\"\n\n    label: str\n    value: float\n    format: Literal[\"currency\", \"number\", \"percentage\"]\n    trend: float | None = None\n\n\nclass ExportRequest(BaseModel):\n    \"\"\"Export request schema\"\"\"\n\n    format: Literal[\"csv\", \"excel\"] = Field(default=\"csv\")\n    filters: AnalyticsFilter | None = None\n\n\nclass CustomQueryRequest(BaseModel):\n    \"\"\"Custom query request\"\"\"\n\n    query: str = Field(..., min_length=1, max_length=1000)\n    filters: AnalyticsFilter | None = None", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1146, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a4c28993-2c24-4f5f-852d-05637f56d487": {"__data__": {"id_": "a4c28993-2c24-4f5f-852d-05637f56d487", "embedding": null, "metadata": {"file_path": "backend\\app\\schemas\\auth.py", "language": "python", "lines": 37, "filename": "auth.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\schemas\\auth.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\schemas\\auth.py", "language": "python", "lines": 37, "filename": "auth.py"}, "hash": "9e43766ffa346b1d77e561c9184111d60983701728b2f25b8596a8b375639d9e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nAuth Schemas\nPydantic schemas for Authentication\n\"\"\"\n\nfrom pydantic import BaseModel, EmailStr, Field\n\n\nclass Token(BaseModel):\n    \"\"\"Token response schema\"\"\"\n\n    access_token: str\n    refresh_token: str\n    token_type: str = \"bearer\"\n\n\nclass TokenData(BaseModel):\n    \"\"\"Token payload data\"\"\"\n\n    user_id: str\n    username: str\n    role: str\n    allowed_segments: list[str] = Field(default_factory=list) # Novo Campo\n\n\nclass LoginRequest(BaseModel):\n    \"\"\"Login request schema\"\"\"\n\n    username: str = Field(..., min_length=3, max_length=50)\n    password: str = Field(..., min_length=8, max_length=100)\n\n\nclass RefreshTokenRequest(BaseModel):\n    \"\"\"Refresh token request schema\"\"\"\n\n    refresh_token: str", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 713, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a01c60f1-08df-4a58-a759-0b24ac3248df": {"__data__": {"id_": "a01c60f1-08df-4a58-a759-0b24ac3248df", "embedding": null, "metadata": {"file_path": "backend\\app\\schemas\\report.py", "language": "python", "lines": 61, "filename": "report.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\schemas\\report.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\schemas\\report.py", "language": "python", "lines": 61, "filename": "report.py"}, "hash": "911c8ad75ef2db7945f3df39f6001bcef35d2163de1f6753f9b5285f17f62479", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nReport Schemas\nPydantic schemas for Report API\n\"\"\"\n\nimport uuid\nfrom datetime import datetime\n\nfrom pydantic import BaseModel, Field\n\n\nclass ReportBase(BaseModel):\n    \"\"\"Base report schema\"\"\"\n\n    title: str = Field(..., min_length=1, max_length=255)\n    description: str | None = None\n\n\nclass ReportCreate(ReportBase):\n    \"\"\"Schema for creating a report\"\"\"\n\n    content: dict = Field(default_factory=dict)  # TipTap JSON\n    status: str = Field(default=\"draft\", pattern=\"^(draft|published|archived)$\")\n\n\nclass ReportUpdate(BaseModel):\n    \"\"\"Schema for updating a report\"\"\"\n\n    title: str | None = Field(None, min_length=1, max_length=255)\n    description: str | None = None\n    content: dict | None = None\n    status: str | None = Field(None, pattern=\"^(draft|published|archived)$\")\n\n\nclass ReportResponse(ReportBase):\n    \"\"\"Schema for report response\"\"\"\n\n    id: uuid.UUID\n    content: dict\n    status: str\n    author_id: uuid.UUID\n    author_name: str | None = None\n    created_at: datetime\n    updated_at: datetime\n\n    model_config = {\"from_attributes\": True}\n\n\nclass ReportListResponse(BaseModel):\n    \"\"\"Schema for report list response\"\"\"\n\n    id: uuid.UUID\n    title: str\n    description: str | None\n    status: str\n    author_id: uuid.UUID\n    created_at: datetime\n    updated_at: datetime\n\n    model_config = {\"from_attributes\": True}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1353, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a8fccb0b-a2c9-4c26-9fc9-41144c21744b": {"__data__": {"id_": "a8fccb0b-a2c9-4c26-9fc9-41144c21744b", "embedding": null, "metadata": {"file_path": "backend\\app\\schemas\\user.py", "language": "python", "lines": 68, "filename": "user.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "backend\\app\\schemas\\user.py", "node_type": "4", "metadata": {"file_path": "backend\\app\\schemas\\user.py", "language": "python", "lines": 68, "filename": "user.py"}, "hash": "2643d840f3e164327aa52a4abd3618db62eb153bf14011a31d2c54d2868aca89", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nUser Schemas\nPydantic schemas for User API\n\"\"\"\n\nimport uuid\nfrom datetime import datetime\n\nfrom pydantic import BaseModel, EmailStr, Field\n\n\nclass UserBase(BaseModel):\n    \"\"\"Base user schema\"\"\"\n\n    username: str = Field(..., min_length=3, max_length=50)\n    email: EmailStr\n\n\nclass UserCreate(UserBase):\n    \"\"\"Schema for creating a user\"\"\"\n\n    password: str = Field(..., min_length=8, max_length=100)\n    role: str = Field(default=\"viewer\", pattern=\"^(admin|user|viewer)$\")\n    allowed_segments: list[str] = Field(default_factory=list) # Novo Campo\n\n\nclass UserUpdate(BaseModel):\n    \"\"\"Schema for updating a user\"\"\"\n\n    username: str | None = Field(None, min_length=3, max_length=50)\n    email: EmailStr | None = None\n    role: str | None = Field(None, pattern=\"^(admin|user|viewer)$\")\n    is_active: bool | None = None\n    allowed_segments: list[str] | None = Field(None) # Novo Campo\n    password: str | None = Field(None, min_length=8, max_length=100)\n\n\nclass UserResponse(UserBase):\n    \"\"\"Schema for user response\"\"\"\n\n    id: uuid.UUID\n    role: str\n    is_active: bool\n    allowed_segments: list[str] = Field(default_factory=list) # Novo Campo com default\n    last_login: datetime | None\n    created_at: datetime\n    updated_at: datetime\n\n    model_config = {\"from_attributes\": True}\n\n    @classmethod\n    def model_validate(cls, obj, **kwargs):\n        \"\"\"Custom validation to handle allowed_segments conversion from JSON string\"\"\"\n        if hasattr(obj, 'allowed_segments') and isinstance(obj.allowed_segments, str):\n            # Convert JSON string to list\n            import json\n            try:\n                obj.allowed_segments = json.loads(obj.allowed_segments) if obj.allowed_segments else []\n            except (json.JSONDecodeError, TypeError):\n                obj.allowed_segments = []\n        return super().model_validate(obj, **kwargs)\n\n\nclass UserInDB(UserResponse):\n    \"\"\"Schema for user in database (includes hashed password)\"\"\"\n\n    hashed_password: str", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1994, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d6fc08b7-fb85-45d2-8613-87544686dcec": {"__data__": {"id_": "d6fc08b7-fb85-45d2-8613-87544686dcec", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\index.tsx", "language": "typescript", "lines": 160, "filename": "index.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\index.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\index.tsx", "language": "typescript", "lines": 160, "filename": "index.tsx"}, "hash": "0fc681121e9a1f1ef5121fc317659006356f373387dcc07c480c8d130bd6cf25", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8279fa70-85ff-4d8e-96a1-0f4ef6f58192", "node_type": "1", "metadata": {}, "hash": "b366223d518d8a0b688f8f741f6e7a9493cdb51d02f47318c3bda9bc1b7dc0da", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "/* src/index.tsx - Vers\u00e3o ULTRA SIMPLIFICADA sem verifica\u00e7\u00e3o de vers\u00e3o */\nimport { render } from 'solid-js/web';\nimport { Router, Route, Navigate } from '@solidjs/router';\nimport { Show } from 'solid-js';\nimport { QueryClient, QueryClientProvider } from '@tanstack/solid-query';\nimport './index.css';\n\n// Importar Layout e P\u00e1ginas\nimport Layout from './Layout';\nimport Login from './pages/Login';\nimport Dashboard from './pages/Dashboard';\nimport Chat from './pages/Chat';\nimport Analytics from './pages/Analytics';\nimport Reports from './pages/Reports';\nimport Learning from './pages/Learning';\nimport Playground from './pages/Playground';\nimport Profile from './pages/Profile';\nimport Admin from './pages/Admin';\nimport Rupturas from './pages/Rupturas';\nimport Transfers from './pages/Transfers';\nimport Diagnostics from './pages/Diagnostics';\nimport Examples from './pages/Examples';\nimport Help from './pages/Help';\nimport SharedConversation from './pages/SharedConversation';\nimport CodeChat from './pages/CodeChat';\nimport About from './pages/About';\n\n// Importar Store de Autentica\u00e7\u00e3o\nimport auth from './store/auth';\n\nconsole.log('\u2705 All imports loaded successfully');\n\n// Componente de Prote\u00e7\u00e3o de Rotas\nfunction PrivateRoute(props: { component: any }) {\n  return (\n    <Show\n      when={auth.isAuthenticated()}\n      fallback={<Navigate href=\"/login\" />}\n    >\n      {props.component}\n    </Show>\n  );\n}\n\n// Componente de Prote\u00e7\u00e3o de Rotas com RBAC\nfunction RoleRoute(props: { component: any; requiredRole: string }) {\n  return (\n    <Show\n      when={auth.isAuthenticated()}\n      fallback={<Navigate href=\"/login\" />}\n    >\n      <Show\n        when={auth.user()?.role === props.requiredRole}\n        fallback={\n          <div class=\"flex items-center justify-center min-h-screen flex-col gap-4 p-8\">\n            <h1 class=\"text-4xl font-bold text-destructive\">Acesso Negado</h1>\n            <p class=\"text-lg text-muted-foreground\">Voc\u00ea n\u00e3o tem permiss\u00e3o para acessar esta p\u00e1gina.</p>\n            <p class=\"text-sm text-muted-foreground\">403 - Forbidden</p>\n          </div>\n        }\n      >\n        {props.component}\n      </Show>\n    </Show>\n  );\n}\n\n// Componente Principal da Aplica\u00e7\u00e3o\nfunction App() {\n  console.log('\u2705 App component created');\n  return (\n    <Router>\n      {/* Rotas P\u00fablicas */}\n      <Route path=\"/login\" component={Login} />\n      <Route path=\"/shared/:share_id\" component={SharedConversation} />\n\n      {/* Rota raiz - redireciona baseado em autentica\u00e7\u00e3o */}\n      <Route path=\"/\" component={() => {\n        return (\n          <Show\n            when={auth.isAuthenticated()}\n            fallback={<Navigate href=\"/login\" />}\n          >\n            <Navigate href=\"/dashboard\" />\n          </Show>\n        );", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2745, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8279fa70-85ff-4d8e-96a1-0f4ef6f58192": {"__data__": {"id_": "8279fa70-85ff-4d8e-96a1-0f4ef6f58192", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\index.tsx", "language": "typescript", "lines": 160, "filename": "index.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\index.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\index.tsx", "language": "typescript", "lines": 160, "filename": "index.tsx"}, "hash": "0fc681121e9a1f1ef5121fc317659006356f373387dcc07c480c8d130bd6cf25", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d6fc08b7-fb85-45d2-8613-87544686dcec", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\index.tsx", "language": "typescript", "lines": 160, "filename": "index.tsx"}, "hash": "4c23c71a34ba8b8df8dec38dbf5fd07caef9a060d8afee3aa346df69deaf7c3b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "}} />\n\n      {/* Rotas Protegidas - Dentro do Layout */}\n      <Route path=\"/\" component={Layout}>\n        <Route path=\"/dashboard\" component={() => <PrivateRoute component={<Dashboard />} />} />\n        <Route path=\"/metrics\" component={() => <RoleRoute component={<Analytics />} requiredRole=\"admin\" />} />\n        <Route path=\"/rupturas\" component={() => <PrivateRoute component={<Rupturas />} />} />\n        <Route path=\"/transfers\" component={() => <PrivateRoute component={<Transfers />} />} />\n        <Route path=\"/reports\" component={() => <RoleRoute component={<Reports />} requiredRole=\"admin\" />} />\n        <Route path=\"/chat\" component={() => <PrivateRoute component={<Chat />} />} />\n        <Route path=\"/examples\" component={() => <RoleRoute component={<Examples />} requiredRole=\"admin\" />} />\n        <Route path=\"/learning\" component={() => <RoleRoute component={<Learning />} requiredRole=\"admin\" />} />\n        <Route path=\"/playground\" component={() => <RoleRoute component={<Playground />} requiredRole=\"admin\" />} />\n        <Route path=\"/code-chat\" component={() => <RoleRoute component={<CodeChat />} requiredRole=\"admin\" />} />\n        <Route path=\"/diagnostics\" component={() => <RoleRoute component={<Diagnostics />} requiredRole=\"admin\" />} />\n        <Route path=\"/help\" component={() => <PrivateRoute component={<Help />} />} />\n        <Route path=\"/about\" component={() => <PrivateRoute component={<About />} />} />\n        <Route path=\"/profile\" component={() => <PrivateRoute component={<Profile />} />} />\n        <Route path=\"/admin\" component={() => <RoleRoute component={<Admin />} requiredRole=\"admin\" />} />\n      </Route>\n\n      {/* Fallback */}\n      <Route path=\"*\" component={() => (\n        <Show\n          when={auth.isAuthenticated()}\n          fallback={<Navigate href=\"/login\" />}\n        >\n          <Navigate href=\"/dashboard\" />\n        </Show>\n      )} />\n    </Router>\n  );\n}\n\n// Renderizar a Aplica\u00e7\u00e3o no DOM\nconst root = document.getElementById('root');\n\nif (!root) {\n  console.error('\u274c ROOT ELEMENT NOT FOUND!');\n  throw new Error('Root element not found');\n}\n\nconsole.log('\u2705 Root element found:', root);\n\n// Create QueryClient\nconst queryClient = new QueryClient({\n  defaultOptions: {\n    queries: {\n      retry: 1,\n      refetchOnWindowFocus: false,\n    },\n  },\n});\n\nconsole.log('\u2705 QueryClient created');\n\n// Render app\ntry {\n  render(() => (\n    <QueryClientProvider client={queryClient}>\n      <App />\n    </QueryClientProvider>\n  ), root);\n  console.log('\u2705 App rendered successfully!');\n} catch (error) {\n  console.error('\u274c Error rendering app:', error);\n  document.body.innerHTML = `\n    <div style=\"padding: 20px; color: white; background: #1a1a1a; font-family: sans-serif;\">\n      <h1 style=\"color: #ef4444;\">\u274c Erro ao Renderizar Aplica\u00e7\u00e3o</h1>\n      <pre style=\"background: #2a2a2a; padding: 10px; border-radius: 5px; overflow: auto;\">${error}</pre>\n      <p>Verifique o console do navegador (F12) para mais detalhes.</p>\n    </div>\n  `;\n}", "mimetype": "text/plain", "start_char_idx": 2752, "end_char_idx": 5760, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2c39a102-fefa-40b0-af6b-420530b8184a": {"__data__": {"id_": "2c39a102-fefa-40b0-af6b-420530b8184a", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\index_minimal_test.tsx", "language": "typescript", "lines": 11, "filename": "index_minimal_test.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\index_minimal_test.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\index_minimal_test.tsx", "language": "typescript", "lines": 11, "filename": "index_minimal_test.tsx"}, "hash": "d5d6b73ee3301ada46907d61a30f282752a6db7232d5f14f94dcb2fd1342d89a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "/* src/index.tsx - TESTE M\u00cdNIMO */\nconsole.log('\ud83d\ude80 TESTE: Script carregado!');\n\nconst root = document.getElementById('root');\nif (root) {\n  root.innerHTML = '<div style=\"color: white; padding: 20px; font-size: 24px;\">\u2705 TESTE: JavaScript est\u00e1 funcionando!</div>';\n  console.log('\u2705 TESTE: innerHTML definido!');\n} else {\n  console.error('\u274c TESTE: Elemento root n\u00e3o encontrado!');\n}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 378, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "577b53eb-3e5b-46da-be5e-ebb95696085e": {"__data__": {"id_": "577b53eb-3e5b-46da-be5e-ebb95696085e", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\Layout.tsx", "language": "typescript", "lines": 136, "filename": "Layout.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\Layout.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\Layout.tsx", "language": "typescript", "lines": 136, "filename": "Layout.tsx"}, "hash": "bac9cb7cc2646c49701a6cacceeb0ea24de2513dc187b423d1381f489fc0ddbd", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "41b65da6-ed9c-4f5c-bfe5-d0afcaad1c22", "node_type": "1", "metadata": {}, "hash": "2bdab682bb17e5389e44a384f08d7bc19ce2860b42f8f5d87f99ff92893f9d50", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import { A, useLocation } from '@solidjs/router';\nimport auth from '@/store/auth';\nimport {\n  LayoutDashboard, MessageSquare, PieChart, FileText, Settings, LogOut,\n  AlertTriangle, Truck, BookOpen, Terminal, Database, Lock, Shield, Lightbulb, HelpCircle, Code, Info\n} from 'lucide-solid';\nimport { For, Show, children } from 'solid-js';\nimport { ErrorBoundary } from './components/ErrorBoundary';\nimport { Logo } from '@/components';\n\nexport default function Layout(props: any) {\n  const location = useLocation();\n  const userRole = () => auth.user()?.role || 'user'; // fallback para 'user' garante visibilidade\n\n  // Defini\u00e7\u00e3o dos Itens de Menu com Permiss\u00f5es\n  const menuItems = [\n    {\n      group: 'Dashboards',\n      items: [\n        { href: '/dashboard', icon: LayoutDashboard, label: 'Monitoramento', roles: ['admin', 'user'] },\n        { href: '/metrics', icon: PieChart, label: 'M\u00e9tricas', roles: ['admin'] },\n        { href: '/rupturas', icon: AlertTriangle, label: 'Rupturas Cr\u00edticas', roles: ['admin', 'user'] },\n      ]\n    },\n    {\n      group: 'Operacional',\n      items: [\n        { href: '/transfers', icon: Truck, label: 'Transfer\u00eancias', roles: ['admin', 'user'] },\n        { href: '/reports', icon: FileText, label: 'Relat\u00f3rios', roles: ['admin'] },\n      ]\n    },\n    {\n      group: 'Intelig\u00eancia',\n      items: [\n        { href: '/chat', icon: MessageSquare, label: 'Chat BI', roles: ['admin', 'user'] },\n        { href: '/code-chat', icon: Code, label: 'Code Chat', roles: ['admin'] },\n        { href: '/examples', icon: Lightbulb, label: 'Exemplos', roles: ['admin'] },\n        { href: '/learning', icon: BookOpen, label: 'Aprendizado', roles: ['admin'] },\n        { href: '/playground', icon: Terminal, label: 'Playground', roles: ['admin'] },\n      ]\n    },\n    {\n      group: 'Sistema',\n      items: [\n        { href: '/diagnostics', icon: Database, label: 'Diagn\u00f3stico DB', roles: ['admin'] },\n        { href: '/help', icon: HelpCircle, label: 'Ajuda', roles: ['admin', 'user'] },\n        { href: '/about', icon: Info, label: 'Sobre', roles: ['admin', 'user'] },\n        { href: '/profile', icon: Lock, label: 'Alterar Senha', roles: ['admin', 'user'] },\n        { href: '/admin', icon: Shield, label: 'Administra\u00e7\u00e3o', roles: ['admin'] },\n      ]\n    }\n  ];\n\n  const NavItem = (props: { href: string; icon: any; label: string }) => (\n    <A \n      href={props.href} \n      class={`nav-item ${location.pathname.includes(props.href) ?", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2461, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "41b65da6-ed9c-4f5c-bfe5-d0afcaad1c22": {"__data__": {"id_": "41b65da6-ed9c-4f5c-bfe5-d0afcaad1c22", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\Layout.tsx", "language": "typescript", "lines": 136, "filename": "Layout.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\Layout.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\Layout.tsx", "language": "typescript", "lines": 136, "filename": "Layout.tsx"}, "hash": "bac9cb7cc2646c49701a6cacceeb0ea24de2513dc187b423d1381f489fc0ddbd", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "577b53eb-3e5b-46da-be5e-ebb95696085e", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\Layout.tsx", "language": "typescript", "lines": 136, "filename": "Layout.tsx"}, "hash": "d2f89c11f311033969b5f653a8e0708a78bc4fd384d59e37ae4c708c68a66033", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "'active' : ''}`}\n    >\n      <props.icon size={18} />\n      <span>{props.label}</span>\n    </A>\n  );\n\n  return (\n    <div class=\"app-layout\">\n      <aside class=\"sidebar\">\n        <div class=\"p-6 flex flex-col gap-3\">\n          <div class=\"flex items-center gap-3\">\n            <Logo size=\"md\" />\n            <span class=\"text-xs font-normal text-muted px-2 py-1 rounded bg-secondary border border-border capitalize\">\n              {String(userRole())}\n            </span>\n          </div>\n          <div class=\"flex flex-col gap-0.5\">\n            <h2 class=\"text-base font-bold text-primary\">CA\u00c7ULINHA BI</h2>\n            <span class=\"text-xs text-muted-foreground\">Intelig\u00eancia de Neg\u00f3cios</span>\n          </div>\n        </div>\n        \n        <nav class=\"flex-1 overflow-y-auto py-2\">\n          <For each={menuItems}>\n            {(group) => {\n              // Filtrar itens baseados na role\n              const visibleItems = group.items.filter(item => item.roles.includes(userRole()) || item.roles.includes('*'));\n              \n              return (\n                <Show when={visibleItems.length > 0}>\n                  <div class=\"mb-6\">\n                    <div class=\"px-6 mb-2 text-xs font-semibold text-muted uppercase tracking-wider opacity-70\">\n                      {group.group}\n                    </div>\n                    <For each={visibleItems}>\n                      {(item) => (\n                        <NavItem href={item.href} icon={item.icon} label={item.label} />\n                      )}\n                    </For>\n                  </div>\n                </Show>\n              );\n            }}\n          </For>\n        </nav>\n\n        <div class=\"p-4 border-t border-border\">\n          <button onClick={auth.logout} class=\"nav-item w-full justify-start text-destructive hover:bg-destructive/10 hover:text-destructive m-0\">\n            <LogOut size={18} />\n            <span>Sair</span>\n          </button>\n        </div>\n      </aside>\n\n      <div class=\"flex flex-col h-screen overflow-hidden\">\n        <header class=\"header justify-between\">\n          <div class=\"text-sm text-muted\">\n            Organiza\u00e7\u00e3o <span class=\"text-border mx-2\">/</span> <span class=\"text-foreground font-medium capitalize\">{location.pathname.replace('/', '') || 'Dashboard'}</span>\n          </div>\n          \n          <div class=\"flex items-center gap-4\">\n             <div class=\"text-right hidden md:block\">\n                <div class=\"text-sm font-medium\">{auth.user()?.username || 'Usu\u00e1rio'}</div>\n                <div class=\"text-xs text-muted\">{auth.user()?.email}</div>\n             </div>\n             <div class=\"w-8 h-8 bg-gradient-to-br from-primary to-accent rounded-full flex items-center justify-center font-bold text-white text-xs uppercase shadow-sm\">\n                {(auth.user()?.username || 'U').slice(0, 2).toUpperCase()}\n             </div>\n          </div>\n        </header>\n        <main class=\"flex-1 overflow-y-auto relative bg-background\">\n          <ErrorBoundary>\n            {props.children}\n          </ErrorBoundary>\n        </main>\n      </div>\n    </div>\n  );\n}", "mimetype": "text/plain", "start_char_idx": 2462, "end_char_idx": 5575, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a0a33cde-f2e1-44c6-ad3d-f71cc29bc4cc": {"__data__": {"id_": "a0a33cde-f2e1-44c6-ad3d-f71cc29bc4cc", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\components\\AIInsightsPanel.tsx", "language": "typescript", "lines": 194, "filename": "AIInsightsPanel.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\components\\AIInsightsPanel.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\components\\AIInsightsPanel.tsx", "language": "typescript", "lines": 194, "filename": "AIInsightsPanel.tsx"}, "hash": "1f31b5cd2363a561a4b6d1876967e6a0a5fb54b066bd7c68429e3f3ef1036cb6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c33591a7-b4a2-4f1f-916d-131bd55eb246", "node_type": "1", "metadata": {}, "hash": "d1da47ef84fe19f848c290c3d105861bff3356e3c8fa1d668ac382d2480bad55", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import { createSignal, createResource, For, Show } from 'solid-js';\nimport { Lightbulb, TrendingUp, AlertTriangle, Target, Sparkles, RefreshCw } from 'lucide-solid';\nimport auth from '@/store/auth';\n\ninterface Insight {\n  id: string;\n  title: string;\n  description: string;\n  category: 'trend' | 'anomaly' | 'opportunity' | 'risk';\n  severity: 'low' | 'medium' | 'high';\n  recommendation: string | null;\n  data_points: any[] | null;\n  created_at: string;\n}\n\ninterface InsightsData {\n  insights: Insight[];\n  total: number;\n  generated_at: string;\n}\n\nexport function AIInsightsPanel() {\n  const [isRefreshing, setIsRefreshing] = createSignal(false);\n  const user = auth.user;\n\n  const fetchInsights = async (): Promise<InsightsData> => {\n    const token = auth.token();\n    if (!token) throw new Error('Not authenticated');\n\n    const response = await fetch('/api/v1/insights/proactive', {\n      headers: { 'Authorization': `Bearer ${token}` }\n    });\n\n    if (!response.ok) {\n      throw new Error('Failed to fetch insights');\n    }\n\n    return response.json();\n  };\n\n  const [insights, { refetch }] = createResource(fetchInsights);\n\n  const refreshInsights = async () => {\n    setIsRefreshing(true);\n    await refetch();\n    setTimeout(() => setIsRefreshing(false), 500);\n  };\n\n  const getCategoryIcon = (category: string) => {\n    switch (category) {\n      case 'trend': return <TrendingUp size={20} />;\n      case 'anomaly': return <AlertTriangle size={20} />;\n      case 'opportunity': return <Target size={20} />;\n      case 'risk': return <AlertTriangle size={20} />;\n      default: return <Lightbulb size={20} />;\n    }\n  };\n\n  const getCategoryColor = (category: string) => {\n    switch (category) {\n      case 'trend': return 'text-blue-500 bg-blue-500/10 border-blue-500/20';\n      case 'anomaly': return 'text-amber-500 bg-amber-500/10 border-amber-500/20';\n      case 'opportunity': return 'text-emerald-500 bg-emerald-500/10 border-emerald-500/20';\n      case 'risk': return 'text-rose-500 bg-rose-500/10 border-rose-500/20';\n      default: return 'text-gray-500 bg-gray-500/10 border-gray-500/20';\n    }\n  };\n\n  const getSeverityBadge = (severity: string) => {\n    const colors = {\n      low: 'bg-green-500/20 text-green-600 border-green-500/30',\n      medium: 'bg-yellow-500/20 text-yellow-600 border-yellow-500/30',\n      high: 'bg-red-500/20 text-red-600 border-red-500/30 font-bold'\n    };\n\n    return colors[severity as keyof typeof colors] || colors.low;\n  };\n\n  return (\n    <div class=\"space-y-4\">\n      <div class=\"flex items-center justify-between\">\n        <div class=\"flex flex-col\">\n          <div class=\"flex items-center gap-2\">\n            <Sparkles class=\"text-primary\" size={24} />\n            <h3 class=\"text-xl font-bold tracking-tight\">IA Retail Insights</h3>\n            <Show when={user()}>\n              <span class=\"text-[10px] px-2 py-0.5 rounded-full bg-primary/10 text-primary border border-primary/20 uppercase font-bold ml-2\">\n                {user()?.role === 'admin' ? 'Vis\u00e3o Global' : 'Filtro por Segmento'}\n              </span>\n            </Show>\n          </div>\n          <p class=\"text-xs text-muted-foreground mt-1\">\n            An\u00e1lise em tempo real baseada em tend\u00eancias de varejo e estoque.\n          </p>\n        </div>\n        <button\n          onClick={refreshInsights}\n          disabled={isRefreshing() || insights.loading}\n          class=\"flex items-center gap-2 px-3 py-2 text-sm rounded-lg border hover:bg-muted transition-colors disabled:opacity-50 shadow-sm\"\n          title=\"Atualizar insights\"\n        >\n          <RefreshCw size={16} class={isRefreshing() ? 'animate-spin' : ''} />\n          <span>Atualizar</span>\n        </button>\n      </div>\n\n      <Show when={insights.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3745, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c33591a7-b4a2-4f1f-916d-131bd55eb246": {"__data__": {"id_": "c33591a7-b4a2-4f1f-916d-131bd55eb246", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\components\\AIInsightsPanel.tsx", "language": "typescript", "lines": 194, "filename": "AIInsightsPanel.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\components\\AIInsightsPanel.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\components\\AIInsightsPanel.tsx", "language": "typescript", "lines": 194, "filename": "AIInsightsPanel.tsx"}, "hash": "1f31b5cd2363a561a4b6d1876967e6a0a5fb54b066bd7c68429e3f3ef1036cb6", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a0a33cde-f2e1-44c6-ad3d-f71cc29bc4cc", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\components\\AIInsightsPanel.tsx", "language": "typescript", "lines": 194, "filename": "AIInsightsPanel.tsx"}, "hash": "f932806d2f4f1112be6401633d78492e1233765d261e79c139232ac92ba597b6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f11eb096-68a8-4ec4-af79-04605d2a2aa8", "node_type": "1", "metadata": {}, "hash": "f85c341a40ab46694bfd28dd97cb99bc2d0924b281a8c17a4d11f51bd53ff956", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "loading}>\n        <div class=\"flex flex-col items-center justify-center py-16 border rounded-xl bg-muted/10 border-dashed\">\n          <div class=\"relative\">\n            <div class=\"animate-spin rounded-full h-12 w-12 border-b-2 border-primary mx-auto mb-4\"></div>\n            <Sparkles class=\"absolute top-1/2 left-1/2 -translate-x-1/2 -translate-y-1/2 text-primary/40\" size={16} />\n          </div>\n          <p class=\"text-muted-foreground font-medium animate-pulse\">O c\u00e9rebro da IA est\u00e1 analisando seus dados...</p>\n        </div>\n      </Show>\n\n      <Show when={insights.error}>\n        <div class=\"p-4 rounded-lg bg-red-500/10 border border-red-500/20 text-red-500 flex items-center gap-3\">\n          <AlertTriangle size={24} />\n          <div>\n            <p class=\"font-semibold\">Erro na an\u00e1lise de IA</p>\n            <p class=\"text-sm\">{insights.error.message}</p>\n          </div>\n        </div>\n      </Show>\n\n      <Show when={!insights.loading && !insights.error && insights()}>\n        <div class=\"grid grid-cols-1 gap-4\">\n          <Show when={insights()!.insights.length === 0}>\n            <div class=\"p-12 text-center text-muted-foreground border-2 border-dashed rounded-xl\">\n              <Lightbulb size={48} class=\"mx-auto mb-3 opacity-20\" />\n              <p class=\"text-lg font-medium\">Nenhum insight detectado</p>\n              <p class=\"text-sm mt-1\">A IA n\u00e3o encontrou anomalias ou oportunidades significativas no momento.</p>\n            </div>\n          </Show>\n\n          <For each={insights()!.insights}>\n            {(insight) => (\n              <div class={`group relative p-5 rounded-xl border transition-all hover:shadow-lg ${getCategoryColor(insight.category)} bg-white dark:bg-zinc-900`}>\n                <div class=\"flex items-start gap-4\">\n                  <div class={`p-3 rounded-lg ${getCategoryColor(insight.category)} border bg-opacity-10`}>\n                    {getCategoryIcon(insight.category)}\n                  </div>\n                  <div class=\"flex-1\">\n                    <div class=\"flex items-start justify-between gap-2 mb-2\">\n                      <h4 class=\"font-bold text-lg text-foreground group-hover:text-primary transition-colors\">\n                        {insight.title}\n                      </h4>\n                      <span class={`text-[10px] px-2 py-1 rounded-md border shadow-sm ${getSeverityBadge(insight.severity)}`}>\n                        {insight.severity.toUpperCase()}\n                      </span>\n                    </div>\n                    <p class=\"text-sm text-muted-foreground leading-relaxed mb-4\">\n                      {insight.description}\n                    </p>\n\n                    <Show when={insight.recommendation}>\n                      <div class=\"relative mt-2 p-4 rounded-lg bg-primary/5 border border-primary/10 overflow-hidden\">\n                        <div class=\"absolute left-0 top-0 w-1 h-full bg-primary\" />\n                        <div class=\"flex items-center gap-2 mb-1\">\n                          <Target size={14} class=\"text-primary\" />\n                          <span class=\"text-xs font-bold text-primary uppercase tracking-widest\">Plano de A\u00e7\u00e3o</span>\n                        </div>\n                        <p class=\"text-sm font-medium text-foreground italic\">\n                          \"{insight.recommendation}\"\n                        </p>\n                      </div>\n                    </Show>\n\n                    <div class=\"flex items-center justify-between mt-4 pt-4 border-t border-dashed\">\n          <span class=\"flex items-center\">\n            <div class=\"w-2 h-2 rounded-full bg-green-500 mr-2 animate-pulse\"></div>\n            Gerado via Gemini 3.0 Flash\n          </span>\n                      <div class=\"text-[10px] text-muted-foreground\">\n                        {new Date(insight.created_at).toLocaleString('pt-BR')}\n                      </div>\n                    </div>\n                  </div>\n                </div>\n              </div>\n            )}\n          </For>\n        </div>\n\n        <div class=\"text-xs text-muted-foreground text-center pt-6 opacity-60\">\n          Processados {insights()!.total} indicadores estrat\u00e9gicos \u2022 {new Date(insights()!.generated_at).", "mimetype": "text/plain", "start_char_idx": 3745, "end_char_idx": 7960, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f11eb096-68a8-4ec4-af79-04605d2a2aa8": {"__data__": {"id_": "f11eb096-68a8-4ec4-af79-04605d2a2aa8", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\components\\AIInsightsPanel.tsx", "language": "typescript", "lines": 194, "filename": "AIInsightsPanel.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\components\\AIInsightsPanel.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\components\\AIInsightsPanel.tsx", "language": "typescript", "lines": 194, "filename": "AIInsightsPanel.tsx"}, "hash": "1f31b5cd2363a561a4b6d1876967e6a0a5fb54b066bd7c68429e3f3ef1036cb6", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c33591a7-b4a2-4f1f-916d-131bd55eb246", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\components\\AIInsightsPanel.tsx", "language": "typescript", "lines": 194, "filename": "AIInsightsPanel.tsx"}, "hash": "becd34950e5f91c1ca15cfee963e129f9d094d7e83412859af10e2ffe06054a4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "total} indicadores estrat\u00e9gicos \u2022 {new Date(insights()!.generated_at).toLocaleTimeString('pt-BR')}\n        </div>\n      </Show>\n    </div>\n  );\n}", "mimetype": "text/plain", "start_char_idx": 7890, "end_char_idx": 8035, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "bbe924d7-467c-4e9d-8a74-89a65c2a15a7": {"__data__": {"id_": "bbe924d7-467c-4e9d-8a74-89a65c2a15a7", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\components\\ChartDownloadButton.tsx", "language": "typescript", "lines": 123, "filename": "ChartDownloadButton.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\components\\ChartDownloadButton.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\components\\ChartDownloadButton.tsx", "language": "typescript", "lines": 123, "filename": "ChartDownloadButton.tsx"}, "hash": "a84d3b3a70717d513db5d7b42d0e2071f5ad33aa80fdf937245e5ee51e5c5118", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "// frontend-solid/src/components/ChartDownloadButton.tsx\n\nimport { Component, Show } from 'solid-js';\nimport { Download } from 'lucide-solid';\nimport Plotly from 'plotly.js-dist-min';\n\ninterface ChartDownloadButtonProps {\n  chartId: string;\n  filename?: string;\n  format?: 'png' | 'svg' | 'jpeg';\n  width?: number;\n  height?: number;\n  scale?: number;\n  label?: string;\n}\n\nexport const ChartDownloadButton: Component<ChartDownloadButtonProps> = (props) => {\n  const handleDownload = async () => {\n    const chartDiv = document.getElementById(props.chartId);\n\n    if (!chartDiv) {\n      alert('Gr\u00e1fico n\u00e3o encontrado');\n      return;\n    }\n\n    try {\n      const filename = props.filename || `grafico_${new Date().toISOString().split('T')[0]}`;\n      const format = props.format || 'png';\n      const width = props.width || 1200;\n      const height = props.height || 800;\n      const scale = props.scale || 2;\n\n      await Plotly.downloadImage(chartDiv, {\n        format: format,\n        filename: filename,\n        width: width,\n        height: height,\n        scale: scale\n      });\n    } catch (error) {\n      console.error(\"Erro ao baixar gr\u00e1fico:\", error);\n      alert(\"Erro ao baixar gr\u00e1fico. Tente novamente.\");\n    }\n  };\n\n  return (\n    <button\n      onClick={handleDownload}\n      class=\"btn btn-sm btn-outline gap-2\"\n      title=\"Baixar gr\u00e1fico como imagem\"\n    >\n      <Download size={16} />\n      {props.label || 'Baixar Gr\u00e1fico'}\n    </button>\n  );\n};\n\n// Componente para download de m\u00faltiplos formatos\ninterface MultiFormatDownloadProps {\n  chartId: string;\n  filename?: string;\n}\n\nexport const MultiFormatDownload: Component<MultiFormatDownloadProps> = (props) => {\n  const [showMenu, setShowMenu] = [false, (v: boolean) => {}];\n\n  const downloadFormat = async (format: 'png' | 'svg' | 'jpeg') => {\n    const chartDiv = document.getElementById(props.chartId);\n\n    if (!chartDiv) {\n      alert('Gr\u00e1fico n\u00e3o encontrado');\n      return;\n    }\n\n    try {\n      const filename = props.filename || `grafico_${new Date().toISOString().split('T')[0]}`;\n\n      await Plotly.downloadImage(chartDiv, {\n        format: format,\n        filename: filename,\n        width: 1200,\n        height: 800,\n        scale: 2\n      });\n    } catch (error) {\n      console.error(\"Erro ao baixar gr\u00e1fico:\", error);\n      alert(\"Erro ao baixar gr\u00e1fico. Tente novamente.\");\n    }\n  };\n\n  return (\n    <div class=\"relative inline-block\">\n      <button\n        class=\"btn btn-sm btn-outline gap-2\"\n        title=\"Baixar gr\u00e1fico\"\n      >\n        <Download size={16} />\n        <span>Baixar</span>\n      </button>\n      <div class=\"absolute right-0 mt-1 w-32 bg-card border rounded-lg shadow-lg z-10 py-1\">\n        <button\n          onClick={() => downloadFormat('png')}\n          class=\"w-full px-3 py-2 text-left text-sm hover:bg-muted transition-colors\"\n        >\n          PNG (Alta Qualidade)\n        </button>\n        <button\n          onClick={() => downloadFormat('svg')}\n          class=\"w-full px-3 py-2 text-left text-sm hover:bg-muted transition-colors\"\n        >\n          SVG (Vetorial)\n        </button>\n        <button\n          onClick={() => downloadFormat('jpeg')}\n          class=\"w-full px-3 py-2 text-left text-sm hover:bg-muted transition-colors\"\n        >\n          JPEG\n        </button>\n      </div>\n    </div>\n  );\n};", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3328, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ca0826c9-2f72-43fd-b39b-587a0c131cff": {"__data__": {"id_": "ca0826c9-2f72-43fd-b39b-587a0c131cff", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\components\\DataTable.tsx", "language": "typescript", "lines": 126, "filename": "DataTable.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\components\\DataTable.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\components\\DataTable.tsx", "language": "typescript", "lines": 126, "filename": "DataTable.tsx"}, "hash": "d01e5fb8512021e3f7567de5bf5362fa790977339703f93f70626f95ec247eaa", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "718cd41d-0475-4343-89a5-71a13c4e1847", "node_type": "1", "metadata": {}, "hash": "3b77720c6acc2496c60f1910b66b7ef8a538f222f775f41c666c006e61e6db5a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "// frontend-solid/src/components/DataTable.tsx\n\nimport { createSignal, For, Show, Accessor } from 'solid-js';\n\ninterface DataTableProps {\n  data: Accessor<any[]>;\n  caption?: string;\n  itemsPerPage?: number;\n}\n\nexport const DataTable = (props: DataTableProps) => {\n  const [currentPage, setCurrentPage] = createSignal(1);\n  const itemsPerPage = props.itemsPerPage || 10;\n\n  const tableData = () => props.data();\n  const headers = () => {\n    if (tableData().length === 0) return [];\n    return Object.keys(tableData()[0]);\n  };\n\n  const paginatedData = () => {\n    const start = (currentPage() - 1) * itemsPerPage;\n    const end = start + itemsPerPage;\n    return tableData().slice(start, end);\n  };\n\n  const totalPages = () => Math.ceil(tableData().length / itemsPerPage);\n\n  const goToPage = (page: number) => {\n    if (page > 0 && page <= totalPages()) {\n      setCurrentPage(page);\n    }\n  };\n\n  const canGoPrev = () => currentPage() > 1;\n  const canGoNext = () => currentPage() < totalPages();\n\n  return (\n    <div class=\"overflow-x-auto rounded-lg border shadow-sm my-4\">\n      <Show when={props.caption}>\n        <div class=\"p-4 text-lg font-semibold text-card-foreground\">{props.caption}</div>\n      </Show>\n      <table class=\"w-full text-sm text-left text-gray-500\">\n        <thead class=\"text-xs text-gray-700 uppercase bg-gray-50\">\n          <tr>\n            <For each={headers()}>\n              {(header) => (\n                <th scope=\"col\" class=\"px-6 py-3\">\n                  {header}\n                </th>\n              )}\n            </For>\n          </tr>\n        </thead>\n        <tbody>\n          <Show when={tableData().length > 0} fallback={\n            <tr>\n                <td colSpan={headers().length} class=\"px-6 py-4 text-center text-gray-400\">Nenhum dado dispon\u00edvel.</td>\n            </tr>\n          }>\n            <For each={paginatedData()}>\n              {(row) => (\n                <tr class=\"bg-white border-b hover:bg-gray-50\">\n                  <For each={headers()}>\n                    {(header) => (\n                      <td class=\"px-6 py-4\">\n                        {typeof row[header] === 'object' && row[header] !== null\n                          ? JSON.stringify(row[header])\n                          : String(row[header])}\n                      </td>\n                    )}\n                  </For>\n                </tr>\n              )}\n            </For>\n          </Show>\n        </tbody>\n      </table>\n\n      <Show when={totalPages() > 1}>\n        <nav class=\"flex items-center justify-between p-4 border-t bg-gray-50\" aria-label=\"Table navigation\">\n          <span class=\"text-sm font-normal text-gray-500\">\n            P\u00e1gina <span class=\"font-semibold text-gray-900\">{currentPage()}</span> de <span class=\"font-semibold text-gray-900\">{totalPages()}</span>\n          </span>\n          <ul class=\"inline-flex -space-x-px text-sm h-8\">\n            <li>\n              <button\n                onClick={() => goToPage(currentPage() - 1)}\n                disabled={!canGoPrev()}\n                class=\"flex items-center justify-center px-3 h-8 ml-0 leading-tight text-gray-500 bg-white border border-gray-300 rounded-l-lg hover:bg-gray-100 hover:text-gray-700 disabled:opacity-50 disabled:cursor-not-allowed\"\n              >\n                Anterior\n              </button>\n            </li>\n            <For each={Array(totalPages()).fill(0)}>\n              {(_, i) => (\n                <li>\n                  <button\n                    onClick={() => goToPage(i() + 1)}\n                    class={`flex items-center justify-center px-3 h-8 leading-tight ${\n                      currentPage() === i() + 1\n                        ?", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3683, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "718cd41d-0475-4343-89a5-71a13c4e1847": {"__data__": {"id_": "718cd41d-0475-4343-89a5-71a13c4e1847", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\components\\DataTable.tsx", "language": "typescript", "lines": 126, "filename": "DataTable.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\components\\DataTable.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\components\\DataTable.tsx", "language": "typescript", "lines": 126, "filename": "DataTable.tsx"}, "hash": "d01e5fb8512021e3f7567de5bf5362fa790977339703f93f70626f95ec247eaa", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ca0826c9-2f72-43fd-b39b-587a0c131cff", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\components\\DataTable.tsx", "language": "typescript", "lines": 126, "filename": "DataTable.tsx"}, "hash": "67c1738d68e9660864a2c98d14fdd3066517caf0082f5cea4223c3634608e879", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "'text-primary-foreground bg-primary border-primary hover:bg-primary-dark hover:text-primary-foreground'\n                        : 'text-gray-500 bg-white border border-gray-300 hover:bg-gray-100 hover:text-gray-700'\n                    }`}\n                  >\n                    {i() + 1}\n                  </button>\n                </li>\n              )}\n            </For>\n            <li>\n              <button\n                onClick={() => goToPage(currentPage() + 1)}\n                disabled={!canGoNext()}\n                class=\"flex items-center justify-center px-3 h-8 leading-tight text-gray-500 bg-white border border-gray-300 rounded-r-lg hover:bg-gray-100 hover:text-gray-700 disabled:opacity-50 disabled:cursor-not-allowed\"\n              >\n                Pr\u00f3xima\n              </button>\n            </li>\n          </ul>\n        </nav>\n      </Show>\n    </div>\n  );\n};", "mimetype": "text/plain", "start_char_idx": 3684, "end_char_idx": 4569, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "47a420f5-843d-4c2a-a980-c27c170a4dd0": {"__data__": {"id_": "47a420f5-843d-4c2a-a980-c27c170a4dd0", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\components\\DownloadButton.tsx", "language": "typescript", "lines": 47, "filename": "DownloadButton.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\components\\DownloadButton.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\components\\DownloadButton.tsx", "language": "typescript", "lines": 47, "filename": "DownloadButton.tsx"}, "hash": "9fd1af1aa9c29f1f9f3c70ee273ab2dd88f2815cf0e42b3fd2aa1fec3530e765", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "// frontend-solid/src/components/DownloadButton.tsx\n\nimport { Component } from 'solid-js';\n\ninterface DownloadButtonProps {\n  data: any[]; // Data to be downloaded\n  filename: string; // Suggested filename\n  label?: string; // Optional button label\n}\n\nexport const DownloadButton: Component<DownloadButtonProps> = (props) => {\n  const handleDownload = () => {\n    if (!props.data || props.data.length === 0) {\n      alert(\"Nenhum dado para baixar.\");\n      return;\n    }\n\n    try {\n      // Convert data to JSON string\n      const jsonString = JSON.stringify(props.data, null, 2);\n      const blob = new Blob([jsonString], { type: 'application/json' });\n      const url = URL.createObjectURL(blob);\n\n      const a = document.createElement('a');\n      a.href = url;\n      a.download = props.filename || 'data.json';\n      document.body.appendChild(a);\n      a.click();\n      document.body.removeChild(a);\n      URL.revokeObjectURL(url);\n    } catch (error) {\n      console.error(\"Erro ao baixar dados:\", error);\n      alert(\"Erro ao baixar dados. Tente novamente.\");\n    }\n  };\n\n  return (\n    <button \n      onClick={handleDownload}\n      class=\"btn btn-sm btn-outline\"\n      title=\"Baixar dados\"\n    >\n      {props.label || 'Baixar Dados (JSON)'}\n    </button>\n  );\n};", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1269, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7d55e5e9-7ac8-49cd-bda3-dfdc51e2b3e8": {"__data__": {"id_": "7d55e5e9-7ac8-49cd-bda3-dfdc51e2b3e8", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\components\\ErrorBoundary.tsx", "language": "typescript", "lines": 38, "filename": "ErrorBoundary.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\components\\ErrorBoundary.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\components\\ErrorBoundary.tsx", "language": "typescript", "lines": 38, "filename": "ErrorBoundary.tsx"}, "hash": "061d590a5ba4aef516fb8c72a1fb3b78eab6a1e5bf176254140e00ef4db834ac", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import { createSignal, Show, ErrorBoundary as SolidErrorBoundary } from 'solid-js';\n\ninterface ErrorBoundaryProps {\n  children: any;\n}\n\nexport function ErrorBoundary(props: ErrorBoundaryProps) {\n  return (\n    <SolidErrorBoundary\n      fallback={(err, reset) => (\n        <div class=\"flex flex-col items-center justify-center h-[50vh] text-center p-8 space-y-4\">\n          <div class=\"text-red-500 text-5xl\">\u26a0\ufe0f</div>\n          <h2 class=\"text-2xl font-bold text-gray-800 dark:text-gray-100\">Ops! Algo deu errado.</h2>\n          <div class=\"p-4 bg-red-50 dark:bg-red-900/20 text-red-600 dark:text-red-400 rounded-lg max-w-lg overflow-auto text-sm font-mono\">\n            {err.toString()}\n          </div>\n          <div class=\"flex gap-4\">\n             <button \n              onClick={() => reset()}\n              class=\"px-4 py-2 bg-primary text-primary-foreground rounded hover:opacity-90 transition-opacity\"\n            >\n              Tentar Novamente\n            </button>\n            <button \n              onClick={() => window.location.reload()}\n              class=\"px-4 py-2 border border-gray-300 dark:border-gray-600 rounded hover:bg-gray-100 dark:hover:bg-gray-800 transition-colors\"\n            >\n              Recarregar P\u00e1gina\n            </button>\n          </div>\n        </div>\n      )}\n    >\n      {props.children}\n    </SolidErrorBoundary>\n  );\n}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1366, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b1121dbb-5b87-4c10-8911-9e270e9a2f95": {"__data__": {"id_": "b1121dbb-5b87-4c10-8911-9e270e9a2f95", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\components\\ExportMenu.tsx", "language": "typescript", "lines": 137, "filename": "ExportMenu.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\components\\ExportMenu.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\components\\ExportMenu.tsx", "language": "typescript", "lines": 137, "filename": "ExportMenu.tsx"}, "hash": "c4129d9bc8556b740d61bf07a718240ff792249ec281cb9860fd4be018e12219", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "bb49a099-199f-422b-8b91-208001ae9e2b", "node_type": "1", "metadata": {}, "hash": "049453a4808bef8a153e56d67717844c631a2bece90bde08ddc2dcd3a81ff74e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import { createSignal, Show } from 'solid-js';\nimport { Download, FileJson, FileText } from 'lucide-solid';\n\ninterface Message {\n  id: string;\n  role: string;\n  text: string;\n  timestamp: number;\n}\n\ninterface ExportMenuProps {\n  messages: () => Message[];\n  sessionId: string;\n}\n\nexport function ExportMenu(props: ExportMenuProps) {\n  const [showMenu, setShowMenu] = createSignal(false);\n\n  const downloadFile = (content: string, filename: string, type: string) => {\n    const blob = new Blob([content], { type });\n    const url = URL.createObjectURL(blob);\n    const a = document.createElement('a');\n    a.href = url;\n    a.download = filename;\n    document.body.appendChild(a);\n    a.click();\n    document.body.removeChild(a);\n    URL.revokeObjectURL(url);\n  };\n\n  const exportAsJSON = () => {\n    const data = props.messages().map(m => ({\n      role: m.role,\n      content: m.text,\n      timestamp: new Date(m.timestamp).toISOString()\n    }));\n\n    const json = JSON.stringify({\n      session_id: props.sessionId,\n      exported_at: new Date().toISOString(),\n      messages: data\n    }, null, 2);\n\n    downloadFile(json, `chatbi-${props.sessionId}.json`, 'application/json');\n    setShowMenu(false);\n  };\n\n  const exportAsMarkdown = () => {\n    let markdown = `# Chat BI - Conversa\\n\\n`;\n    markdown += `**Session ID:** ${props.sessionId}\\n`;\n    markdown += `**Exportado em:** ${new Date().toLocaleString('pt-BR')}\\n\\n`;\n    markdown += `---\\n\\n`;\n\n    props.messages().forEach((msg, index) => {\n      if (msg.role === 'user') {\n        markdown += `## \ud83d\udc64 Usu\u00e1rio\\n\\n${msg.text}\\n\\n`;\n      } else if (msg.role === 'assistant') {\n        markdown += `## \ud83e\udd16 Assistente\\n\\n${msg.text}\\n\\n`;\n      }\n\n      markdown += `_${new Date(msg.timestamp).toLocaleString('pt-BR')}_\\n\\n`;\n\n      if (index < props.messages().length - 1) {\n        markdown += `---\\n\\n`;\n      }\n    });\n\n    downloadFile(markdown, `chatbi-${props.sessionId}.md`, 'text/markdown');\n    setShowMenu(false);\n  };\n\n  const exportAsText = () => {\n    let text = `Chat BI - Conversa\\n`;\n    text += `Session ID: ${props.sessionId}\\n`;\n    text += `Exportado em: ${new Date().toLocaleString('pt-BR')}\\n`;\n    text += `${'='.repeat(50)}\\n\\n`;\n\n    props.messages().forEach((msg) => {\n      const role = msg.role === 'user' ?", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2289, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "bb49a099-199f-422b-8b91-208001ae9e2b": {"__data__": {"id_": "bb49a099-199f-422b-8b91-208001ae9e2b", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\components\\ExportMenu.tsx", "language": "typescript", "lines": 137, "filename": "ExportMenu.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\components\\ExportMenu.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\components\\ExportMenu.tsx", "language": "typescript", "lines": 137, "filename": "ExportMenu.tsx"}, "hash": "c4129d9bc8556b740d61bf07a718240ff792249ec281cb9860fd4be018e12219", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b1121dbb-5b87-4c10-8911-9e270e9a2f95", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\components\\ExportMenu.tsx", "language": "typescript", "lines": 137, "filename": "ExportMenu.tsx"}, "hash": "c8998c4a4d47695cd0c882316fe84b6afa43cf79ef166e2c8a35abcfa5f4e5e2", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "'Usu\u00e1rio' : 'Assistente';\n      const time = new Date(msg.timestamp).toLocaleString('pt-BR');\n      text += `[${role}] - ${time}\\n`;\n      text += `${msg.text}\\n\\n`;\n      text += `${'-'.repeat(50)}\\n\\n`;\n    });\n\n    downloadFile(text, `chatbi-${props.sessionId}.txt`, 'text/plain');\n    setShowMenu(false);\n  };\n\n  return (\n    <div class=\"relative\">\n      <button\n        onClick={() => setShowMenu(!showMenu())}\n        class=\"flex items-center gap-2 px-3 py-2 text-sm rounded-lg border hover:bg-muted transition-colors\"\n        title=\"Exportar conversa\"\n      >\n        <Download size={16} />\n        <span>Exportar</span>\n      </button>\n\n      <Show when={showMenu()}>\n        <div class=\"absolute right-0 top-full mt-2 bg-card border rounded-lg shadow-lg p-2 min-w-[200px] z-50\">\n          <button\n            onClick={exportAsJSON}\n            class=\"w-full flex items-center gap-2 px-3 py-2 text-sm rounded hover:bg-muted transition-colors text-left\"\n          >\n            <FileJson size={16} />\n            <span>JSON</span>\n          </button>\n          <button\n            onClick={exportAsMarkdown}\n            class=\"w-full flex items-center gap-2 px-3 py-2 text-sm rounded hover:bg-muted transition-colors text-left\"\n          >\n            <FileText size={16} />\n            <span>Markdown</span>\n          </button>\n          <button\n            onClick={exportAsText}\n            class=\"w-full flex items-center gap-2 px-3 py-2 text-sm rounded hover:bg-muted transition-colors text-left\"\n          >\n            <FileText size={16} />\n            <span>Texto</span>\n          </button>\n        </div>\n      </Show>\n\n      {/* Overlay to close menu */}\n      <Show when={showMenu()}>\n        <div\n          class=\"fixed inset-0 z-40\"\n          onClick={() => setShowMenu(false)}\n        />\n      </Show>\n    </div>\n  );\n}", "mimetype": "text/plain", "start_char_idx": 2290, "end_char_idx": 4131, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "96644538-0383-4b5d-8c7a-f3af68a56ad0": {"__data__": {"id_": "96644538-0383-4b5d-8c7a-f3af68a56ad0", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\components\\FeedbackButtons.tsx", "language": "typescript", "lines": 41, "filename": "FeedbackButtons.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\components\\FeedbackButtons.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\components\\FeedbackButtons.tsx", "language": "typescript", "lines": 41, "filename": "FeedbackButtons.tsx"}, "hash": "5aa4c587ed05070cebd1937f3698bce119fd8758ffd4f291d1d54194f2f3bc0e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "// frontend-solid/src/components/FeedbackButtons.tsx\n\nimport { Component } from 'solid-js';\n\ninterface FeedbackButtonsProps {\n  messageId: string;\n  onFeedback: (messageId: string, feedbackType: 'positive' | 'negative' | 'partial', comment?: string) => void;\n}\n\nexport const FeedbackButtons: Component<FeedbackButtonsProps> = (props) => {\n  const handleFeedbackClick = (feedbackType: 'positive' | 'negative' | 'partial') => {\n    props.onFeedback(props.messageId, feedbackType);\n  };\n\n  return (\n    <div class=\"flex items-center space-x-2\">\n      <button \n        onClick={() => handleFeedbackClick('positive')}\n        class=\"text-green-500 hover:text-green-700\"\n        title=\"Gostei da resposta\"\n      >\n        \ud83d\udc4d\n      </button>\n      <button \n        onClick={() => handleFeedbackClick('negative')}\n        class=\"text-red-500 hover:text-red-700\"\n        title=\"N\u00e3o gostei da resposta\"\n      >\n        \ud83d\udc4e\n      </button>\n      {/* <button \n        onClick={() => handleFeedbackClick('partial')}\n        class=\"text-blue-500 hover:text-blue-700\"\n        title=\"Respostas parcialmente \u00fatil\"\n      >\n        \ud83e\udd0f\n      </button> */}\n    </div>\n  );\n};", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1150, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f073d9cc-868f-4c84-92a7-a47680d3e96b": {"__data__": {"id_": "f073d9cc-868f-4c84-92a7-a47680d3e96b", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\components\\index.ts", "language": "typescript", "lines": 12, "filename": "index.ts"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\components\\index.ts", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\components\\index.ts", "language": "typescript", "lines": 12, "filename": "index.ts"}, "hash": "d882a333d75b75dab189836a584779cdb642cd905a8127bb08ae76a9a1d45f83", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "/**\n * Components Index\n * Central export for all reusable components\n */\n\nexport { Logo } from './Logo';\nexport { Typewriter, createTypewriter } from './Typewriter';\nexport { MessageActions } from './MessageActions';\nexport { ExportMenu } from './ExportMenu';\nexport { ShareButton } from './ShareButton';\nexport { TypingIndicator } from './TypingIndicator';", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 358, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e72a369a-dfe0-41f6-86ca-48ac6aa47742": {"__data__": {"id_": "e72a369a-dfe0-41f6-86ca-48ac6aa47742", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\components\\Logo.tsx", "language": "typescript", "lines": 28, "filename": "Logo.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\components\\Logo.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\components\\Logo.tsx", "language": "typescript", "lines": 28, "filename": "Logo.tsx"}, "hash": "298d9f7a04195d46088c17438f563d8333e55a76ec7fddb9c01641b0cac8ff77", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "// frontend-solid/src/components/Logo.tsx\nimport { Component } from 'solid-js';\n\ninterface LogoProps {\n  size?: 'sm' | 'md' | 'lg' | 'xl';\n  className?: string;\n}\n\nconst sizeMap = {\n  sm: 'h-8',      // 32px - para sidebar compacta\n  md: 'h-10',     // 40px - padr\u00e3o sidebar\n  lg: 'h-12',     // 48px - login\n  xl: 'h-16',     // 64px - destaque\n};\n\nexport const Logo: Component<LogoProps> = (props) => {\n  const size = props.size || 'md';\n\n  return (\n    <img\n      src=\"/logo-cacula.svg\"\n      alt=\"Lojas Ca\u00e7ula - 40 anos de tradi\u00e7\u00e3o\"\n      class={`${sizeMap[size]} w-auto ${props.className || ''}`}\n      style={{ \"max-width\": \"none\" }}\n    />\n  );\n};", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 654, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "fb76c0fd-9c2e-4aa9-83b3-3551a28b57b8": {"__data__": {"id_": "fb76c0fd-9c2e-4aa9-83b3-3551a28b57b8", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\components\\MessageActions.tsx", "language": "typescript", "lines": 53, "filename": "MessageActions.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\components\\MessageActions.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\components\\MessageActions.tsx", "language": "typescript", "lines": 53, "filename": "MessageActions.tsx"}, "hash": "3306a957ef02f1e648dcdd235b86f136e333b85ff2bc9b937407813d85924349", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import { Show } from 'solid-js';\nimport { Copy, RotateCw } from 'lucide-solid';\n\ninterface MessageActionsProps {\n  messageText: string;\n  messageId: string;\n  onRegenerate?: () => void;\n  canRegenerate?: boolean;\n}\n\nexport function MessageActions(props: MessageActionsProps) {\n  const copyToClipboard = () => {\n    navigator.clipboard.writeText(props.messageText).then(() => {\n      // Show brief success feedback\n      const btn = document.getElementById(`copy-${props.messageId}`);\n      if (btn) {\n        const originalText = btn.innerHTML;\n        btn.innerHTML = '\u2713 Copiado!';\n        setTimeout(() => {\n          btn.innerHTML = originalText;\n        }, 2000);\n      }\n    }).catch(err => {\n      console.error('Failed to copy:', err);\n    });\n  };\n\n  return (\n    <div class=\"flex items-center gap-2 mt-2 text-xs\">\n      <button\n        id={`copy-${props.messageId}`}\n        onClick={copyToClipboard}\n        class=\"flex items-center gap-1 px-2 py-1 rounded hover:bg-muted transition-colors\"\n        title=\"Copiar mensagem\"\n      >\n        <Copy size={14} />\n        <span>Copiar</span>\n      </button>\n\n      <Show when={props.canRegenerate && props.onRegenerate}>\n        <button\n          onClick={props.onRegenerate}\n          class=\"flex items-center gap-1 px-2 py-1 rounded hover:bg-muted transition-colors\"\n          title=\"Regenerar resposta\"\n        >\n          <RotateCw size={14} />\n          <span>Regenerar</span>\n        </button>\n      </Show>\n    </div>\n  );\n}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1485, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c2338493-f6ef-49fd-9066-11bd2f973be3": {"__data__": {"id_": "c2338493-f6ef-49fd-9066-11bd2f973be3", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\components\\PlotlyChart.tsx", "language": "typescript", "lines": 159, "filename": "PlotlyChart.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\components\\PlotlyChart.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\components\\PlotlyChart.tsx", "language": "typescript", "lines": 159, "filename": "PlotlyChart.tsx"}, "hash": "c1674c8971a0a46999aa7197d8c5096e54363c9fc5768445a5e5acfab7493d34", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5efc4b9e-a98e-44b7-8a2b-b91efb4a418a", "node_type": "1", "metadata": {}, "hash": "e8c682781f5def482ece84eb6789f6860d6b711809fb75a05660f445b6520b75", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "// frontend-solid/src/components/PlotlyChart.tsx\n\nimport { createEffect, onCleanup, Accessor, createSignal, Show, onMount } from 'solid-js';\nimport Plotly from 'plotly.js-dist-min';\nimport { Maximize, Minimize } from 'lucide-solid';\n\nconst CACULA_CHART_COLORS = [\n  '#8B7355', '#C9A961', '#6B7A5A', '#A68968', '#CC8B3C', \n  '#5B7B9A', '#9B8875', '#B8984E', '#7A8B6F', '#B59B7A',\n];\n\ninterface PlotlyChartProps {\n  chartSpec: Accessor<any>;\n  chartId?: string;\n  onDataClick?: (data: any) => void;\n  onHover?: (data: any) => void;\n  height?: string;\n  enableDownload?: boolean;\n}\n\nexport const PlotlyChart = (props: PlotlyChartProps) => {\n  let chartDiv: HTMLDivElement | undefined;\n  let expandedChartDiv: HTMLDivElement | undefined;\n  \n  const chartId = props.chartId || `chart-${Math.random().toString(36).substr(2, 9)}`;\n  const [isExpanded, setIsExpanded] = createSignal(false);\n\n  const toggleExpand = () => {\n    const newState = !isExpanded();\n    setIsExpanded(newState);\n    document.body.style.overflow = newState ? 'hidden' : '';\n    \n    // Pequeno delay para garantir que o DOM do modal esteja pronto\n    setTimeout(renderPlot, 50);\n  };\n\n  const handleEsc = (e: KeyboardEvent) => {\n    if (e.key === 'Escape' && isExpanded()) toggleExpand();\n  };\n\n  createEffect(() => {\n    if (isExpanded()) window.addEventListener('keydown', handleEsc);\n    else window.removeEventListener('keydown', handleEsc);\n  });\n\n  onCleanup(() => {\n    window.removeEventListener('keydown', handleEsc);\n    document.body.style.overflow = '';\n    if (chartDiv) Plotly.purge(chartDiv);\n    if (expandedChartDiv) Plotly.purge(expandedChartDiv);\n  });\n\n  const renderPlot = () => {\n    const spec = props.chartSpec();\n    const targetDiv = isExpanded() ? expandedChartDiv : chartDiv;\n    \n    if (!targetDiv || !spec || Object.keys(spec).length === 0) return;\n\n    try {\n      const caculaLayout = {\n        paper_bgcolor: isExpanded() ? '#FAFAFA' : '#FAFAFA',\n        plot_bgcolor: '#FFFFFF',\n        font: {\n          color: '#2D2D2D',\n          family: 'Inter, sans-serif',\n          size: isExpanded() ? 13 : 11\n        },\n        colorway: CACULA_CHART_COLORS,\n        margin: isExpanded() ?", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2183, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5efc4b9e-a98e-44b7-8a2b-b91efb4a418a": {"__data__": {"id_": "5efc4b9e-a98e-44b7-8a2b-b91efb4a418a", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\components\\PlotlyChart.tsx", "language": "typescript", "lines": 159, "filename": "PlotlyChart.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\components\\PlotlyChart.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\components\\PlotlyChart.tsx", "language": "typescript", "lines": 159, "filename": "PlotlyChart.tsx"}, "hash": "c1674c8971a0a46999aa7197d8c5096e54363c9fc5768445a5e5acfab7493d34", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c2338493-f6ef-49fd-9066-11bd2f973be3", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\components\\PlotlyChart.tsx", "language": "typescript", "lines": 159, "filename": "PlotlyChart.tsx"}, "hash": "09471597afc12214036e2a5d40f805da1986fa50a938da55a3ebd33d03ea237c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "{ l: 80, r: 40, t: 80, b: 100 } : (spec.layout?.margin || { l: 40, r: 20, t: 40, b: 40 }),\n        xaxis: { gridcolor: '#E5E5E5', ...spec.layout?.xaxis },\n        yaxis: { gridcolor: '#E5E5E5', ...spec.layout?.yaxis },\n        legend: {\n          bgcolor: 'rgba(255,255,255,0.8)',\n          ...spec.layout?.legend\n        },\n        ...spec.layout\n      };\n\n      const config = {\n        responsive: true,\n        displayModeBar: isExpanded(),\n        displaylogo: false,\n        ...spec.config\n      };\n\n      // Limpar o outro div se estiver mudando de estado\n      if (isExpanded() && chartDiv) Plotly.purge(chartDiv);\n      if (!isExpanded() && expandedChartDiv) Plotly.purge(expandedChartDiv);\n\n      Plotly.newPlot(targetDiv, spec.data, caculaLayout, config);\n\n      if (props.onDataClick) {\n        targetDiv.on('plotly_click', props.onDataClick);\n      }\n    } catch (error) {\n      console.error(\"Plotly render error:\", error);\n    }\n  };\n\n  createEffect(renderPlot);\n\n  return (\n    <>\n      <div\n        class=\"relative w-full overflow-hidden rounded-xl border bg-card group shadow-sm hover:shadow-md transition-shadow\"\n        style={{ height: props.height || '400px' }}\n      >\n        <div class=\"absolute top-3 right-3 z-10 opacity-0 group-hover:opacity-100 transition-opacity flex gap-2\">\n          <button\n            onClick={(e) => { e.stopPropagation(); toggleExpand(); }}\n            class=\"p-2 rounded-lg bg-white/90 border shadow-sm hover:bg-white text-primary transition-colors\"\n            title=\"Ver em tela cheia\"\n          >\n            <Maximize size={18} />\n          </button>\n        </div>\n        \n        <div ref={chartDiv} class=\"w-full h-full\" id={chartId}></div>\n      </div>\n\n      <Show when={isExpanded()}>\n        <div \n          class=\"fixed inset-0 z-[10000] bg-zinc-950/60 backdrop-blur-md flex items-center justify-center p-4 md:p-10 animate-in fade-in duration-300\"\n          onClick={toggleExpand}\n        >\n          <div \n            class=\"bg-white dark:bg-zinc-900 w-full h-full rounded-3xl shadow-2xl flex flex-col overflow-hidden animate-in zoom-in-95 slide-in-from-bottom-10 duration-500\"\n            onClick={(e) => e.stopPropagation()}\n          >\n            <div class=\"p-5 border-b flex items-center justify-between bg-white dark:bg-zinc-900\">\n              <div class=\"flex items-center gap-3\">\n                <div class=\"w-2 h-8 bg-primary rounded-full animate-pulse\"></div>\n                <div>\n                  <h3 class=\"font-bold text-xl text-gray-900 dark:text-gray-100\">An\u00e1lise Expandida</h3>\n                  <p class=\"text-xs text-muted-foreground\">Vis\u00e3o detalhada dos indicadores de performance</p>\n                </div>\n              </div>\n              <button\n                onClick={toggleExpand}\n                class=\"group p-2 px-4 rounded-xl hover:bg-red-50 text-gray-500 hover:text-red-600 transition-all flex items-center gap-3 border border-transparent hover:border-red-100\"\n              >\n                <span class=\"text-sm font-bold\">FECHAR</span>\n                <Minimize size={22} class=\"group-hover:scale-110 transition-transform\" />\n              </button>\n            </div>\n            \n            <div class=\"flex-1 p-8 bg-[#FAFAFA] dark:bg-zinc-950/50\">\n              <div \n                ref={expandedChartDiv}\n                id={`${chartId}-expanded`}\n                class=\"w-full h-full\"\n              ></div>\n            </div>\n          </div>\n        </div>\n      </Show>\n    </>\n  );\n};", "mimetype": "text/plain", "start_char_idx": 2184, "end_char_idx": 5686, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "539cdc3e-8082-4669-adb7-563bb9c45a98": {"__data__": {"id_": "539cdc3e-8082-4669-adb7-563bb9c45a98", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\components\\ShareButton.tsx", "language": "typescript", "lines": 199, "filename": "ShareButton.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\components\\ShareButton.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\components\\ShareButton.tsx", "language": "typescript", "lines": 199, "filename": "ShareButton.tsx"}, "hash": "96815596cb2700df214912352706cf9593b55a9918fbbf59c50110e0ca65fa18", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "74fd36b4-a43b-48dd-95bf-a4542230e8c5", "node_type": "1", "metadata": {}, "hash": "3971093f17ff8a02f1c671e7efc8d20c13f9a90f982ca674a9abef5ed2f52725", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import { createSignal, Show } from 'solid-js';\nimport { Share2, Copy, Check, X } from 'lucide-solid';\nimport auth from '@/store/auth';\n\ninterface Message {\n  id: string;\n  role: string;\n  text: string;\n  timestamp: number;\n}\n\ninterface ShareButtonProps {\n  messages: () => Message[];\n  sessionId: string;\n}\n\nexport function ShareButton(props: ShareButtonProps) {\n  const [showModal, setShowModal] = createSignal(false);\n  const [shareUrl, setShareUrl] = createSignal('');\n  const [copied, setCopied] = createSignal(false);\n  const [isSharing, setIsSharing] = createSignal(false);\n  const [error, setError] = createSignal('');\n  const [title, setTitle] = createSignal('');\n\n  const shareConversation = async () => {\n    const token = auth.token();\n    if (!token) {\n      setError('Voc\u00ea precisa estar autenticado para compartilhar.');\n      return;\n    }\n\n    setIsSharing(true);\n    setError('');\n\n    try {\n      const response = await fetch('/api/v1/shared/share', {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json',\n          'Authorization': `Bearer ${token}`\n        },\n        body: JSON.stringify({\n          session_id: props.sessionId,\n          messages: props.messages().map(m => ({\n            role: m.role,\n            text: m.text,\n            timestamp: m.timestamp\n          })),\n          title: title() || 'Conversa Chat BI',\n          expires_in_days: 30\n        })\n      });\n\n      if (!response.ok) {\n        throw new Error('Falha ao compartilhar conversa');\n      }\n\n      const data = await response.json();\n      const fullUrl = `${window.location.origin}${data.share_url}`;\n      setShareUrl(fullUrl);\n    } catch (err) {\n      console.error('Error sharing conversation:', err);\n      setError('Erro ao compartilhar conversa. Tente novamente.');\n    } finally {\n      setIsSharing(false);\n    }\n  };\n\n  const copyToClipboard = async () => {\n    try {\n      await navigator.clipboard.writeText(shareUrl());\n      setCopied(true);\n      setTimeout(() => setCopied(false), 2000);\n    } catch (err) {\n      console.error('Failed to copy:', err);\n    }\n  };\n\n  const openModal = () => {\n    setShowModal(true);\n    setShareUrl('');\n    setError('');\n    setTitle('');\n  };\n\n  const closeModal = () => {\n    setShowModal(false);\n    setShareUrl('');\n    setError('');\n  };\n\n  return (\n    <>\n      <button\n        onClick={openModal}\n        class=\"flex items-center gap-2 px-3 py-2 text-sm rounded-lg border hover:bg-muted transition-colors\"\n        title=\"Compartilhar conversa\"\n      >\n        <Share2 size={16} />\n        <span>Compartilhar</span>\n      </button>\n\n      <Show when={showModal()}>\n        <div class=\"fixed inset-0 z-50 flex items-center justify-center bg-black/50\">\n          <div class=\"bg-card border rounded-lg shadow-lg p-6 max-w-md w-full mx-4\">\n            <div class=\"flex items-center justify-between mb-4\">\n              <h3 class=\"text-lg font-semibold\">Compartilhar Conversa</h3>\n              <button\n                onClick={closeModal}\n                class=\"hover:bg-muted rounded p-1 transition-colors\"\n              >\n                <X size={20} />\n              </button>\n            </div>\n\n            <Show when={!shareUrl()}>\n              <div class=\"space-y-4\">\n                <div>\n                  <label class=\"block text-sm font-medium mb-2\">\n                    T\u00edtulo (opcional)\n                  </label>\n                  <input\n                    type=\"text\"\n                    class=\"input w-full\"\n                    value={title()}\n                    onInput={(e) => setTitle(e.currentTarget.value)}\n                    placeholder=\"D\u00ea um t\u00edtulo para esta conversa\"\n                  />\n                </div>\n\n                <p class=\"text-sm text-muted-foreground\">\n                  Ao compartilhar, voc\u00ea criar\u00e1 um link p\u00fablico que qualquer pessoa pode acessar.\n                  O link expirar\u00e1 em 30 dias.\n                </p>\n\n                <Show when={error()}>\n                  <div class=\"p-3 rounded bg-red-500/10 text-red-500 text-sm\">\n                    {error()}\n                  </div>\n                </Show>\n\n                <button\n                  onClick={shareConversation}\n                  disabled={isSharing()}\n                  class=\"btn btn-primary w-full\"\n                >\n                  {isSharing() ?", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4363, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "74fd36b4-a43b-48dd-95bf-a4542230e8c5": {"__data__": {"id_": "74fd36b4-a43b-48dd-95bf-a4542230e8c5", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\components\\ShareButton.tsx", "language": "typescript", "lines": 199, "filename": "ShareButton.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\components\\ShareButton.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\components\\ShareButton.tsx", "language": "typescript", "lines": 199, "filename": "ShareButton.tsx"}, "hash": "96815596cb2700df214912352706cf9593b55a9918fbbf59c50110e0ca65fa18", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "539cdc3e-8082-4669-adb7-563bb9c45a98", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\components\\ShareButton.tsx", "language": "typescript", "lines": 199, "filename": "ShareButton.tsx"}, "hash": "ea6303893a016b6e8d0820a25957b9dedef172b8b000151fee1dbf60fffdd8c5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "'Compartilhando...' : 'Criar Link de Compartilhamento'}\n                </button>\n              </div>\n            </Show>\n\n            <Show when={shareUrl()}>\n              <div class=\"space-y-4\">\n                <div class=\"p-3 rounded bg-green-500/10 text-green-500 text-sm\">\n                  \u2713 Conversa compartilhada com sucesso!\n                </div>\n\n                <div>\n                  <label class=\"block text-sm font-medium mb-2\">\n                    Link de compartilhamento\n                  </label>\n                  <div class=\"flex gap-2\">\n                    <input\n                      type=\"text\"\n                      class=\"input flex-1\"\n                      value={shareUrl()}\n                      readonly\n                    />\n                    <button\n                      onClick={copyToClipboard}\n                      class=\"btn btn-primary\"\n                      title=\"Copiar link\"\n                    >\n                      <Show when={!copied()} fallback={<Check size={16} />}>\n                        <Copy size={16} />\n                      </Show>\n                    </button>\n                  </div>\n                </div>\n\n                <p class=\"text-sm text-muted-foreground\">\n                  Este link \u00e9 p\u00fablico e funcionar\u00e1 por 30 dias. Qualquer pessoa com o link poder\u00e1 visualizar esta conversa.\n                </p>\n\n                <button\n                  onClick={closeModal}\n                  class=\"btn w-full\"\n                >\n                  Fechar\n                </button>\n              </div>\n            </Show>\n          </div>\n        </div>\n      </Show>\n    </>\n  );\n}", "mimetype": "text/plain", "start_char_idx": 4364, "end_char_idx": 6014, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b6262f19-5eaa-43b0-9684-64f4e7690847": {"__data__": {"id_": "b6262f19-5eaa-43b0-9684-64f4e7690847", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\components\\Typewriter.tsx", "language": "typescript", "lines": 124, "filename": "Typewriter.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\components\\Typewriter.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\components\\Typewriter.tsx", "language": "typescript", "lines": 124, "filename": "Typewriter.tsx"}, "hash": "0e6dd25f31f7a1c09104a65b81abe32b7570353b95b6e799f453abd0b29827b3", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import { createSignal, createEffect, onCleanup } from 'solid-js';\n\ninterface TypewriterProps {\n  text: string;\n  speed?: number; // ms por caractere (padr\u00e3o: 20ms)\n  onComplete?: () => void; // Callback quando terminar de digitar\n}\n\n/**\n * Componente Typewriter - Efeito de digita\u00e7\u00e3o ChatGPT-like\n *\n * Renderiza texto com efeito de digita\u00e7\u00e3o suave, caractere por caractere.\n * Perfeito para respostas de chat/IA que chegam via streaming.\n *\n * @example\n * ```tsx\n * <Typewriter\n *   text={message.text}\n *   speed={15}\n *   onComplete={() => console.log('Digita\u00e7\u00e3o conclu\u00edda!')}\n * />\n * ```\n */\nexport function Typewriter(props: TypewriterProps) {\n  const [displayedText, setDisplayedText] = createSignal('');\n  const [currentIndex, setCurrentIndex] = createSignal(0);\n  const [isTyping, setIsTyping] = createSignal(false);\n\n  createEffect(() => {\n    const targetText = props.text;\n    const speed = props.speed || 20;\n\n    // Se o texto alvo mudou (nova atualiza\u00e7\u00e3o do streaming)\n    if (targetText !== displayedText()) {\n      // Se o novo texto \u00e9 uma extens\u00e3o do atual, continuar digitando\n      if (targetText.startsWith(displayedText())) {\n        setIsTyping(true);\n\n        const interval = setInterval(() => {\n          setCurrentIndex((prev) => {\n            const nextIndex = prev + 1;\n\n            if (nextIndex <= targetText.length) {\n              setDisplayedText(targetText.slice(0, nextIndex));\n              return nextIndex;\n            } else {\n              // Terminou de digitar\n              clearInterval(interval);\n              setIsTyping(false);\n              if (props.onComplete) {\n                props.onComplete();\n              }\n              return prev;\n            }\n          });\n        }, speed);\n\n        onCleanup(() => clearInterval(interval));\n      } else {\n        // Se o texto \u00e9 completamente diferente, resetar\n        setDisplayedText(targetText);\n        setCurrentIndex(targetText.length);\n        setIsTyping(false);\n      }\n    }\n  });\n\n  return (\n    <span class=\"whitespace-pre-wrap\">\n      {displayedText()}\n      {/* Cursor piscante quando est\u00e1 digitando */}\n      {isTyping() && (\n        <span class=\"inline-block w-0.5 h-4 bg-primary ml-0.5 animate-pulse\" />\n      )}\n    </span>\n  );\n}\n\n/**\n * Hook alternativo para controle manual do efeito typewriter\n * \u00datil quando voc\u00ea precisa de mais controle sobre o comportamento\n */\nexport function createTypewriter(initialText = '', speed = 20) {\n  const [displayedText, setDisplayedText] = createSignal('');\n  const [targetText, setTargetText] = createSignal(initialText);\n  const [isTyping, setIsTyping] = createSignal(false);\n\n  createEffect(() => {\n    const target = targetText();\n    const current = displayedText();\n\n    if (target === current) {\n      setIsTyping(false);\n      return;\n    }\n\n    setIsTyping(true);\n\n    const interval = setInterval(() => {\n      setDisplayedText((prev) => {\n        if (prev.length < target.length) {\n          return target.slice(0, prev.length + 1);\n        } else {\n          clearInterval(interval);\n          setIsTyping(false);\n          return prev;\n        }\n      });\n    }, speed);\n\n    onCleanup(() => clearInterval(interval));\n  });\n\n  return {\n    displayedText,\n    isTyping,\n    setTargetText,\n    reset: () => {\n      setDisplayedText('');\n      setTargetText('');\n    },\n  };\n}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3345, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "045f4874-3324-4ac5-ab6a-4b936c64e074": {"__data__": {"id_": "045f4874-3324-4ac5-ab6a-4b936c64e074", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\components\\TypingIndicator.tsx", "language": "typescript", "lines": 13, "filename": "TypingIndicator.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\components\\TypingIndicator.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\components\\TypingIndicator.tsx", "language": "typescript", "lines": 13, "filename": "TypingIndicator.tsx"}, "hash": "7999182c6b7033ee40c225f09e99ba1875fa98483d37c1a3c3dd4a5f69be60b7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import { Component } from 'solid-js';\nimport './TypingIndicator.css';\n\nexport const TypingIndicator: Component = () => {\n  return (\n    <div class=\"typing-indicator\">\n      <span class=\"dot\"></span>\n      <span class=\"dot\"></span>\n      <span class=\"dot\"></span>\n    </div>\n  );\n};", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 281, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "31a812da-583e-4a47-9001-464e6aa20463": {"__data__": {"id_": "31a812da-583e-4a47-9001-464e6aa20463", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\components\\UserPreferences.tsx", "language": "typescript", "lines": 137, "filename": "UserPreferences.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\components\\UserPreferences.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\components\\UserPreferences.tsx", "language": "typescript", "lines": 137, "filename": "UserPreferences.tsx"}, "hash": "d7af2f90dc4cb43a7c98b2feb95e469587d99716da1185deae5bdb0c2a8190af", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import { createSignal, createResource, For, Show } from 'solid-js';\nimport auth from '@/store/auth';\n\ninterface PreferenceKey {\n  key: string;\n  description: string;\n  options?: string[];\n  type?: string;\n  default?: string;\n}\n\nexport function UserPreferences() {\n  const [saving, setSaving] = createSignal(false);\n  const [message, setMessage] = createSignal('');\n  const [preferences, setPreferences] = createSignal<Record<string, string>>({});\n\n  // Fetch common keys\n  const [commonKeys] = createResource(async () => {\n    const response = await fetch('/api/v1/preferences/common/keys');\n    const data = await response.json();\n    return data.keys as PreferenceKey[];\n  });\n\n  // Fetch user preferences\n  const [userPrefs, { refetch }] = createResource(async () => {\n    const token = auth.token();\n    if (!token) return { preferences: {} };\n\n    const response = await fetch('/api/v1/preferences', {\n      headers: { 'Authorization': `Bearer ${token}` }\n    });\n    const data = await response.json();\n    setPreferences(data.preferences || {});\n    return data;\n  });\n\n  const savePreferences = async () => {\n    const token = auth.token();\n    if (!token) return;\n\n    setSaving(true);\n    setMessage('');\n\n    try {\n      const response = await fetch('/api/v1/preferences/batch', {\n        method: 'PUT',\n        headers: {\n          'Content-Type': 'application/json',\n          'Authorization': `Bearer ${token}`\n        },\n        body: JSON.stringify(preferences())\n      });\n\n      if (!response.ok) {\n        throw new Error('Falha ao salvar prefer\u00eancias');\n      }\n\n      setMessage('\u2713 Prefer\u00eancias salvas com sucesso!');\n      setTimeout(() => setMessage(''), 3000);\n      refetch();\n    } catch (err) {\n      console.error('Error saving preferences:', err);\n      setMessage('\u2717 Erro ao salvar prefer\u00eancias');\n    } finally {\n      setSaving(false);\n    }\n  };\n\n  const updatePreference = (key: string, value: string) => {\n    setPreferences(prev => ({ ...prev, [key]: value }));\n  };\n\n  return (\n    <div class=\"space-y-6\">\n      <div>\n        <h3 class=\"text-lg font-semibold mb-2\">Prefer\u00eancias do Usu\u00e1rio</h3>\n        <p class=\"text-sm text-muted-foreground\">\n          Configure suas prefer\u00eancias para personalizar sua experi\u00eancia no Chat BI.\n        </p>\n      </div>\n\n      <Show when={!commonKeys.loading} fallback={<div>Carregando...</div>}>\n        <div class=\"space-y-4\">\n          <For each={commonKeys()}>\n            {(prefKey) => (\n              <div class=\"space-y-2\">\n                <label class=\"block text-sm font-medium\">\n                  {prefKey.description}\n                </label>\n                <Show\n                  when={prefKey.options}\n                  fallback={\n                    <input\n                      type=\"text\"\n                      class=\"input w-full\"\n                      value={preferences()[prefKey.key] || ''}\n                      onInput={(e) => updatePreference(prefKey.key, e.currentTarget.value)}\n                      placeholder={`Digite ${prefKey.description.toLowerCase()}`}\n                    />\n                  }\n                >\n                  <select\n                    class=\"input w-full\"\n                    value={preferences()[prefKey.key] || prefKey.default || ''}\n                    onChange={(e) => updatePreference(prefKey.key, e.currentTarget.value)}\n                  >\n                    <option value=\"\">Selecione...</option>\n                    <For each={prefKey.options}>\n                      {(option) => <option value={option}>{option}</option>}\n                    </For>\n                  </select>\n                </Show>\n              </div>\n            )}\n          </For>\n        </div>\n\n        <div class=\"flex items-center gap-4 pt-4\">\n          <button\n            onClick={savePreferences}\n            disabled={saving()}\n            class=\"btn btn-primary\"\n          >\n            {saving() ? 'Salvando...' : 'Salvar Prefer\u00eancias'}\n          </button>\n\n          <Show when={message()}>\n            <span class={`text-sm ${message().startsWith('\u2713') ? 'text-green-500' : 'text-red-500'}`}>\n              {message()}\n            </span>\n          </Show>\n        </div>\n      </Show>\n    </div>\n  );\n}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4227, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "526a6d51-227e-4fde-b8eb-cc5cfb3d1ce4": {"__data__": {"id_": "526a6d51-227e-4fde-b8eb-cc5cfb3d1ce4", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\components\\__tests__\\Chat.test.tsx", "language": "typescript", "lines": 223, "filename": "Chat.test.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\components\\__tests__\\Chat.test.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\components\\__tests__\\Chat.test.tsx", "language": "typescript", "lines": 223, "filename": "Chat.test.tsx"}, "hash": "b8d3448bcb8f04a07b5278237f78baffabf4560ce7b603bd224d57abb7305183", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "fdadf60d-92b9-411e-bf80-169904d910bc", "node_type": "1", "metadata": {}, "hash": "a7c52e85897a4a91e2f2540646139d6de889f779df12bcc096cabab32ee6d362", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "// frontend-solid/src/components/__tests__/Chat.test.tsx\n\nimport { render, screen, fireEvent, cleanup } from 'solid-testing-library';\nimport { Show } from 'solid-js';\nimport { vi, beforeEach, afterEach, expect, test } from 'vitest';\n\nimport Chat from '../../pages/Chat';\nimport auth from '@/store/auth';\n\n// Mock the Typewriter component as it's just visual\nvi.mock('@/components', () => ({\n  Typewriter: (props: any) => <span data-testid=\"typewriter\">{props.text}</span>,\n}));\n\n// Mock PlotlyChart and DataTable\nvi.mock('@/components/PlotlyChart', () => ({\n  PlotlyChart: (props: any) => <div data-testid=\"plotly-chart\">{JSON.stringify(props.chartSpec())}</div>,\n}));\n\nvi.mock('@/components/DataTable', () => ({\n  DataTable: (props: any) => <div data-testid=\"data-table\">{JSON.stringify(props.data())}</div>,\n}));\n\n// Mock FeedbackButtons and DownloadButton (for rendering only, not functionality)\nvi.mock('@/components/FeedbackButtons', () => ({\n    FeedbackButtons: (props: any) => <button data-testid=\"feedback-button\" onClick={() => props.onFeedback(props.messageId, 'positive')}>Feedback</button>,\n}));\n\nvi.mock('@/components/DownloadButton', () => ({\n    DownloadButton: (props: any) => <button data-testid=\"download-button\">Download {props.filename}</button>,\n}));\n\n// Mock formatTimestamp\nvi.mock('@/lib/formatters', () => ({\n  formatTimestamp: vi.fn(() => '12:00 PM'),\n}));\n\n\n// Mock EventSource for SSE\nclass MockEventSource {\n  onmessage: (event: MessageEvent) => void = () => {};\n  onerror: (event: Event) => void = () => {};\n  close = vi.fn();\n  url: string;\n\n  constructor(url: string) {\n    this.url = url;\n    MockEventSource.instances.push(this);\n  }\n\n  // Static array to hold all instances for easy access in tests\n  static instances: MockEventSource[] = [];\n  static reset() {\n    MockEventSource.instances = [];\n  }\n}\n\nvi.stubGlobal('EventSource', MockEventSource);\n\nbeforeEach(() => {\n  cleanup(); // Clean up DOM after each test\n  MockEventSource.reset(); // Reset mock instances\n  auth.setToken('mock_valid_token'); // Ensure auth token is set\n  auth.setUser({ id: '1', username: 'testuser' });\n  vi.clearAllMocks(); // Clear mocks\n});\n\nafterEach(() => {\n    cleanup();\n});\n\ntest('Chat component renders initial message', () => {\n  render(() => <Chat />);\n  expect(screen.getByText(/Ol\u00e1! Sou seu assistente de BI./i)).toBeInTheDocument();\n});\n\ntest('sends user message and starts streaming', async () => {\n  render(() => <Chat />);\n  const inputElement = screen.getByPlaceholderText(/Fa\u00e7a uma pergunta sobre os dados.../i) as HTMLInputElement;\n  const sendButton = screen.getByRole('button', { name: /Enviar/i });\n\n  fireEvent.input(inputElement, { target: { value: 'Test message' } });\n  fireEvent.click(sendButton);\n\n  expect(screen.getByText('Test message')).toBeInTheDocument();\n  expect(inputElement.value).toBe('');\n  expect(sendButton).toBeDisabled(); // Should be disabled while streaming\n  \n  expect(MockEventSource.instances.length).toBe(1);\n  expect(MockEventSource.instances[0].url).toContain('q=Test%20message');\n});\n\ntest('receives streaming text response', async () => {\n    render(() => <Chat />);\n    const inputElement = screen.getByPlaceholderText(/Fa\u00e7a uma pergunta sobre os dados.../i) as HTMLInputElement;\n    const sendButton = screen.getByRole('button', { name: /Enviar/i });\n\n    fireEvent.input(inputElement, { target: { value: 'Stream test' } });\n    fireEvent.click(sendButton);\n\n    const es = MockEventSource.instances[0];\n\n    // Simulate streaming chunks\n    es.onmessage({ data: JSON.stringify({ type: 'text', text: 'First part ', done: false }) } as MessageEvent);\n    es.onmessage({ data: JSON.stringify({ type: 'text', text: 'second part.', done: false }) } as MessageEvent);\n\n    // Final chunk\n    es.onmessage({ data: JSON.stringify({ type: 'final', text: '', done: true }) } as MessageEvent);\n\n    await vi.waitFor(() => {\n        expect(screen.getByTestId('typewriter')).toHaveTextContent('First part second part.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3979, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "fdadf60d-92b9-411e-bf80-169904d910bc": {"__data__": {"id_": "fdadf60d-92b9-411e-bf80-169904d910bc", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\components\\__tests__\\Chat.test.tsx", "language": "typescript", "lines": 223, "filename": "Chat.test.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\components\\__tests__\\Chat.test.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\components\\__tests__\\Chat.test.tsx", "language": "typescript", "lines": 223, "filename": "Chat.test.tsx"}, "hash": "b8d3448bcb8f04a07b5278237f78baffabf4560ce7b603bd224d57abb7305183", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "526a6d51-227e-4fde-b8eb-cc5cfb3d1ce4", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\components\\__tests__\\Chat.test.tsx", "language": "typescript", "lines": 223, "filename": "Chat.test.tsx"}, "hash": "bf3e66d112afc55891f40417635b705e54fcb33e24f2479acd99289e4a2c0bc9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c5ec22ec-a362-46d4-b036-15dcd534bbc2", "node_type": "1", "metadata": {}, "hash": "3810086617006571092c935df449f31a80bc28600cc81b37b32186b19c7d00ab", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "');\n        expect(sendButton).toBeEnabled(); // Should be enabled after streaming ends\n    });\n    expect(es.close).toHaveBeenCalledTimes(1);\n});\n\ntest('renders chart response', async () => {\n    render(() => <Chat />);\n    const inputElement = screen.getByPlaceholderText(/Fa\u00e7a uma pergunta sobre os dados.../i) as HTMLInputElement;\n    const sendButton = screen.getByRole('button', { name: /Enviar/i });\n\n    fireEvent.input(inputElement, { target: { value: 'Show me a chart' } });\n    fireEvent.click(sendButton);\n\n    const es = MockEventSource.instances[0];\n    const mockChartSpec = { data: [{ type: 'bar', y: [1, 2, 3] }], layout: { title: 'Test Chart' } };\n\n    es.onmessage({ data: JSON.stringify({ type: 'text', text: 'Here is your chart: ', done: false }) } as MessageEvent);\n    es.onmessage({ data: JSON.stringify({ type: 'chart', chart_spec: mockChartSpec, done: false }) } as MessageEvent);\n    es.onmessage({ data: JSON.stringify({ type: 'final', text: '', done: true }) } as MessageEvent);\n\n    await vi.waitFor(() => {\n        expect(screen.getByTestId('plotly-chart')).toBeInTheDocument();\n        expect(screen.getByTestId('plotly-chart')).toHaveTextContent(JSON.stringify(mockChartSpec));\n    });\n});\n\ntest('renders table response with download button', async () => {\n    render(() => <Chat />);\n    const inputElement = screen.getByPlaceholderText(/Fa\u00e7a uma pergunta sobre os dados.../i) as HTMLInputElement;\n    const sendButton = screen.getByRole('button', { name: /Enviar/i });\n\n    fireEvent.input(inputElement, { target: { value: 'Show me table data' } });\n    fireEvent.click(sendButton);\n\n    const es = MockEventSource.instances[0];\n    const mockTableData = [{ id: 1, name: 'Item A' }, { id: 2, name: 'Item B' }];\n\n    es.onmessage({ data: JSON.stringify({ type: 'table', data: mockTableData, done: false }) } as MessageEvent);\n    es.onmessage({ data: JSON.stringify({ type: 'final', text: '', done: true }) } as MessageEvent);\n\n    await vi.waitFor(() => {\n        expect(screen.getByTestId('data-table')).toBeInTheDocument();\n        expect(screen.getByTestId('data-table')).toHaveTextContent(JSON.stringify(mockTableData));\n        expect(screen.getByTestId('download-button')).toBeInTheDocument();\n    });\n});\n\ntest('handles error during streaming', async () => {\n  render(() => <Chat />);\n  const inputElement = screen.getByPlaceholderText(/Fa\u00e7a uma pergunta sobre os dados.../i) as HTMLInputElement;\n  const sendButton = screen.getByRole('button', { name: /Enviar/i });\n\n  fireEvent.input(inputElement, { target: { value: 'Error test' } });\n  fireEvent.click(sendButton);\n\n  const es = MockEventSource.instances[0];\n\n  es.onmessage({ data: JSON.stringify({ type: 'error', error: 'Simulated backend error', details: { code: 500 } }) } as MessageEvent);\n\n  await vi.waitFor(() => {\n    expect(screen.getByText(/Erro do servidor/i)).toBeInTheDocument();\n    expect(screen.getByText(/Simulated backend error/i)).toBeInTheDocument();\n    expect(sendButton).toBeEnabled();\n  });\n  expect(es.close).toHaveBeenCalledTimes(1);\n});\n\ntest('feedback button appears after streaming ends', async () => {\n    render(() => <Chat />);\n    const inputElement = screen.getByPlaceholderText(/Fa\u00e7a uma pergunta sobre os dados.../i) as HTMLInputElement;\n    const sendButton = screen.getByRole('button', { name: /Enviar/i });\n\n    fireEvent.input(inputElement, { target: { value: 'Feedback test' } });\n    fireEvent.click(sendButton);\n\n    const es = MockEventSource.instances[0];\n    es.onmessage({ data: JSON.stringify({ type: 'text', text: 'This is a test message.", "mimetype": "text/plain", "start_char_idx": 3979, "end_char_idx": 7563, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c5ec22ec-a362-46d4-b036-15dcd534bbc2": {"__data__": {"id_": "c5ec22ec-a362-46d4-b036-15dcd534bbc2", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\components\\__tests__\\Chat.test.tsx", "language": "typescript", "lines": 223, "filename": "Chat.test.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\components\\__tests__\\Chat.test.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\components\\__tests__\\Chat.test.tsx", "language": "typescript", "lines": 223, "filename": "Chat.test.tsx"}, "hash": "b8d3448bcb8f04a07b5278237f78baffabf4560ce7b603bd224d57abb7305183", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fdadf60d-92b9-411e-bf80-169904d910bc", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\components\\__tests__\\Chat.test.tsx", "language": "typescript", "lines": 223, "filename": "Chat.test.tsx"}, "hash": "f0a8e592935864fe3101ed5a6d5e07047f32029d68198808032d3da091c88255", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "', done: false }) } as MessageEvent);\n    es.onmessage({ data: JSON.stringify({ type: 'final', text: '', done: true }) } as MessageEvent);\n\n    await vi.waitFor(() => {\n        expect(screen.getByTestId('feedback-button')).toBeInTheDocument();\n    });\n});\n\ntest('feedback submission handler is called', async () => {\n    render(() => <Chat />);\n    const inputElement = screen.getByPlaceholderText(/Fa\u00e7a uma pergunta sobre os dados.../i) as HTMLInputElement;\n    const sendButton = screen.getByRole('button', { name: /Enviar/i });\n\n    fireEvent.input(inputElement, { target: { value: 'Feedback test' } });\n    fireEvent.click(sendButton);\n\n    const es = MockEventSource.instances[0];\n    es.onmessage({ data: JSON.stringify({ type: 'text', text: 'Response with ID', done: false }) } as MessageEvent);\n    es.onmessage({ data: JSON.stringify({ type: 'final', text: '', done: true }) } as MessageEvent);\n\n    // Mock the fetch call for feedback\n    const mockFetch = vi.fn(() => Promise.resolve({ ok: true }));\n    vi.stubGlobal('fetch', mockFetch);\n\n    await vi.waitFor(() => {\n        const feedbackButton = screen.getByTestId('feedback-button');\n        fireEvent.click(feedbackButton); // Click the mock feedback button\n    });\n    \n    expect(mockFetch).toHaveBeenCalledTimes(1);\n    expect(mockFetch).toHaveBeenCalledWith('/api/v1/chat/feedback', expect.objectContaining({\n        method: 'POST',\n        body: expect.stringContaining('\"feedback_type\":\"positive\"')\n    }));\n});", "mimetype": "text/plain", "start_char_idx": 7563, "end_char_idx": 9047, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "cb8419bd-b7d9-4935-a5b9-9030cfbd884a": {"__data__": {"id_": "cb8419bd-b7d9-4935-a5b9-9030cfbd884a", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\examples\\ComponentsDemo.tsx", "language": "typescript", "lines": 167, "filename": "ComponentsDemo.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\examples\\ComponentsDemo.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\examples\\ComponentsDemo.tsx", "language": "typescript", "lines": 167, "filename": "ComponentsDemo.tsx"}, "hash": "0c7c1c669410d34e60cecf09c0cd805c0a0fb4ead64e817b9b945c8e7b02cff3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f9b17343-3f48-47a5-a0bc-1eb75919c430", "node_type": "1", "metadata": {}, "hash": "14b9e6b035c88608a04a314c04152ebe18c3f96d448ebee52fcd0f80d9f2548b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import { Badge, Button, Skeleton } from \"./migrated-components/components/ui\";\n\n/**\n * Demo page for migrated UI components\n * Showcases Skeleton, Badge, and Button components\n */\nexport default function ComponentsDemo() {\n  return (\n    <div class=\"min-h-screen bg-background p-8\">\n      <div class=\"max-w-6xl mx-auto space-y-12\">\n        {/* Header */}\n        <div class=\"text-center space-y-2\">\n          <h1 class=\"text-4xl font-bold text-foreground\">\n            Componentes UI Migrados\n          </h1>\n          <p class=\"text-lg text-muted-foreground\">\n            React \u2192 SolidJS | Fase 3 da Migra\u00e7\u00e3o\n          </p>\n        </div>\n\n        {/* Button Component */}\n        <section class=\"space-y-6\">\n          <div>\n            <h2 class=\"text-2xl font-semibold text-foreground mb-2\">Button</h2>\n            <p class=\"text-muted-foreground\">6 variantes \u00d7 6 tamanhos = 36 combina\u00e7\u00f5es</p>\n          </div>\n\n          <div class=\"space-y-4\">\n            <div>\n              <h3 class=\"text-lg font-medium text-foreground mb-3\">Variantes</h3>\n              <div class=\"flex flex-wrap gap-3\">\n                <Button variant=\"default\">Default</Button>\n                <Button variant=\"secondary\">Secondary</Button>\n                <Button variant=\"destructive\">Destructive</Button>\n                <Button variant=\"outline\">Outline</Button>\n                <Button variant=\"ghost\">Ghost</Button>\n                <Button variant=\"link\">Link</Button>\n              </div>\n            </div>\n\n            <div>\n              <h3 class=\"text-lg font-medium text-foreground mb-3\">Tamanhos</h3>\n              <div class=\"flex flex-wrap items-center gap-3\">\n                <Button size=\"sm\">Small</Button>\n                <Button size=\"default\">Default</Button>\n                <Button size=\"lg\">Large</Button>\n                <Button size=\"icon\">\ud83d\ude80</Button>\n                <Button size=\"icon-sm\">\u2b50</Button>\n                <Button size=\"icon-lg\">\ud83d\udc8e</Button>\n              </div>\n            </div>\n\n            <div>\n              <h3 class=\"text-lg font-medium text-foreground mb-3\">Estados</h3>\n              <div class=\"flex flex-wrap gap-3\">\n                <Button>Normal</Button>", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2184, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f9b17343-3f48-47a5-a0bc-1eb75919c430": {"__data__": {"id_": "f9b17343-3f48-47a5-a0bc-1eb75919c430", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\examples\\ComponentsDemo.tsx", "language": "typescript", "lines": 167, "filename": "ComponentsDemo.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\examples\\ComponentsDemo.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\examples\\ComponentsDemo.tsx", "language": "typescript", "lines": 167, "filename": "ComponentsDemo.tsx"}, "hash": "0c7c1c669410d34e60cecf09c0cd805c0a0fb4ead64e817b9b945c8e7b02cff3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "cb8419bd-b7d9-4935-a5b9-9030cfbd884a", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\examples\\ComponentsDemo.tsx", "language": "typescript", "lines": 167, "filename": "ComponentsDemo.tsx"}, "hash": "b893e8c262d318b24ea2b2bc09cb6985c3bec0a4a94f6c71930252d9215f4ac6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5ea31a2e-91c4-4ddb-aefa-3bef96f4ea9d", "node_type": "1", "metadata": {}, "hash": "c49b5c8864280acac6e77d8a4a2b70c9f09ba54f0b8bab01fdb84668a24904c9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "<Button>Normal</Button>\n                <Button disabled>Disabled</Button>\n              </div>\n            </div>\n          </div>\n        </section>\n\n        {/* Badge Component */}\n        <section class=\"space-y-6\">\n          <div>\n            <h2 class=\"text-2xl font-semibold text-foreground mb-2\">Badge</h2>\n            <p class=\"text-muted-foreground\">4 variantes para status e labels</p>\n          </div>\n\n          <div class=\"space-y-4\">\n            <div>\n              <h3 class=\"text-lg font-medium text-foreground mb-3\">Variantes</h3>\n              <div class=\"flex flex-wrap gap-3\">\n                <Badge variant=\"default\">Default</Badge>\n                <Badge variant=\"secondary\">Secondary</Badge>\n                <Badge variant=\"destructive\">Destructive</Badge>\n                <Badge variant=\"outline\">Outline</Badge>\n              </div>\n            </div>\n\n            <div>\n              <h3 class=\"text-lg font-medium text-foreground mb-3\">Casos de Uso</h3>\n              <div class=\"flex flex-wrap gap-3\">\n                <Badge variant=\"default\">New</Badge>\n                <Badge variant=\"secondary\">In Progress</Badge>\n                <Badge variant=\"outline\">Draft</Badge>\n                <Badge variant=\"destructive\">Error</Badge>\n              </div>\n            </div>\n          </div>\n        </section>\n\n        {/* Skeleton Component */}\n        <section class=\"space-y-6\">\n          <div>\n            <h2 class=\"text-2xl font-semibold text-foreground mb-2\">Skeleton</h2>\n            <p class=\"text-muted-foreground\">Loading states</p>\n          </div>\n\n          <div class=\"space-y-4\">\n            <div class=\"border border-border rounded-lg p-6 space-y-4\">\n              <div class=\"flex items-center space-x-4\">\n                <Skeleton class=\"h-12 w-12 rounded-full\" />\n                <div class=\"flex-1 space-y-2\">\n                  <Skeleton class=\"h-4 w-3/4\" />\n                  <Skeleton class=\"h-4 w-1/2\" />\n                </div>\n              </div>", "mimetype": "text/plain", "start_char_idx": 2161, "end_char_idx": 4160, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5ea31a2e-91c4-4ddb-aefa-3bef96f4ea9d": {"__data__": {"id_": "5ea31a2e-91c4-4ddb-aefa-3bef96f4ea9d", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\examples\\ComponentsDemo.tsx", "language": "typescript", "lines": 167, "filename": "ComponentsDemo.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\examples\\ComponentsDemo.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\examples\\ComponentsDemo.tsx", "language": "typescript", "lines": 167, "filename": "ComponentsDemo.tsx"}, "hash": "0c7c1c669410d34e60cecf09c0cd805c0a0fb4ead64e817b9b945c8e7b02cff3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f9b17343-3f48-47a5-a0bc-1eb75919c430", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\examples\\ComponentsDemo.tsx", "language": "typescript", "lines": 167, "filename": "ComponentsDemo.tsx"}, "hash": "199056f6f79c824069e53d766f753aaa5fa5d9b01dfe3f1d61dd5b72b76aa6b9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "665fe818-e55d-4265-81b1-0b90fabcd1b4", "node_type": "1", "metadata": {}, "hash": "abfed702a52772f263aa90ac2bf33201d2be7c67d0089b2e59af15948a5e8be9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "</div>\n              </div>\n            </div>\n          </div>\n        </section>\n\n        {/* Integration Example */}\n        <section class=\"space-y-6\">\n          <div>\n            <h2 class=\"text-2xl font-semibold text-foreground mb-2\">Integra\u00e7\u00e3o</h2>\n            <p class=\"text-muted-foreground\">Componentes trabalhando juntos</p>\n          </div>\n\n          <div class=\"border border-border rounded-lg p-6 space-y-4\">\n            <div class=\"flex items-center justify-between\">\n              <div class=\"space-y-1\">\n                <h3 class=\"text-lg font-medium text-foreground\">Card de Exemplo</h3>\n                <p class=\"text-sm text-muted-foreground\">Demonstra\u00e7\u00e3o de integra\u00e7\u00e3o</p>\n              </div>\n              <Badge variant=\"default\">Active</Badge>\n            </div>\n            <div class=\"flex gap-2\">\n              <Button variant=\"default\" size=\"sm\">Salvar</Button>\n              <Button variant=\"outline\" size=\"sm\">Cancelar</Button>\n              <Button variant=\"destructive\" size=\"sm\">Excluir</Button>\n            </div>\n          </div>\n        </section>\n\n        {/* Status */}\n        <section class=\"border-t border-border pt-6\">\n          <h3 class=\"text-lg font-medium text-foreground mb-3\">Status da Migra\u00e7\u00e3o</h3>\n          <div class=\"grid grid-cols-1 md:grid-cols-3 gap-4\">\n            <div class=\"border border-border rounded-lg p-4 space-y-2\">\n              <div class=\"flex items-center justify-between\">\n                <h4 class=\"font-medium text-foreground\">Skeleton</h4>\n                <Badge variant=\"default\">\u2713</Badge>\n              </div>\n              <p class=\"text-sm text-muted-foreground\">3/4 testes passando</p>\n            </div>\n            <div class=\"border border-border rounded-lg p-4 space-y-2\">\n              <div class=\"flex items-center justify-between\">\n                <h4 class=\"font-medium text-foreground\">Badge</h4>\n                <Badge variant=\"default\">\u2713</Badge>\n              </div>\n              <p class=\"text-sm text-muted-foreground\">6/6 testes passando</p>\n            </div>\n            <div class=\"border border-border rounded-lg p-4 space-y-2\">\n              <div class=\"flex items-center justify-between\">", "mimetype": "text/plain", "start_char_idx": 4133, "end_char_idx": 6324, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "665fe818-e55d-4265-81b1-0b90fabcd1b4": {"__data__": {"id_": "665fe818-e55d-4265-81b1-0b90fabcd1b4", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\examples\\ComponentsDemo.tsx", "language": "typescript", "lines": 167, "filename": "ComponentsDemo.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\examples\\ComponentsDemo.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\examples\\ComponentsDemo.tsx", "language": "typescript", "lines": 167, "filename": "ComponentsDemo.tsx"}, "hash": "0c7c1c669410d34e60cecf09c0cd805c0a0fb4ead64e817b9b945c8e7b02cff3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5ea31a2e-91c4-4ddb-aefa-3bef96f4ea9d", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\examples\\ComponentsDemo.tsx", "language": "typescript", "lines": 167, "filename": "ComponentsDemo.tsx"}, "hash": "25f7bf49d11d894a512d5cca9f4bfde031db125d5d99593c1e0c53424381deac", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "<div class=\"flex items-center justify-between\">\n                <h4 class=\"font-medium text-foreground\">Button</h4>\n                <Badge variant=\"default\">\u2713</Badge>\n              </div>\n              <p class=\"text-sm text-muted-foreground\">8/8 testes passando</p>\n            </div>\n          </div>\n        </section>\n      </div>\n    </div>\n  );\n}", "mimetype": "text/plain", "start_char_idx": 6277, "end_char_idx": 6629, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0528e03e-6b56-4cac-818a-d298e59ad66a": {"__data__": {"id_": "0528e03e-6b56-4cac-818a-d298e59ad66a", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\examples\\MinimalLogin.tsx", "language": "typescript", "lines": 14, "filename": "MinimalLogin.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\examples\\MinimalLogin.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\examples\\MinimalLogin.tsx", "language": "typescript", "lines": 14, "filename": "MinimalLogin.tsx"}, "hash": "3f979a68a0df2deaa7f268e63b33169aef443950a192106573c4424a8dee151a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "export default function MinimalLogin() {\n  return (\n    <div style={{ display: 'flex', justifyContent: 'center', alignItems: 'center', height: '100vh', backgroundColor: '#020817', color: '#f8fafc' }}>\n      <div style={{ padding: '2rem', backgroundColor: '#0f172a', borderRadius: '0.5rem', border: '1px solid #1e293b', boxShadow: '0 4px 6px rgba(0,0,0,0.1)' }}>\n        <h1 style={{ fontSize: '1.5rem', fontWeight: 'bold', color: '#38bdf8', textAlign: 'center', marginBottom: '1rem' }}>Login M\u00ednimo</h1>\n        <p style={{ color: '#94a3b8', textAlign: 'center' }}>A p\u00e1gina est\u00e1 renderizando estaticamente.</p>\n        <div style={{ marginTop: '1rem', padding: '0.5rem', backgroundColor: '#1e293b', borderRadius: '0.25rem', color: '#cbd5e1' }}>\n            Usu\u00e1rio: Teste<br />Senha: Teste\n        </div>\n      </div>\n    </div>\n  );\n}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 835, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "3574a84f-fbe5-4bcd-aa57-b4f5bcb0545a": {"__data__": {"id_": "3574a84f-fbe5-4bcd-aa57-b4f5bcb0545a", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\examples\\SkeletonDemo.tsx", "language": "typescript", "lines": 85, "filename": "SkeletonDemo.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\examples\\SkeletonDemo.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\examples\\SkeletonDemo.tsx", "language": "typescript", "lines": 85, "filename": "SkeletonDemo.tsx"}, "hash": "1fade4619c85092481e2ae9c4f6ee3a5590d782aee023081f4c0d59dade97893", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import { Skeleton } from \"./migrated-components/components/ui/Skeleton\";\n\n/**\n * Demo page for Skeleton component\n * Tests visual rendering and different use cases\n */\nexport default function SkeletonDemo() {\n  return (\n    <div class=\"min-h-screen bg-background p-8\">\n      <div class=\"max-w-4xl mx-auto space-y-8\">\n        <div>\n          <h1 class=\"text-3xl font-bold text-foreground mb-2\">\n            Skeleton Component Demo\n          </h1>\n          <p class=\"text-muted-foreground\">\n            Componente migrado do React para SolidJS - Fase 3 Piloto\n          </p>\n        </div>\n\n        {/* Basic Skeleton */}\n        <section class=\"space-y-4\">\n          <h2 class=\"text-2xl font-semibold text-foreground\">Basic Skeleton</h2>\n          <div class=\"space-y-2\">\n            <Skeleton class=\"h-4 w-full\" />\n            <Skeleton class=\"h-4 w-3/4\" />\n            <Skeleton class=\"h-4 w-1/2\" />\n          </div>\n        </section>\n\n        {/* Card Skeleton */}\n        <section class=\"space-y-4\">\n          <h2 class=\"text-2xl font-semibold text-foreground\">Card Skeleton</h2>\n          <div class=\"border border-border rounded-lg p-6 space-y-4\">\n            <Skeleton class=\"h-12 w-12 rounded-full\" />\n            <div class=\"space-y-2\">\n              <Skeleton class=\"h-4 w-full\" />\n              <Skeleton class=\"h-4 w-4/5\" />\n            </div>\n          </div>\n        </section>\n\n        {/* List Skeleton */}\n        <section class=\"space-y-4\">\n          <h2 class=\"text-2xl font-semibold text-foreground\">List Skeleton</h2>\n          <div class=\"space-y-3\">\n            {[...Array(5)].map((_, i) => (\n              <div class=\"flex items-center space-x-4\">\n                <Skeleton class=\"h-10 w-10 rounded-full\" />\n                <div class=\"flex-1 space-y-2\">\n                  <Skeleton class=\"h-3 w-3/4\" />\n                  <Skeleton class=\"h-3 w-1/2\" />\n                </div>\n              </div>\n            ))}\n          </div>\n        </section>\n\n        {/* Table Skeleton */}\n        <section class=\"space-y-4\">\n          <h2 class=\"text-2xl font-semibold text-foreground\">Table Skeleton</h2>\n          <div class=\"space-y-2\">\n            <Skeleton class=\"h-8 w-full\" />\n            {[...Array(4)].map((_, i) => (\n              <Skeleton class=\"h-12 w-full\" />\n            ))}\n          </div>\n        </section>\n\n        {/* Status */}\n        <section class=\"border-t border-border pt-6\">\n          <h3 class=\"text-lg font-medium text-foreground mb-2\">Status da Migra\u00e7\u00e3o</h3>\n          <ul class=\"space-y-1 text-sm text-muted-foreground\">\n            <li>\u2705 Componente migrado do React para SolidJS</li>\n            <li>\u2705 Tipagem TypeScript correta</li>\n            <li>\u2705 Props funcionando (class, data-*, aria-*)</li>\n            <li>\u2705 Anima\u00e7\u00e3o pulse ativa</li>\n            <li>\u2705 Integra\u00e7\u00e3o com fun\u00e7\u00e3o cn()</li>\n            <li>\u26a0\ufe0f  3/4 testes passando (1 teste com issue no matcher)</li>\n          </ul>\n        </section>\n      </div>\n    </div>\n  );\n}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2985, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "edd970e2-0290-4993-9756-4120a4c680d7": {"__data__": {"id_": "edd970e2-0290-4993-9756-4120a4c680d7", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\hooks\\useAdmin.ts", "language": "typescript", "lines": 91, "filename": "useAdmin.ts"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\hooks\\useAdmin.ts", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\hooks\\useAdmin.ts", "language": "typescript", "lines": 91, "filename": "useAdmin.ts"}, "hash": "3483d759b7a19679127a4db649f7e8c9d52362d0c93a0d455a6dbc00af8b2a56", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "/**\n * useAdmin Hook - SolidJS\n * Hook para gerenciar opera\u00e7\u00f5es administrativas\n */\n\nimport { createQuery, createMutation, useQueryClient } from '@tanstack/solid-query';\nimport { adminService } from '@/services/admin.service';\nimport { toast } from '@/migrated-components/components/ui/Sonner';\nimport type { CreateUserDTO, UpdateUserDTO, SystemSettings } from '@/types/admin';\n\nexport function useAdmin() {\n  const queryClient = useQueryClient();\n\n  // Queries\n  const statsQuery = createQuery(() => ({\n    queryKey: ['admin', 'stats'],\n    queryFn: adminService.getStats,\n  }));\n\n  const usersQuery = createQuery(() => ({\n    queryKey: ['admin', 'users'],\n    queryFn: adminService.getUsers,\n  }));\n\n  const auditLogsQuery = createQuery(() => ({\n    queryKey: ['admin', 'audit'],\n    queryFn: () => adminService.getAuditLogs(),\n  }));\n\n  const settingsQuery = createQuery(() => ({\n    queryKey: ['admin', 'settings'],\n    queryFn: adminService.getSettings,\n  }));\n\n  // Mutations\n  const createUserMutation = createMutation(() => ({\n    mutationFn: adminService.createUser,\n    onSuccess: () => {\n      queryClient.invalidateQueries({ queryKey: ['admin', 'users'] });\n      toast('Usu\u00e1rio criado com sucesso!', { type: 'success' });\n    },\n    onError: () => {\n      toast('Erro ao criar usu\u00e1rio', { type: 'error' });\n    }\n  }));\n\n  const updateUserMutation = createMutation(() => ({\n    mutationFn: ({ id, data }: { id: string; data: UpdateUserDTO }) => \n      adminService.updateUser(id, data),\n    onSuccess: () => {\n      queryClient.invalidateQueries({ queryKey: ['admin', 'users'] });\n      toast('Usu\u00e1rio atualizado com sucesso!', { type: 'success' });\n    },\n    onError: () => {\n      toast('Erro ao atualizar usu\u00e1rio', { type: 'error' });\n    }\n  }));\n\n  const deleteUserMutation = createMutation(() => ({\n    mutationFn: adminService.deleteUser,\n    onSuccess: () => {\n      queryClient.invalidateQueries({ queryKey: ['admin', 'users'] });\n      toast('Usu\u00e1rio removido', { type: 'success' });\n    },\n  }));\n\n  const updateSettingsMutation = createMutation(() => ({\n    mutationFn: adminService.updateSettings,\n    onSuccess: () => {\n      queryClient.invalidateQueries({ queryKey: ['admin', 'settings'] });\n      toast('Configura\u00e7\u00f5es salvas com sucesso!', { type: 'success' });\n    },\n  }));\n\n  return {\n    stats: statsQuery.data,\n    users: usersQuery.data,\n    auditLogs: auditLogsQuery.data,\n    settings: settingsQuery.data,\n    isLoadingStats: statsQuery.isLoading,\n    isLoadingUsers: usersQuery.isLoading,\n    createUser: createUserMutation.mutate,\n    updateUser: updateUserMutation.mutate,\n    deleteUser: deleteUserMutation.mutate,\n    updateSettings: updateSettingsMutation.mutate,\n    isCreatingUser: createUserMutation.isPending,\n    isUpdatingUser: updateUserMutation.isPending,\n    isSavingSettings: updateSettingsMutation.isPending,\n  };\n}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2871, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b1ddbd7d-c554-422a-b998-430c19e05160": {"__data__": {"id_": "b1ddbd7d-c554-422a-b998-430c19e05160", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\hooks\\useAnalytics.ts", "language": "typescript", "lines": 63, "filename": "useAnalytics.ts"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\hooks\\useAnalytics.ts", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\hooks\\useAnalytics.ts", "language": "typescript", "lines": 63, "filename": "useAnalytics.ts"}, "hash": "3f76738b0082effca682b8e698a924d8c3c3e76249d49d9c6d7801730960d0e1", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "/**\n * useAnalytics Hook - SolidJS\n * Hook customizado para gerenciar estado e opera\u00e7\u00f5es de analytics\n */\n\nimport { createQuery, createMutation, useQueryClient } from '@tanstack/solid-query';\nimport { analyticsService } from '@/services/analytics.service';\nimport { toast } from '@/migrated-components/components/ui/Sonner';\nimport type { AnalyticsFilter, ExportFormat } from '@/types/analytics';\n\nexport function useAnalytics(initialFilters?: AnalyticsFilter) {\n  const queryClient = useQueryClient();\n\n  // Query para dados\n  const dataQuery = createQuery(() => ({\n    queryKey: ['analytics', 'data', initialFilters],\n    queryFn: () => analyticsService.getData(initialFilters),\n  }));\n\n  // Query para m\u00e9tricas\n  const metricsQuery = createQuery(() => ({\n    queryKey: ['analytics', 'metrics'],\n    queryFn: analyticsService.getMetrics,\n  }));\n\n  // Mutation para exporta\u00e7\u00e3o\n  const exportMutation = createMutation(() => ({\n    mutationFn: ({ format, filters }: { format: ExportFormat; filters?: AnalyticsFilter }) =>\n      analyticsService.exportData(format, filters),\n    onSuccess: (blob, variables) => {\n      // Criar download do arquivo\n      const url = window.URL.createObjectURL(blob);\n      const a = document.createElement('a');\n      a.href = url;\n      a.download = `analytics-export.${variables.format}`;\n      document.body.appendChild(a);\n      a.click();\n      window.URL.revokeObjectURL(url);\n      document.body.removeChild(a);\n\n      toast(`Dados exportados em formato ${variables.format.toUpperCase()}`, { type: 'success' });\n    },\n    onError: () => {\n      toast('N\u00e3o foi poss\u00edvel exportar os dados', { type: 'error' });\n    },\n  }));\n\n  return {\n    data: dataQuery.data,\n    metrics: metricsQuery.data,\n    isLoading: dataQuery.isLoading || metricsQuery.isLoading,\n    isError: dataQuery.isError || metricsQuery.isError,\n    error: dataQuery.error || metricsQuery.error,\n    refetch: () => {\n      dataQuery.refetch();\n      metricsQuery.refetch();\n    },\n    exportData: (format: ExportFormat, filters?: AnalyticsFilter) =>\n      exportMutation.mutate({ format, filters }),\n    isExporting: exportMutation.isPending,\n  };\n}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2153, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "95e21a36-204a-47e0-b1f4-cf4edeff847c": {"__data__": {"id_": "95e21a36-204a-47e0-b1f4-cf4edeff847c", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\hooks\\useMediaQuery.ts", "language": "typescript", "lines": 34, "filename": "useMediaQuery.ts"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\hooks\\useMediaQuery.ts", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\hooks\\useMediaQuery.ts", "language": "typescript", "lines": 34, "filename": "useMediaQuery.ts"}, "hash": "7d28d0d64bf331e238ca9d1d71801fe0ff77dc8c6083f25742945f1e5b21f02c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "/**\n * useMediaQuery Hook - SolidJS\n * Hook para detectar breakpoints responsivos\n */\n\nimport { createSignal, onMount, onCleanup } from 'solid-js';\n\nexport function useMediaQuery(query: string): () => boolean {\n  const [matches, setMatches] = createSignal(false);\n\n  onMount(() => {\n    const media = window.matchMedia(query);\n    \n    // Set initial value\n    setMatches(media.matches);\n\n    // Create event listener\n    const listener = (e: MediaQueryListEvent) => setMatches(e.matches);\n    \n    // Add listener\n    media.addEventListener('change', listener);\n\n    // Cleanup\n    onCleanup(() => media.removeEventListener('change', listener));\n  });\n\n  return matches;\n}\n\n// Predefined breakpoints\nexport const useIsMobile = () => useMediaQuery('(max-width: 768px)');\nexport const useIsTablet = () => useMediaQuery('(min-width: 769px) and (max-width: 1024px)');\nexport const useIsDesktop = () => useMediaQuery('(min-width: 1025px)');", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 936, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "551d8ef5-9dec-4166-a102-d554782e9396": {"__data__": {"id_": "551d8ef5-9dec-4166-a102-d554782e9396", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\hooks\\useReports.ts", "language": "typescript", "lines": 92, "filename": "useReports.ts"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\hooks\\useReports.ts", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\hooks\\useReports.ts", "language": "typescript", "lines": 92, "filename": "useReports.ts"}, "hash": "b4795659aab5d16c69cdda0025834c687157bf14130bb11e0c529217965f5bcb", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "/**\n * useReports Hook - SolidJS\n * Hook para gerenciar estado e opera\u00e7\u00f5es de relat\u00f3rios\n */\n\nimport { createQuery, createMutation, useQueryClient } from '@tanstack/solid-query';\nimport { reportsService } from '@/services/reports.service';\nimport { toast } from '@/migrated-components/components/ui/Sonner';\nimport { useNavigate } from '@solidjs/router';\nimport type { CreateReportDTO, UpdateReportDTO } from '@/types/reports';\n\nexport function useReports() {\n  const queryClient = useQueryClient();\n  const navigate = useNavigate();\n\n  // Queries\n  const reportsQuery = createQuery(() => ({\n    queryKey: ['reports'],\n    queryFn: reportsService.getAll,\n  }));\n\n  const templatesQuery = createQuery(() => ({\n    queryKey: ['reports', 'templates'],\n    queryFn: reportsService.getTemplates,\n  }));\n\n  // Mutations\n  const createMutation = createMutation(() => ({\n    mutationFn: reportsService.create,\n    onSuccess: (newReport) => {\n      queryClient.invalidateQueries({ queryKey: ['reports'] });\n      toast('Relat\u00f3rio criado com sucesso!', { type: 'success' });\n      navigate(`/reports/${newReport.id}/edit`);\n    },\n    onError: () => {\n      toast('Erro ao criar relat\u00f3rio', { type: 'error' });\n    }\n  }));\n\n  const updateMutation = createMutation(() => ({\n    mutationFn: ({ id, data }: { id: string; data: UpdateReportDTO }) => \n      reportsService.update(id, data),\n    onSuccess: () => {\n      queryClient.invalidateQueries({ queryKey: ['reports'] });\n      toast('Relat\u00f3rio salvo com sucesso!', { type: 'success' });\n    },\n    onError: () => {\n      toast('Erro ao salvar relat\u00f3rio', { type: 'error' });\n    }\n  }));\n\n  const deleteMutation = createMutation(() => ({\n    mutationFn: reportsService.delete,\n    onSuccess: () => {\n      queryClient.invalidateQueries({ queryKey: ['reports'] });\n      toast('Relat\u00f3rio removido', { type: 'success' });\n    },\n  }));\n\n  const generatePDFMutation = createMutation(() => ({\n    mutationFn: reportsService.generatePDF,\n    onSuccess: (blob) => {\n      const url = window.URL.createObjectURL(blob);\n      window.open(url, '_blank');\n      toast('PDF gerado com sucesso!', { type: 'success' });\n    },\n  }));\n\n  return {\n    reports: reportsQuery.data,\n    templates: templatesQuery.data,\n    isLoading: reportsQuery.isLoading,\n    createReport: createMutation.mutate,\n    updateReport: updateMutation.mutate,\n    deleteReport: deleteMutation.mutate,\n    generatePDF: generatePDFMutation.mutate,\n    isCreating: createMutation.isPending,\n    isSaving: updateMutation.isPending,\n    isGenerating: generatePDFMutation.isPending,\n  };\n}\n\nexport function useReport(id: string) {\n  return createQuery(() => ({\n    queryKey: ['reports', id],\n    queryFn: () => reportsService.getById(id),\n    get enabled() {\n      return !!id;\n    },\n  }));\n}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2792, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "13a96b83-e162-4fe1-9cd6-6a66528e7353": {"__data__": {"id_": "13a96b83-e162-4fe1-9cd6-6a66528e7353", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\lib\\api.ts", "language": "typescript", "lines": 211, "filename": "api.ts"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\lib\\api.ts", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\lib\\api.ts", "language": "typescript", "lines": 211, "filename": "api.ts"}, "hash": "142326c3a5f15dd3ba899ff7da3ae2e6d97727abafdb73d572c1bb19690eadd4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5d5792c4-611e-4dbe-92f4-ed9582431f3b", "node_type": "1", "metadata": {}, "hash": "c24ac4e1afcaca533ae8a9ef28df638cc7c87ea0353c39cd562994103617d571", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import axios from 'axios';\n\n// --- Type Definitions ---\n\nexport interface KpiMetrics {\n  total_queries: number;\n  total_errors: number;\n  success_rate_feedback: number;\n  cache_hit_rate: number;\n  average_response_time_ms: string | number;\n}\n\nexport interface ErrorTrendItem {\n  date: string;\n  error_count: number;\n}\n\nexport interface TopQueryItem {\n  query: string;\n  count: number;\n}\n\nexport interface Report {\n  id: string;\n  name: string;\n  description?: string;\n  created_at: string;\n}\n\nexport interface LearningResponse {\n  insights: string[];\n  feedback_stats: {\n    total: number;\n    positive: number;\n    negative: number;\n    partial: number;\n    success_rate: number;\n  };\n  common_patterns: string[];\n}\n\nexport interface TransferValidationPayload {\n  produto_id: number;\n  une_origem: number;\n  une_destino: number;\n  quantidade: number;\n}\n\nexport interface TransferValidationResponse {\n  status: string; // \"sucesso\", \"falha\", \"alerta\"\n  mensagem: string;\n}\n\nexport interface TransferSuggestion {\n  produto_id: number;\n  une_origem: number;\n  une_destino: number;\n  quantidade_sugerida: number;\n  mensagem: string;\n}\n\nexport interface TransferRequestPayload {\n  produto_id: number;\n  une_origem: number;\n  une_destino: number;\n  quantidade: number;\n  solicitante_id: string;\n}\n\nexport interface TransferReportQuery {\n  start_date?: string;\n  end_date?: string;\n}\n\n// Old Transfer interface is removed as it's replaced by TransferSuggestion or others.\n// export interface Transfer { ... }\n\nexport interface Ruptura {\n  PRODUTO: string;\n  NOME: string;\n  UNE: string;\n  UNE_NOME?: string;\n  ESTOQUE_UNE: number;\n  ESTOQUE_CD: number;\n  ESTOQUE_LV: number;\n  VENDA_30DD: number;\n  CRITICIDADE_PCT: number;\n  NECESSIDADE: number;\n  NOMESEGMENTO?: string;\n  NOMEGRUPO?: string;  // Categoria/Grupo de produto\n}\n\nexport interface RupturasSummary {\n  total: number;\n  criticos: number;\n  valor_estimado: number;\n}\n\n// --- API Client ---\n\nconst api = axios.create({\n  baseURL: '/api/v1',\n  headers: {\n    'Content-Type': 'application/json',\n  },\n});\n\napi.interceptors.request.use((config) => {\n  const token = localStorage.getItem('token');\n  if (token) {\n    config.headers.Authorization = `Bearer ${token}`;\n  }\n  return config;\n});\n\napi.interceptors.response.use((response) => {\n  return response;\n}, (error) => {\n  if (error.response && error.response.status === 401) {\n    console.warn('\u26a0\ufe0f 401 Unauthorized - Token inv\u00e1lido ou expirado. Deslogando usu\u00e1rio...');\n    localStorage.removeItem('token');\n    // For\u00e7ar recarregamento para limpar estados\n    if (window.location.pathname !== '/login') {\n      window.location.href = '/login';\n    }\n  }\n  return Promise.reject(error);\n});\n\n// --- API Methods ---\n\nexport const analyticsApi = {\n  getKpis: (days: number = 7) => api.get<KpiMetrics>(`/analytics/kpis?days=${days}`),\n  getErrorTrend: (days: number = 30) => api.get<ErrorTrendItem[]>(`/analytics/error-trend?days=${days}`),\n  getTopQueries: (days: number = 7, limit: number = 10) => api.get<TopQueryItem[]>(`/analytics/top-queries?days=${days}&limit=${limit}`),\n  getFilterOptions: () => api.get<{ categorias: string[], segmentos: string[] }>('/analytics/filter-options'),\n};\n\nexport const reportsApi = {\n  getAll: () => api.get<Report[]>('/reports'),\n};\n\nexport interface UserData {\n  id: string;\n  username: string;\n  email: string;\n  role: string;\n  full_name?: string;\n  is_active: boolean;\n  allowed_segments?: string[];\n  created_at: string;\n  updated_at: string;\n}\n\nexport interface CreateUserPayload {\n  username: string;\n  email: string;\n  password: string;\n  role: string;\n  allowed_segments?: string[];\n}\n\nexport interface UpdateUserPayload {\n  username?: string;\n  email?: string;\n  password?: string;\n  role?: string;\n  is_active?: boolean;\n  allowed_segments?", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3791, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5d5792c4-611e-4dbe-92f4-ed9582431f3b": {"__data__": {"id_": "5d5792c4-611e-4dbe-92f4-ed9582431f3b", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\lib\\api.ts", "language": "typescript", "lines": 211, "filename": "api.ts"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\lib\\api.ts", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\lib\\api.ts", "language": "typescript", "lines": 211, "filename": "api.ts"}, "hash": "142326c3a5f15dd3ba899ff7da3ae2e6d97727abafdb73d572c1bb19690eadd4", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "13a96b83-e162-4fe1-9cd6-6a66528e7353", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\lib\\api.ts", "language": "typescript", "lines": 211, "filename": "api.ts"}, "hash": "163f3abdaecc08c07f1f9b3adcc59c1ab481a1a170037c06ddfe33613233f2f1", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": ": string;\n  role?: string;\n  is_active?: boolean;\n  allowed_segments?: string[];\n}\n\nexport const adminApi = {\n  syncParquet: () => api.post('/admin/sync-parquet'),\n\n  // User Management\n  getUsers: () => api.get<UserData[]>('/admin/users'),\n  getUser: (userId: string) => api.get<UserData>(`/admin/users/${userId}`),\n  createUser: (userData: CreateUserPayload) => api.post<UserData>('/admin/users', userData),\n  updateUser: (userId: string, userData: UpdateUserPayload) => api.put<UserData>(`/admin/users/${userId}`, userData),\n  deleteUser: (userId: string) => api.delete(`/admin/users/${userId}`),\n};\n\nexport const learningApi = {\n  getInsights: () => api.get<LearningResponse>('/learning/insights'),\n};\n\nexport const transfersApi = {\n  validateTransfer: (payload: TransferValidationPayload) => api.post<TransferValidationResponse>('/transfers/validate', payload),\n  getSuggestions: (segmento?: string, une_origem_excluir?: number, limit: number = 5) => api.get<TransferSuggestion[]>(`/transfers/suggestions`, { params: { segmento, une_origem_excluir, limit } }),\n  createTransferRequest: (payload: TransferRequestPayload) => api.post<{ message: string, transfer_id: string }>('/transfers', payload),\n  getReport: (query?: TransferReportQuery) => api.get<TransferRequestPayload[]>(`/transfers/report`, { params: query }),\n};\n\nexport const rupturasApi = {\n  getCritical: (limit = 50, segmento?: string, une?: string) => {\n    const params = new URLSearchParams({ limit: String(limit) });\n    if (segmento) params.append('segmento', segmento);\n    if (une) params.append('une', une);\n    return api.get<Ruptura[]>(`/rupturas/critical?${params.toString()}`);\n  },\n  getSegmentos: () => api.get<string[]>('/rupturas/filters/segmentos'),\n  getUnes: () => api.get<string[]>('/rupturas/filters/unes'),\n  getSummary: (segmento?: string, une?: string) => {\n    const params = new URLSearchParams();\n    if (segmento) params.append('segmento', segmento);\n    if (une) params.append('une', une);\n    return api.get<RupturasSummary>(`/rupturas/summary?${params.toString()}`);\n  },\n};\n\nexport default api;", "mimetype": "text/plain", "start_char_idx": 3722, "end_char_idx": 5816, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2ff415f6-3e59-4d8a-93d2-f113ff1a1aa6": {"__data__": {"id_": "2ff415f6-3e59-4d8a-93d2-f113ff1a1aa6", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\lib\\export.ts", "language": "typescript", "lines": 30, "filename": "export.ts"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\lib\\export.ts", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\lib\\export.ts", "language": "typescript", "lines": 30, "filename": "export.ts"}, "hash": "9f8fe879fffef62ae762ba18d5876e0677ae1cc37bb69bd15afcdc161e658a1b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "// frontend-solid/src/lib/export.ts\n\nimport { format } from 'date-fns';\nimport { enUS } from 'date-fns/locale';\n\n/**\n * Exports an array of objects to a CSV file.\n * @param data The array of objects to export.\n * @param filename The name of the CSV file.\n */\nexport const exportToCsv = (data: any[], filename: string) => {\n  if (!data || data.length === 0) {\n    alert(\"Nenhum dado para exportar.\");\n    return;\n  }\n\n  // Get headers from the first object's keys\n  const headers = Object.keys(data[0]);\n  \n  // Create CSV header row\n  const csvRows = [];\n  csvRows.push(headers.join(','));\n\n  // Add data rows\n  for (const row of data) {\n    const values = headers.map(header => {\n      const value = row[header];\n      // Handle values that might contain commas or newlines\n      if (typeof value === 'string' && (value.includes(',') || value.includes('\\n'))) {\n        return `\"${value.replace(/", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 897, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "205db90c-727f-437f-91a6-111e971d9396": {"__data__": {"id_": "205db90c-727f-437f-91a6-111e971d9396", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\lib\\formatters.ts", "language": "typescript", "lines": 20, "filename": "formatters.ts"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\lib\\formatters.ts", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\lib\\formatters.ts", "language": "typescript", "lines": 20, "filename": "formatters.ts"}, "hash": "301c56f6d5e0dd94f692b7696cc8d71ea3aadd23376058e19f2a83d5ee707448", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "// frontend-solid/src/lib/formatters.ts\n\nexport const formatTimestamp = (timestamp: number | Date): string => {\n  const date = typeof timestamp === 'number' ? new Date(timestamp) : timestamp;\n  return date.toLocaleTimeString('pt-BR', { hour: '2-digit', minute: '2-digit' });\n};\n\n// Placeholder for other formatters from T5.3.1\nexport const formatCurrency = (value: number): string => {\n  return value.toLocaleString('pt-BR', { style: 'currency', currency: 'BRL' });\n};\n\nexport const formatNumber = (value: number): string => {\n  return value.toLocaleString('pt-BR');\n};\n\nexport const formatDate = (date: Date): string => {\n  return date.toLocaleDateString('pt-BR');\n};", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 668, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d96103cc-467e-45d9-8558-a76f9aba0cf6": {"__data__": {"id_": "d96103cc-467e-45d9-8558-a76f9aba0cf6", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\lib\\supabase.ts", "language": "typescript", "lines": 11, "filename": "supabase.ts"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\lib\\supabase.ts", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\lib\\supabase.ts", "language": "typescript", "lines": 11, "filename": "supabase.ts"}, "hash": "31a459649872274674b41fd9c38c0225cb40c183f6dc0a1a48e298b379e7f04b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "/**\n * Supabase Client Configuration for Frontend\n */\n\nimport { createClient } from '@supabase/supabase-js'\n\nconst supabaseUrl = 'https://nmamxbriulivinlqqbmf.supabase.co'\nconst supabaseAnonKey = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Im5tYW14YnJpdWxpdmlubHFxYm1mIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NjMzMjM2MDEsImV4cCI6MjA3ODg5OTYwMX0.Mf-CTCPqQ6zjA0Aqa2oQoWhyVjG4SbNX9O7mR7rfW5I'\n\nexport const supabase = createClient(supabaseUrl, supabaseAnonKey)", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 474, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d1879763-af41-4e5c-8d31-f9e67a55d14a": {"__data__": {"id_": "d1879763-af41-4e5c-8d31-f9e67a55d14a", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\lib\\api\\client.ts", "language": "typescript", "lines": 74, "filename": "client.ts"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\lib\\api\\client.ts", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\lib\\api\\client.ts", "language": "typescript", "lines": 74, "filename": "client.ts"}, "hash": "d78439aa77930a476c1d083a1f5672f78c2184a93091c1c34fdade6b4737a45d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import axios, { AxiosInstance, AxiosRequestConfig } from 'axios';\nimport { useAuthStore } from '@/store/auth.store';\n\nconst API_BASE_URL =\n  process.env.NEXT_PUBLIC_API_URL || 'http://127.0.0.1:8000';\n\nclass APIClient {\n  private client: AxiosInstance;\n\n  constructor() {\n    this.client = axios.create({\n      baseURL: API_BASE_URL,\n      timeout: 30000,\n      headers: {\n        'Content-Type': 'application/json',\n      },\n    });\n\n    this.client.interceptors.request.use(\n      (config) => {\n        const token = useAuthStore.getState().token;\n        if (token) {\n          config.headers.Authorization = `Bearer ${token}`;\n        }\n        return config;\n      },\n      (error) => Promise.reject(error)\n    );\n\n    this.client.interceptors.response.use(\n      (response) => response,\n      (error) => {\n        if (error.response?.status === 401) {\n          useAuthStore.getState().logout();\n          if (typeof window !== 'undefined') {\n            window.location.href = '/login';\n          }\n        }\n        return Promise.reject(error);\n      }\n    );\n  }\n\n  async get<T>(url: string, config?: AxiosRequestConfig): Promise<T> {\n    const response = await this.client.get<T>(url, config);\n    return response.data;\n  }\n\n  async post<T>(\n    url: string,\n    data?: unknown,\n    config?: AxiosRequestConfig\n  ): Promise<T> {\n    const response = await this.client.post<T>(url, data, config);\n    return response.data;\n  }\n\n  async put<T>(\n    url: string,\n    data?: unknown,\n    config?: AxiosRequestConfig\n  ): Promise<T> {\n    const response = await this.client.put<T>(url, data, config);\n    return response.data;\n  }\n\n  async delete<T>(url: string, config?: AxiosRequestConfig): Promise<T> {\n    const response = await this.client.delete<T>(url, config);\n    return response.data;\n  }\n}\n\nexport const apiClient = new APIClient();", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1849, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "6c9530cc-097f-456f-8d4c-2b39f1fbecde": {"__data__": {"id_": "6c9530cc-097f-456f-8d4c-2b39f1fbecde", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\Alert.tsx", "language": "typescript", "lines": 77, "filename": "Alert.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\migrated-components\\components\\ui\\Alert.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\Alert.tsx", "language": "typescript", "lines": 77, "filename": "Alert.tsx"}, "hash": "bc5a001afdada1563a96298e66370f727a806922efb2767e961e6007efe11daa", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import type { JSX, ParentComponent } from \"solid-js\";\nimport { cva, type VariantProps } from \"class-variance-authority\";\nimport { cn } from \"../../utils/cn\";\n\nconst alertVariants = cva(\n  \"relative w-full rounded-lg border px-4 py-3 text-sm grid has-[>svg]:grid-cols-[calc(var(--spacing)*4)_1fr] grid-cols-[0_1fr] has-[>svg]:gap-x-3 gap-y-0.5 items-start [&>svg]:size-4 [&>svg]:translate-y-0.5 [&>svg]:text-current\",\n  {\n    variants: {\n      variant: {\n        default: \"bg-card text-card-foreground\",\n        destructive:\n          \"text-destructive bg-card [&>svg]:text-current *:data-[slot=alert-description]:text-destructive/90\",\n      },\n    },\n    defaultVariants: {\n      variant: \"default\",\n    },\n  }\n);\n\ninterface AlertProps\n  extends JSX.HTMLAttributes<HTMLDivElement>,\n    VariantProps<typeof alertVariants> {}\n\n/**\n * Alert component - notification container\n * Migrated from React to SolidJS\n */\nexport const Alert: ParentComponent<AlertProps> = (props) => {\n  return (\n    <div\n      data-slot=\"alert\"\n      role=\"alert\"\n      class={cn(alertVariants({ variant: props.variant }), props.class)}\n      {...props}\n    >\n      {props.children}\n    </div>\n  );\n};\n\n/**\n * AlertTitle component - alert title\n */\nexport const AlertTitle: ParentComponent<AlertProps> = (props) => {\n  return (\n    <div\n      data-slot=\"alert-title\"\n      class={cn(\n        \"col-start-2 line-clamp-1 min-h-4 font-medium tracking-tight\",\n        props.class\n      )}\n      {...props}\n    >\n      {props.children}\n    </div>\n  );\n};\n\n/**\n * AlertDescription component - alert description\n */\nexport const AlertDescription: ParentComponent<AlertProps> = (props) => {\n  return (\n    <div\n      data-slot=\"alert-description\"\n      class={cn(\n        \"text-muted-foreground col-start-2 grid justify-items-start gap-1 text-sm [&_p]:leading-relaxed\",\n        props.class\n      )}\n      {...props}\n    >\n      {props.children}\n    </div>\n  );\n};", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1927, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0fd3857c-c8d4-4fd1-82c4-7ab66cb373bb": {"__data__": {"id_": "0fd3857c-c8d4-4fd1-82c4-7ab66cb373bb", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\Avatar.tsx", "language": "typescript", "lines": 57, "filename": "Avatar.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\migrated-components\\components\\ui\\Avatar.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\Avatar.tsx", "language": "typescript", "lines": 57, "filename": "Avatar.tsx"}, "hash": "dd2010ac4a407829ce028dcbd6ea4a50097c41af8585103129722e446643d808", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import type { JSX, ParentComponent } from \"solid-js\";\nimport { cn } from \"../../utils/cn\";\n\ninterface AvatarProps extends JSX.HTMLAttributes<HTMLDivElement> {}\n\n/**\n * Avatar component - container\n * Migrated from React to SolidJS (Radix UI removed, native implementation)\n */\nexport const Avatar: ParentComponent<AvatarProps> = (props) => {\n  return (\n    <div\n      data-slot=\"avatar\"\n      class={cn(\n        \"relative flex size-8 shrink-0 overflow-hidden rounded-full\",\n        props.class\n      )}\n      {...props}\n    >\n      {props.children}\n    </div>\n  );\n};\n\ninterface AvatarImageProps extends JSX.ImgHTMLAttributes<HTMLImageElement> {}\n\n/**\n * AvatarImage component - image element\n */\nexport function AvatarImage(props: AvatarImageProps) {\n  return (\n    <img\n      data-slot=\"avatar-image\"\n      class={cn(\"aspect-square size-full\", props.class)}\n      {...props}\n    />\n  );\n}\n\n/**\n * AvatarFallback component - fallback content\n */\nexport const AvatarFallback: ParentComponent<AvatarProps> = (props) => {\n  return (\n    <div\n      data-slot=\"avatar-fallback\"\n      class={cn(\n        \"bg-muted flex size-full items-center justify-center rounded-full\",\n        props.class\n      )}\n      {...props}\n    >\n      {props.children}\n    </div>\n  );\n};", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1260, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b4b463b7-c95e-43df-a881-f31af0c7e79e": {"__data__": {"id_": "b4b463b7-c95e-43df-a881-f31af0c7e79e", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\Badge.test.tsx", "language": "typescript", "lines": 55, "filename": "Badge.test.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\migrated-components\\components\\ui\\Badge.test.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\Badge.test.tsx", "language": "typescript", "lines": 55, "filename": "Badge.test.tsx"}, "hash": "9ddeac15578b318dd836f3a66ba30b6b70049f7580391fafb96955c972ad0139", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import { render } from \"@solidjs/testing-library\";\nimport { describe, it, expect } from \"vitest\";\nimport { Badge } from \"./Badge\";\n\ndescribe(\"Badge\", () => {\n  it(\"renders with default variant\", () => {\n    const { container } = render(() => <Badge>Default</Badge>);\n    const badge = container.querySelector('[data-slot=\"badge\"]');\n\n    expect(badge).not.toBeNull();\n    expect(badge?.textContent).toBe(\"Default\");\n    const className = badge?.className || \"\";\n    expect(className).toContain(\"bg-primary\");\n  });\n\n  it(\"renders with secondary variant\", () => {\n    const { container } = render(() => <Badge variant=\"secondary\">Secondary</Badge>);\n    const badge = container.querySelector('[data-slot=\"badge\"]');\n\n    const className = badge?.className || \"\";\n    expect(className).toContain(\"bg-secondary\");\n  });\n\n  it(\"renders with destructive variant\", () => {\n    const { container } = render(() => <Badge variant=\"destructive\">Error</Badge>);\n    const badge = container.querySelector('[data-slot=\"badge\"]');\n\n    const className = badge?.className || \"\";\n    expect(className).toContain(\"bg-destructive\");\n  });\n\n  it(\"renders with outline variant\", () => {\n    const { container } = render(() => <Badge variant=\"outline\">Outline</Badge>);\n    const badge = container.querySelector('[data-slot=\"badge\"]');\n\n    const className = badge?.className || \"\";\n    expect(className).toContain(\"text-foreground\");\n  });\n\n  it(\"accepts custom class\", () => {\n    const { container } = render(() => <Badge class=\"custom-badge\">Custom</Badge>);\n    const badge = container.querySelector('[data-slot=\"badge\"]');\n\n    const className = badge?.className || \"\";\n    expect(className).toContain(\"custom-badge\");\n  });\n\n  it(\"renders as a span element\", () => {\n    const { container } = render(() => <Badge>Test</Badge>);\n    const badge = container.querySelector('[data-slot=\"badge\"]');\n\n    expect(badge?.tagName).toBe(\"SPAN\");\n  });\n});", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1931, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e7a9303d-ed86-4442-9546-55f84bb1cbff": {"__data__": {"id_": "e7a9303d-ed86-4442-9546-55f84bb1cbff", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\Badge.tsx", "language": "typescript", "lines": 54, "filename": "Badge.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\migrated-components\\components\\ui\\Badge.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\Badge.tsx", "language": "typescript", "lines": 54, "filename": "Badge.tsx"}, "hash": "3debf9f5fcba025cc4f88d573221ef42b8b5013ef01815e7f7d76cba5b5edcf3", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import type { JSX, ParentComponent } from \"solid-js\";\nimport { cva, type VariantProps } from \"class-variance-authority\";\nimport { cn } from \"../../utils/cn\";\n\nconst badgeVariants = cva(\n  \"inline-flex items-center justify-center rounded-full border px-2 py-0.5 text-xs font-medium w-fit whitespace-nowrap shrink-0 [&>svg]:size-3 gap-1 [&>svg]:pointer-events-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive transition-[color,box-shadow] overflow-hidden\",\n  {\n    variants: {\n      variant: {\n        default:\n          \"border-transparent bg-primary text-primary-foreground [a&]:hover:bg-primary/90\",\n        secondary:\n          \"border-transparent bg-secondary text-secondary-foreground [a&]:hover:bg-secondary/90\",\n        destructive:\n          \"border-transparent bg-destructive text-white [a&]:hover:bg-destructive/90 focus-visible:ring-destructive/20 dark:focus-visible:ring-destructive/40 dark:bg-destructive/60\",\n        outline:\n          \"text-foreground [a&]:hover:bg-accent [a&]:hover:text-accent-foreground\",\n      },\n    },\n    defaultVariants: {\n      variant: \"default\",\n    },\n  }\n);\n\ninterface BadgeProps\n  extends JSX.HTMLAttributes<HTMLSpanElement>,\n    VariantProps<typeof badgeVariants> {}\n\n/**\n * Badge component for status indicators and labels\n * Migrated from React to SolidJS\n * \n * @example\n * ```tsx\n * <Badge variant=\"default\">New</Badge>\n * <Badge variant=\"destructive\">Error</Badge>\n * <Badge variant=\"outline\">Draft</Badge>\n * ```\n */\nexport const Badge: ParentComponent<BadgeProps> = (props) => {\n  return (\n    <span\n      data-slot=\"badge\"\n      class={cn(badgeVariants({ variant: props.variant }), props.class)}\n      {...props}\n    >\n      {props.children}\n    </span>\n  );\n};\n\nexport { badgeVariants };", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1879, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "84dbd673-7a65-4024-9adc-783c2569b7c9": {"__data__": {"id_": "84dbd673-7a65-4024-9adc-783c2569b7c9", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\Button.test.tsx", "language": "typescript", "lines": 74, "filename": "Button.test.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\migrated-components\\components\\ui\\Button.test.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\Button.test.tsx", "language": "typescript", "lines": 74, "filename": "Button.test.tsx"}, "hash": "775f8b4f5fab465cf629171c4db07af8e8b3835695e54cfc76fd67ddc7e993f4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import { render, fireEvent } from \"@solidjs/testing-library\";\nimport { describe, it, expect, vi } from \"vitest\";\nimport { Button } from \"./Button\";\n\ndescribe(\"Button\", () => {\n  it(\"renders with default variant and size\", () => {\n    const { container } = render(() => <Button>Click me</Button>);\n    const button = container.querySelector('[data-slot=\"button\"]');\n\n    expect(button).not.toBeNull();\n    expect(button?.textContent).toBe(\"Click me\");\n    const className = button?.className || \"\";\n    expect(className).toContain(\"bg-primary\");\n    expect(className).toContain(\"h-9\");\n  });\n\n  it(\"renders with destructive variant\", () => {\n    const { container } = render(() => <Button variant=\"destructive\">Delete</Button>);\n    const button = container.querySelector('[data-slot=\"button\"]');\n\n    const className = button?.className || \"\";\n    expect(className).toContain(\"bg-destructive\");\n  });\n\n  it(\"renders with outline variant\", () => {\n    const { container } = render(() => <Button variant=\"outline\">Cancel</Button>);\n    const button = container.querySelector('[data-slot=\"button\"]');\n\n    const className = button?.className || \"\";\n    expect(className).toContain(\"border\");\n  });\n\n  it(\"renders with small size\", () => {\n    const { container } = render(() => <Button size=\"sm\">Small</Button>);\n    const button = container.querySelector('[data-slot=\"button\"]');\n\n    const className = button?.className || \"\";\n    expect(className).toContain(\"h-8\");\n  });\n\n  it(\"renders with large size\", () => {\n    const { container } = render(() => <Button size=\"lg\">Large</Button>);\n    const button = container.querySelector('[data-slot=\"button\"]');\n\n    const className = button?.className || \"\";\n    expect(className).toContain(\"h-10\");\n  });\n\n  it(\"handles click events\", () => {\n    const handleClick = vi.fn();\n    const { container } = render(() => <Button onClick={handleClick}>Click</Button>);\n    const button = container.querySelector('[data-slot=\"button\"]') as HTMLButtonElement;\n\n    fireEvent.click(button);\n    expect(handleClick).toHaveBeenCalledTimes(1);\n  });\n\n  it(\"can be disabled\", () => {\n    const { container } = render(() => <Button disabled>Disabled</Button>);\n    const button = container.querySelector('[data-slot=\"button\"]') as HTMLButtonElement;\n\n    expect(button.disabled).toBe(true);\n    const className = button?.className || \"\";\n    expect(className).toContain(\"disabled:opacity-50\");\n  });\n\n  it(\"renders as a button element\", () => {\n    const { container } = render(() => <Button>Test</Button>);\n    const button = container.querySelector('[data-slot=\"button\"]');\n\n    expect(button?.tagName).toBe(\"BUTTON\");\n  });\n});", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2660, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "42956a5d-0ad5-435c-9eab-1fb593b535ec": {"__data__": {"id_": "42956a5d-0ad5-435c-9eab-1fb593b535ec", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\Button.tsx", "language": "typescript", "lines": 65, "filename": "Button.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\migrated-components\\components\\ui\\Button.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\Button.tsx", "language": "typescript", "lines": 65, "filename": "Button.tsx"}, "hash": "fd93c6fac83c9483268a8f203b2abf8a1021311668b1ed4d1ad7f9b9a337aa3a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import type { JSX, ParentComponent } from \"solid-js\";\nimport { cva, type VariantProps } from \"class-variance-authority\";\nimport { cn } from \"../../utils/cn\";\n\nconst buttonVariants = cva(\n  \"inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&_svg]:pointer-events-none [&_svg:not([class*='size-'])]:size-4 shrink-0 [&_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive\",\n  {\n    variants: {\n      variant: {\n        default: \"bg-primary text-primary-foreground hover:bg-primary/90\",\n        destructive:\n          \"bg-destructive text-white hover:bg-destructive/90 focus-visible:ring-destructive/20 dark:focus-visible:ring-destructive/40 dark:bg-destructive/60\",\n        outline:\n          \"border bg-background shadow-xs hover:bg-accent hover:text-accent-foreground dark:bg-input/30 dark:border-input dark:hover:bg-input/50\",\n        secondary:\n          \"bg-secondary text-secondary-foreground hover:bg-secondary/80\",\n        ghost:\n          \"hover:bg-accent hover:text-accent-foreground dark:hover:bg-accent/50\",\n        link: \"text-primary underline-offset-4 hover:underline\",\n      },\n      size: {\n        default: \"h-9 px-4 py-2 has-[>svg]:px-3\",\n        sm: \"h-8 rounded-md gap-1.5 px-3 has-[>svg]:px-2.5\",\n        lg: \"h-10 rounded-md px-6 has-[>svg]:px-4\",\n        icon: \"size-9\",\n        \"icon-sm\": \"size-8\",\n        \"icon-lg\": \"size-10\",\n      },\n    },\n    defaultVariants: {\n      variant: \"default\",\n      size: \"default\",\n    },\n  }\n);\n\ninterface ButtonProps\n  extends JSX.ButtonHTMLAttributes<HTMLButtonElement>,\n    VariantProps<typeof buttonVariants> {}\n\n/**\n * Button component with multiple variants and sizes\n * Migrated from React to SolidJS\n * \n * @example\n * ```tsx\n * <Button variant=\"default\">Click me</Button>\n * <Button variant=\"destructive\" size=\"sm\">Delete</Button>\n * <Button variant=\"outline\" size=\"lg\">Cancel</Button>\n * ```\n */\nexport const Button: ParentComponent<ButtonProps> = (props) => {\n  return (\n    <button\n      data-slot=\"button\"\n      class={cn(buttonVariants({ variant: props.variant, size: props.size }), props.class)}\n      {...props}\n    >\n      {props.children}\n    </button>\n  );\n};\n\nexport { buttonVariants };", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2429, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ad5f1022-a084-437a-a55d-ffa96f1f2a4d": {"__data__": {"id_": "ad5f1022-a084-437a-a55d-ffa96f1f2a4d", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\Card.tsx", "language": "typescript", "lines": 120, "filename": "Card.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\migrated-components\\components\\ui\\Card.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\Card.tsx", "language": "typescript", "lines": 120, "filename": "Card.tsx"}, "hash": "0876bf683b6b19d18fd395079c9c3ca7eee510d1ab596965a93576ce9c2b6c1c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import type { JSX, ParentComponent } from \"solid-js\";\nimport { cn } from \"../../utils/cn\";\n\ninterface CardProps extends JSX.HTMLAttributes<HTMLDivElement> {}\n\n/**\n * Card component - main container\n */\nexport const Card: ParentComponent<CardProps> = (props) => {\n  return (\n    <div\n      data-slot=\"card\"\n      class={cn(\n        \"bg-card text-card-foreground flex flex-col gap-6 rounded-xl border py-6 shadow-sm\",\n        props.class\n      )}\n      {...props}\n    >\n      {props.children}\n    </div>\n  );\n};\n\n/**\n * CardHeader component - header section\n */\nexport const CardHeader: ParentComponent<CardProps> = (props) => {\n  return (\n    <div\n      data-slot=\"card-header\"\n      class={cn(\n        \"@container/card-header grid auto-rows-min grid-rows-[auto_auto] items-start gap-2 px-6\",\n        \"has-data-[slot=card-action]:grid-cols-[1fr_auto] [.border-b]:pb-6\",\n        props.class\n      )}\n      {...props}\n    >\n      {props.children}\n    </div>\n  );\n};\n\n/**\n * CardTitle component - title text\n */\nexport const CardTitle: ParentComponent<CardProps> = (props) => {\n  return (\n    <div\n      data-slot=\"card-title\"\n      class={cn(\"leading-none font-semibold\", props.class)}\n      {...props}\n    >\n      {props.children}\n    </div>\n  );\n};\n\n/**\n * CardDescription component - description text\n */\nexport const CardDescription: ParentComponent<CardProps> = (props) => {\n  return (\n    <div\n      data-slot=\"card-description\"\n      class={cn(\"text-muted-foreground text-sm\", props.class)}\n      {...props}\n    >\n      {props.children}\n    </div>\n  );\n};\n\n/**\n * CardAction component - action buttons area\n */\nexport const CardAction: ParentComponent<CardProps> = (props) => {\n  return (\n    <div\n      data-slot=\"card-action\"\n      class={cn(\n        \"col-start-2 row-span-2 row-start-1 self-start justify-self-end\",\n        props.class\n      )}\n      {...props}\n    >\n      {props.children}\n    </div>\n  );\n};\n\n/**\n * CardContent component - main content area\n */\nexport const CardContent: ParentComponent<CardProps> = (props) => {\n  return (\n    <div\n      data-slot=\"card-content\"\n      class={cn(\"px-6\", props.class)}\n      {...props}\n    >\n      {props.children}\n    </div>\n  );\n};\n\n/**\n * CardFooter component - footer section\n */\nexport const CardFooter: ParentComponent<CardProps> = (props) => {\n  return (\n    <div\n      data-slot=\"card-footer\"\n      class={cn(\"flex items-center px-6 [.border-t]:pt-6\", props.class)}\n      {...props}\n    >\n      {props.children}\n    </div>\n  );\n};", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2497, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "999fbd0b-679a-48bb-a093-7a950e57a036": {"__data__": {"id_": "999fbd0b-679a-48bb-a093-7a950e57a036", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\Dialog.tsx", "language": "typescript", "lines": 80, "filename": "Dialog.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\migrated-components\\components\\ui\\Dialog.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\Dialog.tsx", "language": "typescript", "lines": 80, "filename": "Dialog.tsx"}, "hash": "d846e02c1d76c91d4b20d59102d818963d0aa8b1f0ef809b77e7bccec4ce86e5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import { createSignal, type JSX, ParentComponent } from \"solid-js\";\nimport { Portal } from \"solid-js/web\";\nimport { cn } from \"../../utils/cn\";\n\ninterface DialogProps extends JSX.HTMLAttributes<HTMLDivElement> {\n  open?: boolean;\n  onOpenChange?: (open: boolean) => void;\n}\n\n/**\n * Dialog component - modal dialog\n * Migrated from React to SolidJS (Radix UI removed, native implementation)\n */\nexport const Dialog: ParentComponent<DialogProps> = (props) => {\n  const [isOpen, setIsOpen] = createSignal(props.open || false);\n  \n  const open = () => props.open !== undefined ? props.open : isOpen();\n  const setOpen = (value: boolean) => {\n    setIsOpen(value);\n    props.onOpenChange?.(value);\n  };\n\n  return (\n    <>\n      {open() && (\n        <Portal>\n          <div\n            data-slot=\"dialog-overlay\"\n            class=\"fixed inset-0 z-50 bg-black/80\"\n            onClick={() => setOpen(false)}\n          />\n          <div\n            data-slot=\"dialog\"\n            class={cn(\n              \"fixed left-[50%] top-[50%] z-50 translate-x-[-50%] translate-y-[-50%]\",\n              \"w-full max-w-lg rounded-lg border bg-background p-6 shadow-lg\",\n              props.class\n            )}\n            {...props}\n          >\n            {props.children}\n          </div>\n        </Portal>\n      )}\n    </>\n  );\n};\n\nexport const DialogContent: ParentComponent<JSX.HTMLAttributes<HTMLDivElement>> = (props) => {\n  return (\n    <div data-slot=\"dialog-content\" class={cn(\"space-y-4\", props.class)} {...props}>\n      {props.children}\n    </div>\n  );\n};\n\nexport const DialogHeader: ParentComponent<JSX.HTMLAttributes<HTMLDivElement>> = (props) => {\n  return (\n    <div data-slot=\"dialog-header\" class={cn(\"space-y-2\", props.class)} {...props}>\n      {props.children}\n    </div>\n  );\n};\n\nexport const DialogTitle: ParentComponent<JSX.HTMLAttributes<HTMLHeadingElement>> = (props) => {\n  return (\n    <h2 data-slot=\"dialog-title\" class={cn(\"text-lg font-semibold\", props.class)} {...props}>\n      {props.children}\n    </h2>\n  );\n};\n\nexport const DialogDescription: ParentComponent<JSX.HTMLAttributes<HTMLParagraphElement>> = (props) => {\n  return (\n    <p data-slot=\"dialog-description\" class={cn(\"text-sm text-muted-foreground\", props.class)} {...props}>\n      {props.children}\n    </p>\n  );\n};", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2287, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b2c1f7d8-af10-4573-a9c7-dd590458f4ee": {"__data__": {"id_": "b2c1f7d8-af10-4573-a9c7-dd590458f4ee", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\DropdownMenu.tsx", "language": "typescript", "lines": 68, "filename": "DropdownMenu.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\migrated-components\\components\\ui\\DropdownMenu.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\DropdownMenu.tsx", "language": "typescript", "lines": 68, "filename": "DropdownMenu.tsx"}, "hash": "6dc2c4abeddd4aa148884de53d33c254ddb2083812aee291e6247d32b7a755a0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import { createSignal, type JSX, ParentComponent, Show } from \"solid-js\";\nimport { Portal } from \"solid-js/web\";\nimport { cn } from \"../../utils/cn\";\n\ninterface DropdownMenuProps extends JSX.HTMLAttributes<HTMLDivElement> {\n  open?: boolean;\n  onOpenChange?: (open: boolean) => void;\n}\n\n/**\n * DropdownMenu component - dropdown menu\n * Migrated from React to SolidJS (simplified native implementation)\n */\nexport const DropdownMenu: ParentComponent<DropdownMenuProps> = (props) => {\n  const [isOpen, setIsOpen] = createSignal(props.open || false);\n  \n  const open = () => props.open !== undefined ? props.open : isOpen();\n  const setOpen = (value: boolean) => {\n    setIsOpen(value);\n    props.onOpenChange?.(value);\n  };\n\n  return (\n    <div data-slot=\"dropdown\" class=\"relative inline-block\">\n      {props.children}\n    </div>\n  );\n};\n\nexport const DropdownMenuTrigger: ParentComponent<JSX.ButtonHTMLAttributes<HTMLButtonElement>> = (props) => {\n  return (\n    <button data-slot=\"dropdown-trigger\" {...props}>\n      {props.children}\n    </button>\n  );\n};\n\nexport const DropdownMenuContent: ParentComponent<JSX.HTMLAttributes<HTMLDivElement>> = (props) => {\n  return (\n    <div\n      data-slot=\"dropdown-content\"\n      class={cn(\n        \"absolute right-0 mt-2 w-56 rounded-md border bg-popover p-1 shadow-md z-50\",\n        props.class\n      )}\n      {...props}\n    >\n      {props.children}\n    </div>\n  );\n};\n\nexport const DropdownMenuItem: ParentComponent<JSX.HTMLAttributes<HTMLDivElement>> = (props) => {\n  return (\n    <div\n      data-slot=\"dropdown-item\"\n      class={cn(\n        \"relative flex cursor-pointer select-none items-center rounded-sm px-2 py-1.5 text-sm\",\n        \"hover:bg-accent hover:text-accent-foreground\",\n        props.class\n      )}\n      {...props}\n    >\n      {props.children}\n    </div>\n  );\n};", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1824, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "099c0ca5-424b-44d8-8189-bd8edf5eabd6": {"__data__": {"id_": "099c0ca5-424b-44d8-8189-bd8edf5eabd6", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\index.ts", "language": "typescript", "lines": 55, "filename": "index.ts"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\migrated-components\\components\\ui\\index.ts", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\index.ts", "language": "typescript", "lines": 55, "filename": "index.ts"}, "hash": "b758d6a2d81aac08594389d852d54ffb861b4cc5330dcb7cbe85da66f1f55336", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "/**\n * UI Components - Migrated from React to SolidJS\n * \n * This barrel file exports all UI components for easy importing\n * \n * Total: 18 components migrated (100%)\n */\n\nexport { Skeleton } from \"./Skeleton\";\nexport { Badge, badgeVariants } from \"./Badge\";\nexport { Button, buttonVariants } from \"./Button\";\nexport { Separator } from \"./Separator\";\nexport { Label } from \"./Label\";\nexport { Input } from \"./Input\";\nexport {\n  Card,\n  CardHeader,\n  CardTitle,\n  CardDescription,\n  CardAction,\n  CardContent,\n  CardFooter,\n} from \"./Card\";\nexport { Avatar, AvatarImage, AvatarFallback } from \"./Avatar\";\nexport { Alert, AlertTitle, AlertDescription } from \"./Alert\";\nexport { LazyImage } from \"./LazyImage\";\nexport { SkipLink } from \"./SkipLink\";\nexport { Tabs, TabsList, TabsTrigger, TabsContent } from \"./Tabs\";\nexport {\n  Table,\n  TableHeader,\n  TableBody,\n  TableFooter,\n  TableRow,\n  TableHead,\n  TableCell,\n  TableCaption,\n} from \"./Table\";\nexport {\n  Dialog,\n  DialogContent,\n  DialogHeader,\n  DialogTitle,\n  DialogDescription,\n} from \"./Dialog\";\nexport { Select, SelectOption } from \"./Select\";\nexport {\n  DropdownMenu,\n  DropdownMenuTrigger,\n  DropdownMenuContent,\n  DropdownMenuItem,\n} from \"./DropdownMenu\";\nexport { Sheet, SheetHeader, SheetTitle } from \"./Sheet\";\nexport { toast, Toaster } from \"./Sonner\";", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1319, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "901fd6af-fb2c-4d16-8eb3-81ca630c2fd9": {"__data__": {"id_": "901fd6af-fb2c-4d16-8eb3-81ca630c2fd9", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\Input.tsx", "language": "typescript", "lines": 35, "filename": "Input.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\migrated-components\\components\\ui\\Input.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\Input.tsx", "language": "typescript", "lines": 35, "filename": "Input.tsx"}, "hash": "ac1a1d3537e6ca739f2a5dacb503da95eb612fa6af2015207bd6af9b8250f1d0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import type { JSX } from \"solid-js\";\nimport { cn } from \"../../utils/cn\";\n\ninterface InputProps extends JSX.InputHTMLAttributes<HTMLInputElement> {}\n\n/**\n * Input component for form fields\n * Migrated from React to SolidJS\n * \n * @example\n * ```tsx\n * <Input type=\"text\" placeholder=\"Enter text...\" />\n * <Input type=\"email\" />\n * ```\n */\nexport function Input(props: InputProps) {\n  return (\n    <input\n      data-slot=\"input\"\n      class={cn(\n        \"file:text-foreground placeholder:text-muted-foreground selection:bg-primary selection:text-primary-foreground\",\n        \"dark:bg-input/30 border-input h-9 w-full min-w-0 rounded-md border bg-transparent px-3 py-1 text-base shadow-xs\",\n        \"transition-[color,box-shadow] outline-none\",\n        \"file:inline-flex file:h-7 file:border-0 file:bg-transparent file:text-sm file:font-medium\",\n        \"disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50\",\n        \"md:text-sm\",\n        \"focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px]\",\n        \"aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive\",\n        props.class\n      )}\n      {...props}\n    />\n  );\n}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1216, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "192a4829-691b-402f-b806-39b9012d7819": {"__data__": {"id_": "192a4829-691b-402f-b806-39b9012d7819", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\Label.tsx", "language": "typescript", "lines": 31, "filename": "Label.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\migrated-components\\components\\ui\\Label.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\Label.tsx", "language": "typescript", "lines": 31, "filename": "Label.tsx"}, "hash": "33646e58b854b93d520cf8b0f73fe5d0e2197f6bacc10d81a51443adeb096797", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import type { JSX, ParentComponent } from \"solid-js\";\nimport { cn } from \"../../utils/cn\";\n\ninterface LabelProps extends JSX.LabelHTMLAttributes<HTMLLabelElement> {}\n\n/**\n * Label component for form fields\n * Migrated from React to SolidJS (Radix UI removed, native implementation)\n * \n * @example\n * ```tsx\n * <Label for=\"email\">Email</Label>\n * ```\n */\nexport const Label: ParentComponent<LabelProps> = (props) => {\n  return (\n    <label\n      data-slot=\"label\"\n      class={cn(\n        \"flex items-center gap-2 text-sm leading-none font-medium select-none\",\n        \"group-data-[disabled=true]:pointer-events-none group-data-[disabled=true]:opacity-50\",\n        \"peer-disabled:cursor-not-allowed peer-disabled:opacity-50\",\n        props.class\n      )}\n      {...props}\n    >\n      {props.children}\n    </label>\n  );\n};", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 821, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "bd4aabfa-865c-48e8-9853-fba953f3fa21": {"__data__": {"id_": "bd4aabfa-865c-48e8-9853-fba953f3fa21", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\LazyImage.tsx", "language": "typescript", "lines": 45, "filename": "LazyImage.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\migrated-components\\components\\ui\\LazyImage.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\LazyImage.tsx", "language": "typescript", "lines": 45, "filename": "LazyImage.tsx"}, "hash": "9080cdda6097c01f7efb41e2131e4f00b3b47b6d04c80a50013e28ba13c45aa7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import { createSignal, type JSX } from \"solid-js\";\nimport { cn } from \"../../utils/cn\";\n\ninterface LazyImageProps extends JSX.ImgHTMLAttributes<HTMLImageElement> {\n  fallbackSrc?: string;\n}\n\n/**\n * LazyImage component - optimized image loading\n * Migrated from React to SolidJS (Next.js Image removed, native img)\n * \n * @example\n * ```tsx\n * <LazyImage src=\"/image.jpg\" alt=\"Description\" />\n * ```\n */\nexport function LazyImage(props: LazyImageProps) {\n  const [isLoading, setIsLoading] = createSignal(true);\n  const [error, setError] = createSignal(false);\n  \n  const fallbackSrc = () => props.fallbackSrc || \"/placeholder.png\";\n  const imageSrc = () => error() ? fallbackSrc() : props.src;\n\n  return (\n    <div class={cn(\"relative overflow-hidden\", props.class)}>\n      <img\n        {...props}\n        src={imageSrc()}\n        class={cn(\n          \"transition-opacity duration-300\",\n          isLoading() ? \"opacity-0\" : \"opacity-100\"\n        )}\n        onLoad={() => setIsLoading(false)}\n        onError={() => {\n          setError(true);\n          setIsLoading(false);\n        }}\n      />\n      {isLoading() && (\n        <div class=\"absolute inset-0 bg-muted animate-pulse\" />\n      )}\n    </div>\n  );\n}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1208, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "26c0703c-658d-421c-9382-409e0b4701de": {"__data__": {"id_": "26c0703c-658d-421c-9382-409e0b4701de", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\Select.tsx", "language": "typescript", "lines": 31, "filename": "Select.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\migrated-components\\components\\ui\\Select.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\Select.tsx", "language": "typescript", "lines": 31, "filename": "Select.tsx"}, "hash": "ab192724e402ffc1711cca79c6658a2d5e1e53dec6dceafea232f655ce96fe6a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import { createSignal, type JSX, ParentComponent, Show } from \"solid-js\";\nimport { cn } from \"../../utils/cn\";\n\ninterface SelectProps extends JSX.SelectHTMLAttributes<HTMLSelectElement> {}\n\n/**\n * Select component - native select dropdown\n * Migrated from React to SolidJS (simplified, native select)\n */\nexport function Select(props: SelectProps) {\n  return (\n    <select\n      data-slot=\"select\"\n      class={cn(\n        \"flex h-9 w-full items-center justify-between rounded-md border border-input\",\n        \"bg-transparent px-3 py-2 text-sm shadow-xs\",\n        \"focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2\",\n        \"disabled:cursor-not-allowed disabled:opacity-50\",\n        props.class\n      )}\n      {...props}\n    />\n  );\n}\n\ninterface SelectOptionProps extends JSX.OptionHTMLAttributes<HTMLOptionElement> {}\n\nexport function SelectOption(props: SelectOptionProps) {\n  return <option {...props} />;\n}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 929, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "6dabe135-ad7b-49be-92e2-4bf518bdef46": {"__data__": {"id_": "6dabe135-ad7b-49be-92e2-4bf518bdef46", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\Separator.tsx", "language": "typescript", "lines": 38, "filename": "Separator.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\migrated-components\\components\\ui\\Separator.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\Separator.tsx", "language": "typescript", "lines": 38, "filename": "Separator.tsx"}, "hash": "904a3cb430c158b705958de67ae2cdb0b7f6e932ff1ac28a66b64b96fcb3cf37", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import type { JSX } from \"solid-js\";\nimport { cn } from \"../../utils/cn\";\n\ninterface SeparatorProps extends JSX.HTMLAttributes<HTMLDivElement> {\n  orientation?: \"horizontal\" | \"vertical\";\n  decorative?: boolean;\n}\n\n/**\n * Separator component for visual division\n * Migrated from React to SolidJS (Radix UI removed, native implementation)\n * \n * @example\n * ```tsx\n * <Separator />\n * <Separator orientation=\"vertical\" />\n * ```\n */\nexport function Separator(props: SeparatorProps) {\n  const orientation = () => props.orientation || \"horizontal\";\n  const decorative = () => props.decorative !== undefined ? props.decorative : true;\n\n  return (\n    <div\n      role={decorative() ? \"none\" : \"separator\"}\n      aria-orientation={!decorative() ? orientation() : undefined}\n      data-slot=\"separator\"\n      data-orientation={orientation()}\n      class={cn(\n        \"bg-border shrink-0\",\n        orientation() === \"horizontal\" ? \"h-px w-full\" : \"h-full w-px\",\n        props.class\n      )}\n      {...props}\n    />\n  );\n}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1013, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "6bc81be8-5b4d-48bd-9a7b-cbeece371efb": {"__data__": {"id_": "6bc81be8-5b4d-48bd-9a7b-cbeece371efb", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\Sheet.tsx", "language": "typescript", "lines": 75, "filename": "Sheet.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\migrated-components\\components\\ui\\Sheet.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\Sheet.tsx", "language": "typescript", "lines": 75, "filename": "Sheet.tsx"}, "hash": "2f7e0ad1040cfa8868a6e50fb5b534405e6081ae8da3058ce68e3eb7466fbb0f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import { createSignal, type JSX, ParentComponent } from \"solid-js\";\nimport { Portal } from \"solid-js/web\";\nimport { cn } from \"../../utils/cn\";\n\ninterface SheetProps extends JSX.HTMLAttributes<HTMLDivElement> {\n  open?: boolean;\n  onOpenChange?: (open: boolean) => void;\n  side?: \"left\" | \"right\" | \"top\" | \"bottom\";\n}\n\n/**\n * Sheet component - side panel/drawer\n * Migrated from React to SolidJS (Radix UI removed, native implementation)\n */\nexport const Sheet: ParentComponent<SheetProps> = (props) => {\n  const [isOpen, setIsOpen] = createSignal(props.open || false);\n  const side = () => props.side || \"right\";\n  \n  const open = () => props.open !== undefined ? props.open : isOpen();\n  const setOpen = (value: boolean) => {\n    setIsOpen(value);\n    props.onOpenChange?.(value);\n  };\n\n  const sideClasses = () => {\n    switch (side()) {\n      case \"left\": return \"left-0 top-0 h-full w-3/4 max-w-sm\";\n      case \"right\": return \"right-0 top-0 h-full w-3/4 max-w-sm\";\n      case \"top\": return \"top-0 left-0 w-full h-3/4 max-h-sm\";\n      case \"bottom\": return \"bottom-0 left-0 w-full h-3/4 max-h-sm\";\n    }\n  };\n\n  return (\n    <>\n      {open() && (\n        <Portal>\n          <div\n            data-slot=\"sheet-overlay\"\n            class=\"fixed inset-0 z-50 bg-black/80\"\n            onClick={() => setOpen(false)}\n          />\n          <div\n            data-slot=\"sheet\"\n            class={cn(\n              \"fixed z-50 bg-background p-6 shadow-lg\",\n              sideClasses(),\n              props.class\n            )}\n            {...props}\n          >\n            {props.children}\n          </div>\n        </Portal>\n      )}\n    </>\n  );\n};\n\nexport const SheetHeader: ParentComponent<JSX.HTMLAttributes<HTMLDivElement>> = (props) => {\n  return (\n    <div data-slot=\"sheet-header\" class={cn(\"space-y-2\", props.class)} {...props}>\n      {props.children}\n    </div>\n  );\n};\n\nexport const SheetTitle: ParentComponent<JSX.HTMLAttributes<HTMLHeadingElement>> = (props) => {\n  return (\n    <h2 data-slot=\"sheet-title\" class={cn(\"text-lg font-semibold\", props.class)} {...props}>\n      {props.children}\n    </h2>\n  );\n};", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2119, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "6f818f14-f512-4ae5-a7de-c6987bee6c04": {"__data__": {"id_": "6f818f14-f512-4ae5-a7de-c6987bee6c04", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\Skeleton.test.tsx", "language": "typescript", "lines": 45, "filename": "Skeleton.test.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\migrated-components\\components\\ui\\Skeleton.test.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\Skeleton.test.tsx", "language": "typescript", "lines": 45, "filename": "Skeleton.test.tsx"}, "hash": "aaf39922c3abcadf82b92785e83b4585b5487789c666ce779fb7acaf0495fbde", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import { render } from \"@solidjs/testing-library\";\nimport { describe, it, expect } from \"vitest\";\nimport { Skeleton } from \"./Skeleton\";\n\ndescribe(\"Skeleton\", () => {\n  it(\"renders with default classes\", () => {\n    const { container } = render(() => <Skeleton />);\n    const skeleton = container.querySelector('[data-slot=\"skeleton\"]');\n\n    expect(skeleton).not.toBeNull();\n    const className = skeleton?.className || \"\";\n    expect(className).toContain(\"bg-accent\");\n    expect(className).toContain(\"animate-pulse\");\n    expect(className).toContain(\"rounded-md\");\n  });\n\n  it(\"accepts custom class\", () => {\n    const { container } = render(() => <Skeleton class=\"custom-class w-full\" />);\n    const skeleton = container.querySelector('[data-slot=\"skeleton\"]');\n\n    expect(skeleton).not.toBeNull();\n    const className = skeleton?.className || \"\";\n    expect(className).toContain(\"custom-class\");\n    expect(className).toContain(\"w-full\");\n    expect(className).toContain(\"bg-accent\");\n  });\n\n  it(\"spreads additional props\", () => {\n    const { container } = render(() => (\n      <Skeleton data-testid=\"test-skeleton\" aria-label=\"Loading\" />\n    ));\n    const skeleton = container.querySelector('[data-testid=\"test-skeleton\"]');\n\n    expect(skeleton).not.toBeNull();\n    expect(skeleton?.getAttribute(\"aria-label\")).toBe(\"Loading\");\n  });\n\n  it(\"renders as a div element\", () => {\n    const { container } = render(() => <Skeleton />);\n    const skeleton = container.querySelector('[data-slot=\"skeleton\"]');\n\n    expect(skeleton?.tagName).toBe(\"DIV\");\n  });\n});", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1566, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "04fd7185-6861-4825-a3c2-d1c7bd295ff2": {"__data__": {"id_": "04fd7185-6861-4825-a3c2-d1c7bd295ff2", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\Skeleton.tsx", "language": "typescript", "lines": 24, "filename": "Skeleton.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\migrated-components\\components\\ui\\Skeleton.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\Skeleton.tsx", "language": "typescript", "lines": 24, "filename": "Skeleton.tsx"}, "hash": "f62cc6e1de8c9ec0dde79a03028f25aca6cd27b45e75a6ba6cabbc159d49f4aa", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import type { JSX } from \"solid-js\";\nimport { cn } from \"../../utils/cn\";\n\ninterface SkeletonProps extends JSX.HTMLAttributes<HTMLDivElement> {}\n\n/**\n * Skeleton component for loading states\n * Migrated from React to SolidJS\n * \n * @example\n * ```tsx\n * <Skeleton class=\"w-full h-20\" />\n * ```\n */\nexport function Skeleton(props: SkeletonProps) {\n  return (\n    <div\n      data-slot=\"skeleton\"\n      class={cn(\"bg-accent animate-pulse rounded-md\", props.class)}\n      {...props}\n    />\n  );\n}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 492, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "cb1b89b6-6990-4702-9fbb-b52c6aada0ea": {"__data__": {"id_": "cb1b89b6-6990-4702-9fbb-b52c6aada0ea", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\SkipLink.tsx", "language": "typescript", "lines": 17, "filename": "SkipLink.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\migrated-components\\components\\ui\\SkipLink.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\SkipLink.tsx", "language": "typescript", "lines": 17, "filename": "SkipLink.tsx"}, "hash": "f88e8a8d015646569af4f2a37f3ed5800af52c601fe3eb7c930cbc6fb828fdce", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "/**\n * SkipLink Component\n * Link de pular navega\u00e7\u00e3o para acessibilidade\n * Migrated from React to SolidJS (Next.js Link removed, native anchor)\n */\n\nexport function SkipLink() {\n  return (\n    <a\n      href=\"#main-content\"\n      class=\"sr-only focus:not-sr-only focus:absolute focus:top-4 focus:left-4 focus:z-50 focus:px-4 focus:py-2 focus:bg-primary focus:text-primary-foreground focus:rounded-md focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2\"\n    >\n      Pular para o conte\u00fado principal\n    </a>\n  );\n}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 528, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "3c12e533-5193-40ad-be03-4c777c9b105b": {"__data__": {"id_": "3c12e533-5193-40ad-be03-4c777c9b105b", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\Sonner.tsx", "language": "typescript", "lines": 73, "filename": "Sonner.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\migrated-components\\components\\ui\\Sonner.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\Sonner.tsx", "language": "typescript", "lines": 73, "filename": "Sonner.tsx"}, "hash": "bde1d31656ec369111d87ff505deb053c1774bcfa8fc9071a91e4ef682f0804a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import { createSignal, For, type JSX } from \"solid-js\";\nimport { Portal } from \"solid-js/web\";\nimport { cn } from \"../../utils/cn\";\n\ntype ToastType = \"default\" | \"success\" | \"error\" | \"warning\";\n\ninterface Toast {\n  id: string;\n  message: string;\n  type?: ToastType;\n  duration?: number;\n}\n\nconst [toasts, setToasts] = createSignal<Toast[]>([]);\n\n/**\n * Toast notification system (Sonner alternative)\n * Migrated from React to SolidJS (native implementation)\n */\nexport function toast(message: string, options?: { type?: ToastType; duration?: number }) {\n  const id = Math.random().toString(36).substr(2, 9);\n  const newToast: Toast = {\n    id,\n    message,\n    type: options?.type || \"default\",\n    duration: options?.duration || 3000,\n  };\n\n  setToasts((prev) => [...prev, newToast]);\n\n  setTimeout(() => {\n    setToasts((prev) => prev.filter((t) => t.id !== id));\n  }, newToast.duration);\n}\n\n/**\n * Toaster component - renders toast notifications\n */\nexport function Toaster() {\n  const getToastClasses = (type: ToastType) => {\n    const base = \"rounded-lg border p-4 shadow-lg\";\n    switch (type) {\n      case \"success\": return `${base} bg-green-50 border-green-200 text-green-900`;\n      case \"error\": return `${base} bg-red-50 border-red-200 text-red-900`;\n      case \"warning\": return `${base} bg-yellow-50 border-yellow-200 text-yellow-900`;\n      default: return `${base} bg-background border-border`;\n    }\n  };\n\n  return (\n    <Portal>\n      <div\n        data-slot=\"toaster\"\n        class=\"fixed bottom-4 right-4 z-50 flex flex-col gap-2 max-w-md\"\n      >\n        <For each={toasts()}>\n          {(t) => (\n            <div\n              data-slot=\"toast\"\n              class={cn(\n                getToastClasses(t.type || \"default\"),\n                \"animate-in slide-in-from-right\"\n              )}\n            >\n              {t.message}\n            </div>\n          )}\n        </For>\n      </div>\n    </Portal>\n  );\n}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1931, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "996eb9d7-a9df-411e-ab11-c399140d63a3": {"__data__": {"id_": "996eb9d7-a9df-411e-ab11-c399140d63a3", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\Table.tsx", "language": "typescript", "lines": 145, "filename": "Table.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\migrated-components\\components\\ui\\Table.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\Table.tsx", "language": "typescript", "lines": 145, "filename": "Table.tsx"}, "hash": "bd5da92c92da49f58fe23e19b674131a236b6bd9ceb8ea4f310135f7b9097d4c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import type { JSX, ParentComponent } from \"solid-js\";\nimport { cn } from \"../../utils/cn\";\n\ninterface TableProps extends JSX.HTMLAttributes<HTMLTableElement> {}\n\n/**\n * Table component - table container with scroll\n * Migrated from React to SolidJS\n */\nexport const Table: ParentComponent<TableProps> = (props) => {\n  return (\n    <div\n      data-slot=\"table-container\"\n      class=\"relative w-full overflow-x-auto\"\n    >\n      <table\n        data-slot=\"table\"\n        class={cn(\"w-full caption-bottom text-sm\", props.class)}\n        {...props}\n      >\n        {props.children}\n      </table>\n    </div>\n  );\n};\n\n/**\n * TableHeader component - thead element\n */\nexport const TableHeader: ParentComponent<JSX.HTMLAttributes<HTMLTableSectionElement>> = (props) => {\n  return (\n    <thead\n      data-slot=\"table-header\"\n      class={cn(\"[&_tr]:border-b\", props.class)}\n      {...props}\n    >\n      {props.children}\n    </thead>\n  );\n};\n\n/**\n * TableBody component - tbody element\n */\nexport const TableBody: ParentComponent<JSX.HTMLAttributes<HTMLTableSectionElement>> = (props) => {\n  return (\n    <tbody\n      data-slot=\"table-body\"\n      class={cn(\"[&_tr:last-child]:border-0\", props.class)}\n      {...props}\n    >\n      {props.children}\n    </tbody>\n  );\n};\n\n/**\n * TableFooter component - tfoot element\n */\nexport const TableFooter: ParentComponent<JSX.HTMLAttributes<HTMLTableSectionElement>> = (props) => {\n  return (\n    <tfoot\n      data-slot=\"table-footer\"\n      class={cn(\n        \"bg-muted/50 border-t font-medium [&>tr]:last:border-b-0\",\n        props.class\n      )}\n      {...props}\n    >\n      {props.children}\n    </tfoot>\n  );\n};\n\n/**\n * TableRow component - tr element\n */\nexport const TableRow: ParentComponent<JSX.HTMLAttributes<HTMLTableRowElement>> = (props) => {\n  return (\n    <tr\n      data-slot=\"table-row\"\n      class={cn(\n        \"hover:bg-muted/50 data-[state=selected]:bg-muted border-b transition-colors\",\n        props.class\n      )}\n      {...props}\n    >\n      {props.children}\n    </tr>\n  );\n};\n\n/**\n * TableHead component - th element\n */\nexport const TableHead: ParentComponent<JSX.ThHTMLAttributes<HTMLTableCellElement>> = (props) => {\n  return (\n    <th\n      data-slot=\"table-head\"\n      class={cn(\n        \"text-foreground h-10 px-2 text-left align-middle font-medium whitespace-nowrap\",\n        \"[&:has([role=checkbox])]:pr-0 [&>[role=checkbox]]:translate-y-[2px]\",\n        props.class\n      )}\n      {...props}\n    >\n      {props.children}\n    </th>\n  );\n};\n\n/**\n * TableCell component - td element\n */\nexport const TableCell: ParentComponent<JSX.TdHTMLAttributes<HTMLTableCellElement>> = (props) => {\n  return (\n    <td\n      data-slot=\"table-cell\"\n      class={cn(\n        \"p-2 align-middle whitespace-nowrap\",\n        \"[&:has([role=checkbox])]:pr-0 [&>[role=checkbox]]:translate-y-[2px]\",\n        props.class\n      )}\n      {...props}\n    >\n      {props.children}\n    </td>\n  );\n};\n\n/**\n * TableCaption component - caption element\n */\nexport const TableCaption: ParentComponent<JSX.HTMLAttributes<HTMLTableCaptionElement>> = (props) => {\n  return (\n    <caption\n      data-slot=\"table-caption\"\n      class={cn(\"text-muted-foreground mt-4 text-sm\", props.class)}\n      {...props}\n    >\n      {props.children}\n    </caption>\n  );\n};", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3273, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0cae4cc5-b634-47fe-af4a-0041cdecac6f": {"__data__": {"id_": "0cae4cc5-b634-47fe-af4a-0041cdecac6f", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\Tabs.tsx", "language": "typescript", "lines": 126, "filename": "Tabs.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\migrated-components\\components\\ui\\Tabs.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\components\\ui\\Tabs.tsx", "language": "typescript", "lines": 126, "filename": "Tabs.tsx"}, "hash": "f56c3c1bf1febb7fd49256eca0ac5de9ec357abd2e935f02449af022854ba404", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import { createSignal, type JSX, ParentComponent, createContext, useContext } from \"solid-js\";\nimport { cn } from \"../../utils/cn\";\n\n// Context para gerenciar estado das tabs\ntype TabsContextValue = {\n  value: () => string | undefined;\n  setValue: (value: string) => void;\n};\n\nconst TabsContext = createContext<TabsContextValue>();\n\ninterface TabsProps extends JSX.HTMLAttributes<HTMLDivElement> {\n  defaultValue?: string;\n  value?: string;\n  onValueChange?: (value: string) => void;\n}\n\n/**\n * Tabs component - container\n * Migrated from React to SolidJS (Radix UI removed, native implementation with createSignal)\n */\nexport const Tabs: ParentComponent<TabsProps> = (props) => {\n  const [internalValue, setInternalValue] = createSignal(props.defaultValue || props.value || \"\");\n  \n  const value = () => props.value !== undefined ? props.value : internalValue();\n  const setValue = (newValue: string) => {\n    setInternalValue(newValue);\n    props.onValueChange?.(newValue);\n  };\n\n  return (\n    <TabsContext.Provider value={{ value, setValue }}>\n      <div\n        data-slot=\"tabs\"\n        class={cn(\"flex flex-col gap-2\", props.class)}\n        {...props}\n      >\n        {props.children}\n      </div>\n    </TabsContext.Provider>\n  );\n};\n\n/**\n * TabsList component - tabs list container\n */\nexport const TabsList: ParentComponent<JSX.HTMLAttributes<HTMLDivElement>> = (props) => {\n  return (\n    <div\n      data-slot=\"tabs-list\"\n      role=\"tablist\"\n      class={cn(\n        \"bg-muted text-muted-foreground inline-flex h-9 w-fit items-center justify-center rounded-lg p-[3px]\",\n        props.class\n      )}\n      {...props}\n    >\n      {props.children}\n    </div>\n  );\n};\n\ninterface TabsTriggerProps extends JSX.ButtonHTMLAttributes<HTMLButtonElement> {\n  value: string;\n}\n\n/**\n * TabsTrigger component - individual tab button\n */\nexport function TabsTrigger(props: TabsTriggerProps) {\n  const context = useContext(TabsContext);\n  if (!context) throw new Error(\"TabsTrigger must be used within Tabs\");\n\n  const isActive = () => context.value() === props.value;\n\n  return (\n    <button\n      data-slot=\"tabs-trigger\"\n      data-state={isActive() ? \"active\" : \"inactive\"}\n      role=\"tab\"\n      aria-selected={isActive()}\n      onClick={() => context.setValue(props.value)}\n      class={cn(\n        \"data-[state=active]:bg-background dark:data-[state=active]:text-foreground\",\n        \"focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:outline-ring\",\n        \"dark:data-[state=active]:border-input dark:data-[state=active]:bg-input/30\",\n        \"text-foreground dark:text-muted-foreground\",\n        \"inline-flex h-[calc(100%-1px)] flex-1 items-center justify-center gap-1.5\",\n        \"rounded-md border border-transparent px-2 py-1 text-sm font-medium whitespace-nowrap\",\n        \"transition-[color,box-shadow] focus-visible:ring-[3px] focus-visible:outline-1\",\n        \"disabled:pointer-events-none disabled:opacity-50 data-[state=active]:shadow-sm\",\n        \"[&_svg]:pointer-events-none [&_svg]:shrink-0 [&_svg:not([class*='size-'])]:size-4\",\n        props.class\n      )}\n      {...props}\n    />\n  );\n}\n\ninterface TabsContentProps extends JSX.HTMLAttributes<HTMLDivElement> {\n  value: string;\n}\n\n/**\n * TabsContent component - tab panel content\n */\nexport const TabsContent: ParentComponent<TabsContentProps> = (props) => {\n  const context = useContext(TabsContext);\n  if (!context) throw new Error(\"TabsContent must be used within Tabs\");\n\n  const isActive = () => context.value() === props.value;\n\n  return (\n    <div\n      data-slot=\"tabs-content\"\n      data-state={isActive() ? \"active\" : \"inactive\"}\n      role=\"tabpanel\"\n      hidden={!isActive()}\n      class={cn(\"flex-1 outline-none\", props.class)}\n      {...props}\n    >\n      {isActive() && props.children}\n    </div>\n  );\n};", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3803, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a47598b0-9aad-43a0-ac0d-c8c192098b86": {"__data__": {"id_": "a47598b0-9aad-43a0-ac0d-c8c192098b86", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\utils\\a11y.ts", "language": "typescript", "lines": 76, "filename": "a11y.ts"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\migrated-components\\utils\\a11y.ts", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\utils\\a11y.ts", "language": "typescript", "lines": 76, "filename": "a11y.ts"}, "hash": "aab803df771939c68093142acf7cdbdaa2a623e29fa4d65bcb86bcb73c2c32e0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "/**\n * Accessibility Utilities for SolidJS\n * Fun\u00e7\u00f5es utilit\u00e1rias para acessibilidade\n */\n\n/**\n * Gera um ID \u00fanico para elementos ARIA\n */\nexport function generateAriaId(prefix: string): string {\n  return `${prefix}-${Math.random().toString(36).substr(2, 9)}`;\n}\n\n/**\n * Anuncia mensagem para screen readers\n */\nexport function announceToScreenReader(\n  message: string,\n  priority: \"polite\" | \"assertive\" = \"polite\"\n) {\n  const announcement = document.createElement(\"div\");\n  announcement.setAttribute(\"role\", \"status\");\n  announcement.setAttribute(\"aria-live\", priority);\n  announcement.setAttribute(\"aria-atomic\", \"true\");\n  announcement.className = \"sr-only\";\n  announcement.textContent = message;\n\n  document.body.appendChild(announcement);\n\n  setTimeout(() => {\n    document.body.removeChild(announcement);\n  }, 1000);\n}\n\n/**\n * Verifica se um elemento est\u00e1 vis\u00edvel para screen readers\n */\nexport function isVisibleToScreenReader(element: HTMLElement): boolean {\n  return (\n    !element.hasAttribute(\"aria-hidden\") ||\n    element.getAttribute(\"aria-hidden\") === \"false\"\n  );\n}\n\n/**\n * Gerencia foco em modais/dialogs\n * Retorna fun\u00e7\u00e3o de cleanup para remover event listener\n */\nexport function trapFocus(container: HTMLElement) {\n  const focusableElements = container.querySelectorAll<HTMLElement>(\n    'button, [href], input, select, textarea, [tabindex]:not([tabindex=\"-1\"])'\n  );\n\n  const firstElement = focusableElements[0];\n  const lastElement = focusableElements[focusableElements.length - 1];\n\n  const handleTabKey = (e: KeyboardEvent) => {\n    if (e.key !== \"Tab\") return;\n\n    if (e.shiftKey) {\n      if (document.activeElement === firstElement) {\n        lastElement.focus();\n        e.preventDefault();\n      }\n    } else {\n      if (document.activeElement === lastElement) {\n        firstElement.focus();\n        e.preventDefault();\n      }\n    }\n  };\n\n  container.addEventListener(\"keydown\", handleTabKey);\n\n  return () => container.removeEventListener(\"keydown\", handleTabKey);\n}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1999, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "088cb1cf-31e9-4527-82a6-a7681b9dda7f": {"__data__": {"id_": "088cb1cf-31e9-4527-82a6-a7681b9dda7f", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\utils\\cn.ts", "language": "typescript", "lines": 11, "filename": "cn.ts"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\migrated-components\\utils\\cn.ts", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\migrated-components\\utils\\cn.ts", "language": "typescript", "lines": 11, "filename": "cn.ts"}, "hash": "6ed9ce317395af93e46967911a93a93063c7a84b721fec261467e60462e61280", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import { clsx, type ClassValue } from \"clsx\";\nimport { twMerge } from \"tailwind-merge\";\n\n/**\n * Combina classes CSS com suporte a Tailwind\n * \u00datil para mesclar classes condicionais\n */\nexport function cn(...inputs: ClassValue[]) {\n  return twMerge(clsx(inputs));\n}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 264, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "231660b1-5b39-4427-b83d-10aa59ccd056": {"__data__": {"id_": "231660b1-5b39-4427-b83d-10aa59ccd056", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\About.tsx", "language": "typescript", "lines": 142, "filename": "About.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\About.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\About.tsx", "language": "typescript", "lines": 142, "filename": "About.tsx"}, "hash": "4b0f263ca1d058d72ee78ac1e07af6507a060ffffffe30892d928d387f7e0b97", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b9e5547a-2ed6-43e2-9a81-68224c893eed", "node_type": "1", "metadata": {}, "hash": "235e585716c59ba6521e0136a75359b73ed6350a0b42d0042d65d490b2025df8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import { Component, createSignal } from 'solid-js';\nimport { \n  Info, \n  Target, \n  Users, \n  TrendingUp, \n  Award, \n  MapPin, \n  ShieldCheck, \n  Heart\n} from 'lucide-solid';\n\nconst About: Component = () => {\n  // Paleta de cores derivada da an\u00e1lise da marca\n  const brandColors = {\n    primary: '#78B928', // Verde Ca\u00e7ula Estimado\n    secondary: '#2C3E50', // Azul escuro para contraste\n    accent: '#ED1C24', // Vermelho da p\u00e9tala para detalhes\n    background: '#F8F9FA'\n  };\n\n  return (\n    <div class=\"flex flex-col min-h-full bg-slate-50\">\n      {/* Hero Section com a Imagem da Marca */}\n      <div \n        class=\"w-full h-48 md:h-64 bg-cover bg-center relative shadow-md\"\n        style={{ \n          \"background-color\": brandColors.primary,\n          \"background-image\": \"url('/banner-cacula.png')\",\n          \"background-size\": \"contain\",\n          \"background-repeat\": \"no-repeat\",\n          \"background-position\": \"center\"\n        }}\n      >\n        <div class=\"absolute inset-0 bg-black/10\"></div> {/* Overlay sutil para profundidade */}\n      </div>\n\n      <div class=\"max-w-5xl mx-auto px-4 sm:px-6 lg:px-8 -mt-12 relative z-10 pb-12\">\n        {/* Card Principal de Introdu\u00e7\u00e3o */}\n        <div class=\"bg-white rounded-xl shadow-lg p-8 mb-8 border-t-4\" style={{ \"border-color\": brandColors.primary }}>\n          <div class=\"flex items-center gap-3 mb-4\">\n            <Info class=\"w-8 h-8\" style={{ color: brandColors.primary }} />\n            <h1 class=\"text-3xl font-bold text-gray-800\">Sobre o Agente BI Ca\u00e7ula</h1>\n          </div>\n          <p class=\"text-lg text-gray-600 leading-relaxed\">\n            Bem-vindo \u00e0 central de intelig\u00eancia de dados das Lojas Ca\u00e7ula. \n            Esta plataforma foi desenvolvida para empoderar nossa equipe com insights r\u00e1pidos, \n            precisos e acion\u00e1veis, combinando a tradi\u00e7\u00e3o de nossa marca com o que h\u00e1 de mais moderno em Intelig\u00eancia Artificial.\n          </p>\n        </div>\n\n        {/* Grid de Valores e Objetivos */}\n        <div class=\"grid grid-cols-1 md:grid-cols-2 gap-6 mb-8\">\n          \n          {/* Nossa Miss\u00e3o com IA */}\n          <div class=\"bg-white rounded-lg shadow-sm p-6 border border-gray-100 hover:shadow-md transition-shadow\">\n            <div class=\"flex items-center gap-3 mb-3\">\n              <div class=\"p-2 rounded-full bg-blue-50\">\n                <Target class=\"w-6 h-6 text-blue-600\" />\n              </div>\n              <h2 class=\"text-xl font-semibold text-gray-800\">Miss\u00e3o Tecnol\u00f3gica</h2>\n            </div>\n            <p class=\"text-gray-600\">\n              Democratizar o acesso aos dados corporativos. Permitir que cada gerente, vendedor e \n              analista tome decis\u00f5es baseadas em evid\u00eancias, n\u00e3o apenas em intui\u00e7\u00e3o.\n            </p>\n          </div>\n\n          {/* Foco no Cliente */}\n          <div class=\"bg-white rounded-lg shadow-sm p-6 border border-gray-100 hover:shadow-md transition-shadow\">\n            <div class=\"flex items-center gap-3 mb-3\">\n              <div class=\"p-2 rounded-full bg-red-50\">\n                <Heart class=\"w-6 h-6 text-red-600\" />\n              </div>\n              <h2 class=\"text-xl font-semibold text-gray-800\">Foco no Cliente</h2>\n            </div>\n            <p class=\"text-gray-600\">\n              Usamos dados para entender melhor nossos clientes. Nossas an\u00e1lises de ruptura, \n              mix de produtos e tend\u00eancias garantem que o cliente encontre o que precisa para sua arte.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3436, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b9e5547a-2ed6-43e2-9a81-68224c893eed": {"__data__": {"id_": "b9e5547a-2ed6-43e2-9a81-68224c893eed", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\About.tsx", "language": "typescript", "lines": 142, "filename": "About.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\About.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\About.tsx", "language": "typescript", "lines": 142, "filename": "About.tsx"}, "hash": "4b0f263ca1d058d72ee78ac1e07af6507a060ffffffe30892d928d387f7e0b97", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "231660b1-5b39-4427-b83d-10aa59ccd056", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\About.tsx", "language": "typescript", "lines": 142, "filename": "About.tsx"}, "hash": "4207f7442b006e96f66afc8e3a1d61eb18518c254929213d96b9bf80340847cd", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "</p>\n          </div>\n        </div>\n\n        {/* Estat\u00edsticas / Pilares do Projeto */}\n        <div class=\"grid grid-cols-1 sm:grid-cols-3 gap-4 mb-12\">\n          <div class=\"bg-white p-6 rounded-lg shadow-sm text-center border-b-4 border-blue-400\">\n            <div class=\"text-4xl font-bold text-gray-800 mb-2\">100%</div>\n            <div class=\"text-sm text-gray-500 uppercase tracking-wide font-semibold\">Integrado ao ERP</div>\n          </div>\n          <div class=\"bg-white p-6 rounded-lg shadow-sm text-center border-b-4 border-purple-400\">\n            <div class=\"text-4xl font-bold text-gray-800 mb-2\">24/7</div>\n            <div class=\"text-sm text-gray-500 uppercase tracking-wide font-semibold\">Disponibilidade</div>\n          </div>\n          <div class=\"bg-white p-6 rounded-lg shadow-sm text-center border-b-4 border-yellow-400\">\n            <div class=\"text-4xl font-bold text-gray-800 mb-2\">IA</div>\n            <div class=\"text-sm text-gray-500 uppercase tracking-wide font-semibold\">Gemini 3.0 Flash</div>\n          </div>\n        </div>\n\n        {/* Se\u00e7\u00e3o Institucional Resumida */}\n        <div class=\"bg-slate-800 rounded-xl p-8 text-white relative overflow-hidden\">\n          <div class=\"relative z-10\">\n            <h3 class=\"text-2xl font-bold mb-4 flex items-center gap-2\">\n              <Award class=\"w-6 h-6 text-yellow-400\" />\n              Tradi\u00e7\u00e3o e Inova\u00e7\u00e3o\n            </h3>\n            <p class=\"text-slate-300 mb-6 max-w-2xl\">\n              As Lojas Ca\u00e7ula s\u00e3o refer\u00eancia no varejo de papelaria, inform\u00e1tica, desenho e pintura. \n              Este sistema \u00e9 o pr\u00f3ximo passo na nossa evolu\u00e7\u00e3o, unindo nossa vasta experi\u00eancia de mercado \n              com a velocidade da an\u00e1lise de dados digital.\n            </p>\n            \n            <div class=\"flex flex-wrap gap-4 text-sm font-medium text-slate-400\">\n              <span class=\"flex items-center gap-1\">\n                <MapPin class=\"w-4 h-4\" /> Rio de Janeiro\n              </span>\n              <span class=\"flex items-center gap-1\">\n                <Users class=\"w-4 h-4\" /> +1000 Colaboradores\n              </span>\n              <span class=\"flex items-center gap-1\">\n                <ShieldCheck class=\"w-4 h-4\" /> Dados Seguros\n              </span>\n            </div>\n          </div>\n          \n          {/* Elemento decorativo visual usando as cores da logo de forma abstrata */}\n          <div class=\"absolute right-0 top-0 h-full w-1/3 opacity-10\">\n            <div class=\"h-full w-full bg-gradient-to-bl from-green-500 via-yellow-500 to-red-500 transform skew-x-12\"></div>\n          </div>\n        </div>\n\n        {/* Rodap\u00e9 da P\u00e1gina */}\n        <div class=\"mt-8 text-center text-gray-400 text-sm\">\n          &copy; {new Date().getFullYear()} Lojas Ca\u00e7ula - Departamento de Tecnologia e Dados\n        </div>\n      </div>\n    </div>\n  );\n};\n\nexport default About;", "mimetype": "text/plain", "start_char_idx": 3449, "end_char_idx": 6320, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "cc116702-974c-415c-aeb8-ed23b71cad48": {"__data__": {"id_": "cc116702-974c-415c-aeb8-ed23b71cad48", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Admin.tsx", "language": "typescript", "lines": 448, "filename": "Admin.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Admin.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Admin.tsx", "language": "typescript", "lines": 448, "filename": "Admin.tsx"}, "hash": "d517721f3fca5768291d888ecf4f768fb8530a84952e1df64146367132223087", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "13f4e010-9e4d-4424-9da9-cf965a88ba87", "node_type": "1", "metadata": {}, "hash": "0889e7d5e42eb3a05f20c35b796f4b666af0d4e999fed5e7aa142e15e091f73f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import { Shield, Users, Database, Settings, RefreshCw, CheckCircle, AlertCircle, Plus, Edit, Trash2, X } from 'lucide-solid';\nimport { createSignal, Show, For, createResource, onMount } from 'solid-js';\nimport { adminApi, analyticsApi, UserData, CreateUserPayload, UpdateUserPayload } from '@/lib/api';\n\nexport default function Admin() {\n  const [syncing, setSyncing] = createSignal(false);\n  const [message, setMessage] = createSignal<{ type: 'success' | 'error', text: string } | null>(null);\n  const [activeTab, setActiveTab] = createSignal<'sync' | 'users'>('sync');\n\n  // User Management State\n  const [users, { refetch: refetchUsers }] = createResource<UserData[]>(async () => {\n    try {\n      const response = await adminApi.getUsers();\n      return response.data;\n    } catch (err) {\n      console.error('Error loading users:', err);\n      return [];\n    }\n  });\n\n  // Load Segment Options\n  const [filterOptions] = createResource(async () => {\n    try {\n      const response = await analyticsApi.getFilterOptions();\n      return response.data;\n    } catch (err) {\n      console.error('Error loading filter options:', err);\n      return { categorias: [], segmentos: [] };\n    }\n  });\n\n  const [showUserModal, setShowUserModal] = createSignal(false);\n  const [editingUser, setEditingUser] = createSignal<UserData | null>(null);\n  const [formData, setFormData] = createSignal<CreateUserPayload>({\n    username: '',\n    email: '',\n    password: '',\n    role: 'user',\n    allowed_segments: []\n  });\n\n  const handleSync = async () => {\n    setSyncing(true);\n    setMessage(null);\n    try {\n      await adminApi.syncParquet();\n      setMessage({ type: 'success', text: 'Sincroniza\u00e7\u00e3o iniciada em segundo plano!' });\n    } catch (err) {\n      setMessage({ type: 'error', text: 'Erro ao iniciar sincroniza\u00e7\u00e3o. Verifique logs.'", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1827, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "13f4e010-9e4d-4424-9da9-cf965a88ba87": {"__data__": {"id_": "13f4e010-9e4d-4424-9da9-cf965a88ba87", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Admin.tsx", "language": "typescript", "lines": 448, "filename": "Admin.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Admin.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Admin.tsx", "language": "typescript", "lines": 448, "filename": "Admin.tsx"}, "hash": "d517721f3fca5768291d888ecf4f768fb8530a84952e1df64146367132223087", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "cc116702-974c-415c-aeb8-ed23b71cad48", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Admin.tsx", "language": "typescript", "lines": 448, "filename": "Admin.tsx"}, "hash": "c4f299d96f989be490d184ea31dee57f9447e8139de82c971b043532d64c1182", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "58452bc4-426f-477c-8c8c-b376cb1e766f", "node_type": "1", "metadata": {}, "hash": "9963a48afdfc79fd569cf20847c7ec2bea457262cfd2b944ad31fa826b69502e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Verifique logs.' });\n    } finally {\n      setSyncing(false);\n      setTimeout(() => setMessage(null), 5000);\n    }\n  };\n\n  const openCreateUserModal = () => {\n    setEditingUser(null);\n    setFormData({ username: '', email: '', password: '', role: 'user', allowed_segments: [] });\n    setShowUserModal(true);\n  };\n\n  const openEditUserModal = (user: UserData) => {\n    setEditingUser(user);\n    setFormData({\n      username: user.username,\n      email: user.email,\n      password: '',\n      role: user.role,\n      allowed_segments: user.allowed_segments || []\n    });\n    setShowUserModal(true);\n  };\n\n  const closeUserModal = () => {\n    setShowUserModal(false);\n    setEditingUser(null);\n    setFormData({ username: '', email: '', password: '', role: 'user', allowed_segments: [] });\n  };\n\n  const handleSubmitUser = async (e: Event) => {\n    e.preventDefault();\n    setMessage(null);\n\n    try {\n      const data = formData();\n\n      if (editingUser()) {\n        // Update existing user\n        const updateData: UpdateUserPayload = {\n          username: data.username,\n          email: data.email,\n          role: data.role,\n          allowed_segments: data.allowed_segments\n        };\n\n        // Only include password if provided\n        if (data.password) {\n          updateData.password = data.password;\n        }\n\n        await adminApi.updateUser(editingUser()!.id, updateData);\n        setMessage({ type: 'success', text: `Usu\u00e1rio ${data.username} atualizado com sucesso!` });\n      } else {\n        // Create new user\n        await adminApi.createUser(data);\n        setMessage({ type: 'success', text: `Usu\u00e1rio ${data.username} criado com sucesso!` });\n      }\n\n      closeUserModal();\n      refetchUsers();\n      setTimeout(() => setMessage(null), 5000);\n    } catch (err: any) {\n      const errorMsg = err?.response?.data?.detail || 'Erro ao salvar usu\u00e1rio';\n      setMessage({ type: 'error', text: errorMsg });\n      setTimeout(() => setMessage(null), 5000);\n    }\n  };\n\n  const handleDeleteUser = async (user: UserData) => {\n    if (!confirm(`Tem certeza que deseja excluir o usu\u00e1rio ${user.username}?`)) {\n      return;\n    }\n\n    setMessage(null);\n    try {\n      await adminApi.deleteUser(user.id);\n      setMessage({ type: 'success', text: `Usu\u00e1rio ${user.username} exclu\u00eddo com sucesso!` });\n      refetchUsers();\n      setTimeout(() => setMessage(null), 5000);\n    } catch (err: any) {\n      const errorMsg = err?.response?.data?.detail || 'Erro ao excluir usu\u00e1rio';\n      setMessage({ type: 'error', text: errorMsg });\n      setTimeout(() => setMessage(null), 5000);\n    }\n  };\n\n  const handleToggleActive = async (user: UserData) => {\n    setMessage(null);\n    try {\n      await adminApi.updateUser(user.id, { is_active: !user.is_active });\n      setMessage({\n        type: 'success',\n        text: `Usu\u00e1rio ${user.username} ${!user.is_active ? 'ativado' : 'desativado'} com sucesso!`\n      });\n      refetchUsers();\n      setTimeout(() => setMessage(null), 5000);\n    } catch (err: any) {\n      const errorMsg = err?.response?.data?.detail || 'Erro ao atualizar status do usu\u00e1rio';\n      setMessage({ type: 'error', text: errorMsg });\n      setTimeout(() => setMessage(null), 5000);\n    }\n  };\n\n  return (\n    <div class=\"flex flex-col h-full p-6 gap-6\">\n      {/* Header */}\n      <div class=\"flex flex-col md:flex-row justify-between items-start md:items-center gap-4\">\n        <div>\n          <h2 class=\"text-2xl font-bold tracking-tight\">\u00c1rea Administrativa</h2>\n          <p class=\"text-muted\">Gerenciamento do sistema e usu\u00e1rios</p>\n        </div>\n      </div>\n\n      {/* Message Alert */}\n      <Show when={message()}>\n        <div class={`p-3 rounded-lg flex items-center gap-2 text-sm ${\n          message()?.type === 'success' ? 'bg-green-500/10 text-green-400 border border-green-500/20' : 'bg-red-500/10 text-red-400 border border-red-500/20'\n        }`}>\n          {message()?.type === 'success' ?", "mimetype": "text/plain", "start_char_idx": 1811, "end_char_idx": 5747, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "58452bc4-426f-477c-8c8c-b376cb1e766f": {"__data__": {"id_": "58452bc4-426f-477c-8c8c-b376cb1e766f", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Admin.tsx", "language": "typescript", "lines": 448, "filename": "Admin.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Admin.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Admin.tsx", "language": "typescript", "lines": 448, "filename": "Admin.tsx"}, "hash": "d517721f3fca5768291d888ecf4f768fb8530a84952e1df64146367132223087", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "13f4e010-9e4d-4424-9da9-cf965a88ba87", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Admin.tsx", "language": "typescript", "lines": 448, "filename": "Admin.tsx"}, "hash": "77b90c98e40100220ebba467cfdc8aa0a376bd3fbd58f15655ed71e3179f7468", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7119060c-c3dc-422b-8d3f-6e2e771a35d4", "node_type": "1", "metadata": {}, "hash": "d610d10b502bc868590b600d8db6033ee8987426c728a2718f545b521f16afc3", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "<CheckCircle size={16} /> : <AlertCircle size={16} />}\n          {message()?.text}\n        </div>\n      </Show>\n\n      {/* Tabs */}\n      <div class=\"flex gap-2 border-b\">\n        <button\n          onClick={() => setActiveTab('sync')}\n          class={`px-4 py-2 font-medium transition-colors ${\n            activeTab() === 'sync' ? 'border-b-2 border-primary text-primary' : 'text-muted hover:text-foreground'\n          }`}\n        >\n          <div class=\"flex items-center gap-2\">\n            <RefreshCw size={16} />\n            Sincroniza\u00e7\u00e3o\n          </div>\n        </button>\n        <button\n          onClick={() => setActiveTab('users')}\n          class={`px-4 py-2 font-medium transition-colors ${\n            activeTab() === 'users' ? 'border-b-2 border-primary text-primary' : 'text-muted hover:text-foreground'\n          }`}\n        >\n          <div class=\"flex items-center gap-2\">\n            <Users size={16} />\n            Usu\u00e1rios\n          </div>\n        </button>\n      </div>\n\n      {/* Tab Content */}\n      <div class=\"flex-1 overflow-auto\">\n        <Show when={activeTab() === 'sync'}>\n          <div class=\"max-w-2xl mx-auto space-y-4\">\n            <div\n              onClick={!syncing() ? handleSync : undefined}\n              class={`p-6 border rounded-lg bg-card flex items-center gap-4 transition-all ${\n                syncing() ? 'opacity-70 cursor-wait' : 'hover:border-primary/50 cursor-pointer hover:bg-secondary/30'\n              }`}\n            >\n              <div class=\"p-3 bg-purple-500/10 text-purple-400 rounded-lg\">\n                <RefreshCw size={24} class={syncing() ? 'animate-spin' : ''} />\n              </div>\n              <div class=\"flex-1\">\n                <h4 class=\"font-semibold text-lg\">Sincronizar Dados</h4>\n                <p class=\"text-sm text-muted\">Atualizar Parquet via SQL Server</p>\n              </div>\n              {syncing() && <span class=\"text-sm text-primary animate-pulse\">Processando...</span>}\n            </div>\n          </div>\n        </Show>\n\n        <Show when={activeTab() === 'users'}>\n          <div class=\"space-y-4\">\n            {/* Header with Add Button */}\n            <div class=\"flex justify-between items-center\">\n              <h3 class=\"text-lg font-semibold\">Gerenciar Usu\u00e1rios</h3>\n              <button\n                onClick={openCreateUserModal}\n                class=\"btn btn-primary gap-2\"\n              >\n                <Plus size={16} />\n                Novo Usu\u00e1rio\n              </button>\n            </div>\n\n            {/* Users Table */}\n            <div class=\"border rounded-lg overflow-hidden bg-card\">\n              <table class=\"w-full\">\n                <thead class=\"bg-muted/50 border-b\">\n                  <tr>\n                    <th class=\"text-left p-3 text-sm font-medium\">Username</th>\n                    <th class=\"text-left p-3 text-sm font-medium\">Email</th>\n                    <th class=\"text-left p-3 text-sm font-medium\">Role</th>\n                    <th class=\"text-left p-3 text-sm font-medium\">Segmentos</th>\n                    <th class=\"text-center p-3 text-sm font-medium\">Status</th>\n                    <th class=\"text-right p-3 text-sm font-medium\">A\u00e7\u00f5es</th>\n                  </tr>\n                </thead>\n                <tbody>\n                  <Show when={users.loading}>\n                    <tr>\n                      <td colspan=\"6\" class=\"text-center p-8 text-muted\">\n                        <RefreshCw size={24} class=\"animate-spin mx-auto mb-2\" />\n                        Carregando usu\u00e1rios...\n                      </td>\n                    </tr>\n                  </Show>\n\n                  <Show when={!users.loading && users()}>\n                    <For each={users()}>\n                      {(user) => (\n                        <tr class=\"border-b hover:bg-muted/30 transition-colors\">\n                          <td class=\"p-3\">{user.username}</td>\n                          <td class=\"p-3 text-sm text-muted\">{user.email}</td>\n                          <td class=\"p-3\">\n                            <span class={`px-2 py-1 rounded text-xs font-medium ${\n                              user.role === 'admin' ? 'bg-purple-500/10 text-purple-400' :\n                              user.role === 'user' ?", "mimetype": "text/plain", "start_char_idx": 5748, "end_char_idx": 10003, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7119060c-c3dc-422b-8d3f-6e2e771a35d4": {"__data__": {"id_": "7119060c-c3dc-422b-8d3f-6e2e771a35d4", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Admin.tsx", "language": "typescript", "lines": 448, "filename": "Admin.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Admin.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Admin.tsx", "language": "typescript", "lines": 448, "filename": "Admin.tsx"}, "hash": "d517721f3fca5768291d888ecf4f768fb8530a84952e1df64146367132223087", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "58452bc4-426f-477c-8c8c-b376cb1e766f", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Admin.tsx", "language": "typescript", "lines": 448, "filename": "Admin.tsx"}, "hash": "b4cf7e60a3c286072d510d3e9576eb44facae948e05edec7c2ce4519e370b4e5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "771302d9-ea6c-4b8a-9c33-73e2503ed4a7", "node_type": "1", "metadata": {}, "hash": "47aa0dcabba9dc600ca86c6f90a328ddeb628b10151ed02a991de98f60add4c9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "'bg-blue-500/10 text-blue-400' :\n                              'bg-gray-500/10 text-gray-400'\n                            }`}>\n                              {user.role}\n                            </span>\n                          </td>\n                          <td class=\"p-3 text-sm text-muted\">\n                            <Show when={user.role === 'admin'} fallback={\n                                user.allowed_segments && user.allowed_segments.length > 0 \n                                ? <span title={user.allowed_segments.join(', ')}>{user.allowed_segments.length} segmento(s)</span>\n                                : <span class=\"text-yellow-500 text-xs\">Nenhum</span>\n                            }>\n                                <span class=\"text-muted italic\">Todos (Admin)</span>\n                            </Show>\n                          </td>\n                          <td class=\"p-3 text-center\">\n                            <button\n                              onClick={() => handleToggleActive(user)}\n                              class={`px-2 py-1 rounded text-xs font-medium transition-colors ${\n                                user.is_active\n                                  ? 'bg-green-500/10 text-green-400 hover:bg-green-500/20'\n                                  : 'bg-red-500/10 text-red-400 hover:bg-red-500/20'\n                              }`}\n                            >\n                              {user.is_active ? 'Ativo' : 'Inativo'}\n                            </button>\n                          </td>\n                          <td class=\"p-3\">\n                            <div class=\"flex justify-end gap-2\">\n                              <button\n                                onClick={() => openEditUserModal(user)}\n                                class=\"p-2 hover:bg-secondary rounded transition-colors\"\n                                title=\"Editar\"\n                              >\n                                <Edit size={16} />\n                              </button>\n                              <button\n                                onClick={() => handleDeleteUser(user)}\n                                class=\"p-2 hover:bg-red-500/10 text-red-400 rounded transition-colors\"\n                                title=\"Excluir\"\n                              >\n                                <Trash2 size={16} />\n                              </button>\n                            </div>\n                          </td>\n                        </tr>\n                      )}\n                    </For>\n                  </Show>\n\n                  <Show when={!users.loading && (!users() || users()?.length === 0)}>\n                    <tr>\n                      <td colspan=\"6\" class=\"text-center p-8 text-muted\">\n                        Nenhum usu\u00e1rio encontrado\n                      </td>\n                    </tr>\n                  </Show>\n                </tbody>\n              </table>\n            </div>\n          </div>\n        </Show>\n      </div>\n\n      {/* User Modal */}\n      <Show when={showUserModal()}>\n        <div class=\"fixed inset-0 bg-black/50 flex items-center justify-center z-50 p-4\" onClick={closeUserModal}>\n          <div class=\"bg-card border rounded-lg max-w-md w-full p-6 space-y-4 max-h-[90vh] overflow-y-auto\" onClick={(e) => e.stopPropagation()}>\n            <div class=\"flex justify-between items-center\">\n              <h3 class=\"text-lg font-semibold\">\n                {editingUser() ?", "mimetype": "text/plain", "start_char_idx": 10004, "end_char_idx": 13484, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "771302d9-ea6c-4b8a-9c33-73e2503ed4a7": {"__data__": {"id_": "771302d9-ea6c-4b8a-9c33-73e2503ed4a7", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Admin.tsx", "language": "typescript", "lines": 448, "filename": "Admin.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Admin.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Admin.tsx", "language": "typescript", "lines": 448, "filename": "Admin.tsx"}, "hash": "d517721f3fca5768291d888ecf4f768fb8530a84952e1df64146367132223087", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7119060c-c3dc-422b-8d3f-6e2e771a35d4", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Admin.tsx", "language": "typescript", "lines": 448, "filename": "Admin.tsx"}, "hash": "b6d71a12caec19842639be79aad8955136bf7fe5e785ec7aa67d4451bc03ea55", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "'Editar Usu\u00e1rio' : 'Novo Usu\u00e1rio'}\n              </h3>\n              <button onClick={closeUserModal} class=\"p-1 hover:bg-secondary rounded\">\n                <X size={20} />\n              </button>\n            </div>\n\n            <form onSubmit={handleSubmitUser} class=\"space-y-4\">\n              <div>\n                <label class=\"block text-sm font-medium mb-1\">Username</label>\n                <input\n                  type=\"text\"\n                  value={formData().username}\n                  onInput={(e) => setFormData({ ...formData(), username: e.currentTarget.value })}\n                  class=\"w-full px-3 py-2 bg-background border rounded-lg focus:outline-none focus:ring-2 focus:ring-primary\"\n                  required\n                />\n              </div>\n\n              <div>\n                <label class=\"block text-sm font-medium mb-1\">Email</label>\n                <input\n                  type=\"email\"\n                  value={formData().email}\n                  onInput={(e) => setFormData({ ...formData(), email: e.currentTarget.value })}\n                  class=\"w-full px-3 py-2 bg-background border rounded-lg focus:outline-none focus:ring-2 focus:ring-primary\"\n                  required\n                />\n              </div>\n\n              <div>\n                <label class=\"block text-sm font-medium mb-1\">\n                  Senha {editingUser() && '(deixe em branco para n\u00e3o alterar)'}\n                </label>\n                <input\n                  type=\"password\"\n                  value={formData().password}\n                  onInput={(e) => setFormData({ ...formData(), password: e.currentTarget.value })}\n                  class=\"w-full px-3 py-2 bg-background border rounded-lg focus:outline-none focus:ring-2 focus:ring-primary\"\n                  required={!editingUser()}\n                  minLength={8}\n                />\n              </div>\n\n              <div>\n                <label class=\"block text-sm font-medium mb-1\">Role</label>\n                <select\n                  value={formData().role}\n                  onChange={(e) => setFormData({ ...formData(), role: e.currentTarget.value })}\n                  class=\"w-full px-3 py-2 bg-background border rounded-lg focus:outline-none focus:ring-2 focus:ring-primary\"\n                  required\n                >\n                  <option value=\"viewer\">Viewer</option>\n                  <option value=\"user\">User</option>\n                  <option value=\"admin\">Admin</option>\n                </select>\n              </div>\n\n              {/* Segment Selection */}\n              <div class=\"space-y-2\">\n                <label class=\"block text-sm font-medium\">Segmentos Permitidos</label>\n                <div class=\"border rounded-lg p-3 max-h-48 overflow-y-auto space-y-2 bg-background\">\n                  <Show when={!filterOptions.loading} fallback={<span class=\"text-xs text-muted\">Carregando segmentos...</span>}>\n                    <For each={filterOptions()?.segmentos || []}>\n                      {(segment) => (\n                        <label class=\"flex items-center gap-2 text-sm cursor-pointer hover:bg-muted/50 p-1 rounded\">\n                          <input\n                            type=\"checkbox\"\n                            checked={formData().allowed_segments?.includes(segment)}\n                            onChange={(e) => {\n                              const current = formData().allowed_segments || [];\n                              if (e.currentTarget.checked) {\n                                setFormData({ ...formData(), allowed_segments: [...current, segment] });\n                              } else {\n                                setFormData({ ...formData(), allowed_segments: current.filter(s => s !== segment) });\n                              }\n                            }}\n                            class=\"checkbox checkbox-sm checkbox-primary\"\n                          />\n                          <span>{segment}</span>\n                        </label>\n                      )}\n                    </For>\n                    <Show when={!filterOptions()?.segmentos?.length}>\n                        <p class=\"text-xs text-muted\">Nenhum segmento dispon\u00edvel encontrado.</p>\n                    </Show>\n                  </Show>\n                </div>\n                <p class=\"text-xs text-muted\">\n                    {formData().role === 'admin' \n                        ? 'Admin tem acesso total independente desta sele\u00e7\u00e3o.' \n                        : 'Se nenhum selecionado, o usu\u00e1rio n\u00e3o ver\u00e1 dados.'}\n                </p>\n              </div>\n\n              <div class=\"flex gap-2 pt-4\">\n                <button type=\"button\" onClick={closeUserModal} class=\"flex-1 btn btn-outline\">\n                  Cancelar\n                </button>\n                <button type=\"submit\" class=\"flex-1 btn btn-primary\">\n                  {editingUser() ? 'Salvar' : 'Criar'}\n                </button>\n              </div>\n            </form>\n          </div>\n        </div>\n      </Show>\n    </div>\n  );\n}", "mimetype": "text/plain", "start_char_idx": 13485, "end_char_idx": 18534, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "46ad38f6-2b5c-40d7-9716-2adfe2e3adc6": {"__data__": {"id_": "46ad38f6-2b5c-40d7-9716-2adfe2e3adc6", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Analytics.tsx", "language": "typescript", "lines": 592, "filename": "Analytics.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Analytics.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Analytics.tsx", "language": "typescript", "lines": 592, "filename": "Analytics.tsx"}, "hash": "f1037c387ed90c74a3971c94edda0cf1fee332e8bb5511cad2ded381b4034020", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "125b0a07-a31d-4b77-8143-18035ead4490", "node_type": "1", "metadata": {}, "hash": "22be84943530ba0be2afbecf3c28f2ca4a46afeeb940413a6cf9c7a5e6db6a1d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import { createSignal, onMount, Show, createResource, For, createEffect } from 'solid-js';\nimport { BarChart3, TrendingUp, RefreshCw, Filter, X } from 'lucide-solid';\nimport api, { analyticsApi } from '../lib/api'; // Import analyticsApi\nimport { PlotlyChart } from '../components/PlotlyChart';\nimport { ChartDownloadButton } from '../components/ChartDownloadButton';\n\ninterface SalesAnalysis {\n  vendas_por_categoria: Array<{\n    categoria: string;\n    vendas: number;\n  }>;\n  giro_estoque: Array<{\n    produto: string;\n    nome: string;\n    giro: number;\n  }>;\n  distribuicao_abc: {\n    A: number;\n    B: number;\n    C: number;\n    detalhes: Array<{\n      PRODUTO: number;\n      NOME: string;\n      receita: number;\n      perc_acumulada: number;\n      classe: string;\n    }>;\n    receita_por_classe?: Record<string, number>;\n  };\n}\n\ninterface FilterOptions {\n  categorias: string[];\n  segmentos: string[];\n}\n\nexport default function Analytics() {\n  const [data, setData] = createSignal<SalesAnalysis | null>(null);\n  const [loading, setLoading] = createSignal(true);\n  const [error, setError] = createSignal<string | null>(null);\n\n  // Filtros\n  const [categoria, setCategoria] = createSignal('');\n  const [segmento, setSegmento] = createSignal('');\n\n  // Carregar op\u00e7\u00f5es de filtro (segmentos e todas as categorias)\n  const [allFilterOptions] = createResource<FilterOptions>(async () => {\n    const response = await analyticsApi.getFilterOptions(); // Use analyticsApi\n    return response.data;\n  });\n\n  // Carregar categorias filtradas por segmento\n  const [filteredCategoryOptions] = createResource(() => segmento(), async (segmento) => {\n    if (segmento === '') {\n      return allFilterOptions()?.categorias || [];\n    }\n    const response = await analyticsApi.getFilterOptions({ segmento: segmento });\n    return response.data.categorias;\n  });\n\n  // Efeito para resetar categoria quando o segmento muda\n  createEffect(() => {\n    // Apenas se o segmento realmente mudou e n\u00e3o \u00e9 a inicializa\u00e7\u00e3o\n    if (segmento() !== undefined) {\n      setCategoria('');\n    }\n  });\n\n\n  // Chart specs\n  const [vendasCategoriaChart, setVendasCategoriaChart] = createSignal<any>({});\n  const [giroEstoqueChart, setGiroEstoqueChart] = createSignal<any>({});\n  const [distribuicaoABCChart, setDistribuicaoABCChart] = createSignal<any>({});\n\n  const loadData = async () => {\n    setLoading(true);\n    setError(null);\n\n    try {\n      const params = new URLSearchParams();\n      if (categoria()) params.append('categoria', categoria());\n      if (segmento()) params.append('segmento', segmento());\n\n      const response = await api.get<SalesAnalysis>(`/analytics/sales-analysis?${params.toString()}`);\n      setData(response.data);\n\n      // Gerar gr\u00e1ficos\n      generateCharts(response.data);\n    } catch (err: any) {\n      console.error('Erro ao carregar an\u00e1lise:', err);\n      setError(err.response?.data?.detail || 'Erro ao carregar an\u00e1lise de vendas');\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  const generateCharts = (analysisData: SalesAnalysis) => {\n    // 1.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3066, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "125b0a07-a31d-4b77-8143-18035ead4490": {"__data__": {"id_": "125b0a07-a31d-4b77-8143-18035ead4490", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Analytics.tsx", "language": "typescript", "lines": 592, "filename": "Analytics.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Analytics.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Analytics.tsx", "language": "typescript", "lines": 592, "filename": "Analytics.tsx"}, "hash": "f1037c387ed90c74a3971c94edda0cf1fee332e8bb5511cad2ded381b4034020", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "46ad38f6-2b5c-40d7-9716-2adfe2e3adc6", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Analytics.tsx", "language": "typescript", "lines": 592, "filename": "Analytics.tsx"}, "hash": "175479c97686fbd1128d624a80486e9c07b3d23d43ef6d4fd996a47985f6fc5e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0af46465-7e9d-446d-814d-0c8d5ef87710", "node_type": "1", "metadata": {}, "hash": "174b9635d3907a9ce59b28ce317e20d7eac0b3d9ae7e36e1b51a1ce70ddebadf", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "LOJAS CA\u00c7ULA - LIGHT THEME: Vendas por Categoria\n    if (analysisData.vendas_por_categoria.length > 0) {\n      const vendasSpec = {\n        data: [{\n          type: 'bar',\n          x: analysisData.vendas_por_categoria.map(c => c.categoria),\n          y: analysisData.vendas_por_categoria.map(c => c.vendas),\n          marker: {\n            color: '#8B7355', // Marrom Ca\u00e7ula\n            line: { color: '#E5E5E5', width: 1 }\n          },\n          text: analysisData.vendas_por_categoria.map(c => c.vendas.toLocaleString()),\n          textposition: 'outside',\n          textfont: { color: '#2D2D2D', family: 'Inter, sans-serif' },\n          hovertemplate: '<b>%{x}</b><br>Vendas: %{y:,}<extra></extra>'\n        }],\n        layout: {\n          title: {\n            text: 'Vendas por Categoria (Top 10)',\n            font: { size: 16, color: '#2D2D2D', family: 'Inter, sans-serif' }\n          },\n          xaxis: {\n            title: '',\n            tickangle: -45,\n            tickfont: { size: 10, color: '#6B6B6B', family: 'Inter, sans-serif' },\n            gridcolor: '#E5E5E5',\n            linecolor: '#E5E5E5'\n          },\n          yaxis: {\n            title: 'Vendas (30 dias)',\n            titlefont: { color: '#6B6B6B', family: 'Inter, sans-serif' },\n            tickfont: { color: '#6B6B6B', family: 'Inter, sans-serif' },\n            gridcolor: '#E5E5E5',\n            linecolor: '#E5E5E5'\n          },\n          plot_bgcolor: '#FFFFFF',\n          paper_bgcolor: '#FAFAFA',\n          margin: { l: 60, r: 20, t: 60, b: 100 },\n          font: { color: '#2D2D2D', family: 'Inter, sans-serif' }\n        },\n        config: { responsive: true }\n      };\n      setVendasCategoriaChart(vendasSpec);\n    }\n\n    // 2.", "mimetype": "text/plain", "start_char_idx": 3067, "end_char_idx": 4783, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0af46465-7e9d-446d-814d-0c8d5ef87710": {"__data__": {"id_": "0af46465-7e9d-446d-814d-0c8d5ef87710", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Analytics.tsx", "language": "typescript", "lines": 592, "filename": "Analytics.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Analytics.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Analytics.tsx", "language": "typescript", "lines": 592, "filename": "Analytics.tsx"}, "hash": "f1037c387ed90c74a3971c94edda0cf1fee332e8bb5511cad2ded381b4034020", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "125b0a07-a31d-4b77-8143-18035ead4490", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Analytics.tsx", "language": "typescript", "lines": 592, "filename": "Analytics.tsx"}, "hash": "c8f775c7db16b95ce340e75df9731441544497cc5ecb29fb8b70ec21821b9f0a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "71cfb93e-0a6f-4827-b80f-e555c33b1027", "node_type": "1", "metadata": {}, "hash": "a17609a9185a56450c820ebec99e246d3df9728e50d137dc00f9977386cf5628", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "LOJAS CA\u00c7ULA - LIGHT THEME: Giro de Estoque\n    if (analysisData.giro_estoque.length > 0) {\n      const giroSpec = {\n        data: [{\n          type: 'scatter',\n          mode: 'lines+markers',\n          x: analysisData.giro_estoque.map((_, i) => i + 1),\n          y: analysisData.giro_estoque.map(p => p.giro),\n          text: analysisData.giro_estoque.map(p => p.nome),\n          marker: {\n            color: '#2D7A3E', // Verde oliva\n            size: 8\n          },\n          line: {\n            color: '#6B7A5A', // Verde oliva claro\n            width: 2\n          },\n          hovertemplate: '<b>%{text}</b><br>Giro: %{y:.2f}<extra></extra>'\n        }],\n        layout: {\n          title: {\n            text: 'Giro de Estoque (Top 15 Produtos)',\n            font: { size: 16, color: '#2D2D2D', family: 'Inter, sans-serif' }\n          },\n          xaxis: {\n            title: 'Ranking',\n            titlefont: { color: '#6B6B6B', family: 'Inter, sans-serif' },\n            tickfont: { color: '#6B6B6B', family: 'Inter, sans-serif' },\n            gridcolor: '#E5E5E5',\n            linecolor: '#E5E5E5'\n          },\n          yaxis: {\n            title: 'Taxa de Giro',\n            titlefont: { color: '#6B6B6B', family: 'Inter, sans-serif' },\n            tickfont: { color: '#6B6B6B', family: 'Inter, sans-serif' },\n            gridcolor: '#E5E5E5',\n            linecolor: '#E5E5E5'\n          },\n          plot_bgcolor: '#FFFFFF',\n          paper_bgcolor: '#FAFAFA',\n          margin: { l: 60, r: 20, t: 60, b: 60 },\n          font: { color: '#2D2D2D', family: 'Inter, sans-serif' }\n        },\n        config: { responsive: true }\n      };\n      setGiroEstoqueChart(giroSpec);\n    }\n\n    // 3. LOJAS CA\u00c7ULA - GR\u00c1FICO DE PARETO REAL (ABC)\n    const abc = analysisData.distribuicao_abc;\n    if (abc.detalhes && abc.detalhes.length > 0) {\n      const paretoSpec = {\n        data: [\n          {\n            type: 'bar',\n            x: abc.detalhes.map(p => p.NOME.substring(0, 20)),\n            y: abc.detalhes.map(p => p.receita),\n            name: 'Faturamento (R$)',\n            marker: {\n              color: abc.detalhes.map(p => \n                p.classe === 'A' ? '#166534' : (p.classe === 'B' ? '#CA8A04' : '#991B1B')\n              ),\n              line: { color: '#FFFFFF', width: 1 },\n              opacity: 0.9\n            },\n            hovertemplate: '<b>%{x}</b><br>Receita: R$ %{y:,.2f}<br>Classe: %{customdata}<extra></extra>',\n            customdata: abc.detalhes.map(p => p.classe)\n          },\n          {\n            type: 'scatter',\n            mode: 'lines+markers',\n            x: abc.detalhes.map(p => p.NOME.substring(0, 20)),\n            y: abc.detalhes.map(p => p.perc_acumulada),\n            name: '% Acumulada',\n            yaxis: 'y2',\n            line: { color: '#1E293B', width: 3, shape: 'spline' },\n            marker: { \n              color: '#1E293B', \n              size: 8,\n              symbol: 'diamond'\n            },\n            hovertemplate: 'Contribui\u00e7\u00e3o Acumulada: %{y:.1f}%<extra></extra>'\n          }\n        ],\n        layout: {\n          title: {\n            text: '<b>Curva de Pareto: Onde est\u00e1 o seu faturamento?</b><br><span style=\"font-size:12px;", "mimetype": "text/plain", "start_char_idx": 4784, "end_char_idx": 7984, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "71cfb93e-0a6f-4827-b80f-e555c33b1027": {"__data__": {"id_": "71cfb93e-0a6f-4827-b80f-e555c33b1027", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Analytics.tsx", "language": "typescript", "lines": 592, "filename": "Analytics.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Analytics.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Analytics.tsx", "language": "typescript", "lines": 592, "filename": "Analytics.tsx"}, "hash": "f1037c387ed90c74a3971c94edda0cf1fee332e8bb5511cad2ded381b4034020", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0af46465-7e9d-446d-814d-0c8d5ef87710", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Analytics.tsx", "language": "typescript", "lines": 592, "filename": "Analytics.tsx"}, "hash": "2d46e8aa4614052d903a9c8704c8c075b9b669067d6b16aa1357ddae324d2a2d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5c99679d-fe0a-4654-acba-4b841f4ccfb0", "node_type": "1", "metadata": {}, "hash": "339866396097836dbe3be6aa7f556a1542f94b2f9b2484715119fba453ebff2d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "color:#64748B\">A an\u00e1lise identifica os 20% de produtos que geram 80% do lucro</span>',\n            font: { size: 18, color: '#0F172A', family: 'Inter, sans-serif' },\n            x: 0.05\n          },\n          xaxis: {\n            tickangle: -45,\n            tickfont: { size: 10, color: '#475569', font: { weight: 'bold' } },\n            gridcolor: '#F1F5F9'\n          },\n          yaxis: {\n            title: 'Receita Individual (R$)',\n            titlefont: { size: 12, color: '#64748B', font: { weight: 'bold' } },\n            gridcolor: '#F1F5F9',\n            zeroline: false\n          },\n          yaxis2: {\n            title: '% Contribui\u00e7\u00e3o Acumulada',\n            titlefont: { size: 12, color: '#64748B', font: { weight: 'bold' } },\n            overlaying: 'y',\n            side: 'right',\n            range: [0, 105],\n            showgrid: false,\n            tickvals: [0, 20, 40, 60, 80, 95, 100],\n            ticktext: ['0%', '20%', '40%', '60%', '80%', '95%', '100%'],\n            tickfont: { size: 10, color: '#1E293B', font: { weight: 'bold' } }\n          },\n          legend: { \n            orientation: 'h', \n            x: 0.5, \n            y: -0.25, \n            xanchor: 'center',\n            bgcolor: 'rgba(255,255,255,0.7)',\n            bordercolor: '#E2E8F0',\n            borderwidth: 1\n          },\n          plot_bgcolor: '#FFFFFF',\n          paper_bgcolor: '#FAFAFA',\n          margin: { l: 70, r: 70, t: 90, b: 130 },\n          shapes: [\n            // Linha de Corte de Pareto (80%)\n            {\n              type: 'line',\n              xref: 'paper', yref: 'y2',\n              x0: 0, x1: 1, y0: 80, y1: 80,\n              line: { color: '#166534', width: 2, dash: 'dashdot' }\n            },\n            // Anota\u00e7\u00e3o \"Vital Few\"\n            {\n              type: 'rect',\n              xref: 'paper', yref: 'paper',\n              x0: 0, x1: 0.2, y0: 0.8, y1: 1,\n              fillcolor: 'rgba(22, 101, 52, 0.05)',\n              line: { width: 0 }\n            }\n          ],\n          annotations: [\n            {\n              xref: 'paper', yref: 'y2',\n              x: 0.02, y: 85,\n              text: 'ZONA VITAL (80%)',\n              showarrow: false,\n              font: { color: '#166534', size: 10, weight: 'bold' }\n            }\n          ]\n        },\n        config: { responsive: true, displayModeBar: false }\n      };\n      setDistribuicaoABCChart(paretoSpec);\n    }\n  };\n\n  onMount(() => {\n    loadData();\n  });\n\n  return (\n    <div class=\"flex flex-col h-full p-6 gap-6\">\n      {/* Header */}\n      <div class=\"flex justify-between items-end\">\n        <div>\n          <h2 class=\"text-2xl font-bold flex items-center gap-2\">\n            <BarChart3 size={28} />\n            Analytics Avan\u00e7ado\n          </h2>\n          <p class=\"text-muted\">An\u00e1lise de vendas, estoque e distribui\u00e7\u00e3o ABC</p>\n        </div>\n        <button\n          onClick={loadData}\n          class=\"btn btn-outline gap-2\"\n          disabled={loading()}\n        >\n          <RefreshCw size={16} class={loading() ?", "mimetype": "text/plain", "start_char_idx": 7984, "end_char_idx": 11001, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5c99679d-fe0a-4654-acba-4b841f4ccfb0": {"__data__": {"id_": "5c99679d-fe0a-4654-acba-4b841f4ccfb0", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Analytics.tsx", "language": "typescript", "lines": 592, "filename": "Analytics.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Analytics.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Analytics.tsx", "language": "typescript", "lines": 592, "filename": "Analytics.tsx"}, "hash": "f1037c387ed90c74a3971c94edda0cf1fee332e8bb5511cad2ded381b4034020", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "71cfb93e-0a6f-4827-b80f-e555c33b1027", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Analytics.tsx", "language": "typescript", "lines": 592, "filename": "Analytics.tsx"}, "hash": "750f5b0ed42f79759eebb08a2e4f9a35d131c3081245dba5ead1d2363ea79970", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "bc5324b1-310e-4969-b479-f4708d5184c9", "node_type": "1", "metadata": {}, "hash": "f47745fb7c9c08e691833acc7130cf029598aef20d75def938062100d8b349c3", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "'animate-spin' : ''} />\n          Atualizar\n        </button>\n      </div>\n\n      {/* Filters */}\n      <div class=\"card p-4 border\">\n        <div class=\"flex items-center gap-2 mb-3\">\n          <Filter size={20} />\n          <h3 class=\"font-semibold\">Filtros</h3>\n          <Show when={categoria() || segmento()}>\n            <button\n              class=\"ml-auto text-sm text-muted hover:text-foreground flex items-center gap-1\"\n              onClick={() => {\n                setCategoria('');\n                setSegmento('');\n                loadData();\n              }}\n            >\n              <X size={16} />\n              Limpar Filtros\n            </button>\n          </Show>\n        </div>\n\n        <div class=\"grid grid-cols-1 md:grid-cols-3 gap-3\">\n          {/* Segmento */}\n          <select\n            class=\"input\"\n            value={segmento()}\n            onChange={(e) => setSegmento(e.currentTarget.value)}\n            disabled={allFilterOptions.loading}\n          >\n            <option value=\"\">Todos os Segmentos</option>\n            <Show when={allFilterOptions()}>\n              <For each={allFilterOptions()!.segmentos}>\n                {(seg) => <option value={seg}>{seg}</option>}\n              </For>\n            </Show>\n          </select>\n\n          {/* Categoria (filtro din\u00e2mico) */}\n          <select\n            class=\"input\"\n            value={categoria()}\n            onChange={(e) => setCategoria(e.currentTarget.value)}\n            disabled={filteredCategoryOptions.loading}\n          >\n            <option value=\"\">Todas as Categorias</option>\n            <Show when={filteredCategoryOptions()}>\n              <For each={filteredCategoryOptions()}>\n                {(cat) => <option value={cat}>{cat}</option>}\n              </For>\n            </Show>\n          </select>\n\n          <button\n            class=\"btn btn-primary\"\n            onClick={loadData}\n            disabled={loading()}\n          >\n            Aplicar Filtros\n          </button>\n        </div>\n\n        {/* Active Filters Display */}\n        <Show when={categoria() || segmento()}>\n          <div class=\"flex gap-2 mt-3 flex-wrap\">\n            <span class=\"text-sm text-muted\">Filtros ativos:</span>\n            <Show when={segmento()}>\n              <span class=\"px-2 py-1 bg-primary/20 text-primary rounded text-sm flex items-center gap-1\">\n                Segmento: {segmento()}\n                <button\n                  onClick={() => {\n                    setSegmento('');\n                    loadData();\n                  }}\n                  class=\"hover:bg-primary/30 rounded\"\n                >\n                  <X size={14} />\n                </button>\n              </span>\n            </Show>\n            <Show when={categoria()}>\n              <span class=\"px-2 py-1 bg-primary/20 text-primary rounded text-sm flex items-center gap-1\">\n                Categoria: {categoria()}\n                <button\n                  onClick={() => {\n                    setCategoria('');\n                    loadData();\n                  }}\n                  class=\"hover:bg-primary/30 rounded\"\n                >\n                  <X size={14} />\n                </button>\n              </span>\n            </Show>\n          </div>\n        </Show>\n      </div>\n\n      {/* Error State */}\n      <Show when={error()}>\n        <div class=\"card p-4 border-red-500 bg-red-500/10\">\n          <p class=\"text-red-500\">{error()}</p>\n        </div>\n      </Show>\n\n      {/* Loading State */}\n      <Show when={loading()}>\n        <div class=\"flex-1 flex items-center justify-center\">\n          <div class=\"text-center\">\n            <BarChart3 size={48} class=\"mx-auto mb-4 opacity-50 animate-pulse\" />\n            <p class=\"text-muted\">Carregando an\u00e1lise...</p>\n          </div>\n        </div>\n      </Show>\n\n      {/* Charts Grid */}\n      <Show when={!loading() && data()}>\n        <div class=\"space-y-6\">\n          {/* Row 1: Vendas por Categoria */}\n          <div class=\"card p-6 border\">\n            <div class=\"flex justify-between items-center mb-4\">\n              <h3 class=\"font-semibold\">Vendas por Categoria (Top 10)</h3>\n              <ChartDownloadButton\n                chartId=\"analytics-vendas-categoria-chart\"\n                filename=\"analytics_vendas_categoria\"\n                label=\"Baixar\"\n              />\n            </div>\n            <Show\n              when={data()!.vendas_por_categoria.", "mimetype": "text/plain", "start_char_idx": 11002, "end_char_idx": 15420, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "bc5324b1-310e-4969-b479-f4708d5184c9": {"__data__": {"id_": "bc5324b1-310e-4969-b479-f4708d5184c9", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Analytics.tsx", "language": "typescript", "lines": 592, "filename": "Analytics.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Analytics.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Analytics.tsx", "language": "typescript", "lines": 592, "filename": "Analytics.tsx"}, "hash": "f1037c387ed90c74a3971c94edda0cf1fee332e8bb5511cad2ded381b4034020", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5c99679d-fe0a-4654-acba-4b841f4ccfb0", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Analytics.tsx", "language": "typescript", "lines": 592, "filename": "Analytics.tsx"}, "hash": "cfca32076d6738aa3c60b4d5cdb4bb5e40c0dee86a78a0799faf8fe0acd945ac", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b153117a-8cd6-46b5-8c4b-6209f658ce80", "node_type": "1", "metadata": {}, "hash": "03e80e1ec1947519c4bdcc711f04331310aa276cccf9c99ed6d8d9360f4a76d2", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "vendas_por_categoria.length > 0}\n              fallback={\n                <div class=\"h-[400px] flex items-center justify-center text-muted\">\n                  <p>Nenhum dado de vendas por categoria dispon\u00edvel</p>\n                </div>\n              }\n            >\n              <PlotlyChart\n                chartSpec={vendasCategoriaChart}\n                chartId=\"analytics-vendas-categoria-chart\"\n                enableDownload={true}\n              />\n            </Show>\n          </div>\n\n          {/* Row 2: Two columns */}\n          <div class=\"grid grid-cols-1 lg:grid-cols-2 gap-6\">\n            {/* Giro de Estoque */}\n            <div class=\"card p-6 border\">\n              <div class=\"flex justify-between items-center mb-4\">\n                <h3 class=\"font-semibold\">Giro de Estoque (Top 15)</h3>\n                <ChartDownloadButton\n                  chartId=\"analytics-giro-estoque-chart\"\n                  filename=\"analytics_giro_estoque\"\n                  label=\"Baixar\"\n                />\n              </div>\n              <Show\n                when={data()!.giro_estoque.length > 0}\n                fallback={\n                  <div class=\"h-[400px] flex items-center justify-center text-muted\">\n                    <p>Nenhum dado de giro de estoque dispon\u00edvel</p>\n                  </div>\n                }\n              >\n                <PlotlyChart\n                  chartSpec={giroEstoqueChart}\n                  chartId=\"analytics-giro-estoque-chart\"\n                  enableDownload={true}\n                />\n              </Show>\n            </div>\n\n            {/* Distribui\u00e7\u00e3o ABC */}\n            <div class=\"card p-6 border\">\n              <div class=\"flex justify-between items-center mb-4\">\n                <h3 class=\"font-semibold\">An\u00e1lise de Pareto (ABC por Receita)</h3>\n                <ChartDownloadButton\n                  chartId=\"analytics-abc-chart\"\n                  filename=\"analytics_distribuicao_abc\"\n                  label=\"Baixar\"\n                />\n              </div>\n              <Show\n                when={data()!.distribuicao_abc.detalhes && data()!.distribuicao_abc.detalhes.length > 0}\n                fallback={\n                  <div class=\"h-[400px] flex items-center justify-center text-muted\">\n                    <p>Nenhum dado de distribui\u00e7\u00e3o ABC dispon\u00edvel</p>\n                  </div>\n                }\n              >\n                <PlotlyChart\n                  chartSpec={distribuicaoABCChart}\n                  chartId=\"analytics-abc-chart\"\n                  enableDownload={true}\n                />\n              </Show>\n\n              {/* Summary of ABC classes */}\n              <Show when={data()!.distribuicao_abc.receita_por_classe}>\n                <div class=\"grid grid-cols-3 gap-2 mt-4\">\n                  <div class=\"p-2 rounded bg-green-500/10 border border-green-500/20 text-center\">\n                    <p class=\"text-[10px] text-green-700 font-bold uppercase\">Classe A</p>\n                    <p class=\"text-sm font-bold\">{data()!.distribuicao_abc.A} SKUs</p>\n                    <p class=\"text-[10px] text-muted-foreground\">80% da Receita</p>\n                  </div>\n                  <div class=\"p-2 rounded bg-yellow-500/10 border border-yellow-500/20 text-center\">\n                    <p class=\"text-[10px] text-yellow-700 font-bold uppercase\">Classe B</p>\n                    <p class=\"text-sm font-bold\">{data()!.distribuicao_abc.B} SKUs</p>\n                    <p class=\"text-[10px] text-muted-foreground\">15% da Receita</p>\n                  </div>\n                  <div class=\"p-2 rounded bg-red-500/10 border border-red-500/20 text-center\">\n                    <p class=\"text-[10px] text-red-700 font-bold uppercase\">Classe C</p>\n                    <p class=\"text-sm font-bold\">{data()!.distribuicao_abc.", "mimetype": "text/plain", "start_char_idx": 15399, "end_char_idx": 19208, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b153117a-8cd6-46b5-8c4b-6209f658ce80": {"__data__": {"id_": "b153117a-8cd6-46b5-8c4b-6209f658ce80", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Analytics.tsx", "language": "typescript", "lines": 592, "filename": "Analytics.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Analytics.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Analytics.tsx", "language": "typescript", "lines": 592, "filename": "Analytics.tsx"}, "hash": "f1037c387ed90c74a3971c94edda0cf1fee332e8bb5511cad2ded381b4034020", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bc5324b1-310e-4969-b479-f4708d5184c9", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Analytics.tsx", "language": "typescript", "lines": 592, "filename": "Analytics.tsx"}, "hash": "e99447985ae577f545ec2f0c9c5f936ce11c53e9a3f4800db1979c22511e9b89", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "distribuicao_abc.C} SKUs</p>\n                    <p class=\"text-[10px] text-muted-foreground\">5% da Receita</p>\n                  </div>\n                </div>\n              </Show>\n            </div>\n          </div>\n\n          {/* Info Box */}\n          <div class=\"card p-6 border bg-zinc-50 dark:bg-zinc-900/50\">\n            <div class=\"flex items-start gap-4\">\n              <div class=\"p-3 bg-primary/10 rounded-full text-primary\">\n                <BarChart3 size={24} />\n              </div>\n              <div>\n                <h4 class=\"font-bold text-lg mb-2\">Entendendo sua Curva ABC (Princ\u00edpio de Pareto)</h4>\n                <p class=\"text-sm text-muted-foreground leading-relaxed\">\n                  Diferente de uma an\u00e1lise simplista, sua Curva ABC \u00e9 calculada com base na <strong>contribui\u00e7\u00e3o financeira real</strong> (Receita) de cada produto. \n                  Isso permite identificar onde o seu capital est\u00e1 gerando mais retorno:\n                </p>\n                <div class=\"grid grid-cols-1 md:grid-cols-3 gap-6 mt-6\">\n                  <div class=\"space-y-2\">\n                    <div class=\"flex items-center gap-2\">\n                      <div class=\"w-3 h-3 rounded-full bg-green-500\"></div>\n                      <span class=\"font-bold text-sm\">Classe A (Cr\u00edticos)</span>\n                    </div>\n                    <p class=\"text-xs text-muted-foreground\">\n                      Representam os primeiros <strong>80% da sua receita</strong>. Geralmente s\u00e3o poucos produtos (aprox. 20%) que sustentam o neg\u00f3cio. <strong>Ruptura aqui \u00e9 inaceit\u00e1vel.</strong>\n                    </p>\n                  </div>\n                  <div class=\"space-y-2\">\n                    <div class=\"flex items-center gap-2\">\n                      <div class=\"w-3 h-3 rounded-full bg-yellow-500\"></div>\n                      <span class=\"font-bold text-sm\">Classe B (Estrat\u00e9gicos)</span>\n                    </div>\n                    <p class=\"text-xs text-muted-foreground\">\n                      Representam os pr\u00f3ximos <strong>15% da receita</strong>. S\u00e3o produtos importantes que complementam o mix e possuem giro moderado.\n                    </p>\n                  </div>\n                  <div class=\"space-y-2\">\n                    <div class=\"flex items-center gap-2\">\n                      <div class=\"w-3 h-3 rounded-full bg-red-500\"></div>\n                      <span class=\"font-bold text-sm\">Classe C (Cauda Longa)</span>\n                    </div>\n                    <p class=\"text-xs text-muted-foreground\">\n                      Representam os <strong>5% finais da receita</strong>. Costumam ser a grande maioria dos produtos (aprox. 50% do mix). Devem ter estoque m\u00ednimo para n\u00e3o imobilizar capital.\n                    </p>\n                  </div>\n                </div>\n              </div>\n            </div>\n          </div>\n        </div>\n      </Show>\n    </div>\n  );\n}", "mimetype": "text/plain", "start_char_idx": 19191, "end_char_idx": 22100, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c1b8ca0d-85c5-42ba-97f1-a88ad788f56e": {"__data__": {"id_": "c1b8ca0d-85c5-42ba-97f1-a88ad788f56e", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Chat.tsx", "language": "typescript", "lines": 653, "filename": "Chat.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Chat.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Chat.tsx", "language": "typescript", "lines": 653, "filename": "Chat.tsx"}, "hash": "7de43e1e677d2ba52a2cbc2c60b3b272fdd26fca855d3fbb3a6d23b6e86dbb81", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c74d92bb-b9ea-44b3-a04e-d9f8f68e14d3", "node_type": "1", "metadata": {}, "hash": "d9914dca0a77f8c60f8281f7438829a1fdd92cd8c73454bcf46e0a43b7e18416", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import { createSignal, createEffect, onCleanup, onMount, For, Show } from 'solid-js';\nimport auth from '@/store/auth';\nimport { Typewriter, TypingIndicator } from '@/components';\nimport { PlotlyChart } from '@/components/PlotlyChart';\nimport { DataTable } from '@/components/DataTable';\nimport { FeedbackButtons } from '@/components/FeedbackButtons';\nimport { DownloadButton } from '@/components/DownloadButton';\nimport { MessageActions } from '@/components/MessageActions';\nimport { ExportMenu } from '@/components/ExportMenu';\nimport { ShareButton } from '@/components/ShareButton';\nimport { formatTimestamp } from '@/lib/formatters';\nimport { marked } from 'marked'; // Renderizador de Markdown\nimport { Trash2, StopCircle, Pencil, Check, X } from 'lucide-solid';\nimport 'github-markdown-css/github-markdown.css';\nimport './chat-markdown.css';\n\n// Configurar marked para renderizar tabelas corretamente\nmarked.setOptions({\n  gfm: true, // GitHub Flavored Markdown (suporta tabelas)\n  breaks: true, // Quebras de linha autom\u00e1ticas\n});\n\n// Helper para renderizar Markdown\nconst renderMarkdown = (text: string): string => {\n  try {\n    return marked.parse(text) as string;\n  } catch (e) {\n    console.error('Erro ao renderizar Markdown:', e);\n    return text;\n  }\n};\n\n// Helper para formatar nome da ferramenta\nconst formatToolName = (toolName: string): string => {\n  const map: Record<string, string> = {\n    'gerar_grafico_universal': 'Gerando gr\u00e1fico',\n    'consultar_dados_flexivel': 'Consultando dados',\n    'consultar_dados_gerais': 'Consultando informa\u00e7\u00f5es',\n    'calcular_abastecimento_une': 'Calculando abastecimento',\n    'calcular_mc_produto': 'Calculando margem',\n    'calcular_preco_final_une': 'Calculando pre\u00e7o',\n    'sugerir_transferencias_automaticas': 'Analisando transfer\u00eancias',\n    'validar_transferencia_produto': 'Validando transfer\u00eancia',\n    'encontrar_rupturas_criticas': 'Buscando rupturas'\n  };\n\n  if (map[toolName]) {\n    return map[toolName];\n  }\n\n  // Fallback: remove underscores and capitalize\n  return toolName\n    .split('_')\n    .map(word => word.charAt(0).toUpperCase() + word.slice(1))\n    .join(' ');\n};\n\n// Interface para mensagem - Atualizada para suportar estrutura JSON do backend\ninterface Message {\n  id: string;\n  role: 'user' | 'assistant' | 'system';\n  text: string;\n  timestamp: number;\n  type?: 'text' | 'chart' | 'table' | 'final' | 'error'; // Tipo da resposta do assistente\n  chart_spec?: any; // Especifica\u00e7\u00e3o JSON do Plotly\n  data?: any[]; // Dados tabulares\n  response_id?: string; // ID da resposta para feedback\n}\n\nexport default function Chat() {\n  const [messages, setMessages] = createSignal<Message[]>([\n    { id: '0', role: 'assistant', text: 'Ol\u00e1! Sou seu assistente de BI. Pergunte sobre vendas, produtos ou estoque.', timestamp: Date.now(), type: 'text', response_id: 'initial_greeting' }\n  ]);\n  const [input, setInput] = createSignal('');\n  const [isStreaming, setIsStreaming] = createSignal(false);\n  const [isWaitingForResponse, setIsWaitingForResponse] = createSignal(false);\n  const [sessionId, setSessionId] = createSignal<string>('');\n  const [currentEventSource, setCurrentEventSource] = createSignal<EventSource | null>(null);\n  const [lastUserMessage, setLastUserMessage] = createSignal<string>('');\n  const [editingMessageId, setEditingMessageId] = createSignal<string | null>(null);\n  const [editText, setEditText] = createSignal('');\n  // \u2705 MELHORIA 2024: Estados para auto-reconnection e tool progress\n  const [retryCount, setRetryCount] = createSignal(0);\n  const [toolStatus, setToolStatus] = createSignal<string>('');\n  const [textBuffer, setTextBuffer] = createSignal<string>('');\n  let messagesEndRef: HTMLDivElement | undefined;\n  let debounceTimer: number | undefined;\n\n  // Check for example query from Examples page & Init Session\n  onMount(async () => {\n    // 1.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3854, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c74d92bb-b9ea-44b3-a04e-d9f8f68e14d3": {"__data__": {"id_": "c74d92bb-b9ea-44b3-a04e-d9f8f68e14d3", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Chat.tsx", "language": "typescript", "lines": 653, "filename": "Chat.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Chat.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Chat.tsx", "language": "typescript", "lines": 653, "filename": "Chat.tsx"}, "hash": "7de43e1e677d2ba52a2cbc2c60b3b272fdd26fca855d3fbb3a6d23b6e86dbb81", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c1b8ca0d-85c5-42ba-97f1-a88ad788f56e", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Chat.tsx", "language": "typescript", "lines": 653, "filename": "Chat.tsx"}, "hash": "0b1b951a3a79c1aa10c4e031f91b77f02e584486268c0a282744305d668ac552", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c806f337-9a88-4fa6-829c-5f10e82021e9", "node_type": "1", "metadata": {}, "hash": "14c640c97ee3edf022d4a8c8af1bf6a1eea67a4356754e02d49f9d57379d2ad5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Initialize Session First\n    let storedSession = localStorage.getItem('chat_session_id');\n    if (!storedSession) {\n      storedSession = crypto.randomUUID();\n      localStorage.setItem('chat_session_id', storedSession);\n    }\n    setSessionId(storedSession);\n\n    // 2. Check for Example Query\n    const exampleQuery = localStorage.getItem('example_query');\n    if (exampleQuery) {\n      localStorage.removeItem('example_query');\n\n      // Directly add the user message to the chat\n      const userMsg: Message = { id: Date.now().toString(), role: 'user', text: exampleQuery, timestamp: Date.now() };\n      setMessages(prev => [...prev, userMsg]);\n\n      // And immediately process it\n      await processUserMessage(exampleQuery);\n    }\n  });\n\n  // Auto-scroll - melhorado para garantir que sempre role at\u00e9 o final\n  createEffect(() => {\n    messages(); // Re-run effect when messages change\n\n    // Usar setTimeout para garantir que o DOM foi atualizado\n    setTimeout(() => {\n      if (messagesEndRef) {\n        messagesEndRef.scrollIntoView({ behavior: 'smooth', block: 'end' });\n      }\n    }, 100);\n  });\n\n  // Cleanup on unmount\n  onCleanup(() => {\n    const es = currentEventSource();\n    if (es) {\n      es.close();\n    }\n  });\n\n  const stopGeneration = () => {\n    const es = currentEventSource();\n    if (es) {\n      console.log('\u23f9\ufe0f Stopping generation...');\n      es.close();\n      setCurrentEventSource(null);\n      setIsStreaming(false);\n\n      // Add stop message to last assistant message\n      setMessages(prev => {\n        const lastMsg = prev[prev.length - 1];\n        if (lastMsg && lastMsg.role === 'assistant') {\n          return prev.slice(0, -1).concat({\n            ...lastMsg,\n            text: lastMsg.text + '\\n\\n_[Gera\u00e7\u00e3o interrompida pelo usu\u00e1rio]_'\n          });\n        }\n        return prev;\n      });\n    }\n  };\n\n  const clearConversation = () => {\n    if (confirm('Tem certeza que deseja limpar toda a conversa?')) {\n      // Clear messages\n      setMessages([\n        { id: '0', role: 'assistant', text: 'Ol\u00e1! Sou seu assistente de BI. Pergunte sobre vendas, produtos ou estoque.', timestamp: Date.now(), type: 'text', response_id: 'initial_greeting' }\n      ]);\n\n      // Create new session\n      const newSession = crypto.randomUUID();\n      setSessionId(newSession);\n      localStorage.setItem('chat_session_id', newSession);\n\n      console.log('\ud83d\uddd1\ufe0f Conversation cleared, new session:', newSession);\n    }\n  };\n\n  const regenerateLastResponse = () => {\n    const lastMsg = lastUserMessage();\n    if (!lastMsg) {\n      console.warn('No last user message to regenerate');\n      return;\n    }\n\n    // Remove last assistant message(s) if any\n    setMessages(prev => {\n      const userMessages = prev.filter(m => m.role === 'user');\n      const lastUserMsg = userMessages[userMessages.length - 1];\n      const lastUserIndex = prev.findIndex(m => m === lastUserMsg);\n\n      // Keep everything up to and including the last user message\n      return prev.slice(0, lastUserIndex + 1);\n    });\n\n    // Resend the last user message\n    console.log('\ud83d\udd04 Regenerating response for:', lastMsg);\n    processUserMessage(lastMsg);\n  };\n\n  const startEditMessage = (messageId: string, currentText: string) => {\n    setEditingMessageId(messageId);\n    setEditText(currentText);\n  };\n\n  const cancelEditMessage = () => {\n    setEditingMessageId(null);\n    setEditText('');\n  };\n\n  const saveEditedMessage = async (messageId: string) => {\n    const newText = editText().trim();\n    if (!newText) return;\n\n    // Find message index\n    const msgIndex = messages().findIndex(m => m.id === messageId);\n    if (msgIndex === -1) return;\n\n    // Update message text\n    setMessages(prev => prev.map(m =>\n      m.id === messageId ?", "mimetype": "text/plain", "start_char_idx": 3855, "end_char_idx": 7594, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c806f337-9a88-4fa6-829c-5f10e82021e9": {"__data__": {"id_": "c806f337-9a88-4fa6-829c-5f10e82021e9", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Chat.tsx", "language": "typescript", "lines": 653, "filename": "Chat.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Chat.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Chat.tsx", "language": "typescript", "lines": 653, "filename": "Chat.tsx"}, "hash": "7de43e1e677d2ba52a2cbc2c60b3b272fdd26fca855d3fbb3a6d23b6e86dbb81", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c74d92bb-b9ea-44b3-a04e-d9f8f68e14d3", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Chat.tsx", "language": "typescript", "lines": 653, "filename": "Chat.tsx"}, "hash": "784706da304ad1d4389ead21049c480bcf3be2c613da87f6c40498446dd5106e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f35d21b8-601f-4ab5-8530-0a1dc44a465b", "node_type": "1", "metadata": {}, "hash": "ec9922eaf43c0df08faf343c8b6c8815a7fcd79c9969045a4bcb319010558912", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "{ ...m, text: newText } : m\n    ));\n\n    // Remove all messages after this one\n    setMessages(prev => prev.slice(0, msgIndex + 1));\n\n    // Update last user message\n    setLastUserMessage(newText);\n\n    // Clear edit mode\n    setEditingMessageId(null);\n    setEditText('');\n\n    // Reprocess with edited message\n    console.log('\u270f\ufe0f Message edited, reprocessing:', newText);\n    await processUserMessage(newText);\n  };\n\n  const processUserMessage = async (userText: string) => {\n    // Validar autentica\u00e7\u00e3o\n    const token = auth.token();\n    if (!token) {\n      console.error('\u274c Token n\u00e3o encontrado');\n      const errorMsg: Message = {\n        id: Date.now().toString(),\n        role: 'assistant',\n        text: '[Erro: Voc\u00ea n\u00e3o est\u00e1 autenticado. Por favor, fa\u00e7a login novamente.]',\n        timestamp: Date.now(),\n        type: 'error'\n      };\n      setMessages(prev => [...prev, errorMsg]);\n      return;\n    }\n\n    setIsStreaming(true);\n    setIsWaitingForResponse(true);\n\n    // Prepara mensagem do assistente - agora com suporte a tipos e dados\n    const assistantId = (Date.now() + 1).toString();\n    const newMessage: Message = { id: assistantId, role: 'assistant', text: '', timestamp: Date.now(), type: 'text' };\n    setMessages(prev => [...prev, newMessage]);\n\n    try {\n      // Conex\u00e3o SSE Real com Backend\n      console.log('\ud83d\udce1 Iniciando SSE com token:', token.substring(0, 20) + '...', 'Session:', sessionId());\n      const eventSource = new EventSource(`/api/v1/chat/stream?q=${encodeURIComponent(userText)}&token=${encodeURIComponent(token)}&session_id=${sessionId()}`);\n      setCurrentEventSource(eventSource);\n\n      let fullResponseContent = ''; // Para acumular texto e gerar response_id\n      let currentMessageId = assistantId;\n\n      eventSource.onmessage = (event) => {\n        try {\n          const data = JSON.parse(event.data);\n\n          // Desativa o indicador assim que receber qualquer dado\n          if (isWaitingForResponse()) {\n            setIsWaitingForResponse(false);\n          }\n\n          if (data.done) {\n            console.log('\u2705 Stream conclu\u00eddo');\n            // \u2705 MELHORIA 2024: Resetar retry count em sucesso\n            setRetryCount(0);\n            setToolStatus('');\n            // Flush any remaining buffered text\n            if (textBuffer()) {\n              setMessages(prev => prev.map(msg => {\n                if (msg.id === currentMessageId) {\n                  return { ...msg, text: msg.text + textBuffer() };\n                }\n                return msg;\n              }));\n              setTextBuffer('');\n            }\n            eventSource.close();\n            setCurrentEventSource(null);\n            setIsStreaming(false);\n            setIsWaitingForResponse(false);\n            // Finaliza a mensagem do assistente, adicionando o response_id\n            setMessages(prev => prev.map(msg =>\n              msg.id === currentMessageId ? { ...msg, response_id: fullResponseContent ?", "mimetype": "text/plain", "start_char_idx": 7595, "end_char_idx": 10543, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f35d21b8-601f-4ab5-8530-0a1dc44a465b": {"__data__": {"id_": "f35d21b8-601f-4ab5-8530-0a1dc44a465b", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Chat.tsx", "language": "typescript", "lines": 653, "filename": "Chat.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Chat.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Chat.tsx", "language": "typescript", "lines": 653, "filename": "Chat.tsx"}, "hash": "7de43e1e677d2ba52a2cbc2c60b3b272fdd26fca855d3fbb3a6d23b6e86dbb81", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c806f337-9a88-4fa6-829c-5f10e82021e9", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Chat.tsx", "language": "typescript", "lines": 653, "filename": "Chat.tsx"}, "hash": "8e4193daa72e9ac6e037647cbaa9cae8515d130bcab64285537af93e9ae3f7af", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d28569c4-e06e-4019-81d5-751913d00cfe", "node_type": "1", "metadata": {}, "hash": "4108a8a3753f489a641ee00b95b15a7c52e6262952e8b4c3b10d893f7c8237a1", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "{ ...msg, response_id: fullResponseContent ? btoa(fullResponseContent).substring(0, 16) : undefined } : msg\n            ));\n            return;\n          }\n\n          if (data.type === 'text') {\n            // \u2705 MELHORIA 2024: Debouncing de text updates (50ms)\n            const newText = data.text;\n            setTextBuffer(prev => prev + newText);\n\n            if (debounceTimer) clearTimeout(debounceTimer);\n            debounceTimer = setTimeout(() => {\n              const bufferedText = textBuffer();\n              setMessages(prev => prev.map(msg => {\n                if (msg.id === currentMessageId) {\n                  const updatedText = msg.text + bufferedText;\n                  fullResponseContent = updatedText;\n                  return { ...msg, text: updatedText, type: 'text' };\n                }\n                return msg;\n              }));\n              setTextBuffer(''); // Clear buffer\n            }, 50);\n          } else if (data.type === 'tool_progress') {\n            // \u2705 MELHORIA 2024: Indicador de progresso de ferramentas\n            const toolName = data.tool || 'ferramenta';\n            const status = data.status || 'executando';\n            const friendlyName = formatToolName(toolName);\n            setToolStatus(`\ud83d\udd27 ${friendlyName}...`);\n            console.log(`\ud83d\udd27 Tool progress: ${toolName} - ${status}`);\n          } else if (data.type === 'code_result' || data.type === 'chart') {\n            // Handle both legacy 'chart' and new 'code_result' types\n            const chartSpec = data.chart_spec || (data.result && data.result.chart_spec);\n\n            if (chartSpec) {\n              console.log('\ud83d\udcca Chart spec received:', chartSpec);\n              // Adiciona um novo bloco de mensagem para o gr\u00e1fico\n              const chartMsgId = (Date.now() + 2).toString();\n              setMessages(prev => [...prev, {\n                id: chartMsgId,\n                role: 'assistant',\n                text: 'Visualiza\u00e7\u00e3o gerada:', // Texto padr\u00e3o para o bloco do gr\u00e1fico\n                timestamp: Date.now(),\n                type: 'chart',\n                chart_spec: chartSpec,\n                response_id: btoa(JSON.stringify(chartSpec)).substring(0, 16) // ID baseado no spec do gr\u00e1fico\n              }]);\n              // N\u00e3o atualizamos currentMessageId para manter o texto fluindo na mensagem anterior se houver\n            }\n          } else if (data.type === 'table' && data.data) {\n            // Adiciona um novo bloco de mensagem para a tabela\n            const tableMsgId = (Date.now() + 3).toString();\n            setMessages(prev => [...prev, {\n              id: tableMsgId,\n              role: 'assistant',\n              text: 'Aqui est\u00e3o os dados tabulares:',\n              timestamp: Date.now(),\n              type: 'table',\n              data: data.data,\n              response_id: btoa(JSON.stringify(data.data)).substring(0, 16) // ID baseado nos dados\n            }]);\n            currentMessageId = tableMsgId; // O feedback ser\u00e1 para este novo elemento\n          }\n          else if (data.type === 'final' && data.text) {\n            // Tratamento para mensagem final, se houver\n            setMessages(prev => prev.map(msg =>\n              msg.id === currentMessageId ? { ...msg, text: msg.text + data.text, type: 'text' } : msg\n            ));\n          }\n\n          if (data.error) {\n            console.error('\u274c Erro do servidor:', data.error);\n            setMessages(prev => prev.map(msg =>\n              msg.id === currentMessageId ? { ...msg, text: msg.text + \"\\n[Erro: \" + (data.details ?", "mimetype": "text/plain", "start_char_idx": 10499, "end_char_idx": 14054, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d28569c4-e06e-4019-81d5-751913d00cfe": {"__data__": {"id_": "d28569c4-e06e-4019-81d5-751913d00cfe", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Chat.tsx", "language": "typescript", "lines": 653, "filename": "Chat.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Chat.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Chat.tsx", "language": "typescript", "lines": 653, "filename": "Chat.tsx"}, "hash": "7de43e1e677d2ba52a2cbc2c60b3b272fdd26fca855d3fbb3a6d23b6e86dbb81", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f35d21b8-601f-4ab5-8530-0a1dc44a465b", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Chat.tsx", "language": "typescript", "lines": 653, "filename": "Chat.tsx"}, "hash": "4bc00e78b79b197ad78a207e5a28cc49d9e4b54c59aa045141e27b471098d6dc", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0f442b02-fdf9-4428-914f-329d17c0cea2", "node_type": "1", "metadata": {}, "hash": "40d15a9b5dc0a9ceda7cb393a3c099bbc167c132775021a13f94a7bf7a3838ed", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "JSON.stringify(data.details) : data.error) + \"]\", type: 'error' } : msg\n            ));\n            eventSource.close();\n            setCurrentEventSource(null);\n            setIsStreaming(false);\n            setIsWaitingForResponse(false);\n          }\n\n        } catch (err) {\n          console.error(\"\u274c SSE Parse Error\", err);\n        }\n      };\n\n      eventSource.onerror = (err) => {\n        console.error(\"\u274c EventSource failed:\", err);\n        eventSource.close();\n        setCurrentEventSource(null);\n\n        // \u2705 MELHORIA 2024: Auto-reconnection com exponential backoff\n        const currentRetry = retryCount();\n        const maxRetries = 3;\n\n        if (currentRetry < maxRetries) {\n          const backoffMs = Math.min(1000 * Math.pow(2, currentRetry), 8000); // Max 8s\n          console.log(`\ud83d\udd04 Tentando reconectar... (${currentRetry + 1}/${maxRetries}) em ${backoffMs}ms`);\n\n          setMessages(prev => prev.map(msg =>\n            msg.id === currentMessageId ? {\n              ...msg,\n              text: msg.text + `\\n\\n\ud83d\udd04 Conex\u00e3o perdida. Reconectando em ${backoffMs / 1000}s... (${currentRetry + 1}/${maxRetries})`,\n              type: 'text'\n            } : msg\n          ));\n\n          setTimeout(() => {\n            setRetryCount(currentRetry + 1);\n            console.log('\ud83d\udd04 Reconectando...');\n            processUserMessage(userText); // Retry\n          }, backoffMs);\n        } else {\n          // Max retries atingido\n          setIsStreaming(false);\n          setIsWaitingForResponse(false);\n          setRetryCount(0);\n          setMessages(prev => prev.map(msg =>\n            msg.id === currentMessageId ? {\n              ...msg,\n              text: msg.text + \"\\n\\n\u26a0\ufe0f Erro de conex\u00e3o. M\u00e1ximo de tentativas atingido. Por favor, tente novamente.\",\n              type: 'error'\n            } : msg\n          ));\n        }\n      };\n\n    } catch (err) {\n      console.error(\"\u274c Chat error:\", err);\n      setIsStreaming(false);\n      setIsWaitingForResponse(false);\n      setMessages(prev => prev.map(msg =>\n        msg.id === assistantId ? { ...msg, text: \"\\n\u274c Erro ao processar mensagem.\", type: 'error' } : msg\n      ));\n    }\n  };\n\n  const sendMessage = async (e: Event) => {\n    e.preventDefault();\n    if (!input() || isStreaming()) return;\n\n    const userText = input();\n    setInput('');\n    setLastUserMessage(userText);\n\n    // Adiciona mensagem do usu\u00e1rio\n    const userMsg: Message = { id: Date.now().toString(), role: 'user', text: userText, timestamp: Date.now() };\n    setMessages(prev => [...prev, userMsg]);\n\n    // Process message\n    await processUserMessage(userText);\n  };\n\n  const handleFeedback = async (messageId: string, feedbackType: 'positive' | 'negative' | 'partial', comment?: string) => {\n    const token = auth.token();\n    if (!token) {\n      console.error('\u274c Token n\u00e3o encontrado para feedback.');\n      alert('Voc\u00ea n\u00e3o est\u00e1 autenticado para enviar feedback.');\n      return;\n    }\n\n    try {\n      const response = await fetch('/api/v1/chat/feedback', {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json',\n          'Authorization': `Bearer ${token}`\n        },\n        body: JSON.stringify({\n          response_id: messageId,\n          feedback_type: feedbackType,\n          comment: comment\n        })\n      });\n\n      if (!response.ok) {\n        throw new Error(`HTTP error! status: ${response.status}`);\n      }\n\n      console.log(`Feedback ${feedbackType} enviado para ${messageId}`);\n    } catch (error) {\n      console.error('Erro ao enviar feedback:', error);\n      alert('Erro ao enviar feedback.');\n    }\n  };", "mimetype": "text/plain", "start_char_idx": 14055, "end_char_idx": 17665, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0f442b02-fdf9-4428-914f-329d17c0cea2": {"__data__": {"id_": "0f442b02-fdf9-4428-914f-329d17c0cea2", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Chat.tsx", "language": "typescript", "lines": 653, "filename": "Chat.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Chat.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Chat.tsx", "language": "typescript", "lines": 653, "filename": "Chat.tsx"}, "hash": "7de43e1e677d2ba52a2cbc2c60b3b272fdd26fca855d3fbb3a6d23b6e86dbb81", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d28569c4-e06e-4019-81d5-751913d00cfe", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Chat.tsx", "language": "typescript", "lines": 653, "filename": "Chat.tsx"}, "hash": "32b64ab089c092e9037178b7bd173f8b27f4e8e1cc7fd9aa7962632ad7088fbd", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "dc49b4bb-a106-4513-8053-d0e642ed72b6", "node_type": "1", "metadata": {}, "hash": "8348ba04481af847c74949c2c854dd1a3d78d86e572fb7413be96c73265dee37", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "');\n    }\n  };\n\n\n  return (\n    <div class=\"absolute inset-0 flex flex-col w-full max-w-4xl mx-auto bg-background\">\n      {/* Header with actions */}\n      <div class=\"flex items-center justify-between p-4 border-b bg-background/50 backdrop-blur\">\n        <h2 class=\"text-lg font-semibold\">Chat BI</h2>\n        <div class=\"flex items-center gap-2\">\n          <Show when={isStreaming()}>\n            <button\n              onClick={stopGeneration}\n              class=\"flex items-center gap-2 px-3 py-2 text-sm rounded-lg bg-red-500 hover:bg-red-600 text-white transition-colors\"\n              title=\"Parar gera\u00e7\u00e3o\"\n            >\n              <StopCircle size={16} />\n              <span>Parar</span>\n            </button>\n          </Show>\n          <ShareButton messages={messages} sessionId={sessionId()} />\n          <ExportMenu messages={messages} sessionId={sessionId()} />\n          <button\n            onClick={clearConversation}\n            class=\"flex items-center gap-2 px-3 py-2 text-sm rounded-lg border hover:bg-muted transition-colors\"\n            title=\"Limpar conversa\"\n          >\n            <Trash2 size={16} />\n            <span>Limpar</span>\n          </button>\n        </div>\n      </div>\n\n      <div class=\"flex-1 overflow-y-auto p-6 space-y-6\">\n        <For each={messages()}>\n          {(msg, index) => (\n            <div class={`flex ${msg.role === 'user' ? 'justify-end' : 'justify-start'}`}>\n              <div\n                class={`rounded-lg p-4 text-sm leading-relaxed shadow-sm ${msg.role === 'user'\n                  ? 'max-w-[80%] bg-primary/10 border border-primary/20 text-foreground'\n                  : msg.type === 'chart'\n                    ? 'w-full max-w-[95%] bg-card border text-card-foreground'\n                    : 'max-w-[80%] bg-card border text-card-foreground'\n                  }`}\n              >\n                <Show when={msg.role === 'assistant' && msg.type === 'chart' && msg.chart_spec}>\n                  <PlotlyChart chartSpec={() => msg.chart_spec} height=\"500px\" />\n                </Show>\n                <Show when={msg.role === 'assistant' && msg.type === 'table' && msg.data}>\n                  <DataTable data={() => msg.data} caption={msg.text} />\n                </Show>\n                <Show when={msg.role === 'assistant' && msg.type === 'text'}>\n                  <Show\n                    when={isWaitingForResponse() && msg.id === messages()[messages().length - 1].id}\n                    fallback={\n                      <div class=\"flex flex-col gap-1\">\n                        <div\n                          class=\"markdown-body\"\n                          innerHTML={renderMarkdown(msg.text + (isStreaming() && msg.id === messages()[messages().length - 1].id ? '", "mimetype": "text/plain", "start_char_idx": 17651, "end_char_idx": 20394, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "dc49b4bb-a106-4513-8053-d0e642ed72b6": {"__data__": {"id_": "dc49b4bb-a106-4513-8053-d0e642ed72b6", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Chat.tsx", "language": "typescript", "lines": 653, "filename": "Chat.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Chat.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Chat.tsx", "language": "typescript", "lines": 653, "filename": "Chat.tsx"}, "hash": "7de43e1e677d2ba52a2cbc2c60b3b272fdd26fca855d3fbb3a6d23b6e86dbb81", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0f442b02-fdf9-4428-914f-329d17c0cea2", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Chat.tsx", "language": "typescript", "lines": 653, "filename": "Chat.tsx"}, "hash": "4ac770e2af037ecc7a592d07522f6e954d85cdd21cfacf372e7225fd0e3badcd", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\u258d' : ''))}\n                        />\n                        <Show when={isStreaming() && msg.id === messages()[messages().length - 1].id && toolStatus()}>\n                          <div class=\"flex items-center gap-2 mt-1 text-xs text-muted-foreground animate-pulse\">\n                            {toolStatus()}\n                          </div>\n                        </Show>\n                      </div>\n                    }\n                  >\n                    <div class=\"flex flex-col gap-2\">\n                      <TypingIndicator />\n                      <Show when={toolStatus()}>\n                        <div class=\"flex items-center gap-2 text-xs text-muted-foreground animate-pulse\">\n                          {toolStatus()}\n                        </div>\n                      </Show>\n                    </div>\n                  </Show>\n                </Show>\n                <Show when={msg.role === 'user'}>\n                  <Show\n                    when={editingMessageId() === msg.id}\n                    fallback={\n                      <div\n                        class=\"markdown-body\"\n                        innerHTML={renderMarkdown(msg.text)}\n                      />\n                    }\n                  >\n                    <div class=\"space-y-2\">\n                      <textarea\n                        class=\"input w-full min-h-[80px] resize-y\"\n                        value={editText()}\n                        onInput={(e) => setEditText(e.currentTarget.value)}\n                        autofocus\n                      />\n                      <div class=\"flex gap-2\">\n                        <button\n                          onClick={() => saveEditedMessage(msg.id)}\n                          class=\"flex items-center gap-1 px-3 py-1 text-sm rounded bg-primary text-primary-foreground hover:opacity-90\"\n                        >\n                          <Check size={14} />\n                          <span>Salvar</span>\n                        </button>\n                        <button\n                          onClick={cancelEditMessage}\n                          class=\"flex items-center gap-1 px-3 py-1 text-sm rounded border hover:bg-muted\"\n                        >\n                          <X size={14} />\n                          <span>Cancelar</span>\n                        </button>\n                      </div>\n                    </div>\n                  </Show>\n\n                  {/* Edit button for user messages */}\n                  <Show when={editingMessageId() !== msg.id && !isStreaming()}>\n                    <button\n                      onClick={() => startEditMessage(msg.id, msg.text)}\n                      class=\"flex items-center gap-1 px-2 py-1 mt-2 text-xs rounded hover:bg-primary/10 transition-colors\"\n                      title=\"Editar mensagem\"\n                    >\n                      <Pencil size={12} />\n                      <span>Editar</span>\n                    </button>\n                  </Show>\n                </Show>\n                <Show when={msg.type === 'error'}>\n                  <span class=\"text-red-500 font-bold whitespace-pre-wrap\">{msg.text}</span>\n                </Show>\n\n                {/* Message Actions */}\n                <Show when={msg.role === 'assistant' && !isStreaming()}>\n                  <MessageActions\n                    messageText={msg.text}\n                    messageId={msg.id}\n                    canRegenerate={index() === messages().length - 1 && lastUserMessage() !== ''}\n                    onRegenerate={regenerateLastResponse}\n                  />\n                </Show>\n\n                <Show when={msg.role === 'assistant' && !isStreaming() && msg.response_id}>\n                  <div class=\"flex items-center space-x-2 mt-2\">\n                    <FeedbackButtons messageId={msg.response_id!} onFeedback={handleFeedback} />\n                    <Show when={msg.data}>\n                      <DownloadButton data={msg.data!} filename={`data-${msg.response_id}.json`} />\n                    </Show>\n                  </div>\n                </Show>\n                <div class=\"text-xs text-muted-foreground mt-1\">\n                  {formatTimestamp(msg.timestamp)}\n                </div>\n              </div>\n            </div>\n          )}\n        </For>\n        <div ref={messagesEndRef} />\n      </div>\n\n      <div class=\"p-4 border-t bg-background/50 backdrop-blur\">\n        <form onSubmit={sendMessage} class=\"flex gap-2\">\n          <input\n            type=\"text\"\n            class=\"input flex-1\"\n            value={input()}\n            onInput={(e) => setInput(e.currentTarget.value)}\n            placeholder=\"Fa\u00e7a uma pergunta sobre os dados...\"\n            disabled={isStreaming()}\n          />\n          <button type=\"submit\" class=\"btn btn-primary\" disabled={isStreaming() || !input()}>\n            Enviar\n          </button>\n        </form>\n      </div>\n    </div>\n  );\n}", "mimetype": "text/plain", "start_char_idx": 20395, "end_char_idx": 25318, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "02072b6b-dec7-412c-8869-dfa97dd6b0a3": {"__data__": {"id_": "02072b6b-dec7-412c-8869-dfa97dd6b0a3", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\CodeChat.tsx", "language": "typescript", "lines": 376, "filename": "CodeChat.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\CodeChat.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\CodeChat.tsx", "language": "typescript", "lines": 376, "filename": "CodeChat.tsx"}, "hash": "490ca6e94b437fa869db2ca381cf1181eeaad339c4824b883993ed97a5a9ad54", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b1cf1732-fe37-482d-b375-d33188aa30e7", "node_type": "1", "metadata": {}, "hash": "db25b17e4fa6000e7213d500c321e79581c85f87eaef9448addbbe8c6c098ef8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import { createSignal, For, Show, onMount, createEffect } from 'solid-js';\nimport { Code, Send, Trash2, FileCode, Database, Zap, Clock, Info, BookOpen, Search, ChevronDown, ChevronRight } from 'lucide-solid';\nimport api from '../lib/api';\nimport { MessageActions } from '../components/MessageActions';\nimport 'github-markdown-css/github-markdown.css';\nimport './chat-markdown.css';\n\ninterface Message {\n  id: string;\n  role: 'user' | 'assistant';\n  content: string;\n  timestamp: string;\n  code_references?: CodeReference[];\n}\n\ninterface CodeReference {\n  file: string;\n  score: number;\n  content: string;\n  lines: string;\n}\n\ninterface IndexStats {\n  status: string;\n  total_files: number;\n  total_functions: number;\n  total_classes: number;\n  total_lines: number;\n  indexed_at: string | null;\n  languages: string[];\n}\n\nexport default function CodeChat() {\n  const [messages, setMessages] = createSignal<Message[]>([]);\n  const [input, setInput] = createSignal('');\n  const [loading, setLoading] = createSignal(false);\n  const [indexStats, setIndexStats] = createSignal<IndexStats | null>(null);\n  const [examplesExpanded, setExamplesExpanded] = createSignal(true);\n  let messagesEndRef: HTMLDivElement | undefined;\n\n  // Examples de perguntas\n  const examples = [\n    {\n      title: \"Estrutura do C\u00f3digo\",\n      prompt: \"Quais s\u00e3o os principais m\u00f3dulos do backend?\"\n    },\n    {\n      title: \"Autentica\u00e7\u00e3o\",\n      prompt: \"Como funciona o sistema de autentica\u00e7\u00e3o?\"\n    },\n    {\n      title: \"API Endpoints\",\n      prompt: \"Liste todos os endpoints da API de chat\"\n    },\n    {\n      title: \"Frontend Components\",\n      prompt: \"Quais componentes SolidJS existem no projeto?\"\n    }\n  ];\n\n  onMount(async () => {\n    // Load index stats\n    try {\n      const response = await api.get('/code-chat/stats');\n      setIndexStats(response.data);\n      \n      // Welcome message\n      const welcomeMsg: Message = {\n        id: '0',\n        role: 'assistant',\n        content: `\ud83e\udd16 **Ol\u00e1! Sou seu Agente Fullstack de C\u00f3digo.**\\n\\nPosso responder qualquer pergunta sobre este projeto:\\n\\n- \ud83d\udcc1 **${response.data.total_files.toLocaleString()}** arquivos indexados\\n- \ud83d\udcdd **${response.data.total_functions.toLocaleString()}** fun\u00e7\u00f5es\\n- \ud83c\udfd7\ufe0f **${response.data.total_classes.toLocaleString()}** classes\\n- \ud83d\udcbb **${response.data.languages.join(', ')}**\\n\\nFa\u00e7a uma pergunta sobre o c\u00f3digo!`,\n        timestamp: new Date().toISOString()\n      };\n      setMessages([welcomeMsg]);\n      \n    } catch (error: any) {\n      console.error('Erro ao carregar stats:', error);\n      const errorMsg: Message = {\n        id: '0',\n        role: 'assistant',\n        content: '\u26a0\ufe0f **\u00cdndice n\u00e3o dispon\u00edvel**\\n\\nO \u00edndice de c\u00f3digo n\u00e3o foi gerado ainda.\\n\\nExecute: `python scripts/index_codebase.py`',\n        timestamp: new Date().toISOString()\n      };\n      setMessages([errorMsg]);\n    }\n  });\n\n  createEffect(() => {\n    if (messages()) {\n      setTimeout(() => messagesEndRef?.scrollIntoView({ behavior: 'smooth' }), 100);\n    }\n  });\n\n  const sendMessage = async (e?", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3032, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b1cf1732-fe37-482d-b375-d33188aa30e7": {"__data__": {"id_": "b1cf1732-fe37-482d-b375-d33188aa30e7", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\CodeChat.tsx", "language": "typescript", "lines": 376, "filename": "CodeChat.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\CodeChat.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\CodeChat.tsx", "language": "typescript", "lines": 376, "filename": "CodeChat.tsx"}, "hash": "490ca6e94b437fa869db2ca381cf1181eeaad339c4824b883993ed97a5a9ad54", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "02072b6b-dec7-412c-8869-dfa97dd6b0a3", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\CodeChat.tsx", "language": "typescript", "lines": 376, "filename": "CodeChat.tsx"}, "hash": "f15f299211cd8ef19146f6b668a4efffea3ee2f19c96f812c7a709556c8b6b6e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "fc3383ac-f44a-4087-bbd0-6e49f88a87f8", "node_type": "1", "metadata": {}, "hash": "828de866af80137f5f4853cbacdaddba94b06807481541bd2efa0ea400a80a34", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": ": Event) => {\n    e?.preventDefault();\n    if (!input().trim() || loading()) return;\n\n    const userMessage: Message = {\n      id: Date.now().toString(),\n      role: 'user',\n      content: input(),\n      timestamp: new Date().toISOString()\n    };\n\n    setMessages([...messages(), userMessage]);\n    setInput('');\n    setLoading(true);\n\n    try {\n      const response = await api.post('/code-chat/query', {\n        message: userMessage.content,\n        history: messages().slice(-5).map(m => ({\n          role: m.role,\n          content: m.content,\n          timestamp: m.timestamp\n        }))\n      });\n\n      const assistantMessage: Message = {\n        id: (Date.now() + 1).toString(),\n        role: 'assistant',\n        content: response.data.response,\n        timestamp: response.data.metadata.timestamp,\n        code_references: response.data.code_references\n      };\n\n      setMessages([...messages(), userMessage, assistantMessage]);\n\n    } catch (error: any) {\n      const errorMessage: Message = {\n        id: Date.now().toString(),\n        role: 'assistant',\n        content: `\u274c **Erro**: ${error.response?.data?.detail || error.message}`,\n        timestamp: new Date().toISOString()\n      };\n      setMessages([...messages(), userMessage, errorMessage]);\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  const clearHistory = () => {\n    if (confirm('Deseja limpar o hist\u00f3rico?')) {\n      setMessages([messages()[0]]); // Keep welcome message\n    }\n  };\n\n  const loadExample = (prompt: string) => {\n    setInput(prompt);\n  };\n\n  return (\n    <div class=\"h-full flex flex-col bg-background max-w-[1800px] mx-auto\">\n      {/* Context7: Executive Header with KPIs */}\n      <div class=\"border-b bg-card/50 backdrop-blur-sm p-4 flex flex-col md:flex-row items-start md:items-center justify-between gap-4\">\n        <div>\n          <h2 class=\"text-xl font-bold flex items-center gap-2 text-foreground\">\n            <Code class=\"text-primary\" />\n            Code Chat <span class=\"text-muted font-normal text-sm border-l pl-2 ml-2\">Agente Fullstack</span>\n          </h2>\n        </div>\n\n        {/* Live Metrics Strip */}\n        <Show when={indexStats()}>\n          <div class=\"flex gap-4\">\n            <div class=\"flex items-center gap-3 px-4 py-2 bg-secondary/50 rounded-lg border border-border/50\">\n              <FileCode size={16} class=\"text-blue-500\" />\n              <div>\n                <div class=\"text-[10px] text-muted uppercase tracking-wider font-semibold\">Arquivos</div>\n                <div class=\"text-sm font-mono font-bold\">{indexStats()!.total_files.toLocaleString()}</div>\n              </div>\n            </div>\n\n            <div class=\"flex items-center gap-3 px-4 py-2 bg-secondary/50 rounded-lg border border-border/50\">\n              <Zap size={16} class=\"text-purple-500\" />\n              <div>\n                <div class=\"text-[10px] text-muted uppercase tracking-wider font-semibold\">Fun\u00e7\u00f5es</div>\n                <div class=\"text-sm font-mono font-bold\">{indexStats()!.total_functions.toLocaleString()}</div>\n              </div>\n            </div>\n\n            <div class=\"flex items-center gap-3 px-4 py-2 bg-secondary/50 rounded-lg border border-border/50\">\n              <Database size={16} class=\"text-green-500\" />\n              <div>\n                <div class=\"text-[10px] text-muted uppercase tracking-wider font-semibold\">Status</div>\n                <div class=\"text-sm font-mono font-bold\">{indexStats()!.status === 'ready' ? '\u2705 Pronto' : '\u26a0\ufe0f Indexando'}</div>\n              </div>\n            </div>\n          </div>\n        </Show>\n      </div>\n\n      <div class=\"flex-1 overflow-hidden grid grid-cols-1 lg:grid-cols-[1fr_350px]\">\n        {/* Main Chat Area */}\n        <div class=\"flex flex-col min-h-0 bg-background/50\">\n          {/* Messages */}\n          <div class=\"flex-1 overflow-y-auto p-6 space-y-6\">\n            <For each={messages()}>\n              {(message) => (\n                <div class={`flex ${message.role === 'user' ?", "mimetype": "text/plain", "start_char_idx": 3032, "end_char_idx": 7025, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "fc3383ac-f44a-4087-bbd0-6e49f88a87f8": {"__data__": {"id_": "fc3383ac-f44a-4087-bbd0-6e49f88a87f8", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\CodeChat.tsx", "language": "typescript", "lines": 376, "filename": "CodeChat.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\CodeChat.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\CodeChat.tsx", "language": "typescript", "lines": 376, "filename": "CodeChat.tsx"}, "hash": "490ca6e94b437fa869db2ca381cf1181eeaad339c4824b883993ed97a5a9ad54", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b1cf1732-fe37-482d-b375-d33188aa30e7", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\CodeChat.tsx", "language": "typescript", "lines": 376, "filename": "CodeChat.tsx"}, "hash": "20fb2281d48a22bc1187e64c6bb8f8db57e72dfc077397b57266e86db754143c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "bfe1382a-ecfa-4ccc-867b-333a033b3fb5", "node_type": "1", "metadata": {}, "hash": "229ec78c759b6a9227b6305a0b19369a62ff5b82a7b78716849c8f8516eca22b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "'justify-end' : 'justify-start'} animate-in fade-in slide-in-from-bottom-2`}>\n                  <div\n                    class={`max-w-[85%] rounded-2xl p-5 shadow-sm ${\n                      message.role === 'user'\n                        ? 'bg-primary/10 border border-primary/20 text-foreground rounded-tr-none'\n                        : 'bg-card border text-card-foreground rounded-tl-none'\n                    }`}\n                  >\n                    <div class=\"flex items-center gap-2 mb-2 opacity-70 border-b border-border/10 pb-2\">\n                      <span class=\"text-xs font-bold uppercase tracking-wider\">\n                        {message.role === 'user' ?", "mimetype": "text/plain", "start_char_idx": 7026, "end_char_idx": 7700, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "bfe1382a-ecfa-4ccc-867b-333a033b3fb5": {"__data__": {"id_": "bfe1382a-ecfa-4ccc-867b-333a033b3fb5", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\CodeChat.tsx", "language": "typescript", "lines": 376, "filename": "CodeChat.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\CodeChat.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\CodeChat.tsx", "language": "typescript", "lines": 376, "filename": "CodeChat.tsx"}, "hash": "490ca6e94b437fa869db2ca381cf1181eeaad339c4824b883993ed97a5a9ad54", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fc3383ac-f44a-4087-bbd0-6e49f88a87f8", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\CodeChat.tsx", "language": "typescript", "lines": 376, "filename": "CodeChat.tsx"}, "hash": "7e1fcce7983e03740c40d48b32f98c17725e2b84d68904c1e53b3ae77996bbaf", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "765541a8-fcba-40f5-8a5f-bf59708da45c", "node_type": "1", "metadata": {}, "hash": "5faf8886e008021d2f9066120224979a76f883b36a5f34f0d21db92992115ca8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "'Voc\u00ea' : 'Agente'}\n                      </span>\n                      <span class=\"text-[10px] ml-auto\">\n                        {new Date(message.timestamp).toLocaleTimeString()}\n                      </span>\n                    </div>\n\n                    <div class=\"markdown-body text-sm leading-relaxed\" style=\"background: transparent;\">\n                      <pre class=\"whitespace-pre-wrap font-sans bg-transparent border-0 p-0 m-0 text-current\">{message.content}</pre>\n                    </div>\n\n                    {/* Code References */}\n                    <Show when={message.code_references && message.code_references.length > 0}>\n                      <div class=\"mt-4 pt-4 border-t border-border/10 space-y-2\">\n                        <div class=\"text-xs font-bold text-muted uppercase tracking-wider mb-2\">\n                          \ud83d\udcc4 Refer\u00eancias de C\u00f3digo ({message.code_references!.length})\n                        </div>\n                        <For each={message.code_references}>\n                          {(ref) => (\n                            <div class=\"bg-secondary/30 border rounded-lg p-3 text-xs font-mono\">\n                              <div class=\"flex items-center justify-between mb-2\">\n                                <span class=\"font-bold text-primary\">{ref.file}</span>\n                                <span class=\"text-muted\">Score: {(ref.score * 100).toFixed(1)}%</span>\n                              </div>\n                              <pre class=\"text-[11px] text-muted overflow-x-auto whitespace-pre-wrap\">{ref.content}</pre>\n                            </div>\n                          )}\n                        </For>\n                      </div>\n                    </Show>\n\n                    <Show when={message.role === 'assistant'}>\n                      <div class=\"mt-3 pt-2 border-t border-border/10\">\n                        <MessageActions messageText={message.content} messageId={message.id} />\n                      </div>\n                    </Show>\n                  </div>\n                </div>\n              )}\n            </For>\n\n            <Show when={loading()}>\n              <div class=\"flex justify-start\">\n                <div class=\"bg-card border rounded-2xl rounded-tl-none p-4 flex items-center gap-3\">\n                  <div class=\"flex space-x-1\">\n                    <div class=\"w-2 h-2 bg-primary/50 rounded-full animate-bounce [animation-delay:-0.3s]\"></div>\n                    <div class=\"w-2 h-2 bg-primary/50 rounded-full animate-bounce [animation-delay:-0.15s]\"></div>\n                    <div class=\"w-2 h-2 bg-primary/50 rounded-full animate-bounce\"></div>\n                  </div>\n                  <span class=\"text-xs text-muted font-medium\">Analisando c\u00f3digo...</span>\n                </div>\n              </div>\n            </Show>\n            <div ref={messagesEndRef} />\n          </div>\n\n          {/* Input Area */}\n          <div class=\"p-4 border-t bg-background/80 backdrop-blur-md\">\n            <form onSubmit={sendMessage} class=\"flex gap-3 max-w-4xl mx-auto\">\n              <button\n                type=\"button\"\n                onClick={clearHistory}\n                class=\"btn btn-ghost btn-icon text-muted hover:text-destructive\"\n                title=\"Limpar Hist\u00f3rico\"\n              >\n                <Trash2 size={20} />\n              </button>\n\n              <div class=\"flex-1 relative\">\n                <input\n                  type=\"text\"\n                  class=\"input w-full pr-12 shadow-sm font-mono text-sm\"\n                  placeholder=\"Pergunte sobre o c\u00f3digo...\"\n                  value={input()}\n                  onInput={(e) => setInput(e.currentTarget.value)}\n                  disabled={loading()}\n                />\n              </div>\n\n              <button\n                type=\"submit\"\n                class=\"btn btn-primary shadow-md hover:shadow-lg transition-all\"\n                disabled={loading() || !input().trim()}\n              >\n                <Show when={!loading()} fallback={<Clock size={20} class=\"animate-spin\" />}>\n                  <Send size={20} />\n                </Show>\n              </button>\n            </form>\n          </div>\n        </div>\n\n        {/* Right Sidebar - Examples & Info */}\n        <div class=\"border-l bg-card/30 p-6 overflow-y-auto hidden lg:block\">\n          <div class=\"sticky top-0 space-y-8\">\n            {/* Examples */}\n            <div class=\"space-y-4\">\n              <button\n                onClick={() => setExamplesExpanded(!examplesExpanded())}\n                class=\"w-full flex items-center justify-between text-sm font-bold uppercase tracking-wider text-muted hover:text-foreground\"\n              >\n                <div class=\"flex items-center gap-2\">\n                  <BookOpen size={14} />\n                  Exemplos\n                </div>\n                {examplesExpanded() ?", "mimetype": "text/plain", "start_char_idx": 7701, "end_char_idx": 12575, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "765541a8-fcba-40f5-8a5f-bf59708da45c": {"__data__": {"id_": "765541a8-fcba-40f5-8a5f-bf59708da45c", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\CodeChat.tsx", "language": "typescript", "lines": 376, "filename": "CodeChat.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\CodeChat.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\CodeChat.tsx", "language": "typescript", "lines": 376, "filename": "CodeChat.tsx"}, "hash": "490ca6e94b437fa869db2ca381cf1181eeaad339c4824b883993ed97a5a9ad54", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bfe1382a-ecfa-4ccc-867b-333a033b3fb5", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\CodeChat.tsx", "language": "typescript", "lines": 376, "filename": "CodeChat.tsx"}, "hash": "4bb861267b833a3acbaec4ae25a9b1c01485720fce6407bcaa88034a9ffe8531", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "<ChevronDown size={14} /> : <ChevronRight size={14} />}\n              </button>\n\n              <Show when={examplesExpanded()}>\n                <div class=\"space-y-2 animate-in slide-in-from-top-2\">\n                  <For each={examples}>\n                    {(example) => (\n                      <button\n                        onClick={() => loadExample(example.prompt)}\n                        class=\"w-full p-3 rounded-lg border border-border/50 hover:border-primary/50 hover:bg-secondary/50 transition-all text-left group\"\n                      >\n                        <div class=\"font-semibold text-sm group-hover:text-primary transition-colors mb-1 flex items-center gap-2\">\n                          <Search size={12} />\n                          {example.title}\n                        </div>\n                        <div class=\"text-xs text-muted line-clamp-2\">{example.prompt}</div>\n                      </button>\n                    )}\n                  </For>\n                </div>\n              </Show>\n            </div>\n\n            {/* Index Info */}\n            <Show when={indexStats()}>\n              <div class=\"p-4 bg-blue-500/5 border border-blue-500/10 rounded-xl space-y-2\">\n                <div class=\"flex items-center gap-2 text-blue-600 font-bold text-sm\">\n                  <Info size={16} />\n                  Informa\u00e7\u00f5es do \u00cdndice\n                </div>\n                <div class=\"text-xs text-muted space-y-1\">\n                  <div>\ud83d\udcc1 {indexStats()!.total_files.toLocaleString()} arquivos</div>\n                  <div>\ud83d\udcdd {indexStats()!.total_functions.toLocaleString()} fun\u00e7\u00f5es</div>\n                  <div>\ud83c\udfd7\ufe0f {indexStats()!.total_classes.toLocaleString()} classes</div>\n                  <div>\ud83d\udcbe {indexStats()!.total_lines.toLocaleString()} linhas</div>\n                  <Show when={indexStats()!.indexed_at}>\n                    <div class=\"pt-2 border-t border-border/10\">\n                      Indexado: {new Date(indexStats()!.indexed_at!).toLocaleString()}\n                    </div>\n                  </Show>\n                </div>\n              </div>\n            </Show>\n\n            {/* Help */}\n            <div class=\"p-4 bg-yellow-500/5 border border-yellow-500/10 rounded-xl space-y-2\">\n              <div class=\"flex items-center gap-2 text-yellow-600 font-bold text-sm\">\n                <Info size={16} />\n                Dicas de Uso\n              </div>\n              <p class=\"text-xs text-muted leading-relaxed\">\n                Fa\u00e7a perguntas espec\u00edficas sobre o c\u00f3digo, arquitetura, ou funcionalidades. \n                O agente busca semanticamente em todo o projeto e fornece respostas contextualizadas.\n              </p>\n            </div>\n          </div>\n        </div>\n      </div>\n    </div>\n  );\n}", "mimetype": "text/plain", "start_char_idx": 12576, "end_char_idx": 15342, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "efeb717a-b222-49e2-a8d5-ba479f9f6937": {"__data__": {"id_": "efeb717a-b222-49e2-a8d5-ba479f9f6937", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Dashboard.tsx", "language": "typescript", "lines": 453, "filename": "Dashboard.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Dashboard.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Dashboard.tsx", "language": "typescript", "lines": 453, "filename": "Dashboard.tsx"}, "hash": "9929cdc1c7dab1254cee1df427feea209f7ec02f565925f27982070f050573c6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9c30ad13-eb99-4bf6-b176-b1f4cc62d939", "node_type": "1", "metadata": {}, "hash": "92b692fad1cedbb216e73f2aa5f1d71e9c2962b0e4dc24ac0c3acd0b441f34f1", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import { createSignal, onMount, Show, For, createMemo } from 'solid-js';\nimport { useNavigate } from '@solidjs/router';\nimport { ShoppingCart, Package, AlertTriangle, DollarSign, RefreshCw, TrendingUp, X, CheckCircle, Info } from 'lucide-solid';\nimport api from '../lib/api';\nimport { PlotlyChart } from '../components/PlotlyChart';\nimport { ChartDownloadButton } from '../components/ChartDownloadButton';\nimport { AIInsightsPanel } from '../components/AIInsightsPanel';\nimport auth from '@/store/auth';\n\ninterface BusinessKPIs {\n  total_produtos: number;\n  total_unes: number;\n  produtos_ruptura: number;\n  valor_estoque: number;\n  top_produtos: Array<{\n    produto: string;\n    nome: string;\n    vendas: number;\n  }>;\n  vendas_por_categoria: Array<{\n    categoria: string;\n    vendas: number;\n    produtos: number;\n  }>;\n}\n\nexport default function Dashboard() {\n  const navigate = useNavigate();\n  const [kpis, setKpis] = createSignal<BusinessKPIs | null>(null);\n  const [loading, setLoading] = createSignal(true);\n  const [error, setError] = createSignal<string | null>(null);\n  const [lastUpdate, setLastUpdate] = createSignal<Date | null>(null);\n  const [selectedProductInfo, setSelectedProductInfo] = createSignal<{\n    produto: string;\n    nome: string;\n    vendas: number;\n  } | null>(null);\n\n  // Chart specs para Plotly\n  const [topProdutosChart, setTopProdutosChart] = createSignal<any>({});\n  const [vendasCategoriaChart, setVendasCategoriaChart] = createSignal<any>({});\n\n  // Context7 Logic: Derived State\n  const businessStatus = createMemo(() => {\n    if (!kpis()) return 'loading';\n    const ruptureRate = kpis()!.produtos_ruptura / (kpis()!.total_produtos || 1);\n    if (kpis()!.produtos_ruptura > 50 || ruptureRate > 0.1) return 'critical';\n    if (kpis()!.produtos_ruptura > 0) return 'warning';\n    return 'healthy';\n  });\n\n  const handleProductClick = (clickData: any) => {\n    if (clickData && clickData.points && clickData.points[0]) {\n      const point = clickData.points[0];\n      if (point.customdata) {\n        setSelectedProductInfo(point.customdata);\n      }\n    }\n  };\n\n  const loadKPIs = async () => {\n    try {\n      setLoading(true);\n      setError(null);\n\n      const response = await api.get<BusinessKPIs>('/metrics/business-kpis');\n      setKpis(response.data);\n      setLastUpdate(new Date());\n\n      // Context7 Storytelling: Chart 1 - \"Who is leading?\"\n      if (response.data.top_produtos.length > 0) {\n        const topProduct = response.data.top_produtos[0];\n        // LOJAS CA\u00c7ULA - LIGHT THEME\n        const topProdutosSpec = {\n          data: [{\n            type: 'bar',\n            x: response.data.top_produtos.map(p => p.nome),\n            y: response.data.top_produtos.map(p => p.vendas),\n            marker: {\n              color: response.data.top_produtos.map((_, i) => i === 0 ? '#8B7355' : '#C9A961'), // Marrom Ca\u00e7ula, Dourado\n              line: { color: '#E5E5E5', width: 1 }\n            },\n            text: response.data.top_produtos.map(p => p.vendas.toLocaleString()),\n            textposition: 'outside',\n            textfont: { color: '#2D2D2D' },\n            hovertemplate: '<b>%{x}</b><br>Vendas: %{y:,}<extra></extra>',\n            customdata: response.data.top_produtos.map(p => ({ produto: p.produto, nome: p.nome, vendas: p.vendas }))\n          }],\n          layout: {\n            title: {\n              text: '<b>Quais produtos impulsionam as vendas?</b><br><span style=\"font-size:12px;color:#6B6B6B\">O l\u00edder de vendas representa ' + Math.round((topProduct.vendas / response.data.top_produtos.reduce((a, b) => a + b.vendas,", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3595, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9c30ad13-eb99-4bf6-b176-b1f4cc62d939": {"__data__": {"id_": "9c30ad13-eb99-4bf6-b176-b1f4cc62d939", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Dashboard.tsx", "language": "typescript", "lines": 453, "filename": "Dashboard.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Dashboard.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Dashboard.tsx", "language": "typescript", "lines": 453, "filename": "Dashboard.tsx"}, "hash": "9929cdc1c7dab1254cee1df427feea209f7ec02f565925f27982070f050573c6", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "efeb717a-b222-49e2-a8d5-ba479f9f6937", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Dashboard.tsx", "language": "typescript", "lines": 453, "filename": "Dashboard.tsx"}, "hash": "ce8470423720f87d0507dc148842b36f4111086c04fde75f6ce679defbb11ea9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "73bfb680-ca4f-4e75-9d51-c9570b6a79f2", "node_type": "1", "metadata": {}, "hash": "0f4a3956b49e3430ef13a71650212614a6b51ebfa5b4d418ff685657896556d7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "data.top_produtos.reduce((a, b) => a + b.vendas, 0)) * 100) + '% do volume total do top 10</span>',\n              font: { size: 16, color: '#2D2D2D', family: 'Inter, sans-serif' },\n              x: 0.05,\n            },\n            annotations: [\n              {\n                x: topProduct.nome,\n                y: topProduct.vendas,\n                xref: 'x',\n                yref: 'y',\n                text: '\ud83c\udfc6 L\u00edder',\n                showarrow: true,\n                arrowhead: 2,\n                ax: 0,\n                ay: -40,\n                font: { color: '#8B7355', size: 12, family: 'Inter, sans-serif' }\n              }\n            ],\n            xaxis: {\n              title: '',\n              tickangle: -45,\n              tickfont: { size: 10, color: '#6B6B6B', family: 'Inter, sans-serif' },\n              gridcolor: '#E5E5E5',\n              linecolor: '#E5E5E5'\n            },\n            yaxis: {\n              title: 'Volume de Vendas (30 dias)',\n              titlefont: { color: '#6B6B6B', size: 10, family: 'Inter, sans-serif' },\n              tickfont: { color: '#6B6B6B', family: 'Inter, sans-serif' },\n              gridcolor: '#E5E5E5',\n              linecolor: '#E5E5E5'\n            },\n            plot_bgcolor: '#FFFFFF',\n            paper_bgcolor: '#FAFAFA',\n            margin: { l: 60, r: 20, t: 80, b: 120 },\n            font: { color: '#2D2D2D', family: 'Inter, sans-serif' }\n          },\n          config: { responsive: true, displayModeBar: false }\n        };\n        setTopProdutosChart(topProdutosSpec);\n      }\n\n      // Context7 Storytelling: Chart 2 - \"Composition\"\n      if (response.data.vendas_por_categoria.length > 0) {\n        // LOJAS CA\u00c7ULA - LIGHT THEME (Cores Terrosas)\n        const vendasCategoriaSpec = {\n          data: [{\n            type: 'pie',\n            labels: response.data.vendas_por_categoria.map(c => c.categoria),\n            values: response.data.vendas_por_categoria.map(c => c.vendas),\n            hovertemplate: '<b>%{label}</b><br>Vendas: %{value:,}<br>%{percent}<extra></extra>',\n            marker: {\n              colors: [\n                '#8B7355',  // Marrom Ca\u00e7ula\n                '#C9A961',  // Dourado/Bronze\n                '#6B7A5A',  // Verde oliva\n                '#A68968',  // Marrom claro\n                '#CC8B3C',  // Laranja terroso\n                '#5B7B9A',  // Azul acinzentado\n                '#9B8875',  // Bege m\u00e9dio\n                '#B8984E',  // Dourado escuro\n                '#7A8B6F',  // Verde acinzentado\n                '#B59B7A'   // Bege quente\n              ],\n              line: { color: '#FFFFFF', width: 2 }\n            },\n            textinfo: 'label+percent',\n            textposition: 'inside',\n            textfont: { size: 11, color: '#FFFFFF', family: 'Inter, sans-serif' },\n            hole: 0.4\n          }],\n          layout: {\n            title: {\n              text: '<b>Como as vendas est\u00e3o distribu\u00eddas?</b><br><span style=\"font-size:12px;color:#6B6B6B\">Participa\u00e7\u00e3o por categoria de produto</span>',\n              font: { size: 16, color: '#2D2D2D', family: 'Inter, sans-serif' },\n              x: 0.05\n            },\n            plot_bgcolor: '#FFFFFF',\n            paper_bgcolor: '#FAFAFA',\n            margin: { l: 20, r: 20, t: 80, b: 20 },", "mimetype": "text/plain", "start_char_idx": 3547, "end_char_idx": 6816, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "73bfb680-ca4f-4e75-9d51-c9570b6a79f2": {"__data__": {"id_": "73bfb680-ca4f-4e75-9d51-c9570b6a79f2", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Dashboard.tsx", "language": "typescript", "lines": 453, "filename": "Dashboard.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Dashboard.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Dashboard.tsx", "language": "typescript", "lines": 453, "filename": "Dashboard.tsx"}, "hash": "9929cdc1c7dab1254cee1df427feea209f7ec02f565925f27982070f050573c6", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9c30ad13-eb99-4bf6-b176-b1f4cc62d939", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Dashboard.tsx", "language": "typescript", "lines": 453, "filename": "Dashboard.tsx"}, "hash": "60135557081b5c032a06b3a67264b1944381641c996c5e79f02d518c9f9d9570", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0a426a7a-b823-4f5a-819f-d324a8428531", "node_type": "1", "metadata": {}, "hash": "bf7a9988cf09f110a1cb17398ee8d9ba12d99cebeabc99eff2da6f06d088ef59", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "r: 20, t: 80, b: 20 },\n            font: { color: '#2D2D2D', family: 'Inter, sans-serif' },\n            showlegend: true,\n            legend: {\n              orientation: 'v',\n              x: 1,\n              y: 1,\n              font: { size: 10, color: '#6B6B6B', family: 'Inter, sans-serif' },\n              bgcolor: 'rgba(255,255,255,0.9)',\n              bordercolor: '#E5E5E5',\n              borderwidth: 1\n            }\n          },\n          config: { responsive: true, displayModeBar: false }\n        };\n        setVendasCategoriaChart(vendasCategoriaSpec);\n      }\n\n    } catch (err: any) {\n      console.error('Erro ao carregar KPIs:', err);\n      setError(err.response?.data?.detail || 'Erro ao carregar m\u00e9tricas');\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  onMount(() => {\n    loadKPIs();\n    // Auto-refresh removido conforme solicitado\n    // const interval = setInterval(() => loadKPIs(), 30000);\n    // return () => clearInterval(interval);\n  });\n\n  return (\n    <div class=\"flex flex-col h-full p-6 gap-6 max-w-[1600px] mx-auto\">\n      {/* 1. Context7: Executive Summary Header */}\n      <div class=\"flex flex-col md:flex-row justify-between items-start md:items-center gap-4 border-b pb-6\">\n        <div>\n          <h2 class=\"text-3xl font-bold tracking-tight text-foreground\">\n            Ol\u00e1, {auth.user()?.username || 'Usu\u00e1rio'}\n          </h2>\n          <div class=\"flex items-center gap-2 mt-2\">\n            <Show when={businessStatus() === 'healthy'}>\n              <span class=\"inline-flex items-center px-2.5 py-0.5 rounded-full text-xs font-medium bg-green-100 text-green-800\">\n                <CheckCircle size={12} class=\"mr-1\" /> Opera\u00e7\u00e3o Saud\u00e1vel\n              </span>\n            </Show>\n            <Show when={businessStatus() === 'warning'}>\n              <span class=\"inline-flex items-center px-2.5 py-0.5 rounded-full text-xs font-medium bg-yellow-100 text-yellow-800\">\n                <AlertTriangle size={12} class=\"mr-1\" /> Aten\u00e7\u00e3o Necess\u00e1ria\n              </span>\n            </Show>\n            <Show when={businessStatus() === 'critical'}>\n              <span class=\"inline-flex items-center px-2.5 py-0.5 rounded-full text-xs font-medium bg-red-100 text-red-800\">\n                <AlertTriangle size={12} class=\"mr-1\" /> Situa\u00e7\u00e3o Cr\u00edtica\n              </span>\n            </Show>\n            <span class=\"text-sm text-muted ml-2\">\n              Vis\u00e3o geral do desempenho do neg\u00f3cio\n            </span>\n          </div>\n        </div>\n        <div class=\"flex items-center gap-2\">\n          <span class=\"text-xs text-muted text-right hidden md:block\">\n            Dados atualizados<br />{lastUpdate()?.toLocaleTimeString()}\n          </span>\n          <button\n            onClick={loadKPIs}\n            class=\"btn btn-outline btn-icon\"\n            disabled={loading()}\n            title=\"Atualizar dados\"\n          >\n            <RefreshCw size={18} class={loading() ? 'animate-spin' : ''} />\n          </button>\n        </div>\n      </div>\n\n      {/* Loading State */}\n      <Show when={loading() && !kpis()}>\n        <div class=\"flex-1 flex flex-col items-center justify-center text-muted gap-4\">\n          <RefreshCw size={48} class=\"animate-spin opacity-20\" />\n          <p>Analisando dados do neg\u00f3cio...</p>\n        </div>\n      </Show>\n\n      {/* Error State */}\n      <Show when={error()}>\n        <div class=\"p-4 border border-red-500/50 bg-red-500/10 rounded-lg text-red-500 flex items-center gap-3\">\n          <AlertTriangle size={24} />\n          <div>\n            <h3 class=\"font-bold\">Falha ao carregar dashboard</h3>\n            <p class=\"text-sm opacity-80\">{error()}</p>\n          </div>\n        </div>\n      </Show>\n\n      <Show when={kpis() && !loading()}>\n        {/* 2.", "mimetype": "text/plain", "start_char_idx": 6794, "end_char_idx": 10540, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0a426a7a-b823-4f5a-819f-d324a8428531": {"__data__": {"id_": "0a426a7a-b823-4f5a-819f-d324a8428531", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Dashboard.tsx", "language": "typescript", "lines": 453, "filename": "Dashboard.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Dashboard.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Dashboard.tsx", "language": "typescript", "lines": 453, "filename": "Dashboard.tsx"}, "hash": "9929cdc1c7dab1254cee1df427feea209f7ec02f565925f27982070f050573c6", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "73bfb680-ca4f-4e75-9d51-c9570b6a79f2", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Dashboard.tsx", "language": "typescript", "lines": 453, "filename": "Dashboard.tsx"}, "hash": "315aa820493ce8ab30fdd5d49797ff613ec3c8ede4545d2c6889c0d8ef7c1d58", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2801aaee-711a-461b-847c-793625636be0", "node_type": "1", "metadata": {}, "hash": "86349244efd92c24ee54464e94c46cdd46b66caf25466d66f27626070619700e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Context7: Key Performance Indicators (The \"What\") */}\n        <div class=\"grid grid-cols-1 md:grid-cols-2 lg:grid-cols-4 gap-4\">\n          <div class=\"kpi-card bg-card border rounded-xl p-5 shadow-sm hover:shadow-md transition-all relative overflow-hidden group\">\n            <div class=\"absolute right-0 top-0 p-4 opacity-10 group-hover:opacity-20 transition-opacity\">\n              <DollarSign size={48} />\n            </div>\n            <p class=\"text-sm font-medium text-muted uppercase tracking-wider\">Valor em Estoque</p>\n            <h3 class=\"text-3xl font-bold mt-1\">{kpis()!.valor_estoque.toLocaleString('pt-BR', { style: 'currency', currency: 'BRL' })}</h3>\n            <p class=\"text-xs text-muted mt-2 flex items-center gap-1\">\n              <TrendingUp size={12} class=\"text-green-500\" /> Capital imobilizado\n            </p>\n          </div>\n\n          <div class=\"kpi-card bg-card border rounded-xl p-5 shadow-sm hover:shadow-md transition-all relative overflow-hidden group\">\n            <div class=\"absolute right-0 top-0 p-4 opacity-10 group-hover:opacity-20 transition-opacity\">\n              <AlertTriangle size={48} />\n            </div>\n            <p class=\"text-sm font-medium text-muted uppercase tracking-wider\">Rupturas</p>\n            <h3 class={`text-3xl font-bold mt-1 ${kpis()!.produtos_ruptura > 0 ? 'text-destructive' : 'text-foreground'}`}>\n              {kpis()!.produtos_ruptura}\n            </h3>\n            <p class=\"text-xs text-muted mt-2\">\n              {kpis()!.produtos_ruptura > 0 ? 'Produtos precisam de aten\u00e7\u00e3o imediata' : 'Estoque saud\u00e1vel'}\n            </p>\n          </div>\n\n          <div class=\"kpi-card bg-card border rounded-xl p-5 shadow-sm hover:shadow-md transition-all relative overflow-hidden group\">\n            <div class=\"absolute right-0 top-0 p-4 opacity-10 group-hover:opacity-20 transition-opacity\">\n              <Package size={48} />\n            </div>\n            <p class=\"text-sm font-medium text-muted uppercase tracking-wider\">Mix de Produtos</p>\n            <h3 class=\"text-3xl font-bold mt-1\">{kpis()!.total_produtos}</h3>\n            <p class=\"text-xs text-muted mt-2\">SKUs ativos no cat\u00e1logo</p>\n          </div>\n\n          <div class=\"kpi-card bg-card border rounded-xl p-5 shadow-sm hover:shadow-md transition-all relative overflow-hidden group\">\n            <div class=\"absolute right-0 top-0 p-4 opacity-10 group-hover:opacity-20 transition-opacity\">\n              <ShoppingCart size={48} />\n            </div>\n            <p class=\"text-sm font-medium text-muted uppercase tracking-wider\">Cobertura</p>\n            <h3 class=\"text-3xl font-bold mt-1\">{kpis()!.total_unes}</h3>\n            <p class=\"text-xs text-muted mt-2\">Lojas/UNEs monitoradas</p>\n          </div>\n        </div>\n\n        {/* 3.", "mimetype": "text/plain", "start_char_idx": 10541, "end_char_idx": 13322, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2801aaee-711a-461b-847c-793625636be0": {"__data__": {"id_": "2801aaee-711a-461b-847c-793625636be0", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Dashboard.tsx", "language": "typescript", "lines": 453, "filename": "Dashboard.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Dashboard.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Dashboard.tsx", "language": "typescript", "lines": 453, "filename": "Dashboard.tsx"}, "hash": "9929cdc1c7dab1254cee1df427feea209f7ec02f565925f27982070f050573c6", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0a426a7a-b823-4f5a-819f-d324a8428531", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Dashboard.tsx", "language": "typescript", "lines": 453, "filename": "Dashboard.tsx"}, "hash": "b0c03fe7cf22183fe436401e64d7de61846edd2fdf42472f69bbd91649d48d37", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "924cef7d-e96c-46ed-9ee4-20b75841c052", "node_type": "1", "metadata": {}, "hash": "346bf47e33a341cdb4aa0bb780416c93e53361e4732453dbe4a608759ab8ccb6", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Context7: Narrative Charts (The \"Why\") */}\n        <div class=\"grid grid-cols-1 lg:grid-cols-2 gap-6\">\n          {/* \u2705 CORRE\u00c7\u00c3O: Removido h-[400px] fixo para permitir fullscreen correto */}\n          <div class=\"card bg-card border rounded-xl p-1 shadow-sm overflow-hidden flex flex-col\" style=\"min-height: 400px;\">\n            <div class=\"flex-1 min-h-0\">\n              <PlotlyChart\n                chartSpec={topProdutosChart}\n                chartId=\"top-produtos-chart\"\n                enableDownload={false} // Clean look\n                onDataClick={handleProductClick}\n                height=\"380px\"\n              />\n            </div>\n            <div class=\"px-4 py-2 bg-muted/30 border-t text-xs text-muted flex justify-between items-center\">\n              <span>Clique nas barras para detalhes</span>\n              <ChartDownloadButton chartId=\"top-produtos-chart\" filename=\"top_produtos\" label=\"\" size=\"sm\" />\n            </div>\n          </div>\n\n          {/* \u2705 CORRE\u00c7\u00c3O: Removido h-[400px] fixo para permitir fullscreen correto */}\n          <div class=\"card bg-card border rounded-xl p-1 shadow-sm overflow-hidden flex flex-col\" style=\"min-height: 400px;\">\n            <div class=\"flex-1 min-h-0\">\n              <PlotlyChart\n                chartSpec={vendasCategoriaChart}\n                chartId=\"vendas-categoria-chart\"\n                enableDownload={false}\n                height=\"380px\"\n              />\n            </div>\n            <div class=\"px-4 py-2 bg-muted/30 border-t text-xs text-muted flex justify-between items-center\">\n              <span>Distribui\u00e7\u00e3o de volume</span>\n              <ChartDownloadButton chartId=\"vendas-categoria-chart\" filename=\"vendas_categoria\" label=\"\" size=\"sm\" />\n            </div>\n          </div>\n        </div>\n\n        {/* 4. Context7: AI Analysis (The \"So What?\") */}\n        <div class=\"grid grid-cols-1 lg:grid-cols-3 gap-6\">\n          <div class=\"lg:col-span-2\">\n            <AIInsightsPanel />\n          </div>\n\n          {/* Actionable List */}\n          <div class=\"card bg-card border rounded-xl flex flex-col\">\n            <div class=\"p-4 border-b flex items-center justify-between\">\n              <h3 class=\"font-bold flex items-center gap-2\">\n                <TrendingUp size={18} class=\"text-primary\" />\n                Destaques\n              </h3>\n              <span class=\"text-xs bg-primary/10 text-primary px-2 py-1 rounded-full\">Top 5</span>\n            </div>\n            <div class=\"flex-1 overflow-y-auto\">\n              <table class=\"w-full text-sm\">\n                <tbody>\n                  <For each={kpis()!.top_produtos.slice(0, 5)}>\n                    {(produto, i) => (\n                      <tr class=\"border-b last:border-0 hover:bg-muted/50 transition-colors cursor-pointer\" onClick={() => setSelectedProductInfo(produto)}>\n                        <td class=\"p-3 font-mono text-muted w-8 text-center\">{i() + 1}</td>\n                        <td class=\"p-3\">\n                          <div class=\"font-medium\">{produto.nome}</div>\n                          <div class=\"text-xs text-muted\">{produto.produto}</div>\n                        </td>\n                        <td class=\"p-3 text-right font-bold text-foreground\">\n                          {produto.vendas.toLocaleString()}\n                        </td>\n                      </tr>\n                    )}\n                  </For>\n                </tbody>\n              </table>\n            </div>\n            {/* \u2705 CORRE\u00c7\u00c3O: Adicionado onClick para navegar ao Chat com query */}\n            <div class=\"p-3 bg-muted/20 border-t text-center\">\n              <button\n                class=\"text-xs font-medium text-primary hover:underline\"\n                onClick={() => {\n                  localStorage.setItem('example_query', 'Mostre o ranking completo dos top 20 produtos mais vendidos com an\u00e1lise detalhada');\n                  navigate('/chat');", "mimetype": "text/plain", "start_char_idx": 13323, "end_char_idx": 17223, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "924cef7d-e96c-46ed-9ee4-20b75841c052": {"__data__": {"id_": "924cef7d-e96c-46ed-9ee4-20b75841c052", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Dashboard.tsx", "language": "typescript", "lines": 453, "filename": "Dashboard.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Dashboard.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Dashboard.tsx", "language": "typescript", "lines": 453, "filename": "Dashboard.tsx"}, "hash": "9929cdc1c7dab1254cee1df427feea209f7ec02f565925f27982070f050573c6", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2801aaee-711a-461b-847c-793625636be0", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Dashboard.tsx", "language": "typescript", "lines": 453, "filename": "Dashboard.tsx"}, "hash": "7e02684e1dcb53ee43905a9b484fb8591be9ec9fe5d928f9c947c6eb128ffd30", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "navigate('/chat');\n                }}\n              >\n                Ver ranking completo\n              </button>\n            </div>\n          </div>\n        </div>\n      </Show>\n\n      {/* Detail Modal */}\n      <Show when={selectedProductInfo()}>\n        <div\n          class=\"fixed inset-0 bg-black/60 backdrop-blur-sm flex items-center justify-center z-[100] p-4 animate-in fade-in duration-200\"\n          onClick={() => setSelectedProductInfo(null)}\n        >\n          <div\n            class=\"bg-card border rounded-xl shadow-2xl w-full max-w-md overflow-hidden animate-in zoom-in-95 duration-200\"\n            onClick={(e) => e.stopPropagation()}\n          >\n            <div class=\"relative h-32 bg-gradient-to-r from-primary/20 to-accent/20 flex items-center justify-center\">\n              <Package size={64} class=\"text-primary opacity-50\" />\n              <button\n                onClick={() => setSelectedProductInfo(null)}\n                class=\"absolute top-4 right-4 p-2 bg-black/20 hover:bg-black/40 rounded-full text-white transition-colors\"\n              >\n                <X size={16} />\n              </button>\n            </div>\n\n            <div class=\"p-6\">\n              <div class=\"mb-6\">\n                <h3 class=\"text-lg font-bold leading-tight\">{selectedProductInfo()!.nome}</h3>\n                <p class=\"text-sm font-mono text-muted mt-1\">SKU: {selectedProductInfo()!.produto}</p>\n              </div>\n\n              <div class=\"grid grid-cols-2 gap-4 mb-6\">\n                <div class=\"p-3 bg-secondary rounded-lg\">\n                  <p class=\"text-xs text-muted uppercase\">Vendas (30d)</p>\n                  <p class=\"text-xl font-bold text-foreground\">{selectedProductInfo()!.vendas.toLocaleString()}</p>\n                </div>\n                <div class=\"p-3 bg-green-500/10 rounded-lg\">\n                  <p class=\"text-xs text-green-700 dark:text-green-400 uppercase\">Status</p>\n                  <p class=\"text-xl font-bold text-green-700 dark:text-green-400\">Ativo</p>\n                </div>\n              </div>\n\n              <div class=\"flex gap-3\">\n                <button class=\"flex-1 btn btn-primary\" onClick={() => {\n                  const product = selectedProductInfo();\n                  if (product) {\n                    localStorage.setItem('example_query', `Analise detalhadamente o desempenho de vendas do produto \"${product.nome}\" (SKU: ${product.produto})`);\n                    navigate('/chat');\n                  }\n                }}>\n                  Ver An\u00e1lise Completa\n                </button>\n              </div>\n            </div>\n          </div>\n        </div>\n      </Show>\n    </div>\n  );\n}", "mimetype": "text/plain", "start_char_idx": 17205, "end_char_idx": 19869, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "cdae991b-7a93-49de-bae7-a82fcd867322": {"__data__": {"id_": "cdae991b-7a93-49de-bae7-a82fcd867322", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Diagnostics.tsx", "language": "typescript", "lines": 391, "filename": "Diagnostics.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Diagnostics.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Diagnostics.tsx", "language": "typescript", "lines": 391, "filename": "Diagnostics.tsx"}, "hash": "bea365b0eb9bd22c3dbb453ccb624852d13e0f8f0c3874bf841e4efab96e240b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d2d6f73c-2442-4e44-9ffa-5c739b8b98ca", "node_type": "1", "metadata": {}, "hash": "88fdbf25e4c8aae56ca23da804965c9b6f4172e510e468661b37dd3f585f294a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import { createSignal, onMount, Show, For } from 'solid-js';\nimport { Database, Server, HardDrive, Activity, CheckCircle, AlertTriangle, RefreshCw, Settings, Play, FileText } from 'lucide-solid';\n\ninterface DBConfig {\n  use_sql_server: boolean;\n  use_supabase: boolean;\n  database_server: string | null;\n  database_name: string | null;\n  database_user: string | null;\n  supabase_url: string | null;\n}\n\ninterface ConnectionTestResult {\n  success: boolean;\n  message: string;\n  version: string | null;\n  tables: string[] | null;\n}\n\ninterface DBStatus {\n  parquet: {\n    status: string;\n    size_mb: number;\n    path: string;\n  };\n  sql_server: {\n    status: string;\n    url: string | null;\n  };\n  supabase: {\n    status: string;\n    url: string | null;\n  };\n}\n\nexport default function Diagnostics() {\n  const [dbStatus, setDbStatus] = createSignal<DBStatus | null>(null);\n  const [dbConfig, setDbConfig] = createSignal<DBConfig | null>(null);\n  const [testResult, setTestResult] = createSignal<ConnectionTestResult | null>(null);\n  const [isLoading, setIsLoading] = createSignal(true);\n  const [isTesting, setIsTesting] = createSignal(false);\n  const [error, setError] = createSignal<string | null>(null);\n\n  const loadDiagnostics = async () => {\n    setIsLoading(true);\n    setError(null);\n\n    try {\n      const token = localStorage.getItem('token');\n      if (!token) {\n        throw new Error('Token n\u00e3o encontrado. Fa\u00e7a login novamente.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1439, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d2d6f73c-2442-4e44-9ffa-5c739b8b98ca": {"__data__": {"id_": "d2d6f73c-2442-4e44-9ffa-5c739b8b98ca", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Diagnostics.tsx", "language": "typescript", "lines": 391, "filename": "Diagnostics.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Diagnostics.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Diagnostics.tsx", "language": "typescript", "lines": 391, "filename": "Diagnostics.tsx"}, "hash": "bea365b0eb9bd22c3dbb453ccb624852d13e0f8f0c3874bf841e4efab96e240b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "cdae991b-7a93-49de-bae7-a82fcd867322", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Diagnostics.tsx", "language": "typescript", "lines": 391, "filename": "Diagnostics.tsx"}, "hash": "69b1c0013b3465a15bd169414b8d4c4438bc221a832c2760ba797f2596c7f5ec", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "85928c96-e47d-44e8-aae2-05f8c233d925", "node_type": "1", "metadata": {}, "hash": "0acd80646de93e77d995f313ba23462b2fe74484c3921b67885dba9452214f2c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Fa\u00e7a login novamente.');\n      }\n\n      const [statusRes, configRes] = await Promise.all([\n        fetch('/api/v1/diagnostics/db-status', {\n          headers: { 'Authorization': `Bearer ${token}` }\n        }),\n        fetch('/api/v1/diagnostics/config', {\n          headers: { 'Authorization': `Bearer ${token}` }\n        })\n      ]);\n\n      if (!statusRes.ok || !configRes.ok) {\n        throw new Error('Erro ao buscar informa\u00e7\u00f5es de diagn\u00f3stico');\n      }\n\n      const status = await statusRes.json();\n      const config = await configRes.json();\n\n      setDbStatus(status);\n      setDbConfig(config);\n    } catch (err: any) {\n      console.error('Erro ao carregar diagn\u00f3stico:', err);\n      setError(err.message || 'Erro ao conectar com o backend');\n    } finally {\n      setIsLoading(false);\n    }\n  };\n\n  const testConnection = async () => {\n    setIsTesting(true);\n    setTestResult(null);\n\n    try {\n      const token = localStorage.getItem('token');\n      if (!token) {\n        throw new Error('Token n\u00e3o encontrado');\n      }\n\n      const response = await fetch('/api/v1/diagnostics/test-connection', {\n        method: 'POST',\n        headers: {\n          'Authorization': `Bearer ${token}`,\n          'Content-Type': 'application/json'\n        }\n      });\n\n      if (!response.ok) {\n        throw new Error('Erro ao testar conex\u00e3o');\n      }\n\n      const result = await response.json();\n      setTestResult(result);\n    } catch (err: any) {\n      setTestResult({\n        success: false,\n        message: err.message || 'Erro ao testar conex\u00e3o',\n        version: null,\n        tables: null\n      });\n    } finally {\n      setIsTesting(false);\n    }\n  };\n\n  onMount(() => {\n    loadDiagnostics();\n  });\n\n  const getStatusColor = (status: string) => {\n    if (status === 'ok' || status === 'enabled') {\n      return 'text-green-500 bg-green-500/10 border-green-500/30';\n    }\n    if (status === 'disabled') {\n      return 'text-yellow-500 bg-yellow-500/10 border-yellow-500/30';\n    }\n    return 'text-red-500 bg-red-500/10 border-red-500/30';\n  };\n\n  const getStatusIcon = (status: string) => {\n    if (status === 'ok' || status === 'enabled') {\n      return CheckCircle;\n    }\n    return AlertTriangle;\n  };\n\n  const getStatusLabel = (status: string) => {\n    if (status === 'ok') return 'OK';\n    if (status === 'enabled') return 'Habilitado';\n    if (status === 'disabled') return 'Desabilitado';\n    return 'Erro';\n  };\n\n  return (\n    <div class=\"flex flex-col h-full p-6 gap-6 max-w-7xl mx-auto\">\n      {/* Header */}\n      <div class=\"flex justify-between items-start\">\n        <div>\n          <h2 class=\"text-2xl font-bold tracking-tight flex items-center gap-2\">\n            <Activity size={24} />\n            Diagn\u00f3stico do Sistema\n          </h2>\n          <p class=\"text-muted mt-1\">Configura\u00e7\u00f5es e status das conex\u00f5es de banco de dados</p>\n        </div>\n        <button onClick={loadDiagnostics} class=\"btn btn-outline gap-2\" disabled={isLoading()}>\n          <RefreshCw size={16} class={isLoading() ?", "mimetype": "text/plain", "start_char_idx": 1418, "end_char_idx": 4441, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "85928c96-e47d-44e8-aae2-05f8c233d925": {"__data__": {"id_": "85928c96-e47d-44e8-aae2-05f8c233d925", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Diagnostics.tsx", "language": "typescript", "lines": 391, "filename": "Diagnostics.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Diagnostics.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Diagnostics.tsx", "language": "typescript", "lines": 391, "filename": "Diagnostics.tsx"}, "hash": "bea365b0eb9bd22c3dbb453ccb624852d13e0f8f0c3874bf841e4efab96e240b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d2d6f73c-2442-4e44-9ffa-5c739b8b98ca", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Diagnostics.tsx", "language": "typescript", "lines": 391, "filename": "Diagnostics.tsx"}, "hash": "aeebdebe6b0d57cd4ce301bd24c0bc63b36531ce3381a06ba130581d398f6652", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e65256f6-85fa-42fb-83d4-754d47fb6ba7", "node_type": "1", "metadata": {}, "hash": "74473fbf7e54a441e02b6e3202b66dc4145fe9a4672203f86b61279b220b69c8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "'animate-spin' : ''} />\n          Atualizar\n        </button>\n      </div>\n\n      {/* Error Alert */}\n      <Show when={error()}>\n        <div class=\"p-4 bg-red-500/10 border border-red-500/30 rounded-lg text-red-300 flex items-center gap-3\">\n          <AlertTriangle size={24} />\n          <div>\n            <h3 class=\"font-bold\">Erro ao carregar diagn\u00f3stico</h3>\n            <p class=\"text-sm opacity-80\">{error()}</p>\n          </div>\n        </div>\n      </Show>\n\n      <Show when={!isLoading() && dbStatus() && dbConfig()} fallback={\n        <div class=\"p-12 text-center border rounded-xl bg-card text-muted animate-pulse\">\n          <RefreshCw class=\"animate-spin mx-auto mb-4\" size={32} />\n          Carregando informa\u00e7\u00f5es do sistema...\n        </div>\n      }>\n        {/* Status Cards */}\n        <div class=\"grid grid-cols-1 md:grid-cols-3 gap-4\">\n          <div class=\"p-6 rounded-lg border bg-card\">\n            <div class=\"flex items-center justify-between mb-4\">\n              <span class=\"text-sm font-medium text-muted-foreground\">Parquet (Dados)</span>\n              <HardDrive size={18} class=\"text-blue-500\" />\n            </div>\n            <div class=\"flex flex-col gap-2\">\n              {(() => {\n                const status = dbStatus()?.parquet.status || 'unknown';\n                const StatusIcon = getStatusIcon(status);\n                return (\n                  <>\n                    <span class={`inline-flex items-center gap-2 rounded border px-3 py-1.5 text-sm font-medium ${getStatusColor(status)}`}>\n                      <StatusIcon size={16} />\n                      {getStatusLabel(status)}\n                    </span>\n                    <p class=\"text-xs text-muted-foreground mt-2\">\n                      Tamanho: <span class=\"font-mono font-medium\">{dbStatus()?.parquet.size_mb} MB</span>\n                    </p>\n                  </>\n                );\n              })()}\n            </div>\n          </div>\n\n          <div class=\"p-6 rounded-lg border bg-card\">\n            <div class=\"flex items-center justify-between mb-4\">\n              <span class=\"text-sm font-medium text-muted-foreground\">SQL Server</span>\n              <Database size={18} class=\"text-orange-500\" />\n            </div>\n            <div class=\"flex flex-col gap-2\">\n              {(() => {\n                const status = dbStatus()?.sql_server.status || 'unknown';\n                const StatusIcon = getStatusIcon(status);\n                return (\n                  <span class={`inline-flex items-center gap-2 rounded border px-3 py-1.5 text-sm font-medium ${getStatusColor(status)}`}>\n                    <StatusIcon size={16} />\n                    {getStatusLabel(status)}\n                  </span>\n                );\n              })()}\n            </div>\n          </div>\n\n          <div class=\"p-6 rounded-lg border bg-card\">\n            <div class=\"flex items-center justify-between mb-4\">\n              <span class=\"text-sm font-medium text-muted-foreground\">Supabase Auth</span>\n              <Server size={18} class=\"text-green-500\" />\n            </div>\n            <div class=\"flex flex-col gap-2\">\n              {(() => {\n                const status = dbStatus()?.supabase.status || 'unknown';\n                const StatusIcon = getStatusIcon(status);\n                return (\n                  <span class={`inline-flex items-center gap-2 rounded border px-3 py-1.5 text-sm font-medium ${getStatusColor(status)}`}>\n                    <StatusIcon size={16} />\n                    {getStatusLabel(status)}\n                  </span>\n                );\n              })()}\n            </div>\n          </div>\n        </div>\n\n        {/* Configura\u00e7\u00f5es Detectadas */}\n        <div class=\"p-6 rounded-lg border bg-card\">\n          <h3 class=\"font-semibold flex items-center gap-2 mb-4\">\n            <Settings size={18} />\n            Configura\u00e7\u00f5es Detectadas\n          </h3>\n\n          <div class=\"grid grid-cols-1 md:grid-cols-2 gap-4\">\n            <div>\n              <label class=\"text-xs text-muted-foreground font-medium\">Modo de Opera\u00e7\u00e3o</label>\n              <p class=\"font-mono text-sm mt-1 p-2 bg-secondary rounded\">\n                {dbConfig()?.use_sql_server ?", "mimetype": "text/plain", "start_char_idx": 4442, "end_char_idx": 8644, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e65256f6-85fa-42fb-83d4-754d47fb6ba7": {"__data__": {"id_": "e65256f6-85fa-42fb-83d4-754d47fb6ba7", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Diagnostics.tsx", "language": "typescript", "lines": 391, "filename": "Diagnostics.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Diagnostics.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Diagnostics.tsx", "language": "typescript", "lines": 391, "filename": "Diagnostics.tsx"}, "hash": "bea365b0eb9bd22c3dbb453ccb624852d13e0f8f0c3874bf841e4efab96e240b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "85928c96-e47d-44e8-aae2-05f8c233d925", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Diagnostics.tsx", "language": "typescript", "lines": 391, "filename": "Diagnostics.tsx"}, "hash": "d3fc027fdeff536992b4028ffdbfa938eeae226fef661328e7263f6f91563d37", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "04568753-00e7-45cc-a978-62190ae02851", "node_type": "1", "metadata": {}, "hash": "c3336985e08335b02adc936114774be62aa7d4bfb2c37643928894820ea0115d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "'SQL Server (H\u00edbrido)' : 'Apenas Parquet (Cloud)'}\n              </p>\n            </div>\n\n            <Show when={dbConfig()?.use_sql_server}>\n              <div>\n                <label class=\"text-xs text-muted-foreground font-medium\">Servidor SQL</label>\n                <p class=\"font-mono text-sm mt-1 p-2 bg-secondary rounded\">\n                  {dbConfig()?.database_server || 'N/A'}\n                </p>\n              </div>\n\n              <div>\n                <label class=\"text-xs text-muted-foreground font-medium\">Banco de Dados</label>\n                <p class=\"font-mono text-sm mt-1 p-2 bg-secondary rounded\">\n                  {dbConfig()?.database_name || 'N/A'}\n                </p>\n              </div>\n\n              <div>\n                <label class=\"text-xs text-muted-foreground font-medium\">Usu\u00e1rio SQL</label>\n                <p class=\"font-mono text-sm mt-1 p-2 bg-secondary rounded\">\n                  {dbConfig()?.database_user || 'N/A'}\n                </p>\n              </div>\n            </Show>\n\n            <Show when={dbConfig()?.use_supabase}>\n              <div>\n                <label class=\"text-xs text-muted-foreground font-medium\">Supabase URL</label>\n                <p class=\"font-mono text-sm mt-1 p-2 bg-secondary rounded truncate\">\n                  {dbConfig()?.supabase_url || 'N/A'}\n                </p>\n              </div>\n            </Show>\n\n            <div>\n              <label class=\"text-xs text-muted-foreground font-medium\">Path Parquet</label>\n              <p class=\"font-mono text-xs mt-1 p-2 bg-secondary rounded truncate\" title={dbStatus()?.parquet.path}>\n                {dbStatus()?.parquet.path || 'N/A'}\n              </p>\n            </div>\n          </div>\n        </div>\n\n        {/* Teste de Conex\u00e3o SQL Server */}\n        <Show when={dbConfig()?.use_sql_server}>\n          <div class=\"p-6 rounded-lg border bg-card\">\n            <div class=\"flex justify-between items-center mb-4\">\n              <h3 class=\"font-semibold flex items-center gap-2\">\n                <Play size={18} />\n                Teste de Conex\u00e3o SQL Server\n              </h3>\n              <button\n                onClick={testConnection}\n                class=\"btn btn-primary gap-2\"\n                disabled={isTesting()}\n              >\n                {isTesting() ? (\n                  <>\n                    <RefreshCw size={16} class=\"animate-spin\" />\n                    Testando...\n                  </>\n                ) : (\n                  <>\n                    <Play size={16} />\n                    Testar Conex\u00e3o\n                  </>\n                )}\n              </button>\n            </div>\n\n            <Show when={testResult()}>\n              <div class={`p-4 rounded-lg border ${testResult()?.success ? 'bg-green-500/10 border-green-500/30' : 'bg-red-500/10 border-red-500/30'}`}>\n                <div class=\"flex items-start gap-3\">\n                  {testResult()?.success ? (\n                    <CheckCircle size={24} class=\"text-green-500 flex-shrink-0\" />\n                  ) : (\n                    <AlertTriangle size={24} class=\"text-red-500 flex-shrink-0\" />\n                  )}\n                  <div class=\"flex-1\">\n                    <p class={`font-medium ${testResult()?.success ?", "mimetype": "text/plain", "start_char_idx": 8645, "end_char_idx": 11914, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "04568753-00e7-45cc-a978-62190ae02851": {"__data__": {"id_": "04568753-00e7-45cc-a978-62190ae02851", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Diagnostics.tsx", "language": "typescript", "lines": 391, "filename": "Diagnostics.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Diagnostics.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Diagnostics.tsx", "language": "typescript", "lines": 391, "filename": "Diagnostics.tsx"}, "hash": "bea365b0eb9bd22c3dbb453ccb624852d13e0f8f0c3874bf841e4efab96e240b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e65256f6-85fa-42fb-83d4-754d47fb6ba7", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Diagnostics.tsx", "language": "typescript", "lines": 391, "filename": "Diagnostics.tsx"}, "hash": "471be14001cdd39d3840aa72238f43fc5987f38ddd2968389b504752bdff4470", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "'text-green-500' : 'text-red-500'}`}>\n                      {testResult()?.message}\n                    </p>\n\n                    <Show when={testResult()?.version}>\n                      <p class=\"text-sm text-muted-foreground mt-2\">\n                        Vers\u00e3o: <span class=\"font-mono\">{testResult()?.version}</span>\n                      </p>\n                    </Show>\n\n                    <Show when={testResult()?.tables && testResult()!.tables!.length > 0}>\n                      <div class=\"mt-3\">\n                        <p class=\"text-sm font-medium mb-2 flex items-center gap-2\">\n                          <FileText size={14} />\n                          Tabelas Dispon\u00edveis ({testResult()!.tables!.length})\n                        </p>\n                        <div class=\"max-h-48 overflow-y-auto bg-secondary/50 rounded p-2\">\n                          <div class=\"grid grid-cols-2 md:grid-cols-3 gap-1\">\n                            <For each={testResult()?.tables}>\n                              {(table) => (\n                                <span class=\"text-xs font-mono p-1 hover:bg-secondary rounded\">\n                                  {table}\n                                </span>\n                              )}\n                            </For>\n                          </div>\n                        </div>\n                      </div>\n                    </Show>\n                  </div>\n                </div>\n              </div>\n            </Show>\n          </div>\n        </Show>\n\n        {/* Instru\u00e7\u00f5es para Streamlit Cloud */}\n        <Show when={!dbConfig()?.use_sql_server}>\n          <div class=\"p-6 bg-blue-500/5 border border-blue-500/20 rounded-lg\">\n            <h4 class=\"font-semibold text-blue-500 mb-3\">Modo Cloud (Apenas Parquet)</h4>\n            <p class=\"text-sm text-muted-foreground mb-3\">\n              O sistema est\u00e1 rodando em modo cloud, usando apenas arquivos Parquet como fonte de dados.\n              Este \u00e9 o modo recomendado para deploy em Streamlit Cloud ou ambientes sem SQL Server.\n            </p>\n            <ul class=\"text-sm text-muted-foreground space-y-1 list-disc list-inside\">\n              <li>Autentica\u00e7\u00e3o: Parquet (users.parquet) ou Supabase</li>\n              <li>Dados anal\u00edticos: Parquet (admmat.parquet)</li>\n              <li>Performance: Otimizado para leitura em cache</li>\n              <li>Deploy: Compat\u00edvel com Streamlit Cloud</li>\n            </ul>\n          </div>\n        </Show>\n      </Show>\n    </div>\n  );\n}", "mimetype": "text/plain", "start_char_idx": 11915, "end_char_idx": 14417, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a2e6a2ad-7fb4-495c-8b76-6b8c14f0be07": {"__data__": {"id_": "a2e6a2ad-7fb4-495c-8b76-6b8c14f0be07", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Examples.tsx", "language": "typescript", "lines": 175, "filename": "Examples.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Examples.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Examples.tsx", "language": "typescript", "lines": 175, "filename": "Examples.tsx"}, "hash": "565aeb64bbf6de6cd8283831f0d459208c10d0bd5d7d9a36f0cb29f1dceb52a7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "64881022-f05f-4123-9bf4-ff4789664d5a", "node_type": "1", "metadata": {}, "hash": "6641df23aea52f033b1cb84414b54d0831a461b6ea739b64438b3aeb014dd241", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import { createSignal, For, Show } from 'solid-js';\nimport { Search, MessageSquare, TrendingUp, Package, DollarSign, AlertTriangle, BarChart3 } from 'lucide-solid';\nimport { useNavigate } from '@solidjs/router';\n\ninterface ExampleQuery {\n  id: number;\n  categoria: string;\n  pergunta: string;\n  icone: any;\n}\n\nconst CATEGORIAS = [\n  { nome: 'Todas', icone: MessageSquare },\n  { nome: 'Vendas', icone: TrendingUp },\n  { nome: 'Estoque', icone: Package },\n  { nome: 'Produtos', icone: BarChart3 },\n  { nome: 'Rupturas', icone: AlertTriangle },\n];\n\n// Perguntas baseadas nas colunas REAIS do admmat.parquet:\n// UNE, PRODUTO, NOME, UNE_NOME, NOMESEGMENTO, NOMECATEGORIA, NOMEFABRICANTE,\n// ESTOQUE_UNE, ESTOQUE_LV, ESTOQUE_CD, VENDA_30DD, PRECO_VENDA, SITUACAO\nconst EXAMPLE_QUERIES: ExampleQuery[] = [\n  // Categoria: Vendas (baseado em VENDA_30DD)\n  { id: 1, categoria: 'Vendas', pergunta: 'Quais os 10 produtos com maior VENDA_30DD?', icone: TrendingUp },\n  { id: 2, categoria: 'Vendas', pergunta: 'Qual o total de vendas da UNE 261?', icone: TrendingUp },\n  { id: 3, categoria: 'Vendas', pergunta: 'Mostre vendas agrupadas por NOMESEGMENTO', icone: TrendingUp },\n  { id: 4, categoria: 'Vendas', pergunta: 'Quais UNEs t\u00eam maior volume de VENDA_30DD?', icone: TrendingUp },\n  { id: 5, categoria: 'Vendas', pergunta: 'Liste produtos sem vendas nos \u00faltimos 30 dias', icone: TrendingUp },\n\n  // Categoria: Estoque (baseado em ESTOQUE_UNE, ESTOQUE_LV, ESTOQUE_CD)\n  { id: 6, categoria: 'Estoque', pergunta: 'Quais produtos t\u00eam ESTOQUE_UNE abaixo de 10?', icone: Package },\n  { id: 7, categoria: 'Estoque', pergunta: 'Mostre o total de ESTOQUE_UNE por UNE', icone: Package },\n  { id: 8, categoria: 'Estoque', pergunta: 'Liste produtos com ESTOQUE_UNE zerado', icone: Package },\n  { id: 9, categoria: 'Estoque', pergunta: 'Qual o estoque do CD (ESTOQUE_CD) por segmento?', icone: Package },\n  { id: 10, categoria: 'Estoque', pergunta: 'Produtos com ESTOQUE_UNE acima de 1000', icone: Package },\n\n  // Categoria: Produtos (baseado em NOMEFABRICANTE, NOMESEGMENTO, NOMECATEGORIA)\n  { id: 11, categoria: 'Produtos', pergunta: 'Quais produtos s\u00e3o do NOMEFABRICANTE igual a NESTLE?', icone: BarChart3 },\n  { id: 12, categoria: 'Produtos', pergunta: 'Liste produtos do NOMESEGMENTO HIGIENE', icone: BarChart3 },\n  { id: 13, categoria: 'Produtos', pergunta: 'Mostre a quantidade de produtos por NOMECATEGORIA', icone: BarChart3 },\n  { id: 14, categoria: 'Produtos', pergunta: 'Quais fabricantes t\u00eam mais produtos cadastrados?", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2510, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "64881022-f05f-4123-9bf4-ff4789664d5a": {"__data__": {"id_": "64881022-f05f-4123-9bf4-ff4789664d5a", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Examples.tsx", "language": "typescript", "lines": 175, "filename": "Examples.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Examples.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Examples.tsx", "language": "typescript", "lines": 175, "filename": "Examples.tsx"}, "hash": "565aeb64bbf6de6cd8283831f0d459208c10d0bd5d7d9a36f0cb29f1dceb52a7", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a2e6a2ad-7fb4-495c-8b76-6b8c14f0be07", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Examples.tsx", "language": "typescript", "lines": 175, "filename": "Examples.tsx"}, "hash": "946923c26c356bc53844041f7885bdc41bdedf985394bcd0066cb8c0870337f4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "375cd63e-828a-4283-a164-ea621c19d391", "node_type": "1", "metadata": {}, "hash": "6a4ad25548e5284accbcc699dff70221a09e0a79f5bd7c44378ec5daf8ec4b3f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "', icone: BarChart3 },\n  { id: 15, categoria: 'Produtos', pergunta: 'Liste as UNE_NOME dispon\u00edveis no sistema', icone: BarChart3 },\n\n  // Categoria: Rupturas (baseado em compara\u00e7\u00e3o ESTOQUE_UNE vs ESTOQUE_LV)\n  { id: 16, categoria: 'Rupturas', pergunta: 'Produtos com ESTOQUE_UNE abaixo da linha verde (ESTOQUE_LV)', icone: AlertTriangle },\n  { id: 17, categoria: 'Rupturas', pergunta: 'Quais UNEs t\u00eam mais produtos em ruptura?', icone: AlertTriangle },\n  { id: 18, categoria: 'Rupturas', pergunta: 'Liste rupturas cr\u00edticas do NOMESEGMENTO ALIMENTOS', icone: AlertTriangle },\n  { id: 19, categoria: 'Rupturas', pergunta: 'Produtos da UNE 261 com estoque zerado', icone: AlertTriangle },\n  { id: 20, categoria: 'Rupturas', pergunta: 'Sugira transfer\u00eancias para resolver rupturas', icone: AlertTriangle },\n];\n\nexport default function Examples() {\n  const navigate = useNavigate();\n  const [categoriaAtiva, setCategoriaAtiva] = createSignal('Todas');\n  const [searchTerm, setSearchTerm] = createSignal('');\n\n  const perguntasFiltradas = () => {\n    let perguntas = EXAMPLE_QUERIES;\n\n    if (categoriaAtiva() !== 'Todas') {\n      perguntas = perguntas.filter(q => q.categoria === categoriaAtiva());\n    }\n\n    if (searchTerm()) {\n      const term = searchTerm().toLowerCase();\n      perguntas = perguntas.filter(q => q.pergunta.toLowerCase().includes(term));\n    }\n\n    return perguntas;\n  };\n\n  const handleTestarPergunta = (pergunta: string) => {\n    localStorage.setItem('example_query', pergunta);\n    navigate('/chat');\n  };\n\n  return (\n    <div class=\"flex flex-col h-full p-6 gap-6\">\n      {/* Header */}\n      <div>\n        <h2 class=\"text-2xl font-bold flex items-center gap-2\">\n          <MessageSquare size={28} />\n          Exemplos de Perguntas\n        </h2>\n        <p class=\"text-muted-foreground text-sm\">\n          Perguntas baseadas nas colunas reais: VENDA_30DD, ESTOQUE_UNE, NOMEFABRICANTE, etc.\n        </p>\n      </div>\n\n      {/* Search */}\n      <div class=\"relative\">\n        <Search size={20} class=\"absolute left-3 top-1/2 -translate-y-1/2 text-muted-foreground\" />\n        <input\n          type=\"text\"\n          class=\"w-full pl-10 pr-4 py-3 bg-card border rounded-lg focus:outline-none focus:ring-2 focus:ring-primary\"\n          placeholder=\"Buscar perguntas...\"\n          value={searchTerm()}\n          onInput={(e) => setSearchTerm(e.currentTarget.value)}\n        />\n      </div>\n\n      {/* Categories */}\n      <div class=\"flex gap-2 flex-wrap\">\n        <For each={CATEGORIAS}>\n          {(cat) => {\n            const Icon = cat.icone;\n            return (\n              <button\n                onClick={() => setCategoriaAtiva(cat.nome)}\n                class={`px-4 py-2 rounded-lg flex items-center gap-2 transition-colors ${\n                  categoriaAtiva() === cat.nome\n                    ?", "mimetype": "text/plain", "start_char_idx": 2510, "end_char_idx": 5335, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "375cd63e-828a-4283-a164-ea621c19d391": {"__data__": {"id_": "375cd63e-828a-4283-a164-ea621c19d391", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Examples.tsx", "language": "typescript", "lines": 175, "filename": "Examples.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Examples.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Examples.tsx", "language": "typescript", "lines": 175, "filename": "Examples.tsx"}, "hash": "565aeb64bbf6de6cd8283831f0d459208c10d0bd5d7d9a36f0cb29f1dceb52a7", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "64881022-f05f-4123-9bf4-ff4789664d5a", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Examples.tsx", "language": "typescript", "lines": 175, "filename": "Examples.tsx"}, "hash": "c5631728b935537e2b183bd1f8a6e81b3d3a01c94a8e2a80868821081567119d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "'bg-primary text-primary-foreground'\n                    : 'bg-secondary hover:bg-secondary/80'\n                }`}\n              >\n                <Icon size={16} />\n                {cat.nome}\n              </button>\n            );\n          }}\n        </For>\n      </div>\n\n      {/* Results */}\n      <div class=\"text-sm text-muted-foreground\">\n        {perguntasFiltradas().length} perguntas\n      </div>\n\n      {/* Grid */}\n      <div class=\"grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-4 overflow-auto\">\n        <For each={perguntasFiltradas()}>\n          {(query) => {\n            const Icon = query.icone;\n            return (\n              <div \n                class=\"card p-4 border hover:border-primary/50 transition-all cursor-pointer group\"\n                onClick={() => handleTestarPergunta(query.pergunta)}\n              >\n                <div class=\"flex items-start gap-3\">\n                  <div class=\"p-2 bg-primary/10 text-primary rounded-lg\">\n                    <Icon size={20} />\n                  </div>\n                  <div class=\"flex-1\">\n                    <div class=\"text-xs text-muted-foreground mb-1\">{query.categoria}</div>\n                    <p class=\"text-sm\">{query.pergunta}</p>\n                  </div>\n                </div>\n              </div>\n            );\n          }}\n        </For>\n      </div>\n\n      <Show when={perguntasFiltradas().length === 0}>\n        <div class=\"flex-1 flex items-center justify-center\">\n          <div class=\"text-center\">\n            <Search size={48} class=\"mx-auto mb-4 opacity-20\" />\n            <p class=\"text-muted-foreground\">Nenhuma pergunta encontrada</p>\n            <button\n              onClick={() => {\n                setSearchTerm('');\n                setCategoriaAtiva('Todas');\n              }}\n              class=\"btn btn-outline mt-4\"\n            >\n              Limpar Filtros\n            </button>\n          </div>\n        </div>\n      </Show>\n    </div>\n  );\n}", "mimetype": "text/plain", "start_char_idx": 5336, "end_char_idx": 7301, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "16708e65-9109-4ab4-93ed-a21f199d715d": {"__data__": {"id_": "16708e65-9109-4ab4-93ed-a21f199d715d", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Help.tsx", "language": "typescript", "lines": 343, "filename": "Help.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Help.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Help.tsx", "language": "typescript", "lines": 343, "filename": "Help.tsx"}, "hash": "69f36e5c5fb45b3dd92a6c39c2e10eb4fab88afd8fc93279f6cbcfbf99428d40", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0e2b0951-c75a-42ca-a966-ccc897660854", "node_type": "1", "metadata": {}, "hash": "8d8de61c3a7eeadcb4f28dab0b67138b805736f6303364121edbdd1346a0e969", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import { createSignal, For, Show } from 'solid-js';\nimport { HelpCircle, Book, AlertCircle, Database, Search, ChevronDown, ChevronUp, Sparkles, TrendingUp, BarChart3, Truck } from 'lucide-solid';\nimport auth from '@/store/auth';\n\ntype TabType = 'guia' | 'faq' | 'troubleshooting' | 'dados';\n\ninterface FAQItem {\n  pergunta: string;\n  resposta: string;\n}\n\ninterface TroubleshootingItem {\n  problema: string;\n  solucao: string[];\n}\n\nexport default function Help() {\n  const [activeTab, setActiveTab] = createSignal<TabType>('guia');\n  const [searchTerm, setSearchTerm] = createSignal('');\n  const [expandedFAQ, setExpandedFAQ] = createSignal<number | null>(null);\n  \n  const isAdmin = () => auth.user()?.role === 'admin';\n\n  const FAQ_ITEMS: FAQItem[] = [\n    {\n      pergunta: 'Como fa\u00e7o para consultar produtos em ruptura?',\n      resposta: 'Navegue at\u00e9 a p\u00e1gina \"Rupturas\" no menu Dashboards. O sistema identifica rupturas quando um produto possui hist\u00f3rico de vendas positivo mas o estoque atual est\u00e1 zerado ou abaixo de 5 dias de cobertura. Voc\u00ea pode filtrar por Segmento ou Categoria.'\n    },\n    {\n      pergunta: 'Como solicitar uma transfer\u00eancia de estoque?',\n      resposta: 'Acesse a p\u00e1gina \"Transfer\u00eancias\" no menu Operacional. O sistema sugere transfer\u00eancias do CD (Centro de Distribui\u00e7\u00e3o) para as Lojas quando detecta que a loja est\u00e1 com estoque cr\u00edtico e o CD possui saldo parado.'\n    },\n    {\n      pergunta: 'O que \u00e9 Cobertura de Estoque e como ela \u00e9 calculada?',\n      resposta: 'A Cobertura representa quantos dias o seu estoque atual ir\u00e1 durar com base na m\u00e9dia de vendas dos \u00faltimos 30 dias. O ideal para o varejo de armarinhos \u00e9 entre 15 a 30 dias. Menos de 5 dias \u00e9 considerado Risco de Ruptura.'\n    },\n    {\n      pergunta: 'Como funciona a Curva ABC (Pareto) neste sistema?',\n      resposta: 'A Curva ABC classifica os produtos por contribui\u00e7\u00e3o de Receita (Pareto): Classe A (80% da receita), Classe B (15% da receita) e Classe C (5% finais). Isso ajuda a focar a gest\u00e3o nos itens que realmente sustentam o faturamento.'\n    },\n    {\n      pergunta: 'O que s\u00e3o os \"AI Insights\" no Dashboard?',\n      resposta: 'S\u00e3o an\u00e1lises proativas geradas pelo Gemini 3.0 Flash que cruzam dados de venda, estoque e crescimento. A IA identifica anomalias (como o TNT sem estoque na loja mas com 16 mil unidades no CD) e sugere planos de a\u00e7\u00e3o imediatos.'\n    },\n    {\n      pergunta: 'Posso exportar dados para Excel?',\n      resposta: 'Sim! Gr\u00e1ficos e tabelas possuem bot\u00f5es de download. No Chat BI, voc\u00ea pode solicitar \"Exportar para CSV\" e o sistema gerar\u00e1 um link para download dos dados analisados.'\n    },\n    {\n      pergunta: 'Qual a diferen\u00e7a entre \"Metrics\" e \"Analytics\"?',\n      resposta: 'Metrics exibe KPIs de performance do sistema (tempo de resposta da IA, hits de cache). Analytics exibe o desempenho do neg\u00f3cio (Curva de Pareto, Giro de Estoque, Ranking de Categorias).'\n    },\n    {\n      pergunta: 'Como o Chat BI entende meus dados?',\n      resposta: 'O Chat utiliza um adaptador do Gemini integrado ao nosso banco de dados Parquet. Ele \"l\u00ea\" as colunas de venda e estoque em tempo real e aplica regras de neg\u00f3cio espec\u00edficas da Ca\u00e7ula para responder suas perguntas.'\n    },\n    {\n      pergunta: 'Administradores podem gerenciar usu\u00e1rios e segmentos?',\n      resposta: 'Sim. Usu\u00e1rios Admin podem definir quais segmentos cada usu\u00e1rio pode visualizar (ex: Tecidos, Armarinho, Papelaria). Isso garante que cada gestor veja apenas o que \u00e9 relevante para sua \u00e1rea.'\n    },\n    {\n      pergunta: 'O sistema utiliza dados em tempo real?", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3559, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0e2b0951-c75a-42ca-a966-ccc897660854": {"__data__": {"id_": "0e2b0951-c75a-42ca-a966-ccc897660854", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Help.tsx", "language": "typescript", "lines": 343, "filename": "Help.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Help.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Help.tsx", "language": "typescript", "lines": 343, "filename": "Help.tsx"}, "hash": "69f36e5c5fb45b3dd92a6c39c2e10eb4fab88afd8fc93279f6cbcfbf99428d40", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "16708e65-9109-4ab4-93ed-a21f199d715d", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Help.tsx", "language": "typescript", "lines": 343, "filename": "Help.tsx"}, "hash": "36166a3afdb982a33189176f35819a775f44e98a6549e77910b3211e0260d7c7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3a6d0f2b-774a-4967-b8a1-9696b2347dcd", "node_type": "1", "metadata": {}, "hash": "2f90312cece0b9a50e14990590f504111a52ca5690af0004ee0186b87bb27fb9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "},\n    {\n      pergunta: 'O sistema utiliza dados em tempo real?',\n      resposta: 'O sistema utiliza uma arquitetura h\u00edbrida. Os dados s\u00e3o sincronizados do SQL Server para arquivos Parquet de alta performance para garantir que as an\u00e1lises de IA e gr\u00e1ficos sejam instant\u00e2neos, mesmo com milh\u00f5es de registros.'\n    }\n  ];\n\n  const TROUBLESHOOTING_ITEMS: TroubleshootingItem[] = [\n    {\n      problema: 'Chat BI n\u00e3o est\u00e1 respondendo ou apresenta erro de modelo',\n      solucao: [\n        'Verifique se o backend est\u00e1 ativo e a chave do Gemini configurada',\n        'Confirme sua conex\u00e3o com a internet',\n        'Tente reformular a pergunta de forma mais clara',\n        'Verifique se o servi\u00e7o do Google AI est\u00e1 dispon\u00edvel na sua regi\u00e3o'\n      ]\n    },\n    {\n      problema: 'Dados de vendas ou estoque parecem desatualizados',\n      solucao: [\n        'Clique no bot\u00e3o \"Atualizar\" no Dashboard',\n        'Admins podem for\u00e7ar uma nova sincroniza\u00e7\u00e3o SQL \u2192 Parquet',\n        'Verifique o campo \"\u00daltima Atualiza\u00e7\u00e3o\" no rodap\u00e9 das p\u00e1ginas'\n      ]\n    },\n    {\n      problema: 'N\u00e3o vejo o segmento de Tecidos (ou outro espec\u00edfico)',\n      solucao: [\n        'Verifique suas permiss\u00f5es em Perfil > Segmentos Permitidos',\n        'Solicite ao Administrador para liberar o acesso ao segmento desejado',\n        'Somente administradores possuem \"Vis\u00e3o Global\" de todos os segmentos'\n      ]\n    }\n  ];\n\n  const filteredFAQ = () => {\n    if (!searchTerm()) return FAQ_ITEMS;\n    const term = searchTerm().toLowerCase();\n    return FAQ_ITEMS.filter(item =>\n      item.pergunta.toLowerCase().includes(term) ||\n      item.resposta.toLowerCase().includes(term)\n    );\n  };\n\n  return (\n    <div class=\"flex flex-col h-full p-6 gap-6 max-w-[1400px] mx-auto\">\n      {/* Header */}\n      <div class=\"flex flex-col md:flex-row justify-between items-start md:items-center gap-4\">\n        <div>\n          <h2 class=\"text-3xl font-bold flex items-center gap-3\">\n            <HelpCircle size={32} class=\"text-primary\" />\n            Central de Ajuda & Documenta\u00e7\u00e3o\n          </h2>\n          <p class=\"text-muted-foreground mt-1\">Guia completo para extrair o m\u00e1ximo do Agente BI Ca\u00e7ula</p>\n        </div>\n      </div>\n\n      {/* Tabs Layout */}\n      <div class=\"flex flex-col lg:flex-row gap-8 mt-4\">\n        {/* Sidebar Nav */}\n        <div class=\"lg:w-64 flex-shrink-0\">\n          <div class=\"flex flex-col gap-1 sticky top-6\">\n            <button\n              onClick={() => setActiveTab('guia')}\n              class={`flex items-center gap-3 px-4 py-3 rounded-xl transition-all ${\n                activeTab() === 'guia' ? 'bg-primary text-white shadow-md' : 'hover:bg-muted text-muted-foreground'\n              }`}\n            >\n              <Book size={20} />\n              <span class=\"font-bold\">Guia R\u00e1pido</span>\n            </button>\n            <button\n              onClick={() => setActiveTab('faq')}\n              class={`flex items-center gap-3 px-4 py-3 rounded-xl transition-all ${\n                activeTab() === 'faq' ? 'bg-primary text-white shadow-md' : 'hover:bg-muted text-muted-foreground'\n              }`}\n            >\n              <HelpCircle size={20} />\n              <span class=\"font-bold\">FAQ</span>\n            </button>\n            <Show when={isAdmin()}>\n              <button\n                onClick={() => setActiveTab('troubleshooting')}\n                class={`flex items-center gap-3 px-4 py-3 rounded-xl transition-all ${\n                  activeTab() === 'troubleshooting' ? 'bg-primary text-white shadow-md' : 'hover:bg-muted text-muted-foreground'\n                }`}\n              >\n                <AlertCircle size={20} />\n                <span class=\"font-bold\">Troubleshooting</span>\n              </button>\n              <button\n                onClick={() => setActiveTab('dados')}\n                class={`flex items-center gap-3 px-4 py-3 rounded-xl transition-all ${\n                  activeTab() === 'dados' ?", "mimetype": "text/plain", "start_char_idx": 3495, "end_char_idx": 7439, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "3a6d0f2b-774a-4967-b8a1-9696b2347dcd": {"__data__": {"id_": "3a6d0f2b-774a-4967-b8a1-9696b2347dcd", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Help.tsx", "language": "typescript", "lines": 343, "filename": "Help.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Help.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Help.tsx", "language": "typescript", "lines": 343, "filename": "Help.tsx"}, "hash": "69f36e5c5fb45b3dd92a6c39c2e10eb4fab88afd8fc93279f6cbcfbf99428d40", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0e2b0951-c75a-42ca-a966-ccc897660854", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Help.tsx", "language": "typescript", "lines": 343, "filename": "Help.tsx"}, "hash": "ee27981c4c6b535f28fd8d3a50d6d4489a2efe49fc1a36fd573d2770cfb92bd2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9e9526c7-62fa-4ae4-9010-89d7fd66f205", "node_type": "1", "metadata": {}, "hash": "203da9b727dba5a15691183d2784bdc1eeb7f53fc882ae3e5df1e79a815c1873", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "'bg-primary text-white shadow-md' : 'hover:bg-muted text-muted-foreground'\n                }`}\n              >\n                <Database size={20} />\n                <span class=\"font-bold\">Schema de Dados</span>\n              </button>\n            </Show>\n          </div>\n        </div>\n\n        {/* Main Content Area */}\n        <div class=\"flex-1\">\n          {/* Tab: Guia R\u00e1pido */}\n          <Show when={activeTab() === 'guia'}>\n            <div class=\"space-y-8 animate-in fade-in duration-500\">\n              <div class=\"grid grid-cols-1 md:grid-cols-3 gap-4\">\n                <div class=\"card p-6 border bg-blue-50/50 dark:bg-blue-900/10\">\n                  <Sparkles size={24} class=\"text-blue-500 mb-4\" />\n                  <h4 class=\"font-bold mb-2\">IA Generativa</h4>\n                  <p class=\"text-xs text-muted-foreground leading-relaxed\">\n                    O Gemini analisa milh\u00f5es de linhas de estoque para encontrar oportunidades que o olho humano n\u00e3o veria de forma r\u00e1pida.\n                  </p>\n                </div>\n                <div class=\"card p-6 border bg-green-50/50 dark:bg-green-900/10\">\n                  <BarChart3 size={24} class=\"text-green-500 mb-4\" />\n                  <h4 class=\"font-bold mb-2\">Pareto ABC</h4>\n                  <p class=\"text-xs text-muted-foreground leading-relaxed\">\n                    Foque no que importa. 80% do seu faturamento vem de apenas 20% do seu mix. Nossa an\u00e1lise identifica esses itens Classe A.\n                  </p>\n                </div>\n                <div class=\"card p-6 border bg-amber-50/50 dark:bg-amber-900/10\">\n                  <Truck size={24} class=\"text-amber-500 mb-4\" />\n                  <h4 class=\"font-bold mb-2\">Log\u00edstica Reversa</h4>\n                  <p class=\"text-xs text-muted-foreground leading-relaxed\">\n                    Sugest\u00f5es autom\u00e1ticas de transfer\u00eancia entre CD e Lojas para evitar capital imobilizado e rupturas de venda.\n                  </p>\n                </div>\n              </div>\n\n              <div class=\"card p-8 border\">\n                <h3 class=\"text-xl font-bold mb-6 flex items-center gap-2\">\n                  <TrendingUp size={24} class=\"text-primary\" />\n                  Fluxo de Trabalho Recomendado\n                </h3>\n                <div class=\"space-y-6 relative before:absolute before:left-3 before:top-2 before:bottom-2 before:w-0.5 before:bg-muted\">\n                  <div class=\"relative pl-10\">\n                    <div class=\"absolute left-0 top-0 w-6 h-6 rounded-full bg-primary text-white flex items-center justify-center text-xs font-bold\">1</div>\n                    <h5 class=\"font-bold\">Analise o AI Insights</h5>\n                    <p class=\"text-sm text-muted-foreground\">No Dashboard, veja as sugest\u00f5es proativas da IA sobre riscos e oportunidades.</p>\n                  </div>\n                  <div class=\"relative pl-10\">\n                    <div class=\"absolute left-0 top-0 w-6 h-6 rounded-full bg-primary text-white flex items-center justify-center text-xs font-bold\">2</div>\n                    <h5 class=\"font-bold\">Monitore a Cobertura</h5>\n                    <p class=\"text-sm text-muted-foreground\">Mantenha seus produtos Classe A com cobertura entre 15 e 30 dias para otimizar o ROI.</p>\n                  </div>\n                  <div class=\"relative pl-10\">\n                    <div class=\"absolute left-0 top-0 w-6 h-6 rounded-full bg-primary text-white flex items-center justify-center text-xs font-bold\">3</div>\n                    <h5 class=\"font-bold\">Use o Chat para Aprofundar</h5>\n                    <p class=\"text-sm text-muted-foreground\">Pergunte: \"Por que o produto X est\u00e1 vendendo menos este m\u00eas?\"", "mimetype": "text/plain", "start_char_idx": 7440, "end_char_idx": 11129, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9e9526c7-62fa-4ae4-9010-89d7fd66f205": {"__data__": {"id_": "9e9526c7-62fa-4ae4-9010-89d7fd66f205", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Help.tsx", "language": "typescript", "lines": 343, "filename": "Help.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Help.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Help.tsx", "language": "typescript", "lines": 343, "filename": "Help.tsx"}, "hash": "69f36e5c5fb45b3dd92a6c39c2e10eb4fab88afd8fc93279f6cbcfbf99428d40", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3a6d0f2b-774a-4967-b8a1-9696b2347dcd", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Help.tsx", "language": "typescript", "lines": 343, "filename": "Help.tsx"}, "hash": "f6eb867c4c8f1d707940cd07215df43dfc19af896b37d9b5a986736bfe7b9175", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "60948662-4fd1-4dff-ac5f-3739a5c2e9f5", "node_type": "1", "metadata": {}, "hash": "ae4c9438c25ab0e5498a76fb04f119f05fa49dc6a4554a9046c94fb1e8479bc3", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "ou \"Compare o giro de Tecidos vs Armarinho\".</p>\n                  </div>\n                </div>\n              </div>\n            </div>\n          </Show>\n\n          {/* Tab: FAQ */}\n          <Show when={activeTab() === 'faq'}>\n            <div class=\"space-y-4 animate-in slide-in-from-right-4 duration-300\">\n              <div class=\"relative mb-6\">\n                <Search size={20} class=\"absolute left-4 top-1/2 -translate-y-1/2 text-muted\" />\n                <input\n                  type=\"text\"\n                  class=\"w-full pl-12 pr-4 py-4 bg-card border rounded-2xl focus:ring-2 focus:ring-primary outline-none shadow-sm\"\n                  placeholder=\"Busque por termos como: ABC, Ruptura, Gemini, Transfer\u00eancia...\"\n                  value={searchTerm()}\n                  onInput={(e) => setSearchTerm(e.currentTarget.value)}\n                />\n              </div>\n\n              <div class=\"space-y-3\">\n                <For each={filteredFAQ()}>\n                  {(item, index) => (\n                    <div class=\"card border rounded-2xl overflow-hidden hover:border-primary/50 transition-colors\">\n                      <button\n                        onClick={() => setExpandedFAQ(expandedFAQ() === index() ? null : index())}\n                        class=\"w-full p-5 text-left flex items-center justify-between\"\n                      >\n                        <span class=\"font-bold text-gray-800 dark:text-gray-200\">{item.pergunta}</span>\n                        <Show when={expandedFAQ() === index()} fallback={<ChevronDown size={20} />}>\n                          <ChevronUp size={20} class=\"text-primary\" />\n                        </Show>\n                      </button>\n                      <Show when={expandedFAQ() === index()}>\n                        <div class=\"px-5 pb-5 text-sm text-muted-foreground leading-relaxed animate-in fade-in slide-in-from-top-2\">\n                          <div class=\"h-px bg-muted mb-4\"></div>\n                          {item.resposta}\n                        </div>\n                      </Show>\n                    </div>\n                  )}\n                </For>\n              </div>\n            </div>\n          </Show>\n\n          {/* Tab: Troubleshooting */}\n          <Show when={activeTab() === 'troubleshooting' && isAdmin()}>\n            <div class=\"space-y-4 animate-in fade-in\">\n              <For each={TROUBLESHOOTING_ITEMS}>\n                {(item) => (\n                  <div class=\"card p-6 border-l-4 border-l-red-500\">\n                    <h4 class=\"font-bold text-lg mb-4 flex items-center gap-2\">\n                      <AlertCircle size={20} class=\"text-red-500\" />\n                      {item.problema}\n                    </h4>\n                    <ul class=\"space-y-2\">\n                      <For each={item.solucao}>\n                        {(sol) => (\n                          <li class=\"text-sm text-muted-foreground flex items-start gap-2\">\n                            <div class=\"w-1.5 h-1.5 rounded-full bg-red-400 mt-1.", "mimetype": "text/plain", "start_char_idx": 11130, "end_char_idx": 14144, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "60948662-4fd1-4dff-ac5f-3739a5c2e9f5": {"__data__": {"id_": "60948662-4fd1-4dff-ac5f-3739a5c2e9f5", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Help.tsx", "language": "typescript", "lines": 343, "filename": "Help.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Help.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Help.tsx", "language": "typescript", "lines": 343, "filename": "Help.tsx"}, "hash": "69f36e5c5fb45b3dd92a6c39c2e10eb4fab88afd8fc93279f6cbcfbf99428d40", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9e9526c7-62fa-4ae4-9010-89d7fd66f205", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Help.tsx", "language": "typescript", "lines": 343, "filename": "Help.tsx"}, "hash": "24901f82002e1f12132060d8040dfa1613567e9c3b62e69c580e66391361bd3a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "5 h-1.5 rounded-full bg-red-400 mt-1.5 flex-shrink-0\"></div>\n                            {sol}\n                          </li>\n                        )}\n                      </For>\n                    </ul>\n                  </div>\n                )}\n              </For>\n            </div>\n          </Show>\n\n          {/* Tab: Schema de Dados */}\n          <Show when={activeTab() === 'dados' && isAdmin()}>\n            <div class=\"card p-8 border space-y-6 animate-in zoom-in-95\">\n              <div class=\"flex items-center gap-3 border-b pb-4\">\n                <Database size={28} class=\"text-primary\" />\n                <h3 class=\"text-xl font-bold\">Dicion\u00e1rio de Dados do Neg\u00f3cio</h3>\n              </div>\n              \n              <div class=\"grid grid-cols-1 md:grid-cols-2 gap-8\">\n                <div>\n                  <h5 class=\"font-bold text-sm uppercase tracking-wider text-muted-foreground mb-4\">Identificadores e Categoriza\u00e7\u00e3o</h5>\n                  <div class=\"space-y-3\">\n                    <div class=\"flex justify-between text-sm border-b pb-1\">\n                      <code class=\"text-primary\">PRODUTO</code>\n                      <span class=\"text-muted-foreground\">C\u00f3digo SKU (ID \u00danico)</span>\n                    </div>\n                    <div class=\"flex justify-between text-sm border-b pb-1\">\n                      <code class=\"text-primary\">UNE</code>\n                      <span class=\"text-muted-foreground\">Unidade de Neg\u00f3cio (Loja)</span>\n                    </div>\n                    <div class=\"flex justify-between text-sm border-b pb-1\">\n                      <code class=\"text-primary\">NOMESEGMENTO</code>\n                      <span class=\"text-muted-foreground\">Segmento (Tecidos, Papelaria...)</span>\n                    </div>\n                  </div>\n                </div>\n\n                <div>\n                  <h5 class=\"font-bold text-sm uppercase tracking-wider text-muted-foreground mb-4\">M\u00e9tricas de Estoque e Venda</h5>\n                  <div class=\"space-y-3\">\n                    <div class=\"flex justify-between text-sm border-b pb-1\">\n                      <code class=\"text-primary\">VENDA_30DD</code>\n                      <span class=\"text-muted-foreground\">Volume vendido nos \u00faltimos 30 dias</span>\n                    </div>\n                    <div class=\"flex justify-between text-sm border-b pb-1\">\n                      <code class=\"text-primary\">MES_01</code>\n                      <span class=\"text-muted-foreground\">Faturamento do m\u00eas atual</span>\n                    </div>\n                    <div class=\"flex justify-between text-sm border-b pb-1\">\n                      <code class=\"text-primary\">ESTOQUE_UNE</code>\n                      <span class=\"text-muted-foreground\">Estoque dispon\u00edvel na Loja</span>\n                    </div>\n                    <div class=\"flex justify-between text-sm border-b pb-1\">\n                      <code class=\"text-primary\">ESTOQUE_CD</code>\n                      <span class=\"text-muted-foreground\">Estoque dispon\u00edvel no CD</span>\n                    </div>\n                  </div>\n                </div>\n              </div>\n\n              <div class=\"mt-8 p-4 bg-muted/30 rounded-xl text-xs text-muted-foreground\">\n                <p><strong>Nota:</strong> As m\u00e9tricas de Cobertura e Pareto ABC s\u00e3o calculadas dinamicamente pelo backend utilizando a biblioteca Polars para m\u00e1xima precis\u00e3o.</p>\n              </div>\n            </div>\n          </Show>\n        </div>\n      </div>\n    </div>\n  );\n}", "mimetype": "text/plain", "start_char_idx": 14107, "end_char_idx": 17626, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8e499860-c6dd-422e-a48b-a721f9c08e65": {"__data__": {"id_": "8e499860-c6dd-422e-a48b-a721f9c08e65", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Learning.tsx", "language": "typescript", "lines": 475, "filename": "Learning.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Learning.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Learning.tsx", "language": "typescript", "lines": 475, "filename": "Learning.tsx"}, "hash": "8e199b17f19041227ee67c283be5256d3f6992491e9b5af18aba223b05443ec1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d530ae07-b6a5-4662-a7dc-6838f9d2d7fc", "node_type": "1", "metadata": {}, "hash": "016a7b3a28136a09ac633aa7115667189d4ccaa7137e4390aa9eb104ae414eea", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import { createSignal, onMount, Show, For } from 'solid-js';\nimport { BrainCircuit, ThumbsUp, ThumbsDown, AlertTriangle, TrendingUp, Search, BarChart3 } from 'lucide-solid';\nimport api from '../lib/api';\nimport auth from '../store/auth';\n\n// Types\ninterface FeedbackStats {\n  total_feedback: number;\n  positive: number;\n  negative: number;\n  partial: number;\n  success_rate: number;\n  problematic_queries: Array<{\n    query: string;\n    feedback_type: string;\n    timestamp: string;\n  }>;\n}\n\ninterface ErrorAnalysis {\n  total_errors: number;\n  error_types: Record<string, number>;\n  error_details: Array<{\n    error_type: string;\n    count: number;\n    suggestion: string;\n  }>;\n}\n\ninterface Pattern {\n  id: number;\n  keywords: string[];\n  pattern: string;\n  examples: string[];\n  success_count: number;\n}\n\ninterface PatternsResponse {\n  total_patterns: number;\n  patterns: Pattern[];\n}\n\ntype TabType = 'feedback' | 'errors' | 'patterns';\n\nexport default function Learning() {\n  const [activeTab, setActiveTab] = createSignal<TabType>('feedback');\n  const [loading, setLoading] = createSignal(true);\n  const [error, setError] = createSignal<string | null>(null);\n\n  // Data states\n  const [feedbackStats, setFeedbackStats] = createSignal<FeedbackStats | null>(null);\n  const [errorAnalysis, setErrorAnalysis] = createSignal<ErrorAnalysis | null>(null);\n  const [patterns, setPatterns] = createSignal<PatternsResponse | null>(null);\n\n  // Search\n  const [searchTerm, setSearchTerm] = createSignal('');\n\n  const loadData = async () => {\n    setLoading(true);\n    setError(null);\n\n    try {\n      const [feedbackRes, errorsRes, patternsRes] = await Promise.all([\n        api.get<FeedbackStats>('/learning/feedback-stats'),\n        api.get<ErrorAnalysis>('/learning/error-analysis'),\n        api.get<PatternsResponse>('/learning/patterns')\n      ]);\n\n      setFeedbackStats(feedbackRes.data);\n      setErrorAnalysis(errorsRes.data);\n      setPatterns(patternsRes.data);\n    } catch (err: any) {\n      console.error('Erro ao carregar dados de aprendizado:', err);\n      setError(err.response?.data?.detail || 'Erro ao carregar dados');\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  const searchPatterns = async () => {\n    if (!searchTerm()) {\n      loadData();\n      return;\n    }\n\n    try {\n      const response = await api.get<PatternsResponse>(`/learning/patterns?search=${encodeURIComponent(searchTerm())}`);\n      setPatterns(response.data);\n    } catch (err: any) {\n      console.error('Erro ao buscar padr\u00f5es:', err);\n    }\n  };\n\n  onMount(() => {\n    loadData();\n  });\n\n  const getSuccessRateColor = (rate: number) => {\n    if (rate >= 80) return 'text-green-500';\n    if (rate >= 60) return 'text-yellow-500';\n    return 'text-red-500';\n  };\n\n  return (\n    <div class=\"flex flex-col h-full p-6 gap-6\">\n      {/* Header */}\n      <div>\n        <h2 class=\"text-2xl font-bold flex items-center gap-2\">\n          <BrainCircuit size={28} />\n          Sistema de Aprendizado\n        </h2>\n        <p class=\"text-muted\">An\u00e1lise de feedback, erros e padr\u00f5es de uso do assistente BI</p>\n      </div>\n\n      {/* Error State */}\n      <Show when={error()}>\n        <div class=\"card p-4 border-red-500 bg-red-500/10\">\n          <div class=\"flex items-center gap-2 text-red-500\">\n            <AlertTriangle size={20} />\n            <span>{error()}</span>\n          </div>\n        </div>\n      </Show>\n\n      {/* Tabs */}\n      <div class=\"border-b\">\n        <div class=\"flex gap-1\">\n          <button\n            class={`px-4 py-2 font-medium transition-colors ${\n              activeTab() === 'feedback'\n                ? 'border-b-2 border-primary text-primary'\n                : 'text-muted hover:text-foreground'\n            }`}\n            onClick={() => setActiveTab('feedback')}\n          >\n            <div class=\"flex items-center gap-2\">\n              <ThumbsUp size={16} />\n              Feedback\n            </div>\n          </button>\n\n          <button\n            class={`px-4 py-2 font-medium transition-colors ${\n              activeTab() === 'errors'\n                ?", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4087, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d530ae07-b6a5-4662-a7dc-6838f9d2d7fc": {"__data__": {"id_": "d530ae07-b6a5-4662-a7dc-6838f9d2d7fc", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Learning.tsx", "language": "typescript", "lines": 475, "filename": "Learning.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Learning.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Learning.tsx", "language": "typescript", "lines": 475, "filename": "Learning.tsx"}, "hash": "8e199b17f19041227ee67c283be5256d3f6992491e9b5af18aba223b05443ec1", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8e499860-c6dd-422e-a48b-a721f9c08e65", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Learning.tsx", "language": "typescript", "lines": 475, "filename": "Learning.tsx"}, "hash": "32afe6dfce018b2b8659d866039504a8755f051ce6c4109973693299ab4ca81a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "75298a21-66bb-44e6-a8bd-cd789118274f", "node_type": "1", "metadata": {}, "hash": "620306b478ab9066bbaa4d18145fb9b9d6cfd2524b14322f5bd493a1dfbeb64b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "'border-b-2 border-primary text-primary'\n                : 'text-muted hover:text-foreground'\n            }`}\n            onClick={() => setActiveTab('errors')}\n          >\n            <div class=\"flex items-center gap-2\">\n              <AlertTriangle size={16} />\n              Erros\n            </div>\n          </button>\n\n          <button\n            class={`px-4 py-2 font-medium transition-colors ${\n              activeTab() === 'patterns'\n                ? 'border-b-2 border-primary text-primary'\n                : 'text-muted hover:text-foreground'\n            }`}\n            onClick={() => setActiveTab('patterns')}\n          >\n            <div class=\"flex items-center gap-2\">\n              <TrendingUp size={16} />\n              Padr\u00f5es\n            </div>\n          </button>\n        </div>\n      </div>\n\n      {/* Loading State */}\n      <Show when={loading()}>\n        <div class=\"flex-1 flex items-center justify-center\">\n          <div class=\"text-center\">\n            <BrainCircuit size={48} class=\"mx-auto mb-4 opacity-50 animate-pulse\" />\n            <p class=\"text-muted\">Carregando dados...</p>\n          </div>\n        </div>\n      </Show>\n\n      {/* Content */}\n      <Show when={!loading()}>\n        {/* Tab: Feedback */}\n        <Show when={activeTab() === 'feedback'}>\n          <Show when={feedbackStats()}>\n            <div class=\"space-y-6\">\n              {/* KPIs */}\n              <div class=\"grid grid-cols-1 md:grid-cols-4 gap-4\">\n                <div class=\"card p-4 border\">\n                  <div class=\"text-sm text-muted mb-1\">Total de Feedback</div>\n                  <div class=\"text-2xl font-bold\">{feedbackStats()!.total_feedback}</div>\n                </div>\n\n                <div class=\"card p-4 border border-green-500/30 bg-green-500/5\">\n                  <div class=\"text-sm text-muted mb-1\">Positivos</div>\n                  <div class=\"text-2xl font-bold text-green-500\">\n                    {feedbackStats()!.positive}\n                  </div>\n                </div>\n\n                <div class=\"card p-4 border border-red-500/30 bg-red-500/5\">\n                  <div class=\"text-sm text-muted mb-1\">Negativos</div>\n                  <div class=\"text-2xl font-bold text-red-500\">\n                    {feedbackStats()!.negative}\n                  </div>\n                </div>\n\n                <div class=\"card p-4 border border-yellow-500/30 bg-yellow-500/5\">\n                  <div class=\"text-sm text-muted mb-1\">Parciais</div>\n                  <div class=\"text-2xl font-bold text-yellow-500\">\n                    {feedbackStats()!.partial}\n                  </div>\n                </div>\n              </div>\n\n              {/* Success Rate Gauge */}\n              <div class=\"card p-8 border bg-gradient-to-br from-card to-muted/20 relative overflow-hidden group\">\n                <div class=\"absolute -right-10 -top-10 opacity-5 group-hover:opacity-10 transition-opacity\">\n                  <BrainCircuit size={200} />\n                </div>\n                \n                <h3 class=\"font-bold text-lg mb-8 flex items-center gap-2\">\n                  <BarChart3 size={20} class=\"text-primary\" />\n                  Performance da Intelig\u00eancia\n                </h3>\n                \n                <div class=\"flex flex-col md:flex-row items-center justify-around gap-8\">\n                  {/* Circular Progress */}\n                  <div class=\"relative w-48 h-48\">\n                    <svg class=\"w-full h-full\" viewBox=\"0 0 36 36\">\n                      <path\n                        class=\"text-muted stroke-current\"\n                        stroke-width=\"3\"\n                        fill=\"none\"\n                        d=\"M18 2.0845 a 15.9155 15.9155 0 0 1 0 31.831 a 15.9155 15.9155 0 0 1 0 -31.831\"\n                      />\n                      <path\n                        class={`${getSuccessRateColor(feedbackStats()!.success_rate)} stroke-current transition-all duration-1000 ease-out`}\n                        stroke-width=\"3\"\n                        stroke-dasharray={`${feedbackStats()!.success_rate}, 100`}\n                        stroke-linecap=\"round\"\n                        fill=\"none\"\n                        d=\"M18 2.0845 a 15.9155 15.9155 0 0 1 0 31.831 a 15.9155 15.9155 0 0 1 0 -31.", "mimetype": "text/plain", "start_char_idx": 4088, "end_char_idx": 8353, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "75298a21-66bb-44e6-a8bd-cd789118274f": {"__data__": {"id_": "75298a21-66bb-44e6-a8bd-cd789118274f", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Learning.tsx", "language": "typescript", "lines": 475, "filename": "Learning.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Learning.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Learning.tsx", "language": "typescript", "lines": 475, "filename": "Learning.tsx"}, "hash": "8e199b17f19041227ee67c283be5256d3f6992491e9b5af18aba223b05443ec1", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d530ae07-b6a5-4662-a7dc-6838f9d2d7fc", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Learning.tsx", "language": "typescript", "lines": 475, "filename": "Learning.tsx"}, "hash": "8e90ad76d2d4c00db74161fb63396bcf56aec0c6d4456452409825c027484e87", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "975cfaa4-a5da-4d7f-baf7-3ac75c600398", "node_type": "1", "metadata": {}, "hash": "37511206974c1791fd0b2de3f2c205122ffccd49e711b30310bc7d7841a07b96", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "9155 15.9155 0 0 1 0 -31.831\"\n                      />\n                    </svg>\n                    <div class=\"absolute inset-0 flex flex-col items-center justify-center\">\n                      <span class={`text-4xl font-black ${getSuccessRateColor(feedbackStats()!.success_rate)}`}>\n                        {feedbackStats()!.success_rate}%\n                      </span>\n                      <span class=\"text-[10px] uppercase font-bold text-muted-foreground tracking-widest\">Acur\u00e1cia</span>\n                    </div>\n                  </div>\n\n                  <div class=\"flex-1 space-y-4\">\n                    <div class=\"p-4 rounded-xl bg-background/50 border border-dashed\">\n                      <h4 class=\"text-sm font-bold mb-2 uppercase text-muted-foreground\">Estado do Aprendizado</h4>\n                      <p class=\"text-sm italic text-foreground\">\n                        {feedbackStats()!.success_rate >= 80 \n                          ? \"A IA est\u00e1 operando com alta precis\u00e3o t\u00e9cnica. Os padr\u00f5es identificados s\u00e3o robustos.\"\n                          : feedbackStats()!.success_rate >= 50\n                          ? \"O sistema est\u00e1 em fase de refinamento. Continue fornecendo feedback para melhorar a acur\u00e1cia.\"\n                          : \"A IA requer ajustes nos prompts base. Grande volume de feedbacks negativos detectados.\"}\n                      </p>\n                    </div>\n                    \n                    <Show when={auth.user()?.role === 'admin'}>\n                      <button \n                        class=\"w-full py-2 px-4 rounded-lg bg-red-500/10 text-red-500 border border-red-500/20 hover:bg-red-500 hover:text-white transition-all text-xs font-bold\"\n                        onClick={() => {\n                          if(confirm(\"Deseja realmente limpar todo o hist\u00f3rico de aprendizado? Esta a\u00e7\u00e3o \u00e9 irrevers\u00edvel.\")) {\n                            alert(\"Comando de reset enviado com sucesso.\");\n                          }\n                        }}\n                      >\n                        RESETAR DADOS DE APRENDIZADO\n                      </button>\n                    </Show>\n                  </div>\n                </div>\n              </div>\n\n              {/* Problematic Queries */}\n              <Show when={feedbackStats()!.problematic_queries.length > 0}>\n                <div class=\"card border\">\n                  <div class=\"p-4 border-b\">\n                    <h3 class=\"font-semibold\">Queries Problem\u00e1ticas (Top 10)</h3>\n                    <p class=\"text-sm text-muted\">Queries que receberam feedback negativo</p>\n                  </div>\n                  <div class=\"overflow-x-auto\">\n                    <table class=\"w-full\">\n                      <thead class=\"bg-muted/50\">\n                        <tr class=\"text-left text-xs font-medium text-muted uppercase\">\n                          <th class=\"p-3\">Query</th>\n                          <th class=\"p-3\">Tipo</th>\n                          <th class=\"p-3\">Timestamp</th>\n                        </tr>\n                      </thead>\n                      <tbody class=\"divide-y\">\n                        <For each={feedbackStats()!.problematic_queries}>\n                          {(query) => (\n                            <tr class=\"hover:bg-muted/30\">\n                              <td class=\"p-3 text-sm\">{query.query}</td>\n                              <td class=\"p-3\">\n                                <span class=\"px-2 py-1 bg-red-500/10 text-red-500 text-xs rounded\">\n                                  {query.feedback_type}\n                                </span>\n                              </td>\n                              <td class=\"p-3 text-sm text-muted font-mono\">{query.timestamp}</td>\n                            </tr>\n                          )}\n                        </For>\n                      </tbody>\n                    </table>\n                  </div>\n                </div>\n              </Show>\n            </div>\n          </Show>\n        </Show>\n\n        {/* Tab: Errors */}\n        <Show when={activeTab() === 'errors'}>\n          <Show when={errorAnalysis()}>\n            <div class=\"space-y-6\">\n              {/* Total Errors */}\n              <div class=\"card p-6 border\">\n                <div class=\"text-sm text-muted mb-1\">Total de Erros</div>\n                <div class=\"text-4xl font-bold text-red-500\">\n                  {errorAnalysis()!.total_errors}\n                </div>\n              </div>\n\n              {/* Error Types Bar Chart */}\n              <div class=\"card p-6 border\">\n                <h3 class=\"font-semibold mb-4 flex items-center gap-2\">\n                  <BarChart3 size={20} />\n                  Tipos de Erro\n                </h3>\n                <div class=\"space-y-3\">\n                  <For each={Object.entries(errorAnalysis()!.error_types)}>\n                    {([type,", "mimetype": "text/plain", "start_char_idx": 8328, "end_char_idx": 13199, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "975cfaa4-a5da-4d7f-baf7-3ac75c600398": {"__data__": {"id_": "975cfaa4-a5da-4d7f-baf7-3ac75c600398", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Learning.tsx", "language": "typescript", "lines": 475, "filename": "Learning.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Learning.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Learning.tsx", "language": "typescript", "lines": 475, "filename": "Learning.tsx"}, "hash": "8e199b17f19041227ee67c283be5256d3f6992491e9b5af18aba223b05443ec1", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "75298a21-66bb-44e6-a8bd-cd789118274f", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Learning.tsx", "language": "typescript", "lines": 475, "filename": "Learning.tsx"}, "hash": "9fc60e349e079b8d14129e5c4b044c55972468942fbb0588875fd05716f1c5f8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "932bc291-0018-4ffa-a2c0-da21eb1b5dd7", "node_type": "1", "metadata": {}, "hash": "e65eac7b0c71da6ab9d048830bd37ab0522245393c5b714fa9c06684eb1bf11a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "entries(errorAnalysis()!.error_types)}>\n                    {([type, count]) => {\n                      const total = errorAnalysis()!.total_errors;\n                      const percentage = (count / total) * 100;\n                      return (\n                        <div>\n                          <div class=\"flex justify-between text-sm mb-1\">\n                            <span class=\"font-medium\">{type}</span>\n                            <span class=\"text-muted\">{count} ({percentage.toFixed(1)}%)</span>\n                          </div>\n                          <div class=\"h-2 bg-muted rounded-full overflow-hidden\">\n                            <div\n                              class=\"h-full bg-red-500\"\n                              style={{ width: `${percentage}%` }}\n                            />\n                          </div>\n                        </div>\n                      );\n                    }}\n                  </For>\n                </div>\n              </div>\n\n              {/* Error Details & Suggestions */}\n              <div class=\"card border\">\n                <div class=\"p-4 border-b\">\n                  <h3 class=\"font-semibold\">Detalhes e Sugest\u00f5es</h3>\n                </div>\n                <div class=\"divide-y\">\n                  <For each={errorAnalysis()!.error_details}>\n                    {(detail) => (\n                      <div class=\"p-4\">\n                        <div class=\"flex items-start gap-3\">\n                          <div class=\"p-2 bg-red-500/10 rounded\">\n                            <AlertTriangle size={20} class=\"text-red-500\" />\n                          </div>\n                          <div class=\"flex-1\">\n                            <div class=\"font-medium mb-1\">{detail.error_type}</div>\n                            <div class=\"text-sm text-muted mb-2\">{detail.count} ocorr\u00eancias</div>\n                            <div class=\"text-sm bg-blue-500/10 text-blue-400 p-2 rounded\">\n                              \ud83d\udca1 {detail.suggestion}\n                            </div>\n                          </div>\n                        </div>\n                      </div>\n                    )}\n                  </For>\n                </div>\n              </div>\n            </div>\n          </Show>\n        </Show>\n\n        {/* Tab: Patterns */}\n        <Show when={activeTab() === 'patterns'}>\n          <Show when={patterns()}>\n            <div class=\"space-y-6\">\n              {/* Search */}\n              <div class=\"flex gap-2\">\n                <div class=\"flex-1 relative\">\n                  <Search size={20} class=\"absolute left-3 top-1/2 -translate-y-1/2 text-muted\" />\n                  <input\n                    type=\"text\"\n                    class=\"input pl-10 w-full\"\n                    placeholder=\"Buscar padr\u00f5es por palavra-chave...\"\n                    value={searchTerm()}\n                    onInput={(e) => setSearchTerm(e.currentTarget.value)}\n                    onKeyPress={(e) => e.key === 'Enter' && searchPatterns()}\n                  />\n                </div>\n                <button class=\"btn btn-primary\" onClick={searchPatterns}>\n                  Buscar\n                </button>\n              </div>\n\n              {/* Total Patterns */}\n              <div class=\"card p-4 border\">\n                <div class=\"text-sm text-muted mb-1\">Padr\u00f5es Identificados</div>\n                <div class=\"text-2xl font-bold\">{patterns()!.total_patterns}</div>\n              </div>\n\n              {/* Patterns List */}\n              <div class=\"grid grid-cols-1 md:grid-cols-2 gap-4\">\n                <For each={patterns()!.patterns}>\n                  {(pattern) => (\n                    <div class=\"card p-4 border hover:border-primary/50 transition-colors\">\n                      <div class=\"flex items-start justify-between mb-3\">\n                        <h4 class=\"font-semibold\">{pattern.pattern}</h4>\n                        <span class=\"px-2 py-1 bg-primary/10 text-primary text-xs rounded\">\n                          {pattern.success_count} sucessos\n                        </span>\n                      </div>\n\n                      <div class=\"mb-3\">\n                        <div class=\"text-xs text-muted mb-1\">Palavras-chave:</div>\n                        <div class=\"flex flex-wrap gap-1\">\n                          <For each={pattern.keywords}>\n                            {(keyword) => (\n                              <span class=\"px-2 py-0.5 bg-secondary text-xs rounded\">\n                                {keyword}\n                              </span>\n                            )}\n                          </For>\n                        </div>\n                      </div>\n\n                      <div>\n                        <div class=\"text-xs text-muted mb-1\">Exemplos:</div>\n                        <ul class=\"text-sm space-y-1\">\n                          <For each={pattern.", "mimetype": "text/plain", "start_char_idx": 13131, "end_char_idx": 18015, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "932bc291-0018-4ffa-a2c0-da21eb1b5dd7": {"__data__": {"id_": "932bc291-0018-4ffa-a2c0-da21eb1b5dd7", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Learning.tsx", "language": "typescript", "lines": 475, "filename": "Learning.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Learning.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Learning.tsx", "language": "typescript", "lines": 475, "filename": "Learning.tsx"}, "hash": "8e199b17f19041227ee67c283be5256d3f6992491e9b5af18aba223b05443ec1", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "975cfaa4-a5da-4d7f-baf7-3ac75c600398", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Learning.tsx", "language": "typescript", "lines": 475, "filename": "Learning.tsx"}, "hash": "ef5f5d32e0d50a0df85ee92da3cd124ab2c79ee1407eeb936d85e7c84980c0c2", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "examples}>\n                            {(example) => (\n                              <li class=\"text-muted italic\">\u2022 {example}</li>\n                            )}\n                          </For>\n                        </ul>\n                      </div>\n                    </div>\n                  )}\n                </For>\n              </div>\n\n              <Show when={patterns()!.patterns.length === 0}>\n                <div class=\"card p-12 text-center border-dashed\">\n                  <Search size={48} class=\"mx-auto mb-4 opacity-20\" />\n                  <p class=\"text-muted\">Nenhum padr\u00e3o encontrado</p>\n                </div>\n              </Show>\n            </div>\n          </Show>\n        </Show>\n      </Show>\n    </div>\n  );\n}", "mimetype": "text/plain", "start_char_idx": 18015, "end_char_idx": 18760, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "6a9c5f82-1121-4cf7-8b4a-ca58bbe2658c": {"__data__": {"id_": "6a9c5f82-1121-4cf7-8b4a-ca58bbe2658c", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Login.tsx", "language": "typescript", "lines": 146, "filename": "Login.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Login.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Login.tsx", "language": "typescript", "lines": 146, "filename": "Login.tsx"}, "hash": "eaf08b903345ec6f0d748688f018abb9f5976fd77b2e8b81f03709037f7df50d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d2d4e083-23e1-4f05-b69f-87d83997d051", "node_type": "1", "metadata": {}, "hash": "169467ade30b0b9d05959e838732f6f5fc6e19bf60828ff7d89bfbf3d028ef08", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import { createSignal, Show, createEffect } from 'solid-js';\nimport { useNavigate } from '@solidjs/router';\nimport auth from '@/store/auth';\nimport { LogIn, Loader2 } from 'lucide-solid';\nimport { Logo } from '@/components/Logo';\n\nexport default function Login() {\n  console.log('\ud83d\udd35 Login component mounting...');\n  const [username, setUsername] = createSignal('');\n  const [password, setPassword] = createSignal('');\n  const navigate = useNavigate();\n  \n  // Log when rendering\n  createEffect(() => {\n    console.log('\ud83d\udd35 Login component rendered. Auth loading:', auth.loading());\n  });\n\n  const handleSubmit = async (e: Event) => {\n    e.preventDefault();\n    console.log('\ud83d\udd10 Login attempt:', { username: username(), passwordLength: password().length });\n    \n    if (!username() || !password()) {\n      console.error('\u274c Username or password empty');\n      return;\n    }\n    \n    try {\n      console.log('\ud83d\udce1 Calling auth.login...');\n      const success = await auth.login(username(), password());\n      console.log('\u2705 Login result:', success);\n      \n      if (success) {\n        console.log('\ud83c\udf89 Login successful! Navigating to dashboard...');\n        // Usar window.location.href para for\u00e7ar reload completo e garantir que o estado seja propagado\n        window.location.href = '/dashboard';\n      } else {\n        console.error('\u274c Login failed');\n      }\n    } catch (error) {\n      console.error('\ud83d\udca5 Login error:', error);\n    }\n  };\n\n  return (\n    <div class=\"min-h-screen flex items-center justify-center bg-gradient-to-br from-amber-50 via-orange-50 to-stone-100 p-4\">\n      {/* Background Effects - Lojas Ca\u00e7ula (warm tones) */}\n      <div class=\"absolute inset-0 overflow-hidden pointer-events-none\">\n        <div class=\"absolute top-1/4 left-1/4 w-96 h-96 bg-primary/5 rounded-full blur-3xl animate-pulse\"></div>\n        <div class=\"absolute bottom-1/4 right-1/4 w-96 h-96 bg-accent/5 rounded-full blur-3xl animate-pulse\" style=\"animation-delay: 1s\"></div>\n      </div>\n\n      {/* Login Card - Lojas Ca\u00e7ula */}\n      <div class=\"relative w-full max-w-md\">\n        <div class=\"bg-white/95 backdrop-blur-xl border-2 border-primary/20 rounded-2xl shadow-2xl p-8 space-y-6\">\n          {/* Header */}\n          <div class=\"text-center space-y-4\">\n            <div class=\"flex justify-center mb-4\">\n              <Logo size=\"xl\" className=\"filter drop-shadow-lg\" />\n            </div>\n            <div class=\"space-y-2\">\n              <h1 class=\"text-3xl font-bold text-primary\">\n                CA\u00c7ULINHA BI\n              </h1>\n              <p class=\"text-sm text-muted-foreground\">\n                Entre para acessar seus dados anal\u00edticos\n              </p>\n            </div>\n          </div>\n\n          {/* Error Message */}\n          <Show when={auth.error()}>\n            <div class=\"bg-red-500/10 border border-red-500/30 rounded-lg p-4 flex items-start gap-3\">\n              <svg class=\"w-5 h-5 text-red-400 flex-shrink-0 mt-0.5\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                <path stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" d=\"M12 8v4m0 4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z\" />\n              </svg>\n              <div class=\"flex-1\">\n                <p class=\"text-sm text-red-200 font-medium\">Erro de Autentica\u00e7\u00e3o</p>\n                <p class=\"text-xs text-red-300/80 mt-1\">{auth.error()}</p>\n              </div>\n            </div>\n          </Show>\n\n          {/* Form */}\n          <form onSubmit={handleSubmit} class=\"space-y-4\">\n            {/* Username Field */}\n            <div class=\"space-y-2\">\n              <label for=\"username\" class=\"block text-sm font-medium text-foreground\">\n                Usu\u00e1rio\n              </label>\n              <input\n                id=\"username\"\n                type=\"text\"\n                value={username()}\n                onInput={(e) => setUsername(e.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3858, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d2d4e083-23e1-4f05-b69f-87d83997d051": {"__data__": {"id_": "d2d4e083-23e1-4f05-b69f-87d83997d051", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Login.tsx", "language": "typescript", "lines": 146, "filename": "Login.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Login.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Login.tsx", "language": "typescript", "lines": 146, "filename": "Login.tsx"}, "hash": "eaf08b903345ec6f0d748688f018abb9f5976fd77b2e8b81f03709037f7df50d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6a9c5f82-1121-4cf7-8b4a-ca58bbe2658c", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Login.tsx", "language": "typescript", "lines": 146, "filename": "Login.tsx"}, "hash": "7ea0b0e2f9ae6a27aaa5b71c230a6be071d64517d446f88fa12dcec8047290c4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "currentTarget.value)}\n                placeholder=\"Digite seu usu\u00e1rio\"\n                required\n                autocomplete=\"username\"\n                class=\"w-full px-4 py-3 bg-white border-2 border-border rounded-lg text-foreground placeholder-muted-foreground focus:outline-none focus:ring-2 focus:ring-primary/30 focus:border-primary transition-all\"\n              />\n            </div>\n\n            {/* Password Field */}\n            <div class=\"space-y-2\">\n              <label for=\"password\" class=\"block text-sm font-medium text-foreground\">\n                Senha\n              </label>\n              <input\n                id=\"password\"\n                type=\"password\"\n                value={password()}\n                onInput={(e) => setPassword(e.currentTarget.value)}\n                placeholder=\"Digite sua senha\"\n                required\n                autocomplete=\"current-password\"\n                class=\"w-full px-4 py-3 bg-white border-2 border-border rounded-lg text-foreground placeholder-muted-foreground focus:outline-none focus:ring-2 focus:ring-primary/30 focus:border-primary transition-all\"\n              />\n            </div>\n\n            {/* Submit Button - Lojas Ca\u00e7ula */}\n            <button\n              type=\"submit\"\n              disabled={auth.loading()}\n              class=\"w-full py-3 px-4 bg-gradient-to-r from-primary to-accent hover:from-primary/90 hover:to-accent/90 text-white font-semibold rounded-lg shadow-lg shadow-primary/20 transition-all duration-200 disabled:opacity-50 disabled:cursor-not-allowed flex items-center justify-center gap-2\"\n            >\n              <Show when={auth.loading()} fallback={<>Entrar</>}>\n                <Loader2 size={20} class=\"animate-spin\" />\n                <span>Entrando...</span>\n              </Show>\n            </button>\n          </form>\n        </div>\n\n        {/* Version Info - Lojas Ca\u00e7ula */}\n        <div class=\"text-center mt-6 space-y-2\">\n          <div class=\"flex justify-center\">\n            <Logo size=\"sm\" className=\"opacity-60\" />\n          </div>\n          <div class=\"text-xs text-muted-foreground\">\n            Ca\u00e7ulinha BI v1.0.0 \u2022 Powered by SolidJS\n          </div>\n        </div>\n      </div>\n    </div>\n  );\n}", "mimetype": "text/plain", "start_char_idx": 3858, "end_char_idx": 6086, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "017d1aa9-0444-4c15-93fa-d0571a78809f": {"__data__": {"id_": "017d1aa9-0444-4c15-93fa-d0571a78809f", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Playground.tsx", "language": "typescript", "lines": 491, "filename": "Playground.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Playground.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Playground.tsx", "language": "typescript", "lines": 491, "filename": "Playground.tsx"}, "hash": "468248c8d9bd9bd03d5b0c543d3fb649874259f6efcd70d50c39fb98c64aab32", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4e6bc397-75da-47b3-b250-ebe9895b1282", "node_type": "1", "metadata": {}, "hash": "990e94e03b94af0b6dc86e56b0ce76a5eef4bfe28f1b021ce59b8fc141694877", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import { createSignal, For, Show, onMount, createEffect } from 'solid-js';\nimport { Terminal, Send, Trash2, Settings, Zap, Activity, Clock, Cpu, Info, Code, FileJson, Save, Play, X, ChevronDown, ChevronRight, Pencil } from 'lucide-solid';\nimport api from '../lib/api';\nimport { MessageActions } from '../components/MessageActions';\nimport 'github-markdown-css/github-markdown.css';\nimport './chat-markdown.css';\n\ninterface Message {\n  id: string; \n  role: 'user' | 'assistant';\n  content: string;\n  timestamp: string;\n}\n\ninterface ModelInfo {\n  model: string;\n  temperature: number;\n  max_tokens: number;\n  json_mode: boolean;\n  default_temperature?: number;\n  default_max_tokens?: number;\n  max_temperature_limit?: number;\n  max_tokens_limit?: number;\n}\n\ninterface CacheStats {\n  hits: number;\n  misses: number;\n  hit_rate: number;\n  enabled: boolean;\n}\n\ninterface ChatResponse {\n  response: string;\n  model_info: ModelInfo;\n  metadata: {\n    response_time: number;\n    timestamp: string;\n    user: string;\n  };\n  cache_stats: CacheStats;\n}\n\nexport default function Playground() {\n  const [messages, setMessages] = createSignal<Message[]>([]);\n  const [input, setInput] = createSignal('');\n  const [systemInstruction, setSystemInstruction] = createSignal('');\n  const [loading, setLoading] = createSignal(false);\n  let messagesEndRef: HTMLDivElement | undefined;\n  const [showCodeModal, setShowCodeModal] = createSignal(false);\n  const [systemExpanded, setSystemExpanded] = createSignal(false);\n\n  // Controls\n  const [temperature, setTemperature] = createSignal(1.0);\n  const [maxTokens, setMaxTokens] = createSignal(2048);\n  const [jsonMode, setJsonMode] = createSignal(false);\n  const [streamMode, setStreamMode] = createSignal(false);\n\n  // Stats & Info\n  const [modelInfo, setModelInfo] = createSignal<ModelInfo | null>(null);\n  const [cacheStats, setCacheStats] = createSignal<CacheStats | null>(null);\n  const [responseTime, setResponseTime] = createSignal(0);\n\n  // Editing state\n  const [editingMessageId, setEditingMessageId] = createSignal<string | null>(null);\n  const [editText, setEditText] = createSignal('');\n\n  // Examples\n  const examples = [\n    {\n      title: \"An\u00e1lise Financeira\",\n      system: \"Voc\u00ea \u00e9 um analista financeiro s\u00eanior. Responda de forma concisa e use tabelas markdown quando apropriado.\",\n      prompt: \"Analise o ROI de uma campanha de marketing que custou R$ 50.000 e gerou R$ 120.000 em vendas.\"\n    },\n    {\n      title: \"SQL Expert\",\n      system: \"Voc\u00ea \u00e9 um DBA especialista em SQL Server. Forne\u00e7a apenas o c\u00f3digo SQL otimizado sem explica\u00e7\u00f5es verbosas.\",\n      prompt: \"Escreva uma query para encontrar produtos que n\u00e3o venderam nos \u00faltimos 6 meses.\"\n    },\n    {\n      title: \"Python Data\",\n      system: \"Voc\u00ea \u00e9 um engenheiro de dados Python. Prefira a biblioteca Polars sobre Pandas.\",\n      prompt: \"Crie um script para ler um arquivo Parquet e filtrar linhas onde 'status' \u00e9 'error'.\"\n    }\n  ];\n\n  onMount(async () => {\n    try {\n      const response = await api.get('/playground/info');\n      \n      // Update ModelInfo with all details from the backend\n      setModelInfo(response.data);\n\n      // Set initial maxTokens and temperature from backend defaults\n      if (response.data.default_max_tokens) {\n        setMaxTokens(response.data.default_max_tokens);\n      }\n      if (response.data.default_temperature) {\n        setTemperature(response.data.default_temperature);\n      }\n\n    } catch (error) {\n      console.error('Erro ao carregar info do modelo:', error);\n    }\n  });\n\n  createEffect(() => {\n    if (messages()) {\n       setTimeout(() => messagesEndRef.scrollIntoView({ behavior: 'smooth' }), 100);\n    }\n  });\n\n  const sendMessage = async (e?", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3708, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4e6bc397-75da-47b3-b250-ebe9895b1282": {"__data__": {"id_": "4e6bc397-75da-47b3-b250-ebe9895b1282", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Playground.tsx", "language": "typescript", "lines": 491, "filename": "Playground.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Playground.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Playground.tsx", "language": "typescript", "lines": 491, "filename": "Playground.tsx"}, "hash": "468248c8d9bd9bd03d5b0c543d3fb649874259f6efcd70d50c39fb98c64aab32", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "017d1aa9-0444-4c15-93fa-d0571a78809f", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Playground.tsx", "language": "typescript", "lines": 491, "filename": "Playground.tsx"}, "hash": "538b3d02c58efb86b6ba6527f2aeeaf390ec4e0020817abfedc9df687b75144f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6b1a7653-0aec-4a6c-8db1-b6511b5029fc", "node_type": "1", "metadata": {}, "hash": "2c7c0f6767e1d17ee330d2be7a999433d5b08620852082d264b659882058c35f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": ": Event) => {\n    e?.preventDefault();\n    if (!input().trim() || loading()) return;\n\n    const userMessage: Message = {\n      id: Date.now().toString(),\n      role: 'user',\n      content: input(),\n      timestamp: new Date().toISOString()\n    };\n\n    setMessages([...messages(), userMessage]);\n    setInput('');\n    setLoading(true);\n\n    await executeRequest([...messages(), userMessage]);\n  };\n\n  const executeRequest = async (currentHistory: Message[]) => {\n    try {\n      const response = await api.post<ChatResponse>('/playground/chat', {\n        message: currentHistory[currentHistory.length - 1].content,\n        system_instruction: systemInstruction(),\n        history: currentHistory.slice(0, -1).map(m => ({\n          role: m.role,\n          content: m.content,\n          timestamp: m.timestamp\n        })),\n        temperature: temperature(),\n        max_tokens: maxTokens(),\n        json_mode: jsonMode(),\n        stream: streamMode()\n      });\n\n      const assistantMessage: Message = {\n        id: (Date.now() + 1).toString(),\n        role: 'assistant',\n        content: response.data.response,\n        timestamp: response.data.metadata.timestamp\n      };\n\n      setMessages([...currentHistory, assistantMessage]);\n      setModelInfo(response.data.model_info);\n      setCacheStats(response.data.cache_stats);\n      setResponseTime(response.data.metadata.response_time);\n\n    } catch (error: any) {\n      const errorMessage: Message = {\n        id: Date.now().toString(),\n        role: 'assistant',\n        content: `\u274c **Erro na execu\u00e7\u00e3o**: ${error.response?.data?.detail || error.message}`,\n        timestamp: new Date().toISOString()\n      };\n      setMessages([...currentHistory, errorMessage]);\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  const clearHistory = () => {\n    if (confirm('Deseja limpar o hist\u00f3rico e come\u00e7ar do zero?')) {\n      setMessages([]);\n      setResponseTime(0);\n    }\n  };\n\n  const loadExample = (ex: any) => {\n    setSystemInstruction(ex.system);\n    setInput(ex.prompt);\n    setSystemExpanded(true);\n  };\n\n  const generateCodeSnippet = () => {\n    const pyCode = `\nimport requests\n\nurl = \"http://localhost:8000/api/v1/playground/chat\"\nheaders = {\"Authorization\": \"Bearer YOUR_TOKEN\"}\npayload = {\n    \"system_instruction\": \"${systemInstruction().replace(/\"/g, '\\\\\"')}\",\n    \"message\": \"${messages().length > 0 ? messages()[messages().length - 1].content.replace(/\"/g, '\\\\\"') : ''}\",\n    \"history\": ${JSON.stringify(messages().slice(0, -1).map(m => ({ role: m.role, content: m.content }))).replace(/\"/g, '\\\\\"')},\n    \"temperature\": ${temperature()},\n    \"max_tokens\": ${maxTokens()},\n    \"json_mode\": ${jsonMode()}\n}\n\nresponse = requests.post(url, json=payload, headers=headers)\nprint(response.json())\n    `.trim();\n    return pyCode;\n  };\n\n  return (\n    <div class=\"h-full flex flex-col bg-background max-w-[1800px] mx-auto relative\">\n      {/* 1. Context7: Executive Header with KPIs */}\n      <div class=\"border-b bg-card/50 backdrop-blur-sm p-4 flex flex-col md:flex-row items-start md:items-center justify-between gap-4 z-10\">\n        <div>\n          <h2 class=\"text-xl font-bold flex items-center gap-2 text-foreground\">\n            <Terminal class=\"text-primary\" /> \n            Playground <span class=\"text-muted font-normal text-sm border-l pl-2 ml-2\">Ambiente de Desenvolvimento</span>\n          </h2>\n        </div>\n\n        {/* Live Metrics Strip */}\n        <div class=\"flex gap-4\">\n           <div class=\"flex items-center gap-3 px-4 py-2 bg-secondary/50 rounded-lg border border-border/50\">\n              <Clock size={16} class=\"text-blue-500\" />\n              <div>\n                 <div class=\"text-[10px] text-muted uppercase tracking-wider font-semibold\">Lat\u00eancia</div>\n                 <div class=\"text-sm font-mono font-bold\">{responseTime() > 0 ?", "mimetype": "text/plain", "start_char_idx": 3708, "end_char_idx": 7529, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "6b1a7653-0aec-4a6c-8db1-b6511b5029fc": {"__data__": {"id_": "6b1a7653-0aec-4a6c-8db1-b6511b5029fc", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Playground.tsx", "language": "typescript", "lines": 491, "filename": "Playground.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Playground.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Playground.tsx", "language": "typescript", "lines": 491, "filename": "Playground.tsx"}, "hash": "468248c8d9bd9bd03d5b0c543d3fb649874259f6efcd70d50c39fb98c64aab32", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4e6bc397-75da-47b3-b250-ebe9895b1282", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Playground.tsx", "language": "typescript", "lines": 491, "filename": "Playground.tsx"}, "hash": "688f86e18a43dcba7513ec572e928f8f5ea2c826114fc6eb5321eb260668efc6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2ff36678-27aa-4e17-8c87-68dfb997fdba", "node_type": "1", "metadata": {}, "hash": "918b58fdc7ee706ab5f665a9caa1aeed299ed812151be08bc79f31aa84856b09", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "`${responseTime().toFixed(2)}s` : '--'}</div>\n              </div>\n           </div>\n           \n           <div class=\"flex items-center gap-3 px-4 py-2 bg-secondary/50 rounded-lg border border-border/50\">\n              <Cpu size={16} class=\"text-purple-500\" />\n              <div>\n                 <div class=\"text-[10px] text-muted uppercase tracking-wider font-semibold\">Modelo</div>\n                 <div class=\"text-sm font-mono font-bold\">{modelInfo()?.model || 'Gemini 3.0 Flash'}</div>\n              </div>\n           </div>\n\n           <button \n             onClick={() => setShowCodeModal(true)}\n             class=\"btn btn-outline gap-2\"\n             title=\"Ver C\u00f3digo\"\n           >\n              <Code size={16} /> <span class=\"hidden md:inline\">Ver C\u00f3digo</span>\n           </button>\n        </div>\n      </div>\n\n      <div class=\"flex-1 overflow-hidden grid grid-cols-1 lg:grid-cols-[1fr_350px]\">\n        {/* Main Workspace */}\n        <div class=\"flex flex-col min-h-0 bg-background/50 relative\">\n          \n          {/* System Instruction Panel - Context7: Define Persona First */}\n          <div class=\"border-b bg-card/20 transition-all duration-300\">\n             <button \n                onClick={() => setSystemExpanded(!systemExpanded())}\n                class=\"w-full flex items-center justify-between p-3 text-xs font-bold uppercase tracking-wider text-muted hover:bg-card/40\"\n             >\n                <div class=\"flex items-center gap-2\">\n                   <Settings size={14} /> Instru\u00e7\u00f5es do Sistema (Persona)\n                </div>\n                {systemExpanded() ? <ChevronDown size={14} /> : <ChevronRight size={14} />}\n             </button>\n             \n             <Show when={systemExpanded()}>\n                <div class=\"p-4 pt-0 animate-in slide-in-from-top-2\">\n                   <textarea \n                      class=\"input w-full min-h-[100px] font-mono text-sm bg-background\" \n                      placeholder=\"Ex: Voc\u00ea \u00e9 um assistente especialista em an\u00e1lise de dados. Responda sempre em JSON.\"\n                      value={systemInstruction()}\n                      onInput={(e) => setSystemInstruction(e.currentTarget.value)}\n                   />\n                </div>\n             </Show>\n          </div>\n\n          {/* Messages */}\n          <div class=\"flex-1 overflow-y-auto p-6 space-y-6 scroll-smooth\">\n            <Show when={messages().length === 0}>\n              <div class=\"h-full flex flex-col items-center justify-center text-muted gap-6 animate-in fade-in zoom-in duration-500\">\n                <div class=\"p-6 bg-secondary/30 rounded-full\">\n                   <FileJson size={64} class=\"opacity-20\" />\n                </div>\n                <div class=\"text-center max-w-md space-y-2\">\n                  <h3 class=\"text-xl font-bold text-foreground\">Playground de Desenvolvimento</h3>\n                  <p>Defina uma persona, configure os par\u00e2metros e teste prompts complexos antes de implementar.</p>\n                </div>\n                \n                <div class=\"grid grid-cols-1 md:grid-cols-3 gap-3 w-full max-w-4xl mt-4\">\n                   <For each={examples}>\n                      {(example) => (\n                         <button \n                            onClick={() => loadExample(example)}\n                            class=\"p-4 rounded-xl border border-border/50 hover:border-primary/50 hover:bg-secondary/50 transition-all text-left group\"\n                         >\n                            <div class=\"font-semibold text-sm group-hover:text-primary transition-colors mb-1 flex items-center gap-2\">\n                               <Play size={14} /> {example.title}\n                            </div>\n                            <div class=\"text-xs text-muted line-clamp-2\">{example.system}</div>\n                         </button>\n                      )}\n                   </For>\n                </div>\n              </div>\n            </Show>\n\n            <For each={messages()}>\n              {(message) => (\n                <div class={`flex ${message.role === 'user' ? 'justify-end' : 'justify-start'} animate-in fade-in slide-in-from-bottom-2 group`}>\n                  <div\n                    class={`max-w-[85%] rounded-2xl p-5 shadow-sm relative ${\n                      message.role === 'user'\n                        ?", "mimetype": "text/plain", "start_char_idx": 7530, "end_char_idx": 11864, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2ff36678-27aa-4e17-8c87-68dfb997fdba": {"__data__": {"id_": "2ff36678-27aa-4e17-8c87-68dfb997fdba", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Playground.tsx", "language": "typescript", "lines": 491, "filename": "Playground.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Playground.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Playground.tsx", "language": "typescript", "lines": 491, "filename": "Playground.tsx"}, "hash": "468248c8d9bd9bd03d5b0c543d3fb649874259f6efcd70d50c39fb98c64aab32", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6b1a7653-0aec-4a6c-8db1-b6511b5029fc", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Playground.tsx", "language": "typescript", "lines": 491, "filename": "Playground.tsx"}, "hash": "eb2da4afc0e7aa908bd23c6daaecbf487714dee5a46bad316faf85f57d296e35", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "92db475e-6fce-4f7d-a4d0-28e89bc7ef7f", "node_type": "1", "metadata": {}, "hash": "d84f99bfa4c47dec027e76c0e7647d1cb34f6203c3f1febc3e59fe2e75a6b11d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "'bg-primary/10 border border-primary/20 text-foreground rounded-tr-none'\n                        : 'bg-card border text-card-foreground rounded-tl-none'\n                    }`}\n                  >\n                    <div class=\"flex items-center gap-2 mb-2 opacity-70 border-b border-border/10 pb-2\">\n                      <span class=\"text-xs font-bold uppercase tracking-wider\">\n                         {message.role === 'user' ? 'User' : 'Model'}\n                      </span>\n                      <span class=\"text-[10px] ml-auto\">\n                        {new Date(message.timestamp).toLocaleTimeString()}\n                      </span>\n                    </div>\n                    \n                    <div class=\"markdown-body text-sm leading-relaxed\" style=\"background: transparent;\">\n                       <pre class=\"whitespace-pre-wrap font-sans bg-transparent border-0 p-0 m-0 text-current\">{message.content}</pre>\n                    </div>\n\n                    <Show when={message.role === 'assistant'}>\n                        <div class=\"mt-3 pt-2 border-t border-border/10\">\n                           <MessageActions messageText={message.content} messageId={message.id} />\n                        </div>\n                    </Show>\n                  </div>\n                </div>\n              )}\n            </For>\n            \n            <Show when={loading()}>\n               <div class=\"flex justify-start\">\n                  <div class=\"bg-card border rounded-2xl rounded-tl-none p-4 flex items-center gap-3\">\n                     <div class=\"flex space-x-1\">\n                        <div class=\"w-2 h-2 bg-primary/50 rounded-full animate-bounce [animation-delay:-0.3s]\"></div>\n                        <div class=\"w-2 h-2 bg-primary/50 rounded-full animate-bounce [animation-delay:-0.15s]\"></div>\n                        <div class=\"w-2 h-2 bg-primary/50 rounded-full animate-bounce\"></div>\n                     </div>\n                     <span class=\"text-xs text-muted font-medium\">Gerando resposta...</span>\n                  </div>\n               </div>\n            </Show>\n            <div ref={messagesEndRef} />\n          </div>\n\n          {/* Input Area */}\n          <div class=\"p-4 border-t bg-background/80 backdrop-blur-md\">\n            <form onSubmit={sendMessage} class=\"flex gap-3 max-w-4xl mx-auto\">\n              <button\n                type=\"button\"\n                onClick={clearHistory}\n                class=\"btn btn-ghost btn-icon text-muted hover:text-destructive\"\n                title=\"Limpar Hist\u00f3rico\"\n              >\n                <Trash2 size={20} />\n              </button>\n              \n              <div class=\"flex-1 relative\">\n                 <input\n                   type=\"text\"\n                   class=\"input w-full pr-12 shadow-sm font-mono text-sm\"\n                   placeholder=\"Digite sua mensagem...\"\n                   value={input()}\n                   onInput={(e) => setInput(e.currentTarget.value)}\n                   disabled={loading()}\n                 />\n              </div>\n\n              <button\n                type=\"submit\"\n                class=\"btn btn-primary shadow-md hover:shadow-lg transition-all\"\n                disabled={loading() || !input().trim()}\n              >\n                <Show when={!loading()} fallback={<Clock size={20} class=\"animate-spin\" />}>\n                   <Send size={20} />\n                </Show>\n              </button>\n            </form>\n          </div>\n        </div>\n\n        {/* Right Sidebar - Configuration */}\n        <div class=\"border-l bg-card/30 p-6 overflow-y-auto hidden lg:block\">\n           <div class=\"sticky top-0 space-y-8\">\n              {/* Settings Group */}\n              <div class=\"space-y-4\">\n                 <h3 class=\"font-bold flex items-center gap-2 text-foreground/80\">\n                    <Settings size={18} /> Par\u00e2metros\n                 </h3>\n                 \n                 <div class=\"space-y-4 p-4 bg-background border rounded-xl shadow-sm\">\n                    {/* Temperature */}\n                    <div class=\"space-y-3\">\n                       <div class=\"flex justify-between items-center\">\n                          <label class=\"text-sm font-medium\">Temperatura</label>\n                          <span class=\"text-xs font-mono bg-secondary px-2 py-1 rounded\">{temperature().toFixed(1)}</span>\n                       </div>\n                       <input\n                          type=\"range\" min=\"0\" max=\"2\" step=\"0.1\"\n                          value={temperature()}\n                          onInput={(e) => setTemperature(parseFloat(e.currentTarget.value))}\n                          class=\"w-full h-1.", "mimetype": "text/plain", "start_char_idx": 11865, "end_char_idx": 16549, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "92db475e-6fce-4f7d-a4d0-28e89bc7ef7f": {"__data__": {"id_": "92db475e-6fce-4f7d-a4d0-28e89bc7ef7f", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Playground.tsx", "language": "typescript", "lines": 491, "filename": "Playground.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Playground.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Playground.tsx", "language": "typescript", "lines": 491, "filename": "Playground.tsx"}, "hash": "468248c8d9bd9bd03d5b0c543d3fb649874259f6efcd70d50c39fb98c64aab32", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2ff36678-27aa-4e17-8c87-68dfb997fdba", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Playground.tsx", "language": "typescript", "lines": 491, "filename": "Playground.tsx"}, "hash": "330696e64ced25bdee98826c8d1ab06b49bc125b6f8323106b3e5ac716ba21eb", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "currentTarget.value))}\n                          class=\"w-full h-1.5 bg-secondary rounded-lg appearance-none cursor-pointer accent-primary\"\n                       />\n                    </div>\n\n                    <div class=\"h-px bg-border/50\"></div>\n\n                    {/* Max Tokens */}\n                    <div class=\"space-y-3\">\n                       <div class=\"flex justify-between items-center\">\n                          <label class=\"text-sm font-medium\">Max Tokens</label>\n                          <span class=\"text-xs font-mono bg-secondary px-2 py-1 rounded\">{maxTokens()}</span>\n                       </div>\n                       <input\n                          type=\"range\" min=\"100\" max={modelInfo()?.max_tokens_limit || 8192} step=\"100\"\n                          value={maxTokens()}\n                          onInput={(e) => setMaxTokens(parseInt(e.currentTarget.value))}\n                          class=\"w-full h-1.5 bg-secondary rounded-lg appearance-none cursor-pointer accent-primary\"\n                       />\n                    </div>\n                 </div>\n              </div>\n\n              {/* Modes Group */}\n              <div class=\"space-y-4\">\n                 <h3 class=\"font-bold flex items-center gap-2 text-foreground/80\">\n                    <Cpu size={18} /> Output\n                 </h3>\n                 \n                 <div class=\"space-y-3 p-4 bg-background border rounded-xl shadow-sm\">\n                    <div class=\"flex items-center justify-between group\">\n                       <div class=\"space-y-0.5\">\n                          <label class=\"text-sm font-medium\">JSON Mode</label>\n                          <p class=\"text-xs text-muted\">Estrutura r\u00edgida</p>\n                       </div>\n                       <input\n                          type=\"checkbox\"\n                          checked={jsonMode()}\n                          onChange={(e) => setJsonMode(e.currentTarget.checked)}\n                          class=\"toggle toggle-sm toggle-primary\"\n                       />\n                    </div>\n                 </div>\n              </div>\n\n              {/* Context7 Help Box */}\n              <div class=\"p-4 bg-yellow-500/5 border border-yellow-500/10 rounded-xl space-y-2\">\n                 <div class=\"flex items-center gap-2 text-yellow-600 font-bold text-sm\">\n                    <Info size={16} /> Best Practice\n                 </div>\n                 <p class=\"text-xs text-muted leading-relaxed\">\n                    Use <strong>System Instructions</strong> para definir o comportamento base antes de iniciar a conversa. Isso economiza tokens e melhora a consist\u00eancia.\n                 </p>\n              </div>\n\n           </div>\n        </div>\n      </div>\n\n      {/* Code Modal */}\n      <Show when={showCodeModal()}>\n        <div class=\"fixed inset-0 z-50 flex items-center justify-center bg-black/50 backdrop-blur-sm p-4\">\n           <div class=\"bg-card w-full max-w-2xl rounded-xl shadow-2xl border animate-in zoom-in-95\">\n              <div class=\"flex items-center justify-between p-4 border-b\">\n                 <h3 class=\"font-bold flex items-center gap-2\"><Code size={20} /> Snippet de Integra\u00e7\u00e3o</h3>\n                 <button onClick={() => setShowCodeModal(false)} class=\"btn btn-ghost btn-icon btn-sm\"><X size={18} /></button>\n              </div>\n              <div class=\"p-0 overflow-hidden\">\n                 <pre class=\"bg-secondary/50 p-4 text-xs font-mono overflow-x-auto text-foreground\">\n                    {generateCodeSnippet()}\n                 </pre>\n              </div>\n              <div class=\"p-4 border-t flex justify-end gap-2\">\n                 <button onClick={() => setShowCodeModal(false)} class=\"btn btn-outline\">Fechar</button>\n                 <button class=\"btn btn-primary\" onClick={() => {\n                    navigator.clipboard.writeText(generateCodeSnippet());\n                    setShowCodeModal(false);\n                 }}>Copiar C\u00f3digo</button>\n              </div>\n           </div>\n        </div>\n      </Show>\n    </div>\n  );\n}", "mimetype": "text/plain", "start_char_idx": 16482, "end_char_idx": 20548, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "83b83e6c-4904-4431-9d61-4022dfe672cf": {"__data__": {"id_": "83b83e6c-4904-4431-9d61-4022dfe672cf", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Profile.tsx", "language": "typescript", "lines": 252, "filename": "Profile.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Profile.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Profile.tsx", "language": "typescript", "lines": 252, "filename": "Profile.tsx"}, "hash": "ba2e215bfd07f43a5c1cf46b4e9d2180018d8959177ced458fe20497f251d984", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "782b1e84-8cc5-4e24-9875-2a923f116f6e", "node_type": "1", "metadata": {}, "hash": "ef4df2f8087170735b3a6a7dafbe2d153ee727e53d51ccffc31c4e7f83619482", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import { createSignal, createMemo, Show } from 'solid-js';\nimport { Lock, CheckCircle, AlertCircle, Shield, Info } from 'lucide-solid';\nimport auth from '@/store/auth';\nimport { UserPreferences } from '@/components/UserPreferences';\n\ninterface PasswordStrength {\n  score: number; // 0-4\n  label: string;\n  color: string;\n  barColor: string;\n}\n\nexport default function Profile() {\n  const [currentPass, setCurrentPass] = createSignal('');\n  const [newPass, setNewPass] = createSignal('');\n  const [confirmPass, setConfirmPass] = createSignal('');\n  const [message, setMessage] = createSignal<{ type: 'success' | 'error', text: string } | null>(null);\n\n  // Valida\u00e7\u00e3o de requisitos de senha\n  const passwordRequirements = createMemo(() => {\n    const pass = newPass();\n    return {\n      length: pass.length >= 8,\n      uppercase: /[A-Z]/.test(pass),\n      lowercase: /[a-z]/.test(pass),\n      number: /\\d/.test(pass),\n      special: /[!@#$%^&*(),.?\":{}|<>]/.test(pass),\n    };\n  });\n\n  // Calcular for\u00e7a da senha\n  const passwordStrength = createMemo((): PasswordStrength => {\n    const reqs = passwordRequirements();\n    const pass = newPass();\n\n    if (!pass) {\n      return { score: 0, label: 'Nenhuma', color: 'text-gray-500', barColor: 'bg-gray-500' };\n    }\n\n    const score = [reqs.length, reqs.uppercase, reqs.lowercase, reqs.number, reqs.special].filter(Boolean).length;\n\n    if (score === 5) {\n      return { score: 4, label: 'Muito Forte', color: 'text-green-500', barColor: 'bg-green-500' };\n    }\n    if (score === 4) {\n      return { score: 3, label: 'Forte', color: 'text-blue-500', barColor: 'bg-blue-500' };\n    }\n    if (score === 3) {\n      return { score: 2, label: 'M\u00e9dia', color: 'text-yellow-500', barColor: 'bg-yellow-500' };\n    }\n    if (score >= 1) {\n      return { score: 1, label: 'Fraca', color: 'text-orange-500', barColor: 'bg-orange-500' };\n    }\n\n    return { score: 0, label: 'Muito Fraca', color: 'text-red-500', barColor: 'bg-red-500' };\n  });\n\n  const isPasswordValid = createMemo(() => {\n    const reqs = passwordRequirements();\n    return reqs.length && reqs.uppercase && reqs.lowercase && reqs.number && reqs.special;\n  });\n\n  const handleChangePassword = async (e: Event) => {\n    e.preventDefault();\n\n    if (newPass() !== confirmPass()) {\n      setMessage({ type: 'error', text: 'As senhas n\u00e3o coincidem.' });\n      return;\n    }\n\n    if (!isPasswordValid()) {\n      setMessage({ type: 'error', text: 'A senha n\u00e3o atende aos requisitos m\u00ednimos de seguran\u00e7a.' });\n      return;\n    }\n\n    try {\n      const token = auth.token();\n      if (!token) {\n        setMessage({ type: 'error', text: 'Voc\u00ea precisa estar logado.' });\n        return;\n      }\n\n      const formData = new FormData();\n      formData.append('old_password', currentPass());\n      formData.append('new_password', newPass());\n      \n      const response = await fetch('/api/v1/auth/change-password', {\n        method: 'POST',\n        headers: { 'Authorization': `Bearer ${token}` },\n        body: formData\n      });\n      \n      if (!response.ok) {\n        const error = await response.json();\n        throw new Error(error.detail || 'Erro ao alterar senha');\n      }\n      \n      setMessage({ type: 'success', text: 'Senha alterada com sucesso!", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3253, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "782b1e84-8cc5-4e24-9875-2a923f116f6e": {"__data__": {"id_": "782b1e84-8cc5-4e24-9875-2a923f116f6e", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Profile.tsx", "language": "typescript", "lines": 252, "filename": "Profile.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Profile.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Profile.tsx", "language": "typescript", "lines": 252, "filename": "Profile.tsx"}, "hash": "ba2e215bfd07f43a5c1cf46b4e9d2180018d8959177ced458fe20497f251d984", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "83b83e6c-4904-4431-9d61-4022dfe672cf", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Profile.tsx", "language": "typescript", "lines": 252, "filename": "Profile.tsx"}, "hash": "ffc87b2f88e2e712d08080fdf767ab691946b9e0ce261e0b52ca5c51a0670c02", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "00bddec0-cf4a-4ab0-b213-1df3ffff553d", "node_type": "1", "metadata": {}, "hash": "081a211336ae7a6149ddae13843a87735ce39186c6093ab43175b573aef6781f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Voc\u00ea ser\u00e1 deslogado em 3 segundos...' });\n      setCurrentPass('');\n      setNewPass('');\n      setConfirmPass('');\n\n      // Logout autom\u00e1tico ap\u00f3s 3 segundos\n      setTimeout(() => {\n        auth.logout();\n        window.location.href = '/login';\n      }, 3000);\n    } catch (err: any) {\n      setMessage({ type: 'error', text: err.message || 'Erro ao alterar senha' });\n    }\n  };\n\n  return (\n    <div class=\"p-6 max-w-3xl mx-auto\">\n      <h2 class=\"text-2xl font-bold mb-6 flex items-center gap-2\">\n        <Lock /> Perfil e Seguran\u00e7a\n      </h2>\n\n      <div class=\"card border p-6 space-y-6\">\n        <div>\n          <h3 class=\"text-lg font-medium\">Dados do Usu\u00e1rio</h3>\n          <div class=\"mt-4 grid grid-cols-2 gap-4\">\n            <div>\n              <label class=\"text-xs text-muted\">Nome de Usu\u00e1rio</label>\n              <div class=\"font-medium\">{auth.user()?.username}</div>\n            </div>\n            <div>\n              <label class=\"text-xs text-muted\">Fun\u00e7\u00e3o (Role)</label>\n              <div class=\"font-medium capitalize\">{auth.user()?.role}</div>\n            </div>\n            <div class=\"col-span-2\">\n              <label class=\"text-xs text-muted\">Segmentos Permitidos</label>\n              <div class=\"font-mono text-xs bg-secondary p-2 rounded mt-1\">\n                {JSON.stringify(auth.user()?.allowed_segments || [], null, 2)}\n              </div>\n            </div>\n          </div>\n        </div>\n\n        <hr class=\"border-border\" />\n\n        <form onSubmit={handleChangePassword} class=\"space-y-4\">\n          <h3 class=\"text-lg font-medium\">Alterar Senha</h3>\n\n          {message() && (\n            <div class={`p-3 rounded text-sm flex items-center gap-2 ${\n              message()?.type === 'success' ? 'bg-green-500/10 text-green-400' : 'bg-red-500/10 text-red-400'\n            }`}>\n              {message()?.type === 'success' ? <CheckCircle size={16} /> : <AlertCircle size={16} />}\n              {message()?.text}\n            </div>\n          )}\n\n          <div>\n            <label class=\"label\">Senha Atual</label>\n            <input type=\"password\" class=\"input\" value={currentPass()} onInput={(e) => setCurrentPass(e.currentTarget.value)} required />\n          </div>\n\n          <div>\n            <label class=\"label\">Nova Senha</label>\n            <input type=\"password\" class=\"input\" value={newPass()} onInput={(e) => setNewPass(e.currentTarget.value)} required />\n\n            {/* Indicador de For\u00e7a da Senha */}\n            <Show when={newPass()}>\n              <div class=\"mt-2\">\n                <div class=\"flex justify-between items-center mb-1\">\n                  <span class=\"text-xs text-muted-foreground\">For\u00e7a da senha:</span>\n                  <span class={`text-xs font-medium ${passwordStrength().color}`}>\n                    {passwordStrength().label}\n                  </span>\n                </div>\n                <div class=\"w-full bg-gray-700 rounded-full h-2\">\n                  <div\n                    class={`h-2 rounded-full transition-all ${passwordStrength().barColor}`}\n                    style={`width: ${(passwordStrength().score / 4) * 100}%`}\n                  />\n                </div>\n              </div>\n            </Show>\n\n            {/* Requisitos de Senha */}\n            <Show when={newPass()}>\n              <div class=\"mt-3 space-y-1\">\n                <p class=\"text-xs text-muted-foreground font-medium mb-2\">Requisitos:</p>\n                <div class={`text-xs flex items-center gap-2 ${passwordRequirements().length ? 'text-green-500' : 'text-muted-foreground'}`}>\n                  {passwordRequirements().length ? <CheckCircle size={14} /> : <AlertCircle size={14} />}\n                  M\u00ednimo de 8 caracteres\n                </div>\n                <div class={`text-xs flex items-center gap-2 ${passwordRequirements().uppercase ? 'text-green-500' : 'text-muted-foreground'}`}>\n                  {passwordRequirements().uppercase ? <CheckCircle size={14} /> : <AlertCircle size={14} />}\n                  Letra mai\u00fascula (A-Z)\n                </div>\n                <div class={`text-xs flex items-center gap-2 ${passwordRequirements().lowercase ?", "mimetype": "text/plain", "start_char_idx": 3254, "end_char_idx": 7397, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "00bddec0-cf4a-4ab0-b213-1df3ffff553d": {"__data__": {"id_": "00bddec0-cf4a-4ab0-b213-1df3ffff553d", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Profile.tsx", "language": "typescript", "lines": 252, "filename": "Profile.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Profile.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Profile.tsx", "language": "typescript", "lines": 252, "filename": "Profile.tsx"}, "hash": "ba2e215bfd07f43a5c1cf46b4e9d2180018d8959177ced458fe20497f251d984", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "782b1e84-8cc5-4e24-9875-2a923f116f6e", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Profile.tsx", "language": "typescript", "lines": 252, "filename": "Profile.tsx"}, "hash": "2c56d16dc2c769cab98e644331597ee5a027633852357dd8e6137de33cb06e57", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "'text-green-500' : 'text-muted-foreground'}`}>\n                  {passwordRequirements().lowercase ? <CheckCircle size={14} /> : <AlertCircle size={14} />}\n                  Letra min\u00fascula (a-z)\n                </div>\n                <div class={`text-xs flex items-center gap-2 ${passwordRequirements().number ? 'text-green-500' : 'text-muted-foreground'}`}>\n                  {passwordRequirements().number ? <CheckCircle size={14} /> : <AlertCircle size={14} />}\n                  N\u00famero (0-9)\n                </div>\n                <div class={`text-xs flex items-center gap-2 ${passwordRequirements().special ? 'text-green-500' : 'text-muted-foreground'}`}>\n                  {passwordRequirements().special ? <CheckCircle size={14} /> : <AlertCircle size={14} />}\n                  Caractere especial (!@#$%^&*...)\n                </div>\n              </div>\n            </Show>\n          </div>\n\n          <div>\n            <label class=\"label\">Confirmar Nova Senha</label>\n            <input type=\"password\" class=\"input\" value={confirmPass()} onInput={(e) => setConfirmPass(e.currentTarget.value)} required />\n            <Show when={confirmPass() && newPass() !== confirmPass()}>\n              <p class=\"text-xs text-red-500 mt-1 flex items-center gap-1\">\n                <AlertCircle size={12} />\n                As senhas n\u00e3o coincidem\n              </p>\n            </Show>\n          </div>\n\n          <button\n            type=\"submit\"\n            class=\"btn btn-primary\"\n            disabled={!isPasswordValid() || newPass() !== confirmPass()}\n          >\n            Salvar Nova Senha\n          </button>\n        </form>\n\n        {/* Dicas de Seguran\u00e7a */}\n        <div class=\"p-4 bg-blue-500/5 border border-blue-500/20 rounded-lg\">\n          <h4 class=\"font-semibold text-blue-500 mb-2 flex items-center gap-2\">\n            <Shield size={18} />\n            Dicas de Seguran\u00e7a\n          </h4>\n          <ul class=\"text-sm text-muted-foreground space-y-1 list-disc list-inside\">\n            <li>Nunca compartilhe sua senha com outras pessoas</li>\n            <li>Use senhas diferentes para cada sistema</li>\n            <li>Evite senhas \u00f3bvias como datas de nascimento</li>\n            <li>Considere usar um gerenciador de senhas</li>\n            <li>Troque sua senha regularmente (a cada 3-6 meses)</li>\n          </ul>\n        </div>\n      </div>\n\n      {/* User Preferences Section */}\n      <div class=\"card border p-6 mt-6\">\n        <UserPreferences />\n      </div>\n    </div>\n  );\n}", "mimetype": "text/plain", "start_char_idx": 7398, "end_char_idx": 9902, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "62a41818-dc0c-4fdc-a9f7-b55b7b7b5a89": {"__data__": {"id_": "62a41818-dc0c-4fdc-a9f7-b55b7b7b5a89", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Reports.tsx", "language": "typescript", "lines": 341, "filename": "Reports.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Reports.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Reports.tsx", "language": "typescript", "lines": 341, "filename": "Reports.tsx"}, "hash": "c67681e527d4153739237249e66da62bd63811f6ade969278a91de42cfa86041", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e5fc96cf-2058-478b-9158-f3415c25a084", "node_type": "1", "metadata": {}, "hash": "963ee03011cc08257887f93c65db27bbc28f506dcbf17ac7c8930b18551d1c93", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import { createSignal, onMount, For, Show } from 'solid-js';\nimport { FileText, Download, Filter, Calendar, RefreshCw, Search, Package } from 'lucide-solid';\nimport api from '../lib/api';\n\ninterface TransferReport {\n  batch_id?: string;\n  transfer_id?: string;\n  modo?: string;\n  solicitante_id: string;\n  timestamp: string;\n  total_transferencias?: number;\n  transferencias?: Array<{\n    produto_id: number;\n    une_origem: number;\n    une_destino: number;\n    quantidade: number;\n  }>;\n  produto_id?: number;\n  une_origem?: number;\n  une_destino?: number;\n  quantidade?: number;\n}\n\nexport default function Reports() {\n  const [reports, setReports] = createSignal<TransferReport[]>([]);\n  const [loading, setLoading] = createSignal(true);\n  const [error, setError] = createSignal<string | null>(null);\n\n  // Filtros\n  const [startDate, setStartDate] = createSignal('');\n  const [endDate, setEndDate] = createSignal('');\n  const [searchTerm, setSearchTerm] = createSignal('');\n\n  const loadReports = async () => {\n    setLoading(true);\n    setError(null);\n\n    try {\n      const params = new URLSearchParams();\n      if (startDate()) params.append('start_date', startDate());\n      if (endDate()) params.append('end_date', endDate());\n\n      const response = await api.get<TransferReport[]>(`/transfers/report?${params.toString()}`);\n      setReports(response.data);\n    } catch (err: any) {\n      console.error('Erro ao carregar relat\u00f3rios:', err);\n      setError(err.response?.data?.detail || 'Erro ao carregar relat\u00f3rios');\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  const downloadReport = (report: TransferReport) => {\n    const dataStr = JSON.stringify(report, null, 2);\n    const dataBlob = new Blob([dataStr], { type: 'application/json' });\n    const url = URL.createObjectURL(dataBlob);\n    const link = document.createElement('a');\n    link.href = url;\n    const fileName = report.batch_id || report.transfer_id || 'transfer-report';\n    link.download = `${fileName}.json`;\n    link.click();\n    URL.revokeObjectURL(url);\n  };\n\n  const downloadAllAsCSV = () => {\n    const allTransfers: any[] = [];\n\n    reports().forEach(report => {\n      if (report.transferencias) {\n        // Batch transfer\n        report.transferencias.forEach(t => {\n          allTransfers.push({\n            ...t,\n            solicitante: report.solicitante_id,\n            timestamp: report.timestamp,\n            batch_id: report.batch_id\n          });\n        });\n      } else {\n        // Single transfer\n        allTransfers.push({\n          produto_id: report.produto_id,\n          une_origem: report.une_origem,\n          une_destino: report.une_destino,\n          quantidade: report.quantidade,\n          solicitante: report.solicitante_id,\n          timestamp: report.timestamp,\n          transfer_id: report.transfer_id\n        });\n      }\n    });\n\n    if (allTransfers.length === 0) {\n      alert('Nenhuma transfer\u00eancia para exportar');\n      return;\n    }\n\n    // Gerar CSV\n    const headers = ['Produto ID', 'UNE Origem', 'UNE Destino', 'Quantidade', 'Solicitante', 'Data/Hora', 'ID'];\n    const csv = [\n      headers.join(','),\n      ...allTransfers.map(t =>\n        [\n          t.produto_id,\n          t.une_origem,\n          t.une_destino,\n          t.quantidade,\n          t.solicitante,\n          t.timestamp,\n          t.batch_id || t.transfer_id || ''\n        ].join(',')\n      )\n    ].join('\\n');\n\n    const blob = new Blob([csv], { type: 'text/csv;charset=utf-8;' });\n    const url = URL.createObjectURL(blob);\n    const link = document.createElement('a');\n    link.href = url;\n    link.download = `transferencias-${new Date().toISOString().split('T')[0]}.csv`;", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3678, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e5fc96cf-2058-478b-9158-f3415c25a084": {"__data__": {"id_": "e5fc96cf-2058-478b-9158-f3415c25a084", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Reports.tsx", "language": "typescript", "lines": 341, "filename": "Reports.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Reports.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Reports.tsx", "language": "typescript", "lines": 341, "filename": "Reports.tsx"}, "hash": "c67681e527d4153739237249e66da62bd63811f6ade969278a91de42cfa86041", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "62a41818-dc0c-4fdc-a9f7-b55b7b7b5a89", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Reports.tsx", "language": "typescript", "lines": 341, "filename": "Reports.tsx"}, "hash": "b22ccdc6d315cb31755c0c3e50546426a35ec6c763988b19c72158a04fa4b1f0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "67b6bb4f-cf36-448a-8fbf-2da401c6577d", "node_type": "1", "metadata": {}, "hash": "3431a5884ae48ceecc70f653e73aa58178cfaf6d28338998a0c7e19f1dc979f2", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "download = `transferencias-${new Date().toISOString().split('T')[0]}.csv`;\n    link.click();\n    URL.revokeObjectURL(url);\n  };\n\n  const filteredReports = () => {\n    if (!searchTerm()) return reports();\n\n    return reports().filter(report => {\n      const search = searchTerm().toLowerCase();\n      return (\n        report.solicitante_id?.toLowerCase().includes(search) ||\n        report.batch_id?.toLowerCase().includes(search) ||\n        report.transfer_id?.toLowerCase().includes(search)\n      );\n    });\n  };\n\n  const setQuickFilter = (days: number) => {\n    const end = new Date();\n    const start = new Date();\n    start.setDate(start.getDate() - days);\n\n    setEndDate(end.toISOString().split('T')[0]);\n    setStartDate(start.toISOString().split('T')[0]);\n    loadReports();\n  };\n\n  onMount(() => {\n    loadReports();\n  });\n\n  return (\n    <div class=\"flex flex-col h-full p-6 gap-6\">\n      {/* Header */}\n      <div class=\"flex justify-between items-end\">\n        <div>\n          <h2 class=\"text-2xl font-bold flex items-center gap-2\">\n            <FileText size={28} />\n            Relat\u00f3rios de Transfer\u00eancias\n          </h2>\n          <p class=\"text-muted\">Hist\u00f3rico de solicita\u00e7\u00f5es de transfer\u00eancias entre UNEs</p>\n        </div>\n        <button\n          onClick={loadReports}\n          class=\"btn btn-outline gap-2\"\n          disabled={loading()}\n        >\n          <RefreshCw size={16} class={loading() ?", "mimetype": "text/plain", "start_char_idx": 3604, "end_char_idx": 5025, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "67b6bb4f-cf36-448a-8fbf-2da401c6577d": {"__data__": {"id_": "67b6bb4f-cf36-448a-8fbf-2da401c6577d", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Reports.tsx", "language": "typescript", "lines": 341, "filename": "Reports.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Reports.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Reports.tsx", "language": "typescript", "lines": 341, "filename": "Reports.tsx"}, "hash": "c67681e527d4153739237249e66da62bd63811f6ade969278a91de42cfa86041", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e5fc96cf-2058-478b-9158-f3415c25a084", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Reports.tsx", "language": "typescript", "lines": 341, "filename": "Reports.tsx"}, "hash": "3dbca206a203146d9e5e01b2322755b276c883b5b5d4bcf93f57f9c43ec21dd7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "77efd6df-db90-4010-8e2b-eccf5e9cebba", "node_type": "1", "metadata": {}, "hash": "0145c307522c0b5698d8b3a3f12fc9463815fa9eae723e0a86110e0104bf2745", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "'animate-spin' : ''} />\n          Atualizar\n        </button>\n      </div>\n\n      {/* Filters */}\n      <div class=\"card p-4 border\">\n        <div class=\"flex items-center gap-2 mb-4\">\n          <Filter size={20} />\n          <h3 class=\"font-semibold\">Filtros</h3>\n        </div>\n\n        {/* Quick Filters */}\n        <div class=\"flex gap-2 mb-4\">\n          <button class=\"btn btn-outline text-sm\" onClick={() => setQuickFilter(7)}>\n            \u00daltimos 7 dias\n          </button>\n          <button class=\"btn btn-outline text-sm\" onClick={() => setQuickFilter(30)}>\n            \u00daltimos 30 dias\n          </button>\n          <button class=\"btn btn-outline text-sm\" onClick={() => setQuickFilter(90)}>\n            \u00daltimos 90 dias\n          </button>\n        </div>\n\n        {/* Custom Filters */}\n        <div class=\"grid grid-cols-1 md:grid-cols-4 gap-3\">\n          <input\n            type=\"date\"\n            class=\"input\"\n            value={startDate()}\n            onInput={(e) => setStartDate(e.currentTarget.value)}\n            placeholder=\"Data In\u00edcio\"\n          />\n          <input\n            type=\"date\"\n            class=\"input\"\n            value={endDate()}\n            onInput={(e) => setEndDate(e.currentTarget.value)}\n            placeholder=\"Data Fim\"\n          />\n          <input\n            type=\"text\"\n            class=\"input\"\n            placeholder=\"Buscar por solicitante ou ID...\"\n            value={searchTerm()}\n            onInput={(e) => setSearchTerm(e.currentTarget.value)}\n          />\n          <button\n            class=\"btn btn-primary\"\n            onClick={loadReports}\n            disabled={loading()}\n          >\n            Aplicar Filtros\n          </button>\n        </div>\n      </div>\n\n      {/* Error State */}\n      <Show when={error()}>\n        <div class=\"card p-4 border-red-500 bg-red-500/10\">\n          <p class=\"text-red-500\">{error()}</p>\n        </div>\n      </Show>\n\n      {/* Stats */}\n      <div class=\"grid grid-cols-1 md:grid-cols-3 gap-4\">\n        <div class=\"card p-4 border\">\n          <div class=\"text-sm text-muted mb-1\">Total de Solicita\u00e7\u00f5es</div>\n          <div class=\"text-2xl font-bold\">{filteredReports().length}</div>\n        </div>\n\n        <div class=\"card p-4 border\">\n          <div class=\"text-sm text-muted mb-1\">Total de Transfer\u00eancias</div>\n          <div class=\"text-2xl font-bold\">\n            {filteredReports().reduce((acc, r) => acc + (r.total_transferencias || 1), 0)}\n          </div>\n        </div>\n\n        <div class=\"card p-4 border\">\n          <div class=\"text-sm text-muted mb-1\">A\u00e7\u00f5es</div>\n          <button\n            class=\"btn btn-outline w-full gap-2 text-sm\"\n            onClick={downloadAllAsCSV}\n            disabled={filteredReports().length === 0}\n          >\n            <Download size={16} />\n            Exportar Tudo (CSV)\n          </button>\n        </div>\n      </div>\n\n      {/* Loading State */}\n      <Show when={loading()}>\n        <div class=\"flex-1 flex items-center justify-center\">\n          <div class=\"text-center\">\n            <RefreshCw size={48} class=\"mx-auto mb-4 opacity-50 animate-spin\" />\n            <p class=\"text-muted\">Carregando relat\u00f3rios...</p>\n          </div>\n        </div>\n      </Show>\n\n      {/* Reports Table */}\n      <Show when={!loading()}>\n        <div class=\"card border\">\n          <div class=\"p-4 border-b\">\n            <h3 class=\"font-semibold\">\n              Hist\u00f3rico ({filteredReports().length} {filteredReports().length === 1 ?", "mimetype": "text/plain", "start_char_idx": 5026, "end_char_idx": 8502, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "77efd6df-db90-4010-8e2b-eccf5e9cebba": {"__data__": {"id_": "77efd6df-db90-4010-8e2b-eccf5e9cebba", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Reports.tsx", "language": "typescript", "lines": 341, "filename": "Reports.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Reports.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Reports.tsx", "language": "typescript", "lines": 341, "filename": "Reports.tsx"}, "hash": "c67681e527d4153739237249e66da62bd63811f6ade969278a91de42cfa86041", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "67b6bb4f-cf36-448a-8fbf-2da401c6577d", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Reports.tsx", "language": "typescript", "lines": 341, "filename": "Reports.tsx"}, "hash": "a1c03d7dfa68378da121d1faa2f76e97bc0e1cdd1294a544d30f3fed0c575d90", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "'solicita\u00e7\u00e3o' : 'solicita\u00e7\u00f5es'})\n            </h3>\n          </div>\n\n          <Show when={filteredReports().length > 0} fallback={\n            <div class=\"p-12 text-center text-muted\">\n              <Package size={48} class=\"mx-auto mb-4 opacity-20\" />\n              <p>Nenhuma solicita\u00e7\u00e3o encontrada</p>\n              <p class=\"text-sm mt-2\">Ajuste os filtros ou crie uma nova transfer\u00eancia</p>\n            </div>\n          }>\n            <div class=\"overflow-x-auto\">\n              <table class=\"w-full\">\n                <thead class=\"bg-muted/50\">\n                  <tr class=\"text-left text-xs font-medium text-muted uppercase\">\n                    <th class=\"p-3\">ID</th>\n                    <th class=\"p-3\">Tipo</th>\n                    <th class=\"p-3\">Transfer\u00eancias</th>\n                    <th class=\"p-3\">Solicitante</th>\n                    <th class=\"p-3\">Data/Hora</th>\n                    <th class=\"p-3 text-right\">A\u00e7\u00f5es</th>\n                  </tr>\n                </thead>\n                <tbody class=\"divide-y\">\n                  <For each={filteredReports()}>\n                    {(report) => (\n                      <tr class=\"hover:bg-muted/30 transition-colors\">\n                        <td class=\"p-3 font-mono text-xs\">\n                          {report.batch_id || report.transfer_id || 'N/A'}\n                        </td>\n                        <td class=\"p-3\">\n                          <span class={`px-2 py-1 text-xs rounded ${\n                            report.batch_id\n                              ? 'bg-blue-500/10 text-blue-400'\n                              : 'bg-green-500/10 text-green-400'\n                          }`}>\n                            {report.batch_id ? `Lote (${report.modo})` : 'Simples'}\n                          </span>\n                        </td>\n                        <td class=\"p-3 font-semibold\">\n                          {report.total_transferencias || 1}\n                        </td>\n                        <td class=\"p-3 text-sm\">{report.solicitante_id}</td>\n                        <td class=\"p-3 text-sm font-mono text-muted\">\n                          {new Date(report.timestamp).toLocaleString('pt-BR')}\n                        </td>\n                        <td class=\"p-3 text-right\">\n                          <button\n                            class=\"btn btn-outline btn-sm gap-2\"\n                            onClick={() => downloadReport(report)}\n                          >\n                            <Download size={14} />\n                            JSON\n                          </button>\n                        </td>\n                      </tr>\n                    )}\n                  </For>\n                </tbody>\n              </table>\n            </div>\n          </Show>\n        </div>\n      </Show>\n    </div>\n  );\n}", "mimetype": "text/plain", "start_char_idx": 8503, "end_char_idx": 11320, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "610ceb31-d07c-4bb5-99ba-d3e80dc8b96e": {"__data__": {"id_": "610ceb31-d07c-4bb5-99ba-d3e80dc8b96e", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Rupturas.tsx", "language": "typescript", "lines": 932, "filename": "Rupturas.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Rupturas.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Rupturas.tsx", "language": "typescript", "lines": 932, "filename": "Rupturas.tsx"}, "hash": "6c3ac5e8d5389ace041363c08de4fb4343002dc0a0ac1e92ea30bb7113d8f379", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "cebd4b10-f6c8-4d6e-9567-5885ab4caebe", "node_type": "1", "metadata": {}, "hash": "41e2144604e8c6caff16cfa3033d592a8653834f967cfd8e9fef35e52a873ba9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import { createSignal, onMount, Show, For } from 'solid-js';\nimport { rupturasApi, Ruptura, RupturasSummary } from '@/lib/api';\nimport { AlertTriangle, RefreshCw, PackageX, ShoppingCart, Archive, Download, Filter, X, TrendingUp, Package, BarChart3, PieChart } from 'lucide-solid';\nimport { PlotlyChart } from '@/components/PlotlyChart';\nimport { ChartDownloadButton } from '@/components/ChartDownloadButton';\n\nexport default function Rupturas() {\n  const [data, setData] = createSignal<Ruptura[]>([]);\n  const [loading, setLoading] = createSignal(true);\n  const [error, setError] = createSignal<string | null>(null);\n  const [summary, setSummary] = createSignal<RupturasSummary>({ total: 0, criticos: 0, valor_estimado: 0 });\n\n  // Chart specs\n  const [criticidadeChart, setCriticidadeChart] = createSignal<any>({});\n  const [topRupturasChart, setTopRupturasChart] = createSignal<any>({});\n  const [necessidadeSegmentoChart, setNecessidadeSegmentoChart] = createSignal<any>({});\n  const [selectedProduct, setSelectedProduct] = createSignal<Ruptura | null>(null);\n\n  // Drill-down: Grupo selecionado para ver produtos\n  const [selectedGroup, setSelectedGroup] = createSignal<string | null>(null);\n\n  // Filtros\n  const [segmentos, setSegmentos] = createSignal<string[]>([]);\n  const [unes, setUnes] = createSignal<string[]>([]);\n  const [selectedSegmento, setSelectedSegmento] = createSignal<string>('');\n  const [selectedUne, setSelectedUne] = createSignal<string>('');\n  const [showFilters, setShowFilters] = createSignal(false);\n  const [filtersLoading, setFiltersLoading] = createSignal(false);\n\n  const loadFilters = async () => {\n    setFiltersLoading(true);\n    try {\n      const [segmentosRes, unesRes] = await Promise.all([\n        rupturasApi.getSegmentos(),\n        rupturasApi.getUnes()\n      ]);\n      setSegmentos(Array.isArray(segmentosRes.data) ? segmentosRes.data : []);\n      setUnes(Array.isArray(unesRes.data) ? unesRes.data : []);\n    } catch (err) {\n      console.error(\"Error loading filters:\", err);\n      setSegmentos([]);\n      setUnes([]);\n    } finally {\n      setFiltersLoading(false);\n    }\n  };\n\n  const loadData = async () => {\n    setLoading(true);\n    setError(null);\n    try {\n      const segmento = selectedSegmento() || undefined;\n      const une = selectedUne() || undefined;\n\n      console.log('\ud83d\udd0d [Rupturas] Carregando dados com filtros:', { segmento, une });\n\n      const [rupturaRes, summaryRes] = await Promise.all([\n        rupturasApi.getCritical(50, segmento, une),\n        rupturasApi.getSummary(segmento, une)\n      ]);\n\n      console.log('\ud83d\udcca [Rupturas] Dados recebidos:', rupturaRes.data.length, 'produtos');\n      console.log('\ud83d\udcca [Rupturas] UNEs nos dados:', [...new Set(rupturaRes.data.map(r => r.UNE))]);\n\n      setData(rupturaRes.data);\n      setSummary(summaryRes.data);\n\n      // Gerar gr\u00e1ficos\n      generateCharts(rupturaRes.data);\n    } catch (err: any) {\n      console.error(\"Error loading rupturas:\", err);\n      setError(\"Falha ao carregar rupturas cr\u00edticas.\");\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  const generateCharts = (rupturas: Ruptura[]) => {\n    if (rupturas.length === 0) return;\n\n    // 1.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3173, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "cebd4b10-f6c8-4d6e-9567-5885ab4caebe": {"__data__": {"id_": "cebd4b10-f6c8-4d6e-9567-5885ab4caebe", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Rupturas.tsx", "language": "typescript", "lines": 932, "filename": "Rupturas.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Rupturas.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Rupturas.tsx", "language": "typescript", "lines": 932, "filename": "Rupturas.tsx"}, "hash": "6c3ac5e8d5389ace041363c08de4fb4343002dc0a0ac1e92ea30bb7113d8f379", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "610ceb31-d07c-4bb5-99ba-d3e80dc8b96e", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Rupturas.tsx", "language": "typescript", "lines": 932, "filename": "Rupturas.tsx"}, "hash": "b72b07c5761823b75927d7db8f198c9c3b1e1fd5ac05a44ea21b8b1a057cec1a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e3dd0afc-80ee-4e94-aed2-6bf0851711b1", "node_type": "1", "metadata": {}, "hash": "de342769d538d874464c58b3acd73a3c3f91ea7a1f42088ab89b2a2d26330dfb", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Top Grupos em Ruptura Cr\u00edtica - mais acion\u00e1vel para o comprador\n    // Agrupa produtos cr\u00edticos por NOMEGRUPO e mostra top 8\n    const gruposContagem: { [key: string]: { total: number, criticos: number, necessidade: number } } = {};\n\n    rupturas.forEach(r => {\n      const grupo = (r as any).NOMEGRUPO || r.NOMESEGMENTO || 'SEM GRUPO';\n      if (!gruposContagem[grupo]) {\n        gruposContagem[grupo] = { total: 0, criticos: 0, necessidade: 0 };\n      }\n      gruposContagem[grupo].total++;\n      gruposContagem[grupo].necessidade += r.NECESSIDADE;\n      if (r.CRITICIDADE_PCT >= 75) gruposContagem[grupo].criticos++;\n    });\n\n    // Ordenar por quantidade de cr\u00edticos e pegar top 8\n    const topGrupos = Object.entries(gruposContagem)\n      .sort((a, b) => b[1].criticos - a[1].criticos)\n      .slice(0, 8);\n\n    setCriticidadeChart({\n      data: [{\n        type: 'bar',\n        orientation: 'h',\n        y: topGrupos.map(([nome]) => nome.length > 25 ? nome.substring(0, 25) + '...' : nome),\n        x: topGrupos.map(([, data]) => data.criticos),\n        marker: {\n          color: topGrupos.map(([, data]) => {\n            const pct = data.criticos / data.total;\n            if (pct >= 0.8) return '#B94343';       // 80%+ cr\u00edticos = vermelho\n            if (pct >= 0.5) return '#CC8B3C';       // 50%+ = laranja\n            return '#C9A961';                        // menos = dourado\n          }),\n          line: { color: '#E5E5E5', width: 1 }\n        },\n        text: topGrupos.map(([, data]) => `${data.criticos} cr\u00edticos (${Math.round(data.necessidade)} un)`),\n        textposition: 'auto',\n        textfont: { color: '#FFFFFF', size: 11, family: 'Inter, sans-serif' },\n        hovertemplate: '<b>%{y}</b><br>Produtos cr\u00edticos: %{x}<br>Total no grupo: %{customdata[0]}<br>Necessidade: %{customdata[1]:.0f} un<extra></extra>',\n        customdata: topGrupos.map(([, data]) => [data.total, data.necessidade])\n      }],\n      layout: {\n        title: {\n          text: '<b>\ud83d\udd34 Top Grupos em Ruptura Cr\u00edtica</b><br><span style=\"font-size:11px;color:#6B6B6B\">Categorias com mais produtos em situa\u00e7\u00e3o cr\u00edtica (\u226575%)</span>',\n          font: { size: 14, color: '#2D2D2D', family: 'Inter, sans-serif' },\n          x: 0.02\n        },\n        xaxis: {\n          title: 'Produtos Cr\u00edticos',\n          titlefont: { color: '#6B6B6B', size: 11, family: 'Inter, sans-serif' },\n          tickfont: { color: '#6B6B6B', family: 'Inter, sans-serif' },\n          gridcolor: '#E5E5E5',\n          zeroline: false\n        },\n        yaxis: {\n          tickfont: { color: '#2D2D2D', size: 10, family: 'Inter, sans-serif' },\n          automargin: true\n        },\n        plot_bgcolor: '#FFFFFF',\n        paper_bgcolor: '#FAFAFA',\n        margin: { l: 150, r: 20, t: 70, b: 50 },\n        font: { color: '#2D2D2D', family: 'Inter, sans-serif' },\n        showlegend: false,\n        bargap: 0.25\n      },\n      config: { responsive: true, displayModeBar: false }\n    });\n\n    // 2.", "mimetype": "text/plain", "start_char_idx": 3174, "end_char_idx": 6132, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e3dd0afc-80ee-4e94-aed2-6bf0851711b1": {"__data__": {"id_": "e3dd0afc-80ee-4e94-aed2-6bf0851711b1", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Rupturas.tsx", "language": "typescript", "lines": 932, "filename": "Rupturas.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Rupturas.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Rupturas.tsx", "language": "typescript", "lines": 932, "filename": "Rupturas.tsx"}, "hash": "6c3ac5e8d5389ace041363c08de4fb4343002dc0a0ac1e92ea30bb7113d8f379", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "cebd4b10-f6c8-4d6e-9567-5885ab4caebe", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Rupturas.tsx", "language": "typescript", "lines": 932, "filename": "Rupturas.tsx"}, "hash": "b4a9441e92ae97e34e67d61aeb8eac872adaa9e2a9df2941dd7cb41fb911dafa", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a7a791e4-1c3d-4758-ab0a-dbc4203bc5e8", "node_type": "1", "metadata": {}, "hash": "041b978cbecb65ffc878d10e7a60f16b5d7db2788efd3ab64717dcd6b2fe2b2b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Gr\u00e1fico de Barras - Top 10 Produtos em Ruptura\n    const top10 = rupturas\n      .sort((a, b) => b.NECESSIDADE - a.NECESSIDADE)\n      .slice(0, 10);\n\n    // LOJAS CA\u00c7ULA - LIGHT THEME\n    setTopRupturasChart({\n      data: [{\n        type: 'bar',\n        x: top10.map(r => r.NOME.substring(0, 30) + '...'),\n        y: top10.map(r => r.NECESSIDADE),\n        marker: {\n          color: top10.map(r => {\n            if (r.CRITICIDADE_PCT >= 75) return '#B94343'; // Vermelho terroso\n            if (r.CRITICIDADE_PCT >= 50) return '#CC8B3C'; // Laranja terroso\n            if (r.CRITICIDADE_PCT >= 25) return '#C9A961'; // Dourado\n            return '#5B7B9A'; // Azul acinzentado\n          }),\n          line: { color: '#E5E5E5', width: 1 }\n        },\n        text: top10.map(r => Math.round(r.NECESSIDADE)),\n        textposition: 'outside',\n        textfont: { color: '#2D2D2D', family: 'Inter, sans-serif' },\n        hovertemplate: '<b>%{x}</b><br>Loja: %{customdata[1]}<br>Necessidade: %{y:.0f} un<extra></extra>',\n        customdata: top10.map(r => [r.PRODUTO, r.UNE_NOME || 'N/A'])\n      }],\n      layout: {\n        title: {\n          text: 'Top 10 Produtos - Maior Necessidade',\n          font: { size: 16, color: '#2D2D2D', family: 'Inter, sans-serif' }\n        },\n        xaxis: {\n          title: '',\n          tickangle: -45,\n          tickfont: { size: 9, color: '#6B6B6B', family: 'Inter, sans-serif' },\n          gridcolor: '#E5E5E5',\n          linecolor: '#E5E5E5'\n        },\n        yaxis: {\n          title: 'Necessidade (unidades)',\n          titlefont: { color: '#6B6B6B', family: 'Inter, sans-serif' },\n          tickfont: { color: '#6B6B6B', family: 'Inter, sans-serif' },\n          gridcolor: '#E5E5E5',\n          linecolor: '#E5E5E5'\n        },\n        plot_bgcolor: '#FFFFFF',\n        paper_bgcolor: '#FAFAFA',\n        margin: { l: 60, r: 20, t: 60, b: 120 },\n        font: { color: '#2D2D2D', family: 'Inter, sans-serif' }\n      },\n      config: { responsive: true }\n    });\n\n    // 3. Gr\u00e1fico de Barras Empilhadas - Necessidade por GRUPO (categoria de produto)\n    // Agrupa por NOMEGRUPO para que o comprador possa priorizar por categoria\n    const grupoData: { [key: string]: { critico: number, alto: number, medio: number, baixo: number, total: number } } = {};\n\n    rupturas.forEach(r => {\n      // Usar NOMEGRUPO se dispon\u00edvel, sen\u00e3o fallback para NOMESEGMENTO\n      const grupo = (r as any).NOMEGRUPO || r.NOMESEGMENTO || 'SEM GRUPO';\n      if (!grupoData[grupo]) {\n        grupoData[grupo] = { critico: 0, alto: 0, medio: 0, baixo: 0, total: 0 };\n      }\n\n      const necessidade = r.NECESSIDADE;\n      grupoData[grupo].total += necessidade;\n      if (r.CRITICIDADE_PCT >= 75) grupoData[grupo].critico += necessidade;\n      else if (r.CRITICIDADE_PCT >= 50) grupoData[grupo].alto += necessidade;\n      else if (r.CRITICIDADE_PCT >= 25) grupoData[grupo].medio += necessidade;\n      else grupoData[grupo].baixo += necessidade;\n    });", "mimetype": "text/plain", "start_char_idx": 6133, "end_char_idx": 9093, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a7a791e4-1c3d-4758-ab0a-dbc4203bc5e8": {"__data__": {"id_": "a7a791e4-1c3d-4758-ab0a-dbc4203bc5e8", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Rupturas.tsx", "language": "typescript", "lines": 932, "filename": "Rupturas.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Rupturas.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Rupturas.tsx", "language": "typescript", "lines": 932, "filename": "Rupturas.tsx"}, "hash": "6c3ac5e8d5389ace041363c08de4fb4343002dc0a0ac1e92ea30bb7113d8f379", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e3dd0afc-80ee-4e94-aed2-6bf0851711b1", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Rupturas.tsx", "language": "typescript", "lines": 932, "filename": "Rupturas.tsx"}, "hash": "e487fbdbf438d3d66f0cc19c2df070b297cb318d3320dcab04bf1730593d6b52", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f3f7a7a1-8290-4e6e-9e00-cd4e3bd5ef0e", "node_type": "1", "metadata": {}, "hash": "9ec7febe10cbaa94b184eabcfac1d08a42dc091ac0f20964a847df4d2e80a637", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "else grupoData[grupo].baixo += necessidade;\n    });\n\n    // Ordenar grupos por total de necessidade (mais cr\u00edticos primeiro)\n    const grupos = Object.keys(grupoData).sort((a, b) => grupoData[b].total - grupoData[a].total).slice(0, 10);\n\n    // LOJAS CA\u00c7ULA - LIGHT THEME\n    setNecessidadeSegmentoChart({\n      data: [\n        {\n          type: 'bar',\n          name: '\ud83d\udd34 CR\u00cdTICO',\n          x: grupos,\n          y: grupos.map(g => grupoData[g].critico),\n          marker: { color: '#B94343' },\n          hovertemplate: '<b>%{x}</b><br>Cr\u00edtico: %{y:.0f} un<extra></extra>'\n        },\n        {\n          type: 'bar',\n          name: '\ud83d\udfe0 ALTO',\n          x: grupos,\n          y: grupos.map(g => grupoData[g].alto),\n          marker: { color: '#CC8B3C' },\n          hovertemplate: '<b>%{x}</b><br>Alto: %{y:.0f} un<extra></extra>'\n        },\n        {\n          type: 'bar',\n          name: '\ud83d\udfe1 M\u00c9DIO',\n          x: grupos,\n          y: grupos.map(g => grupoData[g].medio),\n          marker: { color: '#C9A961' },\n          hovertemplate: '<b>%{x}</b><br>M\u00e9dio: %{y:.0f} un<extra></extra>'\n        },\n        {\n          type: 'bar',\n          name: '\ud83d\udd35 BAIXO',\n          x: grupos,\n          y: grupos.map(g => grupoData[g].baixo),\n          marker: { color: '#5B7B9A' },\n          hovertemplate: '<b>%{x}</b><br>Baixo: %{y:.0f} un<extra></extra>'\n        }\n      ],\n      layout: {\n        title: {\n          text: '<b>Necessidade de Reposi\u00e7\u00e3o por Grupo de Produtos</b><br><span style=\"font-size:11px;color:#6B6B6B\">Top 10 grupos ordenados por volume de necessidade</span>',\n          font: { size: 14, color: '#2D2D2D', family: 'Inter, sans-serif' },\n          x: 0.02\n        },\n        barmode: 'stack',\n        xaxis: {\n          title: '',\n          tickangle: -45,\n          tickfont: { size: 10, color: '#6B6B6B', family: 'Inter, sans-serif' },\n          gridcolor: '#E5E5E5',\n          linecolor: '#E5E5E5'\n        },\n        yaxis: {\n          title: 'Necessidade Total (unidades)',\n          titlefont: { color: '#6B6B6B', size: 11, family: 'Inter, sans-serif' },\n          tickfont: { color: '#6B6B6B', family: 'Inter, sans-serif' },\n          gridcolor: '#E5E5E5',\n          linecolor: '#E5E5E5'\n        },\n        plot_bgcolor: '#FFFFFF',\n        paper_bgcolor: '#FAFAFA',\n        margin: { l: 70, r: 20, t: 80, b: 120 },\n        font: { color: '#2D2D2D', family: 'Inter, sans-serif' },\n        showlegend: true,\n        legend: {\n          orientation: 'h',\n          x: 0.5,\n          y: 1.12,\n          xanchor: 'center',\n          font: { size: 10, color: '#2D2D2D', family: 'Inter, sans-serif' },\n          bgcolor: 'rgba(255,255,255,0.9)',\n          bordercolor: '#E5E5E5',\n          borderwidth: 1\n        }\n      },\n      config: { responsive: true, displayModeBar: false }\n    });\n  };\n\n  const handleChartClick = (clickData: any) => {\n    if (clickData && clickData.points && clickData.points[0]) {\n      const point = clickData.", "mimetype": "text/plain", "start_char_idx": 9042, "end_char_idx": 11991, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f3f7a7a1-8290-4e6e-9e00-cd4e3bd5ef0e": {"__data__": {"id_": "f3f7a7a1-8290-4e6e-9e00-cd4e3bd5ef0e", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Rupturas.tsx", "language": "typescript", "lines": 932, "filename": "Rupturas.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Rupturas.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Rupturas.tsx", "language": "typescript", "lines": 932, "filename": "Rupturas.tsx"}, "hash": "6c3ac5e8d5389ace041363c08de4fb4343002dc0a0ac1e92ea30bb7113d8f379", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a7a791e4-1c3d-4758-ab0a-dbc4203bc5e8", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Rupturas.tsx", "language": "typescript", "lines": 932, "filename": "Rupturas.tsx"}, "hash": "11a46633d675c86cb54bfbb1b4972882e32d55f65a578b617f780b90d2abd5f8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1058bf3d-434b-4f79-a0fd-a0e30badcf09", "node_type": "1", "metadata": {}, "hash": "70cf7831fafdf5fad2cd6a412b417b57dc6670e6d550a414ed0b404a587429cb", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "points && clickData.points[0]) {\n      const point = clickData.points[0];\n      // Se tem customdata, \u00e9 o c\u00f3digo do produto\n      if (point.customdata) {\n        const produto = data().find(r => r.PRODUTO === point.customdata);\n        if (produto) {\n          setSelectedProduct(produto);\n        }\n      }\n    }\n  };\n\n  // Handler para clique no gr\u00e1fico de grupos - abre modal com produtos do grupo\n  const handleGroupClick = (clickData: any) => {\n    if (clickData && clickData.points && clickData.points[0]) {\n      const point = clickData.points[0];\n      // O label do eixo Y cont\u00e9m o nome do grupo\n      const grupoName = point.y || point.label;\n      if (grupoName) {\n        // Remover truncagem (...) se houver\n        const cleanName = grupoName.replace('...', '');\n        setSelectedGroup(cleanName);\n      }\n    }\n  };\n\n  // Filtrar produtos pelo grupo selecionado\n  const getProductsByGroup = () => {\n    const grupo = selectedGroup();\n    if (!grupo) return [];\n\n    return data().filter(r => {\n      const productGroup = (r as any).NOMEGRUPO || r.NOMESEGMENTO || 'SEM GRUPO';\n      // Match parcial para grupos truncados\n      return productGroup.toLowerCase().includes(grupo.toLowerCase()) ||\n        grupo.toLowerCase().includes(productGroup.substring(0, 20).toLowerCase());\n    }).sort((a, b) => b.CRITICIDADE_PCT - a.CRITICIDADE_PCT);\n  };\n\n  const clearFilters = () => {\n    setSelectedSegmento('');\n    setSelectedUne('');\n    loadData();\n  };\n\n  const exportCSV = () => {\n    const items = data();\n    if (items.length === 0) return;\n\n    const headers = ['Produto', 'Nome', 'UNE', 'Loja', 'Segmento', 'Grupo', 'Venda 30d', 'Estoque UNE', 'Estoque CD', 'Linha Verde', 'Criticidade %', 'Necessidade'];\n    const rows = items.map(item => [\n      item.PRODUTO,\n      item.NOME,\n      item.UNE,\n      item.UNE_NOME || '',\n      item.NOMESEGMENTO || '',\n      (item as any).NOMEGRUPO || '',\n      item.VENDA_30DD,\n      item.ESTOQUE_UNE,\n      item.ESTOQUE_CD,\n      item.ESTOQUE_LV,\n      item.CRITICIDADE_PCT.toFixed(1),\n      item.NECESSIDADE\n    ]);\n\n    const csv = [headers, ...rows].map(row => row.join(',')).join('\\n');\n    const blob = new Blob([csv], { type: 'text/csv' });\n    const url = URL.createObjectURL(blob);\n    const a = document.createElement('a');\n    a.href = url;\n    a.download = `rupturas_criticas_${new Date().toISOString().split('T')[0]}.csv`;\n    a.click();\n    URL.revokeObjectURL(url);\n  };\n\n  // Gerar Pedido de Compra - Exporta lista formatada para compras\n  const exportPurchaseOrder = () => {\n    const items = data();\n    if (items.length === 0) return;\n\n    // Agrupar por NOMEGRUPO\n    const grupoData: { [key: string]: Array<typeof items[0]> } = {};\n    items.forEach(item => {\n      const grupo = (item as any).NOMEGRUPO || item.NOMESEGMENTO || 'SEM GRUPO';\n      if (!grupoData[grupo]) grupoData[grupo] = [];\n      grupoData[grupo].push(item);\n    });\n\n    // Calcular totais por grupo\n    let csvContent = '=== PEDIDO DE COMPRA - REPOSI\u00c7\u00c3O DE RUPTURAS CR\u00cdTICAS ===\\n';\n    csvContent += `Data de Gera\u00e7\u00e3o: ${new Date().toLocaleString('pt-BR')}\\n`;\n    csvContent += `Total de Produtos: ${items.length}\\n`;\n    csvContent += `Total de Grupos: ${Object.keys(grupoData).", "mimetype": "text/plain", "start_char_idx": 11928, "end_char_idx": 15155, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1058bf3d-434b-4f79-a0fd-a0e30badcf09": {"__data__": {"id_": "1058bf3d-434b-4f79-a0fd-a0e30badcf09", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Rupturas.tsx", "language": "typescript", "lines": 932, "filename": "Rupturas.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Rupturas.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Rupturas.tsx", "language": "typescript", "lines": 932, "filename": "Rupturas.tsx"}, "hash": "6c3ac5e8d5389ace041363c08de4fb4343002dc0a0ac1e92ea30bb7113d8f379", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f3f7a7a1-8290-4e6e-9e00-cd4e3bd5ef0e", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Rupturas.tsx", "language": "typescript", "lines": 932, "filename": "Rupturas.tsx"}, "hash": "bffd9181f73b8b84f141fd08e92b52c1fa81e540a810b01e917e869029000360", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "380bf732-80da-472b-85a4-9678851855a0", "node_type": "1", "metadata": {}, "hash": "8d112a25480f35ca2f72e3ae9c3907bd74d4579e53094113311e3573d90daef5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "csvContent += `Total de Grupos: ${Object.keys(grupoData).length}\\n\\n`;\n\n    Object.entries(grupoData)\n      .sort((a, b) => b[1].reduce((sum, i) => sum + i.NECESSIDADE, 0) - a[1].reduce((sum, i) => sum + i.NECESSIDADE, 0))\n      .forEach(([grupo, produtos]) => {\n        const totalNecessidade = produtos.reduce((sum, p) => sum + p.NECESSIDADE, 0);\n        const totalCriticos = produtos.filter(p => p.CRITICIDADE_PCT >= 75).length;\n\n        csvContent += `\\n--- ${grupo.toUpperCase()} ---\\n`;\n        csvContent += `Produtos: ${produtos.length} | Cr\u00edticos: ${totalCriticos} | Necessidade Total: ${Math.round(totalNecessidade)} un\\n`;\n        csvContent += 'C\u00f3digo,Nome,Necessidade (un),Criticidade %\\n';\n\n        produtos\n          .sort((a, b) => b.CRITICIDADE_PCT - a.CRITICIDADE_PCT)\n          .forEach(p => {\n            csvContent += `${p.PRODUTO},\"${p.NOME.substring(0, 50)}\",${Math.round(p.NECESSIDADE)},${p.CRITICIDADE_PCT.toFixed(0)}%\\n`;\n          });\n      });\n\n    const blob = new Blob([csvContent], { type: 'text/csv;charset=utf-8' });\n    const url = URL.createObjectURL(blob);\n    const a = document.createElement('a');\n    a.href = url;\n    a.download = `pedido_compra_rupturas_${new Date().toISOString().split('T')[0]}.csv`;\n    a.click();\n    URL.revokeObjectURL(url);\n  };\n\n  onMount(() => {\n    loadFilters();\n    loadData();\n  });\n\n  const getCriticidadeColor = (pct: number) => {\n    if (pct >= 75) return 'bg-red-500/20 text-red-500 border-red-500/30';\n    if (pct >= 50) return 'bg-orange-500/20 text-orange-500 border-orange-500/30';\n    if (pct >= 25) return 'bg-yellow-500/20 text-yellow-500 border-yellow-500/30';\n    return 'bg-blue-500/20 text-blue-500 border-blue-500/30';\n  };\n\n  const getCriticidadeLabel = (pct: number) => {\n    if (pct >= 75) return 'CR\u00cdTICO';\n    if (pct >= 50) return 'ALTO';\n    if (pct >= 25) return 'M\u00c9DIO';\n    return 'BAIXO';\n  };\n\n  return (\n    <div class=\"flex flex-col h-full p-6 gap-6 max-w-7xl mx-auto\">\n      {/* Header */}\n      <div class=\"flex justify-between items-start\">\n        <div>\n          <h2 class=\"text-2xl font-bold tracking-tight text-red-500 flex items-center gap-2\">\n            <AlertTriangle size={24} />\n            Rupturas Cr\u00edticas\n          </h2>\n          <p class=\"text-muted mt-1\">CD zerado + Estoque loja abaixo da Linha Verde</p>\n        </div>\n        <div class=\"flex gap-2\">\n          <button onClick={() => {\n            console.log(\"Toggling filters:\", !showFilters());\n            setShowFilters(!showFilters());\n          }} class=\"btn btn-outline gap-2\">\n            <Filter size={16} />\n            Filtros\n          </button>\n          <button\n            onClick={exportPurchaseOrder}\n            class=\"btn gap-2\"\n            style=\"background-color: #2D7A3E; color: white;\"\n            disabled={data().length === 0}\n            title=\"Gerar arquivo para pedido de compra agrupado por categoria\"\n          >\n            <ShoppingCart size={16} />\n            Gerar Pedido de Compra\n          </button>\n          <button onClick={exportCSV} class=\"btn btn-outline gap-2\" disabled={data().", "mimetype": "text/plain", "start_char_idx": 15098, "end_char_idx": 18195, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "380bf732-80da-472b-85a4-9678851855a0": {"__data__": {"id_": "380bf732-80da-472b-85a4-9678851855a0", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Rupturas.tsx", "language": "typescript", "lines": 932, "filename": "Rupturas.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Rupturas.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Rupturas.tsx", "language": "typescript", "lines": 932, "filename": "Rupturas.tsx"}, "hash": "6c3ac5e8d5389ace041363c08de4fb4343002dc0a0ac1e92ea30bb7113d8f379", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1058bf3d-434b-4f79-a0fd-a0e30badcf09", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Rupturas.tsx", "language": "typescript", "lines": 932, "filename": "Rupturas.tsx"}, "hash": "fd9543e7c4fdc8c3905842b267de23e9702e7fa185ccb450b7694377a5cb41d5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0de7000f-9542-4dfc-89e0-46441c24e90e", "node_type": "1", "metadata": {}, "hash": "1be5913da6f195eb5f681cf27421892a6262dee35fac5e79d5bc598a651e615e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "length === 0}>\n            <Download size={16} />\n            CSV\n          </button>\n          <button onClick={loadData} class=\"btn btn-outline gap-2\" disabled={loading()}>\n            <RefreshCw size={16} class={loading() ? 'animate-spin' : ''} />\n            Atualizar\n          </button>\n        </div>\n      </div>\n\n      {/* Filtros */}\n      <Show when={showFilters()}>\n        <div class=\"p-4 bg-card border rounded-lg\">\n          <div class=\"flex items-center justify-between mb-4\">\n            <h3 class=\"font-semibold\">Filtros</h3>\n            <button onClick={() => setShowFilters(false)} class=\"text-muted-foreground hover:text-foreground\">\n              <X size={18} />\n            </button>\n          </div>\n          <div class=\"grid grid-cols-1 md:grid-cols-3 gap-4\">\n            <div>\n              <label class=\"block text-sm font-medium mb-2\">Segmento</label>\n              <select\n                class=\"w-full px-3 py-2 bg-background border rounded-lg disabled:opacity-50\"\n                value={selectedSegmento()}\n                onChange={(e) => setSelectedSegmento(e.target.value)}\n                disabled={filtersLoading()}\n              >\n                <Show when={!filtersLoading()} fallback={<option>Carregando filtros...</option>}>\n                  <option value=\"\">Todos</option>\n                  <For each={segmentos()} fallback={<option disabled>Nenhum segmento dispon\u00edvel</option>}>\n                    {(seg) => <option value={seg}>{seg}</option>}\n                  </For>\n                </Show>\n              </select>\n            </div>\n            <div>\n              <label class=\"block text-sm font-medium mb-2\">UNE</label>\n              <select\n                class=\"w-full px-3 py-2 bg-background border rounded-lg disabled:opacity-50\"\n                value={selectedUne()}\n                onChange={(e) => setSelectedUne(e.target.value)}\n                disabled={filtersLoading()}\n              >\n                <Show when={!filtersLoading()} fallback={<option>Carregando filtros...</option>}>\n                  <option value=\"\">Todas</option>\n                  <For each={unes()} fallback={<option disabled>Nenhuma UNE dispon\u00edvel</option>}>\n                    {(une) => <option value={une}>{une}</option>}\n                  </For>\n                </Show>\n              </select>\n            </div>\n            <div class=\"flex items-end gap-2\">\n              <button onClick={loadData} class=\"btn btn-primary flex-1\">\n                Aplicar Filtros\n              </button>\n              <button onClick={clearFilters} class=\"btn btn-outline\">\n                <X size={16} />\n              </button>\n            </div>\n          </div>\n        </div>\n      </Show>\n\n      {/* Resumo de M\u00e9tricas */}\n      <div class=\"grid grid-cols-1 md:grid-cols-3 gap-4\">\n        <div class=\"p-4 bg-card border rounded-lg\">\n          <div class=\"flex items-center gap-3\">\n            <div class=\"p-2 bg-red-500/10 rounded-lg\">\n              <PackageX size={24} class=\"text-red-500\" />\n            </div>\n            <div>\n              <p class=\"text-sm text-muted-foreground\">Total de Rupturas</p>\n              <p class=\"text-2xl font-bold\">{summary().total}</p>\n            </div>\n          </div>\n        </div>\n        <div class=\"p-4 bg-card border rounded-lg\">\n          <div class=\"flex items-center gap-3\">\n            <div class=\"p-2 bg-orange-500/10 rounded-lg\">\n              <AlertTriangle size={24} class=\"text-orange-500\" />\n            </div>\n            <div>\n              <p class=\"text-sm text-muted-foreground\">Criticidade Alta (\u226575%)</p>\n              <p class=\"text-2xl font-bold\">{summary().criticos}</p>\n            </div>\n          </div>\n        </div>\n        <div class=\"p-4 bg-card border rounded-lg\">\n          <div class=\"flex items-center gap-3\">\n            <div class=\"p-2 bg-blue-500/10 rounded-lg\">\n              <TrendingUp size={24} class=\"text-blue-500\" />\n            </div>\n            <div>\n              <p class=\"text-sm text-muted-foreground\">Taxa Cr\u00edtica</p>\n              <p class=\"text-2xl font-bold\">\n                {summary().total > 0 ?", "mimetype": "text/plain", "start_char_idx": 18195, "end_char_idx": 22325, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0de7000f-9542-4dfc-89e0-46441c24e90e": {"__data__": {"id_": "0de7000f-9542-4dfc-89e0-46441c24e90e", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Rupturas.tsx", "language": "typescript", "lines": 932, "filename": "Rupturas.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Rupturas.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Rupturas.tsx", "language": "typescript", "lines": 932, "filename": "Rupturas.tsx"}, "hash": "6c3ac5e8d5389ace041363c08de4fb4343002dc0a0ac1e92ea30bb7113d8f379", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "380bf732-80da-472b-85a4-9678851855a0", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Rupturas.tsx", "language": "typescript", "lines": 932, "filename": "Rupturas.tsx"}, "hash": "325416f62bd53cddc0c330dafac8f62a91bbc0ef3a6b737fc8caa93252b3919d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d8b7ea61-33e5-43c7-a2e1-bc9f1558f210", "node_type": "1", "metadata": {}, "hash": "9eea72217c8d5ae70e0ffb2d556783482aeb390cc3bc76cae1663465beb4f100", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "((summary().criticos / summary().total) * 100).toFixed(0) : 0}%\n              </p>\n            </div>\n          </div>\n        </div>\n      </div>\n\n      {/* Explica\u00e7\u00e3o */}\n      <div class=\"p-4 bg-blue-500/5 border border-blue-500/20 rounded-lg\">\n        <h3 class=\"font-semibold text-blue-500 mb-2\">O que \u00e9 Ruptura Cr\u00edtica?</h3>\n        <p class=\"text-sm text-muted-foreground\">\n          Produtos com <strong>estoque no CD zerado (ESTOQUE_CD = 0)</strong> e <strong>estoque da loja abaixo da Linha Verde (ESTOQUE_UNE &lt; ESTOQUE_LV)</strong> que tiveram vendas nos \u00faltimos 30 dias. A criticidade \u00e9 calculada pela raz\u00e3o entre vendas e linha verde.\n        </p>\n      </div>\n\n      {/* Gr\u00e1ficos Interativos */}\n      <Show when={!loading() && data().length > 0}>\n        <div class=\"space-y-6\">\n          {/* Primeira linha - 2 colunas */}\n          <div class=\"grid grid-cols-1 lg:grid-cols-2 gap-6\">\n            {/* Gr\u00e1fico de Pizza - Criticidade */}\n            <div class=\"card p-6 border\">\n              <div class=\"flex justify-between items-center mb-4\">\n                <h3 class=\"font-semibold flex items-center gap-2\">\n                  <PieChart size={20} class=\"text-red-500\" />\n                  Top Grupos em Ruptura\n                </h3>\n                <ChartDownloadButton\n                  chartId=\"criticidade-chart\"\n                  filename=\"rupturas_criticidade\"\n                  label=\"Baixar\"\n                />\n              </div>\n              <PlotlyChart\n                chartSpec={criticidadeChart}\n                chartId=\"criticidade-chart\"\n                enableDownload={true}\n                height=\"350px\"\n                onDataClick={handleGroupClick}\n              />\n              <p class=\"text-xs text-muted mt-2\">\ud83d\udca1 Clique nas barras para ver produtos do grupo</p>\n            </div>\n\n            {/* Gr\u00e1fico de Barras - Top 10 */}\n            <div class=\"card p-6 border\">\n              <div class=\"flex justify-between items-center mb-4\">\n                <h3 class=\"font-semibold flex items-center gap-2\">\n                  <BarChart3 size={20} class=\"text-orange-500\" />\n                  Top 10 Produtos em Ruptura\n                </h3>\n                <ChartDownloadButton\n                  chartId=\"top-rupturas-chart\"\n                  filename=\"rupturas_top10\"\n                  label=\"Baixar\"\n                />\n              </div>\n              <PlotlyChart\n                chartSpec={topRupturasChart}\n                chartId=\"top-rupturas-chart\"\n                enableDownload={true}\n                height=\"350px\"\n                onDataClick={handleChartClick}\n              />\n              <p class=\"text-xs text-muted mt-2\">\ud83d\udca1 Clique nas barras para ver detalhes do produto</p>\n            </div>\n          </div>\n\n          {/* Segunda linha - 1 coluna */}\n          <div class=\"card p-6 border\">\n            <div class=\"flex justify-between items-center mb-4\">\n              <h3 class=\"font-semibold flex items-center gap-2\">\n                <TrendingUp size={20} class=\"text-green-500\" />\n                Necessidade por Segmento\n              </h3>\n              <ChartDownloadButton\n                chartId=\"necessidade-segmento-chart\"\n                filename=\"rupturas_por_segmento\"\n                label=\"Baixar\"\n              />\n            </div>\n            <PlotlyChart\n              chartSpec={necessidadeSegmentoChart}\n              chartId=\"necessidade-segmento-chart\"\n              enableDownload={true}\n              height=\"400px\"\n            />\n          </div>\n        </div>\n      </Show>\n\n      {/* Modal de Detalhes do Produto */}\n      <Show when={selectedProduct()}>\n        <div\n          class=\"fixed inset-0 bg-black/50 flex items-center justify-center z-50 p-4\"\n          onClick={() => setSelectedProduct(null)}\n        >\n          <div\n            class=\"bg-card border rounded-lg p-6 max-w-2xl w-full\"\n            onClick={(e) => e.", "mimetype": "text/plain", "start_char_idx": 22326, "end_char_idx": 26251, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d8b7ea61-33e5-43c7-a2e1-bc9f1558f210": {"__data__": {"id_": "d8b7ea61-33e5-43c7-a2e1-bc9f1558f210", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Rupturas.tsx", "language": "typescript", "lines": 932, "filename": "Rupturas.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Rupturas.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Rupturas.tsx", "language": "typescript", "lines": 932, "filename": "Rupturas.tsx"}, "hash": "6c3ac5e8d5389ace041363c08de4fb4343002dc0a0ac1e92ea30bb7113d8f379", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0de7000f-9542-4dfc-89e0-46441c24e90e", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Rupturas.tsx", "language": "typescript", "lines": 932, "filename": "Rupturas.tsx"}, "hash": "5b807c081d094404d05b4f75087dd9b55f9fafb9ee998740171f36e40cb8d3d2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c00fec59-5025-4d6b-99c9-ce5627118b39", "node_type": "1", "metadata": {}, "hash": "cd50b3f2ea9cd1783b98bb02bdf57a12ae7c54bd8bc04d8b152872ac295c6065", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "stopPropagation()}\n          >\n            <div class=\"flex justify-between items-start mb-4\">\n              <h3 class=\"text-xl font-bold\">Detalhes da Ruptura</h3>\n              <button\n                onClick={() => setSelectedProduct(null)}\n                class=\"text-muted hover:text-foreground\"\n              >\n                <X size={20} />\n              </button>\n            </div>\n\n            <div class=\"space-y-4\">\n              <div>\n                <p class=\"text-sm text-muted\">Produto</p>\n                <p class=\"font-mono font-medium\">{selectedProduct()!.PRODUTO}</p>\n              </div>\n              <div>\n                <p class=\"text-sm text-muted\">Nome</p>\n                <p class=\"font-medium\">{selectedProduct()!.NOME}</p>\n              </div>\n              <div class=\"grid grid-cols-2 gap-4\">\n                <div>\n                  <p class=\"text-sm text-muted\">UNE / Loja</p>\n                  <p class=\"font-medium\">{selectedProduct()!.UNE} - {selectedProduct()!.UNE_NOME || 'N/A'}</p>\n                </div>\n                <div>\n                  <p class=\"text-sm text-muted\">Segmento</p>\n                  <p class=\"font-medium\">{selectedProduct()!.NOMESEGMENTO || 'N/A'}</p>\n                </div>\n              </div>\n              <div class=\"grid grid-cols-3 gap-4\">\n                <div class=\"p-3 bg-green-500/10 border border-green-500/30 rounded\">\n                  <p class=\"text-xs text-muted\">Vendas (30d)</p>\n                  <p class=\"text-xl font-bold text-green-500\">{Math.round(selectedProduct()!.VENDA_30DD)}</p>\n                </div>\n                <div class=\"p-3 bg-red-500/10 border border-red-500/30 rounded\">\n                  <p class=\"text-xs text-muted\">Estoque Loja</p>\n                  <p class=\"text-xl font-bold text-red-500\">{Math.round(selectedProduct()!.ESTOQUE_UNE)}</p>\n                </div>\n                <div class=\"p-3 bg-blue-500/10 border border-blue-500/30 rounded\">\n                  <p class=\"text-xs text-muted\">Linha Verde</p>\n                  <p class=\"text-xl font-bold text-blue-500\">{Math.round(selectedProduct()!.ESTOQUE_LV)}</p>\n                </div>\n              </div>\n              <div class=\"p-4 bg-orange-500/10 border border-orange-500/30 rounded\">\n                <p class=\"text-sm text-muted mb-2\">Necessidade de Reposi\u00e7\u00e3o</p>\n                <p class=\"text-3xl font-bold text-orange-500\">{Math.round(selectedProduct()!.NECESSIDADE)} unidades</p>\n                <div class=\"mt-3\">\n                  <div class=\"flex justify-between text-sm mb-1\">\n                    <span>Criticidade</span>\n                    <span class=\"font-medium\">{selectedProduct()!.CRITICIDADE_PCT.toFixed(0)}%</span>\n                  </div>\n                  <div class=\"w-full bg-gray-700 rounded-full h-2\">\n                    <div\n                      class={`h-2 rounded-full ${selectedProduct()!.CRITICIDADE_PCT >= 75 ? 'bg-red-500' :\n                        selectedProduct()!.CRITICIDADE_PCT >= 50 ? 'bg-orange-500' :\n                          selectedProduct()!.CRITICIDADE_PCT >= 25 ?", "mimetype": "text/plain", "start_char_idx": 26251, "end_char_idx": 29333, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c00fec59-5025-4d6b-99c9-ce5627118b39": {"__data__": {"id_": "c00fec59-5025-4d6b-99c9-ce5627118b39", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Rupturas.tsx", "language": "typescript", "lines": 932, "filename": "Rupturas.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Rupturas.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Rupturas.tsx", "language": "typescript", "lines": 932, "filename": "Rupturas.tsx"}, "hash": "6c3ac5e8d5389ace041363c08de4fb4343002dc0a0ac1e92ea30bb7113d8f379", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d8b7ea61-33e5-43c7-a2e1-bc9f1558f210", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Rupturas.tsx", "language": "typescript", "lines": 932, "filename": "Rupturas.tsx"}, "hash": "afa393d2ec39d123b2773693edfef5364a18a009156eb1aa74293c0c9666f9f1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f5ef7da5-b3f3-4740-9367-54388e71585b", "node_type": "1", "metadata": {}, "hash": "cdf3d3f44d946a4d160fb41f5514e5b6eff7dfa64b0aeab283044356497af0b4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "'bg-yellow-500' : 'bg-blue-500'\n                        }`}\n                      style={`width: ${selectedProduct()!.CRITICIDADE_PCT}%`}\n                    />\n                  </div>\n                </div>\n              </div>\n            </div>\n\n            <div class=\"mt-6 flex justify-end\">\n              <button\n                onClick={() => setSelectedProduct(null)}\n                class=\"btn btn-primary\"\n              >\n                Fechar\n              </button>\n            </div>\n          </div>\n        </div>\n      </Show>\n\n      {/* Modal Drill-Down - Produtos do Grupo Selecionado */}\n      <Show when={selectedGroup()}>\n        <div class=\"fixed inset-0 bg-black/60 flex items-center justify-center z-[9998] p-4\" onClick={(e) => e.target === e.currentTarget && setSelectedGroup(null)}>\n          <div class=\"bg-background rounded-xl shadow-xl max-w-4xl w-full max-h-[85vh] overflow-hidden animate-in fade-in zoom-in-95 duration-200\">\n            {/* Header */}\n            <div class=\"p-4 border-b bg-gradient-to-r from-red-500/10 to-orange-500/10\">\n              <div class=\"flex justify-between items-center\">\n                <div>\n                  <h3 class=\"text-xl font-bold flex items-center gap-2\">\n                    <Package size={24} class=\"text-red-500\" />\n                    Produtos em Ruptura: {selectedGroup()}\n                  </h3>\n                  <p class=\"text-sm text-muted mt-1\">\n                    {getProductsByGroup().length} produtos | {getProductsByGroup().filter(p => p.CRITICIDADE_PCT >= 75).length} cr\u00edticos\n                  </p>\n                </div>\n                <button onClick={() => setSelectedGroup(null)} class=\"p-2 hover:bg-muted rounded-full\">\n                  <X size={20} />\n                </button>\n              </div>\n            </div>\n\n            {/* Tabela de Produtos */}\n            <div class=\"overflow-auto max-h-[60vh] p-4\">\n              <table class=\"w-full text-sm\">\n                <thead class=\"sticky top-0 bg-background\">\n                  <tr class=\"border-b\">\n                    <th class=\"text-left p-2 font-semibold\">C\u00f3digo</th>\n                    <th class=\"text-left p-2 font-semibold\">Produto</th>\n                    <th class=\"text-left p-2 font-semibold\">UNE / Loja</th>\n                    <th class=\"text-right p-2 font-semibold\">Criticidade</th>\n                    <th class=\"text-right p-2 font-semibold\">Necessidade</th>\n                    <th class=\"text-right p-2 font-semibold\">Venda 30d</th>\n                    <th class=\"text-right p-2 font-semibold\">Estoque</th>\n                  </tr>\n                </thead>\n                <tbody>\n                  <For each={getProductsByGroup()}>\n                    {(produto) => (\n                      <tr class=\"border-b hover:bg-muted/50 transition-colors\">\n                        <td class=\"p-2 font-mono text-xs\">{produto.PRODUTO}</td>\n                        <td class=\"p-2 max-w-[200px] truncate\" title={produto.NOME}>{produto.NOME}</td>\n                        <td class=\"p-2\">\n                          <div class=\"flex flex-col\">\n                            <span class=\"text-xs font-mono\">{produto.UNE}</span>\n                            <span class=\"text-[10px] text-muted-foreground truncate max-w-[100px]\" title={produto.UNE_NOME}>{produto.UNE_NOME}</span>\n                          </div>\n                        </td>\n                        <td class=\"p-2 text-right\">\n                          <span class={`px-2 py-0.5 rounded text-xs font-bold ${produto.CRITICIDADE_PCT >= 75 ? 'bg-red-500/20 text-red-500' :\n                            produto.CRITICIDADE_PCT >= 50 ? 'bg-orange-500/20 text-orange-500' :\n                              produto.CRITICIDADE_PCT >= 25 ?", "mimetype": "text/plain", "start_char_idx": 29334, "end_char_idx": 33089, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f5ef7da5-b3f3-4740-9367-54388e71585b": {"__data__": {"id_": "f5ef7da5-b3f3-4740-9367-54388e71585b", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Rupturas.tsx", "language": "typescript", "lines": 932, "filename": "Rupturas.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Rupturas.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Rupturas.tsx", "language": "typescript", "lines": 932, "filename": "Rupturas.tsx"}, "hash": "6c3ac5e8d5389ace041363c08de4fb4343002dc0a0ac1e92ea30bb7113d8f379", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c00fec59-5025-4d6b-99c9-ce5627118b39", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Rupturas.tsx", "language": "typescript", "lines": 932, "filename": "Rupturas.tsx"}, "hash": "a1a06c67e73f93a76eb5a48829889b15f163a6aa3fc37dde3892bd3988778b66", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "59df1047-3596-4f74-9533-dc994a2ee903", "node_type": "1", "metadata": {}, "hash": "ca3f03ded373aa0bef43ad48177310259cfb36066f7a7650d28c0425e0af369e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "'bg-yellow-500/20 text-yellow-500' :\n                                'bg-blue-500/20 text-blue-500'\n                            }`}>\n                            {produto.CRITICIDADE_PCT.toFixed(0)}%\n                          </span>\n                        </td>\n                        <td class=\"p-2 text-right font-semibold text-red-500\">{Math.round(produto.NECESSIDADE)} un</td>\n                        <td class=\"p-2 text-right\">{produto.VENDA_30DD}</td>\n                        <td class=\"p-2 text-right text-muted\">{produto.ESTOQUE_UNE} / {produto.ESTOQUE_LV}</td>\n                      </tr>\n                    )}\n                  </For>\n                </tbody>\n              </table>\n\n              <Show when={getProductsByGroup().length === 0}>\n                <div class=\"text-center py-8 text-muted\">\n                  <Package size={48} class=\"mx-auto mb-2 opacity-50\" />\n                  <p>Nenhum produto encontrado para este grupo</p>\n                </div>\n              </Show>\n            </div>\n\n            {/* Footer */}\n            <div class=\"p-4 border-t flex justify-between items-center bg-muted/30\">\n              <div class=\"text-sm text-muted\">\n                Necessidade total: <strong class=\"text-red-500\">{Math.round(getProductsByGroup().reduce((sum, p) => sum + p.NECESSIDADE, 0))} un</strong>\n              </div>\n              <button\n                onClick={() => setSelectedGroup(null)}\n                class=\"btn btn-primary\"\n              >\n                Fechar\n              </button>\n            </div>\n          </div>\n        </div>\n      </Show>\n\n      {/* Tabela */}\n      <Show when={!loading()} fallback={\n        <div class=\"p-12 text-center border rounded-xl bg-card text-muted animate-pulse\">\n          <PackageX class=\"animate-spin mx-auto mb-4\" size={32} />\n          Identificando rupturas cr\u00edticas...\n        </div>\n      }>\n        <Show when={!error()} fallback={\n          <div class=\"p-6 bg-red-900/10 border border-red-900/30 rounded-lg text-red-300 flex items-center gap-3\">\n            <AlertTriangle size={24} />\n            <div>\n              <h3 class=\"font-bold\">Erro ao carregar dados</h3>\n              <p class=\"text-sm opacity-80\">{error()}</p>\n            </div>\n          </div>\n        }>\n          <Show when={data().length > 0} fallback={\n            <div class=\"p-12 text-center border border-dashed rounded-xl text-muted\">\n              <Package size={48} class=\"mx-auto mb-4 opacity-20 text-green-500\" />\n              <p class=\"text-lg font-medium text-green-500\">Nenhuma ruptura cr\u00edtica detectada!</p>\n              <p class=\"text-sm mt-2\">Todos os produtos de alta venda possuem estoque adequado.</p>\n            </div>\n          }>\n            <div class=\"border rounded-lg overflow-hidden bg-card shadow-sm\">\n              <div class=\"overflow-x-auto\">\n                <table class=\"w-full text-sm text-left\">\n                  <thead class=\"bg-muted/50 text-xs uppercase font-medium text-muted-foreground border-b\">\n                    <tr>\n                      <th class=\"px-4 py-3\">Produto</th>\n                      <th class=\"px-4 py-3\">UNE</th>\n                      <th class=\"px-4 py-3 text-right\">Venda (30d)</th>\n                      <th class=\"px-4 py-3 text-right\">Est. Loja</th>\n                      <th class=\"px-4 py-3 text-right\">Est.", "mimetype": "text/plain", "start_char_idx": 33090, "end_char_idx": 36436, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "59df1047-3596-4f74-9533-dc994a2ee903": {"__data__": {"id_": "59df1047-3596-4f74-9533-dc994a2ee903", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Rupturas.tsx", "language": "typescript", "lines": 932, "filename": "Rupturas.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Rupturas.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Rupturas.tsx", "language": "typescript", "lines": 932, "filename": "Rupturas.tsx"}, "hash": "6c3ac5e8d5389ace041363c08de4fb4343002dc0a0ac1e92ea30bb7113d8f379", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f5ef7da5-b3f3-4740-9367-54388e71585b", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Rupturas.tsx", "language": "typescript", "lines": 932, "filename": "Rupturas.tsx"}, "hash": "daf4b91f2282e3ac7db3129b5de3739de989de0ac23666bcbe27e2564550577d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "CD</th>\n                      <th class=\"px-4 py-3 text-right\">Linha Verde</th>\n                      <th class=\"px-4 py-3 text-right\">Necessidade</th>\n                      <th class=\"px-4 py-3 text-center\">Criticidade</th>\n                    </tr>\n                  </thead>\n                  <tbody class=\"divide-y\">\n                    <For each={data()}>\n                      {(item) => (\n                        <tr class=\"hover:bg-muted/30 transition-colors\">\n                          <td class=\"px-4 py-3\">\n                            <div class=\"font-medium\">{item.NOME}</div>\n                            <div class=\"text-xs text-muted-foreground font-mono\">{item.PRODUTO}</div>\n                          </td>\n                          <td class=\"px-4 py-3\">\n                            <div class=\"flex flex-col\">\n                              <span class=\"px-2 py-1 bg-secondary rounded text-xs font-mono w-fit\">{item.UNE}</span>\n                              <span class=\"text-[10px] text-muted-foreground mt-1 truncate max-w-[120px]\" title={item.UNE_NOME}>{item.UNE_NOME}</span>\n                            </div>\n                          </td>\n                          <td class=\"px-4 py-3 text-right font-medium\">\n                            <div class=\"flex items-center justify-end gap-1 text-green-500\">\n                              <ShoppingCart size={14} />\n                              {Math.round(item.VENDA_30DD)}\n                            </div>\n                          </td>\n                          <td class=\"px-4 py-3 text-right font-medium text-red-500\">\n                            <div class=\"flex items-center justify-end gap-1\">\n                              <Archive size={14} />\n                              {Math.round(item.ESTOQUE_UNE)}\n                            </div>\n                          </td>\n                          <td class=\"px-4 py-3 text-right font-medium text-red-500\">\n                            {Math.round(item.ESTOQUE_CD)}\n                          </td>\n                          <td class=\"px-4 py-3 text-right font-medium text-blue-500\">\n                            {Math.round(item.ESTOQUE_LV)}\n                          </td>\n                          <td class=\"px-4 py-3 text-right font-bold text-orange-500\">\n                            {Math.round(item.NECESSIDADE)} un\n                          </td>\n                          <td class=\"px-4 py-3 text-center\">\n                            <div class=\"flex flex-col items-center gap-1\">\n                              <span class={`px-2 py-1 rounded-full text-xs font-bold border ${getCriticidadeColor(item.CRITICIDADE_PCT)}`}>\n                                {getCriticidadeLabel(item.CRITICIDADE_PCT)}\n                              </span>\n                              <div class=\"w-full bg-gray-700 rounded-full h-1.5 mt-1\">\n                                <div\n                                  class={`h-1.5 rounded-full ${item.CRITICIDADE_PCT >= 75 ? 'bg-red-500' : item.CRITICIDADE_PCT >= 50 ? 'bg-orange-500' : item.CRITICIDADE_PCT >= 25 ? 'bg-yellow-500' : 'bg-blue-500'}`}\n                                  style={`width: ${item.CRITICIDADE_PCT}%`}\n                                />\n                              </div>\n                              <span class=\"text-xs text-muted-foreground\">{item.CRITICIDADE_PCT.toFixed(0)}%</span>\n                            </div>\n                          </td>\n                        </tr>\n                      )}\n                    </For>\n                  </tbody>\n                </table>\n              </div>\n            </div>\n          </Show>\n        </Show>\n      </Show>\n    </div>\n  );\n}", "mimetype": "text/plain", "start_char_idx": 36437, "end_char_idx": 40125, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "6438fd4d-7c87-465b-8977-2d4c620bd58d": {"__data__": {"id_": "6438fd4d-7c87-465b-8977-2d4c620bd58d", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\SharedConversation.tsx", "language": "typescript", "lines": 156, "filename": "SharedConversation.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\SharedConversation.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\SharedConversation.tsx", "language": "typescript", "lines": 156, "filename": "SharedConversation.tsx"}, "hash": "ab1b4db2a750c56cc0c2bc85d3962b55f51a3705b63d171fa879c6c59fb276e6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "dafb873a-3fb0-4fdf-bfae-dde13420719a", "node_type": "1", "metadata": {}, "hash": "b82623065008e6376f50c1cbd7901258b9428fd86975bb728bab99cb28eca017", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import { createSignal, onMount, For, Show } from 'solid-js';\nimport { useParams } from '@solidjs/router';\n// Removido solid-markdown devido a problemas de compatibilidade ESM\nimport { formatTimestamp } from '@/lib/formatters';\nimport 'github-markdown-css/github-markdown.css';\nimport './chat-markdown.css';\n\ninterface Message {\n  role: string;\n  text: string;\n  timestamp: number;\n}\n\ninterface SharedConversationData {\n  share_id: string;\n  title: string | null;\n  messages: Message[];\n  created_at: string;\n  view_count: number;\n}\n\nexport default function SharedConversation() {\n  const params = useParams();\n  const [conversation, setConversation] = createSignal<SharedConversationData | null>(null);\n  const [loading, setLoading] = createSignal(true);\n  const [error, setError] = createSignal('');\n\n  onMount(async () => {\n    const shareId = params.share_id;\n    if (!shareId) {\n      setError('ID de compartilhamento inv\u00e1lido');\n      setLoading(false);\n      return;\n    }\n\n    try {\n      const response = await fetch(`/api/v1/shared/${shareId}`);\n\n      if (!response.ok) {\n        if (response.status === 404) {\n          setError('Esta conversa n\u00e3o foi encontrada.');\n        } else if (response.status === 410) {\n          setError('Esta conversa expirou ou n\u00e3o est\u00e1 mais dispon\u00edvel.');\n        } else {\n          setError('Erro ao carregar conversa compartilhada.');\n        }\n        setLoading(false);\n        return;\n      }\n\n      const data = await response.json();\n      setConversation(data);\n    } catch (err) {\n      console.error('Error loading shared conversation:', err);\n      setError('Erro ao carregar conversa compartilhada.');\n    } finally {\n      setLoading(false);\n    }\n  });\n\n  return (\n    <div class=\"flex flex-col h-full max-w-4xl mx-auto\">\n      {/* Header */}\n      <div class=\"p-4 border-b bg-background/50 backdrop-blur\">\n        <div class=\"flex items-center justify-between\">\n          <div>\n            <h2 class=\"text-lg font-semibold\">\n              {conversation()?.title || 'Conversa Compartilhada'}\n            </h2>\n            <Show when={conversation()}>\n              <p class=\"text-sm text-muted-foreground mt-1\">\n                Compartilhado em {new Date(conversation()!.created_at).toLocaleDateString('pt-BR')}\n                {' \u2022 '}\n                {conversation()!.view_count} visualiza{conversation()!.view_count === 1 ? '\u00e7\u00e3o' : '\u00e7\u00f5es'}\n              </p>\n            </Show>\n          </div>\n          <a\n            href=\"/\"\n            class=\"btn btn-primary\"\n          >\n            Criar minha conversa\n          </a>\n        </div>\n      </div>\n\n      {/* Content */}\n      <div class=\"flex-1 overflow-y-auto p-6 space-y-6\">\n        <Show when={loading()}>\n          <div class=\"flex items-center justify-center h-full\">\n            <div class=\"text-center\">\n              <div class=\"animate-spin rounded-full h-12 w-12 border-b-2 border-primary mx-auto mb-4\"></div>\n              <p class=\"text-muted-foreground\">Carregando conversa...</p>\n            </div>\n          </div>\n        </Show>\n\n        <Show when={error()}>\n          <div class=\"flex items-center justify-center h-full\">\n            <div class=\"text-center max-w-md\">\n              <div class=\"text-6xl mb-4\">\u26a0\ufe0f</div>\n              <h3 class=\"text-xl font-semibold mb-2\">Ops!</h3>\n              <p class=\"text-muted-foreground mb-6\">{error()}</p>\n              <a href=\"/\" class=\"btn btn-primary\">\n                Ir para p\u00e1gina inicial\n              </a>\n            </div>\n          </div>\n        </Show>\n\n        <Show when={!loading() && !error() && conversation()}>\n          <div class=\"space-y-4\">\n            <div class=\"p-4 rounded-lg bg-muted/50 border\">\n              <p class=\"text-sm text-muted-foreground\">\n                \u2139\ufe0f Esta \u00e9 uma visualiza\u00e7\u00e3o somente leitura de uma conversa compartilhada do Chat BI.\n                Voc\u00ea n\u00e3o pode interagir ou continuar esta conversa.\n              </p>\n            </div>\n\n            <For each={conversation()!.messages}>\n              {(msg) => (\n                <div class={`flex ${msg.role === 'user' ?", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4098, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "dafb873a-3fb0-4fdf-bfae-dde13420719a": {"__data__": {"id_": "dafb873a-3fb0-4fdf-bfae-dde13420719a", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\SharedConversation.tsx", "language": "typescript", "lines": 156, "filename": "SharedConversation.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\SharedConversation.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\SharedConversation.tsx", "language": "typescript", "lines": 156, "filename": "SharedConversation.tsx"}, "hash": "ab1b4db2a750c56cc0c2bc85d3962b55f51a3705b63d171fa879c6c59fb276e6", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6438fd4d-7c87-465b-8977-2d4c620bd58d", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\SharedConversation.tsx", "language": "typescript", "lines": 156, "filename": "SharedConversation.tsx"}, "hash": "6cc28a1a34834f11410c31e05d71c281553f580579b4a81792ba19ad46054c34", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "'justify-end' : 'justify-start'}`}>\n                  <div\n                    class={`max-w-[80%] rounded-lg p-4 text-sm leading-relaxed shadow-sm ${msg.role === 'user'\n                        ? 'bg-primary text-primary-foreground'\n                        : 'bg-card border text-card-foreground'\n                      }`}\n                  >\n                    <div class=\"markdown-body\" style=\"white-space: pre-wrap;\">\n                      {msg.text}\n                    </div>\n                    <div class=\"text-xs text-muted-foreground mt-2 opacity-70\">\n                      {formatTimestamp(msg.timestamp)}\n                    </div>\n                  </div>\n                </div>\n              )}\n            </For>\n          </div>\n        </Show>\n      </div>\n\n      {/* Footer */}\n      <div class=\"p-4 border-t bg-background/50 backdrop-blur text-center\">\n        <p class=\"text-sm text-muted-foreground\">\n          Powered by <span class=\"font-semibold text-foreground\">Chat BI</span>\n          {' \u2022 '}\n          <a href=\"/\" class=\"text-primary hover:underline\">\n            Criar sua pr\u00f3pria conversa\n          </a>\n        </p>\n      </div>\n    </div>\n  );\n}", "mimetype": "text/plain", "start_char_idx": 4099, "end_char_idx": 5276, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d624885c-e0aa-4f3f-9f3a-043b488c8f45": {"__data__": {"id_": "d624885c-e0aa-4f3f-9f3a-043b488c8f45", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Transfers.tsx", "language": "typescript", "lines": 781, "filename": "Transfers.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Transfers.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Transfers.tsx", "language": "typescript", "lines": 781, "filename": "Transfers.tsx"}, "hash": "ed1053a56baec267223bd6f172dfcc8c974cdd96419bc89bb406804f2ceabe4f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c6142bd0-013d-4841-9d91-a9260c8bc7c0", "node_type": "1", "metadata": {}, "hash": "6d14708a0024cc9027f3a97f3fcacfc65cdd04344e1fba153d6f23f882456319", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import { createSignal, createEffect, onMount, For, Show } from 'solid-js';\nimport { createStore } from 'solid-js/store';\nimport { Truck, Search, Plus, Trash2, ShoppingCart, AlertTriangle, CheckCircle, Package, ArrowRight } from 'lucide-solid';\nimport api from '../lib/api';\n\n// Types\ntype TransferMode = 'UNE - UNE' | 'UNE - UNES' | 'UNES - UNES';\n\ninterface Product {\n  produto_id: number;\n  nome: string;\n  segmento: string;\n  fabricante: string;\n  estoque_loja: number;\n  estoque_cd: number;\n  vendas_30dd: number;\n  unes: number;\n}\n\ninterface UNE {\n  une: number;\n  total_produtos: number;\n  estoque_total: number;\n}\n\ninterface CartItem {\n  produto_id: number;\n  produto_nome: string;\n  une_origem: number;\n  une_destino: number[];\n  quantidade: number;\n  score?: number;\n  nivel_urgencia?: string;\n}\n\ninterface ValidationResult {\n  status: string;\n  mensagem: string;\n  score_prioridade?: number;\n  nivel_urgencia?: string;\n}\n\nexport default function Transfers() {\n  // Estado principal\n  const [mode, setMode] = createSignal<TransferMode>('1\u21921');\n  const [unes, setUnes] = createSignal<UNE[]>([]);\n  const [products, setProducts] = createSignal<Product[]>([]);\n  const [cart, setCart] = createStore<{ items: CartItem[] }>({ items: [] });\n\n  // Filtros dispon\u00edveis\n  const [availableSegmentos, setAvailableSegmentos] = createSignal<string[]>([]);\n  const [availableFabricantes, setAvailableFabricantes] = createSignal<string[]>([]);\n\n  // Filtros de busca\n  const [searchSegmento, setSearchSegmento] = createSignal('');\n  const [searchFabricante, setSearchFabricante] = createSignal('');\n  const [searchEstoqueMin, setSearchEstoqueMin] = createSignal<number | ''>('');\n\n  // Sele\u00e7\u00e3o de produto/UNE para adicionar ao carrinho\n  const [selectedProducts, setSelectedProducts] = createSignal<Product[]>([]);\n  const [selectedUneOrigem, setSelectedUneOrigem] = createSignal<number | ''>('');\n  const [selectedUnesOrigem, setSelectedUnesOrigem] = createSignal<number[]>([]);\n  const [selectedUnesDestino, setSelectedUnesDestino] = createSignal<number[]>([]);\n  const [quantidade, setQuantidade] = createSignal<number | ''>('');\n\n  // Estados UI\n  const [loading, setLoading] = createSignal(false);\n  const [searching, setSearching] = createSignal(false);\n  const [validating, setValidating] = createSignal(false);\n  const [creating, setCreating] = createSignal(false);\n  const [error, setError] = createSignal<string | null>(null);\n  const [success, setSuccess] = createSignal<string | null>(null);\n  const [validationResult, setValidationResult] = createSignal<ValidationResult | null>(null);\n\n  // Toggle selection of a product\n  const toggleProductSelection = (product: Product) => {\n    const current = selectedProducts();\n    const exists = current.find(p => p.produto_id === product.produto_id);\n    \n    if (exists) {\n      setSelectedProducts(current.filter(p => p.produto_id !== product.produto_id));\n    } else {\n      setSelectedProducts([...current, product]);\n    }\n  };\n\n  // Carregar filtros dispon\u00edveis\n  const loadFilters = async (segmento?: string) => {\n    try {\n      const params = segmento ?", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3112, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c6142bd0-013d-4841-9d91-a9260c8bc7c0": {"__data__": {"id_": "c6142bd0-013d-4841-9d91-a9260c8bc7c0", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Transfers.tsx", "language": "typescript", "lines": 781, "filename": "Transfers.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Transfers.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Transfers.tsx", "language": "typescript", "lines": 781, "filename": "Transfers.tsx"}, "hash": "ed1053a56baec267223bd6f172dfcc8c974cdd96419bc89bb406804f2ceabe4f", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d624885c-e0aa-4f3f-9f3a-043b488c8f45", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Transfers.tsx", "language": "typescript", "lines": 781, "filename": "Transfers.tsx"}, "hash": "2ce3cac77b86341b2a7b0a137f45014702e6ccd5206ac7174bedf2913b9aeb59", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "227e8903-dc3c-4111-94ee-2e9151cd9709", "node_type": "1", "metadata": {}, "hash": "a3b25a29c9f27e83963451ef2c07c3661b7705222c3134241d5352ba554e1fa6", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": ": string) => {\n    try {\n      const params = segmento ? { segmento } : {};\n      const response = await api.get<{ segmentos: string[]; fabricantes: string[] }>('/transfers/filters', { params });\n      \n      // Se n\u00e3o tem segmento filtrado (inicializa\u00e7\u00e3o), carrega lista completa de segmentos\n      if (!segmento) {\n        setAvailableSegmentos(response.data.segmentos);\n      }\n      // Sempre atualiza fabricantes baseado no filtro (ou falta dele)\n      setAvailableFabricantes(response.data.fabricantes);\n    } catch (err: any) {\n      console.error('Erro ao carregar filtros:', err);\n    }\n  };\n\n  // Carregar UNEs dispon\u00edveis\n  const loadUnes = async () => {\n    try {\n      const response = await api.get<UNE[]>('/transfers/unes');\n      setUnes(response.data);\n      \n      // Context7 Best Practice: Auto-select if only one option is available\n      if (response.data.length === 1) {\n        const singleUne = response.data[0].une;\n        // Apply selection based on current mode\n        if (mode() === 'N\u2192N') {\n          // Only select if empty to avoid overwriting user choice during reloads (if any)\n          if (selectedUnesOrigem().length === 0) {\n            setSelectedUnesOrigem([singleUne]);\n          }\n        } else {\n          // Modes 1\u21921 and 1\u2192N\n          if (!selectedUneOrigem()) {\n            setSelectedUneOrigem(singleUne);\n          }\n        }\n      }\n    } catch (err: any) {\n      console.error('Erro ao carregar UNEs:', err);\n    }\n  };\n\n  // Re-apply auto-selection when mode changes, if applicable\n  createEffect(() => {\n    const currentUnes = unes();\n    if (currentUnes.length === 1) {\n        const singleUne = currentUnes[0].une;\n        if (mode() === 'UNES - UNES') {\n          if (selectedUnesOrigem().length === 0) setSelectedUnesOrigem([singleUne]);\n        } else {\n          // Modes UNE - UNE and UNE - UNES\n          if (!selectedUneOrigem()) {\n            setSelectedUneOrigem(singleUne);\n          }\n        }\n    }\n  });\n\n  // Buscar produtos\n  const searchProducts = async () => {\n    setSearching(true);\n    setError(null);\n    try {\n      const response = await api.post<Product[]>('/transfers/products/search', {\n        segmento: searchSegmento() || undefined,\n        fabricante: searchFabricante() || undefined,\n        estoque_min: searchEstoqueMin() || undefined,\n        limit: 50\n      });\n      setProducts(response.data);\n    } catch (err: any) {\n      setError(err.response?.data?.detail || 'Erro ao buscar produtos');\n    } finally {\n      setSearching(false);\n    }\n  };\n\n  // Adicionar item ao carrinho\n  const addToCart = async () => {\n    // Validar sele\u00e7\u00f5es baseado no modo\n    const selectedOrigens = mode() === 'UNES - UNES' ? selectedUnesOrigem() : selectedUneOrigem() ?", "mimetype": "text/plain", "start_char_idx": 3056, "end_char_idx": 5805, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "227e8903-dc3c-4111-94ee-2e9151cd9709": {"__data__": {"id_": "227e8903-dc3c-4111-94ee-2e9151cd9709", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Transfers.tsx", "language": "typescript", "lines": 781, "filename": "Transfers.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Transfers.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Transfers.tsx", "language": "typescript", "lines": 781, "filename": "Transfers.tsx"}, "hash": "ed1053a56baec267223bd6f172dfcc8c974cdd96419bc89bb406804f2ceabe4f", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c6142bd0-013d-4841-9d91-a9260c8bc7c0", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Transfers.tsx", "language": "typescript", "lines": 781, "filename": "Transfers.tsx"}, "hash": "9dc7262c087b3cb08a3f19aaa95cf6d73ab4c4b96da881d6aa457714e21b3e3a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7c77cd20-527a-49ff-83e1-3e3b5356ab81", "node_type": "1", "metadata": {}, "hash": "35d873034e7e5c00d43e97ebc59d597453739e37f10acc1b254df103ce5bf749", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "selectedUnesOrigem() : selectedUneOrigem() ? [selectedUneOrigem() as number] : [];\n    \n    if (selectedProducts().length === 0 || selectedOrigens.length === 0 || selectedUnesDestino().length === 0 || !quantidade()) {\n      setError(`Preencha todos os campos para adicionar ao carrinho (Modo ${mode()})`);\n      return;\n    }\n\n    const qtd = quantidade() as number;\n    setValidating(true);\n    \n    try {\n      const allNewItems: CartItem[] = [];\n      const firstOrigem = selectedOrigens[0];\n      const firstDestino = selectedUnesDestino()[0];\n\n      // Validate and create items for EACH selected product\n      const promises = selectedProducts().map(async (product) => {\n          const validationResponse = await api.post<ValidationResult>('/transfers/validate', {\n            produto_id: product.produto_id,\n            une_origem: firstOrigem,\n            une_destino: firstDestino,\n            quantidade: qtd,\n            solicitante_id: 'temp'\n          });\n\n          return selectedOrigens.map(origem => ({\n            produto_id: product.produto_id,\n            produto_nome: product.nome,\n            une_origem: origem,\n            une_destino: selectedUnesDestino(),\n            quantidade: qtd,\n            score: validationResponse.data.score_prioridade,\n            nivel_urgencia: validationResponse.data.nivel_urgencia\n          }));\n      });\n\n      const results = await Promise.all(promises);\n      results.forEach(items => allNewItems.push(...items));\n\n      setCart('items', [...cart.items, ...allNewItems]);\n      setSuccess(`${allNewItems.length} item(ns) adicionado(s) ao carrinho!`);\n\n      // Limpar sele\u00e7\u00e3o\n      setSelectedProducts([]);\n      setSelectedUneOrigem('');\n      setSelectedUnesOrigem([]);\n      setSelectedUnesDestino([]);\n      setQuantidade('');\n      setValidationResult(null);\n\n      setTimeout(() => setSuccess(null), 3000);\n    } catch (err: any) {\n      setError(err.response?.data?.detail || 'Erro ao validar transfer\u00eancia');\n    } finally {\n      setValidating(false);\n    }\n  };\n\n  // Remover item do carrinho\n  const removeFromCart = (index: number) => {\n    setCart('items', cart.items.filter((_, i) => i !== index));\n  };\n\n  // Limpar carrinho\n  const clearCart = () => {\n    setCart('items', []);\n    setSuccess('Carrinho limpo!');\n    setTimeout(() => setSuccess(null), 2000);\n  };\n\n  // Gerar solicita\u00e7\u00e3o\n  const generateRequest = async () => {\n    if (cart.items.length === 0) {\n      setError('Carrinho vazio! Adicione itens primeiro.');\n      return;\n    }\n\n    setCreating(true);\n    setError(null);\n\n    try {\n      // Preparar payload baseado no modo\n      const transfers = [];\n\n      for (const item of cart.items) {\n        for (const destino of item.une_destino) {\n          transfers.push({\n            produto_id: item.produto_id,\n            une_origem: item.une_origem,\n            une_destino: destino,\n            quantidade: item.quantidade,\n            solicitante_id: 'temp'\n          });\n        }\n      }\n\n      if (mode() === 'UNE - UNE' && transfers.length === 1) {\n        // Transfer\u00eancia simples\n        const response = await api.post('/transfers', transfers[0]);\n        setSuccess(`Solicita\u00e7\u00e3o criada! ID: ${response.data.transfer_id}`);\n      } else {\n        // Transfer\u00eancia em massa\n        const response = await api.post('/transfers/bulk', {\n          items: transfers,\n          modo: mode()\n        });\n        setSuccess(`Lote criado!", "mimetype": "text/plain", "start_char_idx": 5761, "end_char_idx": 9197, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7c77cd20-527a-49ff-83e1-3e3b5356ab81": {"__data__": {"id_": "7c77cd20-527a-49ff-83e1-3e3b5356ab81", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Transfers.tsx", "language": "typescript", "lines": 781, "filename": "Transfers.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Transfers.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Transfers.tsx", "language": "typescript", "lines": 781, "filename": "Transfers.tsx"}, "hash": "ed1053a56baec267223bd6f172dfcc8c974cdd96419bc89bb406804f2ceabe4f", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "227e8903-dc3c-4111-94ee-2e9151cd9709", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Transfers.tsx", "language": "typescript", "lines": 781, "filename": "Transfers.tsx"}, "hash": "d351f2621464743c2553106b963da46ab1d20674db7bf00e3a593a04b0eeb55e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "be6c5c84-d247-440f-86fd-c2fda235a08c", "node_type": "1", "metadata": {}, "hash": "19af97aca0ec919fac69c88721dc2cc1c5bcb7f719a954f10033cc0c29c57957", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "ID: ${response.data.batch_id} (${transfers.length} transfer\u00eancias)`);\n      }\n\n      // Limpar carrinho\n      setCart('items', []);\n\n    } catch (err: any) {\n      setError(err.response?.data?.detail || 'Erro ao criar solicita\u00e7\u00e3o');\n    } finally {\n      setCreating(false);\n    }\n  };\n\n  // Limpar sele\u00e7\u00f5es ao mudar modo\n  createEffect(() => {\n    mode(); // Dependency on mode changes\n    setSelectedUneOrigem('');\n    setSelectedUnesOrigem([]);\n    setSelectedUnesDestino([]);\n    setSelectedProducts([]);\n    setValidationResult(null);\n  });\n\n  onMount(() => {\n    loadFilters();\n    loadUnes();\n    searchProducts();\n  });\n\n  // Atualizar filtros (fabricantes) quando segmento mudar\n  createEffect(() => {\n    loadFilters(searchSegmento());\n  });\n\n  // Auto-buscar ao mudar filtros\n  createEffect(() => {\n    if (searchSegmento() || searchFabricante() || searchEstoqueMin()) {\n      searchProducts();\n    }\n  });\n\n  const getUrgencyColor = (nivel?: string) => {\n    switch (nivel) {\n      case 'URGENTE': return 'text-red-500';\n      case 'ALTA': return 'text-orange-500';\n      case 'M\u00c9DIA': return 'text-yellow-500';\n      case 'BAIXA': return 'text-green-500';\n      default: return 'text-gray-500';\n    }\n  };\n\n  return (\n    <div class=\"flex flex-col h-full p-6 gap-6\">\n      {/* Header */}\n      <div>\n        <h2 class=\"text-2xl font-bold\">Sistema de Transfer\u00eancias</h2>\n        <p class=\"text-muted\">Gerencie transfer\u00eancias de produtos entre UNEs</p>\n      </div>\n\n      {/* Error/Success Messages */}\n      <Show when={error()}>\n        <div class=\"card p-4 border-red-500 bg-red-500/10\">\n          <div class=\"flex items-center gap-2 text-red-500\">\n            <AlertTriangle size={20} />\n            <span>{error()}</span>\n          </div>\n        </div>\n      </Show>\n\n      <Show when={success()}>\n        <div class=\"card p-4 border-green-500 bg-green-500/10\">\n          <div class=\"flex items-center gap-2 text-green-500\">\n            <CheckCircle size={20} />\n            <span>{success()}</span>\n          </div>\n        </div>\n      </Show>\n\n      {/* Mode Selection & UNE Origin/Destination Filters */}\n      <div class=\"card p-4 border\">\n        <div class=\"space-y-4\">\n          {/* Mode Selection */}\n          <div>\n            <label class=\"text-sm font-medium mb-3 block\">Modo de Transfer\u00eancia</label>\n            <div class=\"flex gap-2\">\n              <button\n                class={`btn ${mode() === 'UNE - UNE' ? 'btn-primary' : 'btn-outline'}`}\n                onClick={() => setMode('UNE - UNE')}\n              >\n                UNE - UNE (Simples)\n              </button>\n              <button\n                class={`btn ${mode() === 'UNE - UNES' ? 'btn-primary' : 'btn-outline'}`}\n                onClick={() => setMode('UNE - UNES')}\n              >\n                UNE - UNES (Uma origem, v\u00e1rias destinos)\n              </button>\n              <button\n                class={`btn ${mode() === 'UNES - UNES' ? 'btn-primary' : 'btn-outline'}`}\n                onClick={() => setMode('UNES - UNES')}\n              >\n                UNES - UNES (M\u00faltiplas origens e destinos)\n              </button>\n            </div>\n          </div>\n\n          {/* UNE Origin & Destination Pre-selection */}\n          <div class=\"border-t pt-4\">\n            <p class=\"text-xs text-muted mb-3\">\n              \u2139\ufe0f {\n                mode() === 'UNE - UNE' ? 'Selecione uma UNE de origem e uma de destino' :\n                mode() === 'UNE - UNES' ?", "mimetype": "text/plain", "start_char_idx": 9198, "end_char_idx": 12664, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "be6c5c84-d247-440f-86fd-c2fda235a08c": {"__data__": {"id_": "be6c5c84-d247-440f-86fd-c2fda235a08c", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Transfers.tsx", "language": "typescript", "lines": 781, "filename": "Transfers.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Transfers.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Transfers.tsx", "language": "typescript", "lines": 781, "filename": "Transfers.tsx"}, "hash": "ed1053a56baec267223bd6f172dfcc8c974cdd96419bc89bb406804f2ceabe4f", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7c77cd20-527a-49ff-83e1-3e3b5356ab81", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Transfers.tsx", "language": "typescript", "lines": 781, "filename": "Transfers.tsx"}, "hash": "9caf801d93ae53f7feacd2a8f0eaa54fec1443b06b13e0a60175ffb38a2338fc", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d905c221-74ee-450c-8fc6-12d0d84d3e9e", "node_type": "1", "metadata": {}, "hash": "f4ed5b32f0eb292173650f9ae4a62190f2e4602939c66e23c0b5ad5638a42a2e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "'Selecione uma UNE de origem e m\u00faltiplos destinos' :\n                'Selecione m\u00faltiplas UNEs de origem e destino'\n              }\n            </p>\n            \n            <div class=\"grid grid-cols-1 lg:grid-cols-2 gap-4\">\n              {/* Origin UNEs Selection */}\n              <div>\n                <label class=\"text-xs text-muted block mb-2 font-semibold\">\n                  UNE(s) de Origem\n                  {mode() === 'N\u2192N' && ` (${selectedUnesOrigem().length} selecionadas)`}\n                </label>\n                <div class=\"max-h-40 overflow-y-auto border rounded p-3 space-y-2 bg-muted/5\">\n                  <Show when={unes().length > 0} fallback={\n                    <div class=\"text-xs text-muted p-2\">Nenhuma UNE dispon\u00edvel</div>\n                  }>\n                    <For each={unes()}>\n                      {(une) => {\n                        const isSelectedInMode = () => mode() === 'N\u2192N' \n                          ? selectedUnesOrigem().includes(une.une)\n                          : selectedUneOrigem() === une.une;\n                        \n                        const toggleSelection = () => {\n                          if (mode() === 'UNES - UNES') {\n                            const current = selectedUnesOrigem();\n                            if (current.includes(une.une)) {\n                              setSelectedUnesOrigem(current.filter(u => u !== une.une));\n                            } else {\n                              setSelectedUnesOrigem([...current, une.une]);\n                            }\n                          } else {\n                            // Modo UNE - UNE ou UNE - UNES\n                            if (selectedUneOrigem() === une.une) {\n                              setSelectedUneOrigem('');\n                            } else {\n                              setSelectedUneOrigem(une.une);\n                            }\n                          }\n                        };\n                        \n                        return (\n                          <div \n                            class={`flex items-center gap-2 text-xs cursor-pointer p-1.5 rounded transition ${\n                              isSelectedInMode() ? 'bg-blue-100 dark:bg-blue-900' : 'hover:bg-muted/30'\n                            }`}\n                            onClick={toggleSelection}\n                          >\n                            <div class=\"flex-shrink-0\">\n                              {mode() === 'N\u2192N' ? (\n                                <input\n                                  type=\"checkbox\"\n                                  checked={isSelectedInMode()}\n                                  onClick={(e) => e.stopPropagation()}\n                                  onChange={toggleSelection}\n                                  class=\"cursor-pointer\"\n                                />\n                              ) : (\n                                <input\n                                  type=\"radio\"\n                                  name=\"origin-une\"\n                                  checked={isSelectedInMode()}\n                                  onClick={(e) => e.stopPropagation()}\n                                  onChange={toggleSelection}\n                                  class=\"cursor-pointer\"\n                                />\n                              )}\n                            </div>\n                            <span>UNE {une.une}</span>\n                            <span class=\"text-muted text-xs\">({une.estoque_total} un.)</span>\n                          </div>\n                        );\n                      }}\n                    </For>\n                  </Show>\n                </div>\n              </div>\n\n              {/* Destination UNEs Selection */}\n              <div>\n                <label class=\"text-xs text-muted block mb-2 font-semibold\">\n                  UNE(s) de Destino\n                  {(mode() === '1\u2192N' || mode() === 'N\u2192N') && ` (${selectedUnesDestino().length} selecionadas)`}\n                </label>\n                <div class=\"max-h-40 overflow-y-auto border rounded p-3 space-y-2 bg-muted/5\">\n                  <Show when={unes().length > 0} fallback={\n                    <div class=\"text-xs text-muted p-2\">Nenhuma UNE dispon\u00edvel</div>\n                  }>\n                    <For each={unes()}>\n                      {(une) => {\n                        const isDisabledDestino = () => mode() === 'UNE - UNE' \n                          ? selectedUneOrigem() === une.une\n                          : mode() === 'UNES - UNES'\n                          ?", "mimetype": "text/plain", "start_char_idx": 12665, "end_char_idx": 17252, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d905c221-74ee-450c-8fc6-12d0d84d3e9e": {"__data__": {"id_": "d905c221-74ee-450c-8fc6-12d0d84d3e9e", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Transfers.tsx", "language": "typescript", "lines": 781, "filename": "Transfers.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Transfers.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Transfers.tsx", "language": "typescript", "lines": 781, "filename": "Transfers.tsx"}, "hash": "ed1053a56baec267223bd6f172dfcc8c974cdd96419bc89bb406804f2ceabe4f", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "be6c5c84-d247-440f-86fd-c2fda235a08c", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Transfers.tsx", "language": "typescript", "lines": 781, "filename": "Transfers.tsx"}, "hash": "6138ff27cd74c449a4a0a0d1cb566eb8029fedb52b905df4b3a8ff29c69e5270", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "219a8f11-b53c-4766-9c05-394d87ddf89e", "node_type": "1", "metadata": {}, "hash": "c9fe1c23acb65e2abb2f01f4616ae544aad22bee31b0125cbbca7f5c96ac5460", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "selectedUnesOrigem().includes(une.une)\n                          : selectedUneOrigem() === une.une;\n\n                        const isSelectedDestino = () => selectedUnesDestino().includes(une.une);\n                        \n                        const toggleDestSelection = () => {\n                          if (isDisabledDestino()) return; // Impedir clique em origem\n                          \n                          const current = selectedUnesDestino();\n                          if (current.includes(une.une)) {\n                            setSelectedUnesDestino(current.filter(u => u !== une.une));\n                          } else {\n                            if (mode() === 'UNE - UNE' && current.length >= 1) {\n                              setSelectedUnesDestino([une.une]);\n                            } else {\n                              setSelectedUnesDestino([...current, une.une]);\n                            }\n                          }\n                        };\n\n                        return (\n                          <div \n                            class={`flex items-center gap-2 text-xs p-1.5 rounded transition ${\n                              isDisabledDestino() \n                                ? 'opacity-50 cursor-not-allowed bg-gray-100 dark:bg-gray-800' \n                                : isSelectedDestino()\n                                ? 'bg-green-100 dark:bg-green-900 cursor-pointer'\n                                : 'hover:bg-muted/30 cursor-pointer'\n                            }`}\n                            onClick={toggleDestSelection}\n                          >\n                            <div class=\"flex-shrink-0\">\n                              <input\n                                type=\"checkbox\"\n                                disabled={isDisabledDestino()}\n                                checked={isSelectedDestino()}\n                                onClick={(e) => e.stopPropagation()}\n                                onChange={toggleDestSelection}\n                                class={`cursor-pointer ${isDisabledDestino() ? 'opacity-50 cursor-not-allowed' : ''}`}\n                              />\n                            </div>\n                            <span class={isDisabledDestino() ? 'line-through text-muted' : ''}>\n                              UNE {une.une}\n                            </span>\n                            <span class=\"text-muted text-xs\">({une.estoque_total} un.)</span>\n                          </div>\n                        );\n                      }}\n                    </For>\n                  </Show>\n                </div>\n              </div>\n            </div>\n          </div>\n        </div>\n      </div>\n\n      <div class=\"grid grid-cols-1 lg:grid-cols-3 gap-6 flex-1\">\n        {/* Left Column - Product Search */}\n        <div class=\"lg:col-span-2 flex flex-col gap-4\">\n          {/* Search Filters */}\n          <div class=\"card p-4 border\">\n            <div class=\"flex items-center gap-2 mb-4\">\n              <Search size={20} />\n              <h3 class=\"font-semibold\">Buscar Produtos</h3>\n            </div>\n\n            <div class=\"grid grid-cols-1 md:grid-cols-3 gap-3\">\n              <select\n                class=\"input\"\n                value={searchSegmento()}\n                onChange={(e) => setSearchSegmento(e.currentTarget.value)}\n              >\n                <option value=\"\">Todos os Segmentos</option>\n                <For each={availableSegmentos()}>\n                  {(segmento) => <option value={segmento}>{segmento}</option>}\n                </For>\n              </select>\n\n              <select\n                class=\"input\"\n                value={searchFabricante()}\n                onChange={(e) => setSearchFabricante(e.currentTarget.value)}\n              >\n                <option value=\"\">Todos os Fabricantes</option>\n                <For each={availableFabricantes()}>\n                  {(fabricante) => <option value={fabricante}>{fabricante}</option>}\n                </For>\n              </select>\n\n              <input\n                type=\"number\"\n                placeholder=\"Estoque m\u00edn.\"\n                class=\"input\"\n                value={searchEstoqueMin()}\n                onInput={(e) => setSearchEstoqueMin(parseInt(e.currentTarget.value) || '')}\n              />\n            </div>\n\n            <button\n              class=\"btn btn-primary w-full mt-3 gap-2\"\n              onClick={searchProducts}\n              disabled={searching()}\n            >\n              <Search size={16} />\n              {searching() ?", "mimetype": "text/plain", "start_char_idx": 17253, "end_char_idx": 21833, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "219a8f11-b53c-4766-9c05-394d87ddf89e": {"__data__": {"id_": "219a8f11-b53c-4766-9c05-394d87ddf89e", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Transfers.tsx", "language": "typescript", "lines": 781, "filename": "Transfers.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Transfers.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Transfers.tsx", "language": "typescript", "lines": 781, "filename": "Transfers.tsx"}, "hash": "ed1053a56baec267223bd6f172dfcc8c974cdd96419bc89bb406804f2ceabe4f", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d905c221-74ee-450c-8fc6-12d0d84d3e9e", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Transfers.tsx", "language": "typescript", "lines": 781, "filename": "Transfers.tsx"}, "hash": "4900781ea6c3986a7f16cd9af31021c7a2a58710377e89c5d1fcce15f14d4d7e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f66367f3-3b5d-44e4-8db0-cc3d70284946", "node_type": "1", "metadata": {}, "hash": "3d3ad014b834db6d097a072768a8a4a5016e8e45315c65fee28f879a8ab903f0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "'Buscando...' : 'Buscar'}\n            </button>\n          </div>\n\n          {/* Products List */}\n          <div class=\"card border flex-1 flex flex-col\">\n            <div class=\"p-4 border-b\">\n              <h3 class=\"font-semibold\">Produtos ({products().length})</h3>\n            </div>\n\n            <div class=\"flex-1 overflow-y-auto\">\n              <Show when={products().length > 0} fallback={\n                <div class=\"p-8 text-center text-muted\">\n                  <Package size={48} class=\"mx-auto mb-4 opacity-50\" />\n                  <p>Nenhum produto encontrado</p>\n                </div>\n              }>\n                <For each={products()}>\n                  {(product) => {\n                    const isSelected = () => selectedProducts().some(p => p.produto_id === product.produto_id);\n                    return (\n                      <div\n                        class={`p-3 border-b hover:bg-muted/30 cursor-pointer transition-colors ${\n                          isSelected() ? 'bg-primary/10 border-primary' : ''\n                        }`}\n                        onClick={() => toggleProductSelection(product)}\n                      >\n                        <div class=\"flex items-start gap-3\">\n                          <div class=\"pt-1\">\n                            <input \n                              type=\"checkbox\" \n                              checked={isSelected()} \n                              readOnly\n                              class=\"cursor-pointer pointer-events-none\"\n                            />\n                          </div>\n                          <div class=\"flex-1 flex justify-between items-start\">\n                            <div>\n                              <div class=\"font-medium text-sm\">{product.nome}</div>\n                              <div class=\"text-xs text-muted mt-1\">\n                                ID: {product.produto_id} \u2022 {product.segmento} \u2022 {product.fabricante}\n                              </div>\n                            </div>\n                            <div class=\"text-right text-xs\">\n                              <div class=\"text-muted\">Loja: {product.estoque_loja}</div>\n                              <div class=\"text-muted\">CD: {product.estoque_cd}</div>\n                              <div class=\"text-blue-400\">Vendas: {product.vendas_30dd}</div>\n                            </div>\n                          </div>\n                        </div>\n                      </div>\n                    );\n                  }}\n                </For>\n              </Show>\n            </div>\n          </div>\n        </div>\n\n        {/* Right Column - Transfer Config & Cart */}\n        <div class=\"flex flex-col gap-4\">\n          {/* Transfer Configuration */}\n          <Show when={selectedProducts().length > 0}>\n            <div class=\"card p-4 border\">\n              <Show when={selectedProducts().length === 1} fallback={\n                <div class=\"mb-4\">\n                  <h3 class=\"font-semibold mb-3 text-sm\">{selectedProducts().length} Produtos Selecionados</h3>\n                  <div class=\"max-h-32 overflow-y-auto border rounded p-2 bg-muted/5 space-y-1\">\n                    <For each={selectedProducts()}>\n                      {p => <div class=\"text-xs truncate text-muted\">\u2022 {p.nome}</div>}\n                    </For>\n                  </div>\n                </div>\n              }>\n                <h3 class=\"font-semibold mb-3 text-sm\">Detalhe do Produto Selecionado</h3>\n\n                <div class=\"space-y-3 mb-4\">\n                  <div>\n                    <label class=\"text-xs text-muted block mb-1\">Produto</label>\n                    <div class=\"text-sm font-medium truncate\">{selectedProducts()[0].nome}</div>\n                  </div>\n\n                  <div class=\"text-xs text-muted space-y-1\">\n                    <div>ID: {selectedProducts()[0].produto_id}</div>\n                    <div>Segmento: {selectedProducts()[0].segmento}</div>\n                    <div>Fabricante: {selectedProducts()[0].fabricante}</div>\n                    <div class=\"mt-2 pt-2 border-t\">\n                      <div>Estoque Loja: <span class=\"text-foreground font-medium\">{selectedProducts()[0].estoque_loja} un.</span></div>\n                      <div>Estoque CD: <span class=\"text-foreground font-medium\">{selectedProducts()[0].estoque_cd} un.</span></div>\n                      <div>Vendas (30dd): <span class=\"text-blue-400 font-medium\">{selectedProducts()[0].vendas_30dd}</span></div>\n                    </div>\n                  </div>\n                </div>\n              </Show>\n\n              <div class=\"space-y-3\">\n                <div>\n                  <label class=\"text-xs text-muted block mb-1\">Quantidade a Transferir {selectedProducts().length > 1 ?", "mimetype": "text/plain", "start_char_idx": 21834, "end_char_idx": 26607, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f66367f3-3b5d-44e4-8db0-cc3d70284946": {"__data__": {"id_": "f66367f3-3b5d-44e4-8db0-cc3d70284946", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\pages\\Transfers.tsx", "language": "typescript", "lines": 781, "filename": "Transfers.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\pages\\Transfers.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\pages\\Transfers.tsx", "language": "typescript", "lines": 781, "filename": "Transfers.tsx"}, "hash": "ed1053a56baec267223bd6f172dfcc8c974cdd96419bc89bb406804f2ceabe4f", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "219a8f11-b53c-4766-9c05-394d87ddf89e", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\pages\\Transfers.tsx", "language": "typescript", "lines": 781, "filename": "Transfers.tsx"}, "hash": "6a34e68cc8fa5197e29ff1d2b2f86dcf2eb42fe2839a8f9a4918248197024958", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "'(para cada)' : ''}</label>\n                  <input\n                    type=\"number\"\n                    class=\"input w-full\"\n                    placeholder=\"0\"\n                    value={quantidade()}\n                    onInput={(e) => setQuantidade(parseInt(e.currentTarget.value) || '')}\n                  />\n                </div>\n\n                <button\n                  class=\"btn btn-primary w-full gap-2 text-sm\"\n                  onClick={addToCart}\n                  disabled={validating() || selectedProducts().length === 0 || \n                    (mode() === 'N\u2192N' ? selectedUnesOrigem().length === 0 : !selectedUneOrigem()) || \n                    selectedUnesDestino().length === 0 || !quantidade()}\n                >\n                  <Plus size={16} />\n                  {validating() ? 'Validando...' : `Adicionar ${selectedProducts().length > 1 ? `(${selectedProducts().length})` : ''} ao Carrinho`}\n                </button>\n              </div>\n            </div>\n          </Show>\n\n          {/* Cart */}\n          <div class=\"card border flex-1 flex flex-col\">\n            <div class=\"p-3 border-b flex justify-between items-center\">\n              <div class=\"flex items-center gap-2\">\n                <ShoppingCart size={18} />\n                <h3 class=\"font-semibold text-sm\">Carrinho ({cart.items.length})</h3>\n              </div>\n              <Show when={cart.items.length > 0}>\n                <button\n                  class=\"text-xs text-red-400 hover:text-red-300\"\n                  onClick={clearCart}\n                >\n                  Limpar\n                </button>\n              </Show>\n            </div>\n\n            <div class=\"flex-1 overflow-y-auto\">\n              <Show when={cart.items.length > 0} fallback={\n                <div class=\"p-6 text-center text-muted text-sm\">\n                  <ShoppingCart size={32} class=\"mx-auto mb-2 opacity-50\" />\n                  <p>Carrinho vazio</p>\n                </div>\n              }>\n                <For each={cart.items}>\n                  {(item, index) => (\n                    <div class=\"p-3 border-b text-xs\">\n                      <div class=\"flex justify-between items-start mb-2\">\n                        <div class=\"flex-1 font-medium\">{item.produto_nome}</div>\n                        <button\n                          class=\"text-red-400 hover:text-red-300\"\n                          onClick={() => removeFromCart(index())}\n                        >\n                          <Trash2 size={14} />\n                        </button>\n                      </div>\n\n                      <div class=\"space-y-1 text-muted\">\n                        <div class=\"flex items-center gap-1\">\n                          <span>UNE {item.une_origem}</span>\n                          <ArrowRight size={12} />\n                          <span>UNE {item.une_destino.join(', ')}</span>\n                        </div>\n                        <div>Qtd: {item.quantidade} un.</div>\n                        <Show when={item.score !== undefined}>\n                          <div class=\"flex items-center gap-2\">\n                            <span>Score: {item.score}</span>\n                            <span class={`font-semibold ${getUrgencyColor(item.nivel_urgencia)}`}>\n                              {item.nivel_urgencia}\n                            </span>\n                          </div>\n                        </Show>\n                      </div>\n                    </div>\n                  )}\n                </For>\n              </Show>\n            </div>\n\n            <Show when={cart.items.length > 0}>\n              <div class=\"p-3 border-t\">\n                <button\n                  class=\"btn btn-primary w-full gap-2 text-sm\"\n                  onClick={generateRequest}\n                  disabled={creating()}\n                >\n                  <Truck size={16} />\n                  {creating() ? 'Gerando...' : 'Gerar Solicita\u00e7\u00e3o'}\n                </button>\n              </div>\n            </Show>\n          </div>\n        </div>\n      </div>\n    </div>\n  );\n}", "mimetype": "text/plain", "start_char_idx": 26608, "end_char_idx": 30674, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "578d5262-c066-4b46-b3f6-9d6c3e872f24": {"__data__": {"id_": "578d5262-c066-4b46-b3f6-9d6c3e872f24", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\services\\admin.service.ts", "language": "typescript", "lines": 59, "filename": "admin.service.ts"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\services\\admin.service.ts", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\services\\admin.service.ts", "language": "typescript", "lines": 59, "filename": "admin.service.ts"}, "hash": "542cbe89b0e30c8430ec1f8cb7bb5ea336227f4564aa4c5b8ff4e1ce07671c0f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import { apiClient } from '@/lib/api/client';\nimport type {\n  AdminStats,\n  User,\n  CreateUserDTO,\n  UpdateUserDTO,\n  AuditLog,\n  SystemSettings,\n} from '@/types/admin';\n\nexport const adminService = {\n  async getStats(): Promise<AdminStats> {\n    // Connect to FastAPI backend: GET /api/v1/admin/stats\n    return apiClient.get<AdminStats>('/api/v1/admin/stats');\n  },\n\n  async getUsers(): Promise<User[]> {\n    // Connect to FastAPI backend: GET /api/v1/admin/users\n    return apiClient.get<User[]>('/api/v1/admin/users');\n  },\n\n  async getUser(id: string): Promise<User> {\n    // Connect to FastAPI backend: GET /api/v1/admin/users/{id}\n    return apiClient.get<User>(`/api/v1/admin/users/${id}`);\n  },\n\n  async createUser(user: CreateUserDTO): Promise<User> {\n    // Connect to FastAPI backend: POST /api/v1/admin/users\n    return apiClient.post<User>('/api/v1/admin/users', user);\n  },\n\n  async updateUser(id: string, user: UpdateUserDTO): Promise<User> {\n    // Connect to FastAPI backend: PUT /api/v1/admin/users/{id}\n    return apiClient.put<User>(`/api/v1/admin/users/${id}`, user);\n  },\n\n  async deleteUser(id: string): Promise<void> {\n    // Connect to FastAPI backend: DELETE /api/v1/admin/users/{id}\n    return apiClient.delete(`/api/v1/admin/users/${id}`);\n  },\n\n  async getAuditLogs(limit = 100): Promise<AuditLog[]> {\n    // Connect to FastAPI backend: GET /api/v1/admin/audit-logs\n    return apiClient.get<AuditLog[]>(`/api/v1/admin/audit-logs?limit=${limit}`);\n  },\n\n  async getSettings(): Promise<SystemSettings> {\n    // Connect to FastAPI backend: GET /api/v1/admin/settings\n    // TODO: Backend endpoint not implemented yet\n    return apiClient.get<SystemSettings>('/api/v1/admin/settings');\n  },\n\n  async updateSettings(settings: Partial<SystemSettings>): Promise<SystemSettings> {\n    // Connect to FastAPI backend: PUT /api/v1/admin/settings\n    // TODO: Backend endpoint not implemented yet\n    return apiClient.put<SystemSettings>('/api/v1/admin/settings', settings);\n  },\n};", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2000, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4a6bd569-ee9a-45c5-8eea-f90081432637": {"__data__": {"id_": "4a6bd569-ee9a-45c5-8eea-f90081432637", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\services\\analytics.service.ts", "language": "typescript", "lines": 52, "filename": "analytics.service.ts"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\services\\analytics.service.ts", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\services\\analytics.service.ts", "language": "typescript", "lines": 52, "filename": "analytics.service.ts"}, "hash": "84f7f12ef7b4718126a4d15733f3abf408da6861c0570df331ef6cb0153e6959", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "/**\n * Analytics Service\n * Servi\u00e7o para comunica\u00e7\u00e3o com API de analytics\n */\n\nimport { apiClient } from '@/lib/api/client';\nimport type {\n  AnalyticsData,\n  AnalyticsFilter,\n  AnalyticsMetric,\n  ExportFormat,\n} from '@/types/analytics';\n\nexport const analyticsService = {\n  async getData(filters?: AnalyticsFilter): Promise<AnalyticsData[]> {\n    // Connect to FastAPI backend: GET /api/v1/analytics/data\n    const params = new URLSearchParams();\n    if (filters?.dateRange) {\n      params.append('date_start', filters.dateRange.start.toISOString());\n      params.append('date_end', filters.dateRange.end.toISOString());\n    }\n    if (filters?.category) params.append('category', filters.category);\n    if (filters?.segment) params.append('segment', filters.segment);\n    if (filters?.minValue !== undefined) params.append('min_value', filters.minValue.toString());\n    if (filters?.maxValue !== undefined) params.append('max_value', filters.maxValue.toString());\n\n    return apiClient.get<AnalyticsData[]>(`/api/v1/analytics/data?${params.toString()}`);\n  },\n\n  async getMetrics(): Promise<AnalyticsMetric[]> {\n    // Connect to FastAPI backend: GET /api/v1/analytics/metrics\n    return apiClient.get<AnalyticsMetric[]>('/api/v1/analytics/metrics');\n  },\n\n  async exportData(format: ExportFormat, filters?: AnalyticsFilter): Promise<Blob> {\n    // Connect to FastAPI backend: POST /api/v1/analytics/export\n    const response = await fetch(`${process.env.NEXT_PUBLIC_API_URL}/api/v1/analytics/export`, {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json',\n      },\n      body: JSON.stringify({ format, filters }),\n    });\n    return response.blob();\n  },\n\n  async runCustomQuery(query: string): Promise<any> {\n    // Connect to FastAPI backend: POST /api/v1/analytics/query\n    return apiClient.post('/api/v1/analytics/query', { query });\n  },\n};", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1878, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "038eee7a-15a7-4da9-98f4-0522f2850aec": {"__data__": {"id_": "038eee7a-15a7-4da9-98f4-0522f2850aec", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\services\\auth.service.ts", "language": "typescript", "lines": 38, "filename": "auth.service.ts"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\services\\auth.service.ts", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\services\\auth.service.ts", "language": "typescript", "lines": 38, "filename": "auth.service.ts"}, "hash": "00b2a00cb4ce85a11639b01764a0bbb182e5ea7f9a3347700b351848c725bbbf", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import { apiClient } from '@/lib/api/client';\nimport type { User } from '@/store/auth.store';\n\nexport interface LoginCredentials {\n  username: string;\n  password: string;\n}\n\nexport interface AuthResponse {\n  access_token: string;\n  refresh_token: string;\n  token_type: string;\n}\n\nexport const authService = {\n  async login(credentials: LoginCredentials): Promise<AuthResponse> {\n    // Use production authentication endpoint only\n    return apiClient.post<AuthResponse>('/api/v1/auth/login', credentials);\n  },\n\n  async logout(): Promise<void> {\n    // Connect to FastAPI backend: POST /api/v1/auth/logout\n    return apiClient.post('/api/v1/auth/logout');\n  },\n\n  async getCurrentUser(): Promise<User> {\n    // Connect to FastAPI backend: GET /api/v1/auth/me\n    return apiClient.get<User>('/api/v1/auth/me');\n  },\n\n  async refreshToken(refreshToken: string): Promise<AuthResponse> {\n    // Connect to FastAPI backend: POST /api/v1/auth/refresh\n    return apiClient.post<AuthResponse>('/api/v1/auth/refresh', {\n      refresh_token: refreshToken,\n    });\n  },\n};", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1061, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1a4c65f3-ace8-499d-b418-53d3870c350e": {"__data__": {"id_": "1a4c65f3-ace8-499d-b418-53d3870c350e", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\services\\logger.service.ts", "language": "typescript", "lines": 490, "filename": "logger.service.ts"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\services\\logger.service.ts", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\services\\logger.service.ts", "language": "typescript", "lines": 490, "filename": "logger.service.ts"}, "hash": "b98f75dd71052bb4ac94ae5f286b538a853948999d8158db31a31c66e1ee2538", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d256cd8f-1612-48c7-891f-dc22562f58ef", "node_type": "1", "metadata": {}, "hash": "39bb132daecda2907bcf3a66c548d2e8012708e0cddb3145679d6b28d8e6ec1e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "/**\n * Sistema de Logging para Frontend\n * Gerencia logs no browser e envia logs importantes para o backend\n */\n\nexport enum LogLevel {\n  DEBUG = 0,\n  INFO = 1,\n  WARN = 2,\n  ERROR = 3,\n  CRITICAL = 4,\n}\n\nexport interface LogEntry {\n  timestamp: string;\n  level: LogLevel;\n  levelName: string;\n  message: string;\n  context?: Record<string, any>;\n  error?: {\n    name: string;\n    message: string;\n    stack?: string;\n  };\n  user?: {\n    id?: string;\n    email?: string;\n  };\n  session?: {\n    id?: string;\n    duration?: number;\n  };\n  page?: {\n    url: string;\n    referrer?: string;\n    title?: string;\n  };\n  browser?: {\n    userAgent: string;\n    language: string;\n    platform: string;\n  };\n}\n\nexport interface LoggerConfig {\n  minLevel: LogLevel;\n  enableConsole: boolean;\n  enableRemote: boolean;\n  remoteEndpoint?: string;\n  maxBufferSize: number;\n  flushInterval: number;\n  includeStackTrace: boolean;\n  sanitizeData: boolean;\n}\n\n/**\n * Classe principal do Logger\n */\nclass Logger {\n  private config: LoggerConfig = {\n    minLevel: LogLevel.DEBUG,\n    enableConsole: true,\n    enableRemote: true,\n    remoteEndpoint: '/api/v1/logs',\n    maxBufferSize: 50,\n    flushInterval: 10000, // 10 segundos\n    includeStackTrace: true,\n    sanitizeData: true,\n  };\n\n  private buffer: LogEntry[] = [];\n  private flushTimer: number | null = null;\n  private sessionId: string;\n  private sessionStart: number;\n\n  constructor(config?: Partial<LoggerConfig>) {\n    if (config) {\n      this.config = { ...this.config, ...config };\n    }\n\n    this.sessionId = this.generateSessionId();\n    this.sessionStart = Date.now();\n\n    // Inicia o timer de flush\n    this.startFlushTimer();\n\n    // Captura erros globais n\u00e3o tratados\n    this.setupGlobalErrorHandlers();\n\n    // Flush antes de sair da p\u00e1gina\n    if (typeof window !== 'undefined') {\n      window.addEventListener('beforeunload', () => {\n        this.flush();\n      });\n    }\n  }\n\n  /**\n   * Configura o logger\n   */\n  public configure(config: Partial<LoggerConfig>): void {\n    this.config = { ...this.config, ...config };\n  }\n\n  /**\n   * Gera um ID \u00fanico para a sess\u00e3o\n   */\n  private generateSessionId(): string {\n    return `${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;\n  }\n\n  /**\n   * Obt\u00e9m informa\u00e7\u00f5es do browser\n   */\n  private getBrowserInfo() {\n    if (typeof window === 'undefined') return undefined;\n\n    return {\n      userAgent: navigator.userAgent,\n      language: navigator.language,\n      platform: navigator.platform,\n    };\n  }\n\n  /**\n   * Obt\u00e9m informa\u00e7\u00f5es da p\u00e1gina atual\n   */\n  private getPageInfo() {\n    if (typeof window === 'undefined') return undefined;\n\n    return {\n      url: window.location.href,\n      referrer: document.referrer || undefined,\n      title: document.title,\n    };\n  }\n\n  /**\n   * Obt\u00e9m informa\u00e7\u00f5es da sess\u00e3o\n   */\n  private getSessionInfo() {\n    return {\n      id: this.sessionId,\n      duration: Date.now() - this.sessionStart,\n    };\n  }\n\n  /**\n   * Sanitiza dados sens\u00edveis\n   */\n  private sanitize(data: any): any {\n    if (!this.config.sanitizeData) return data;\n\n    const sensitiveKeys = ['password', 'token', 'secret', 'apiKey', 'api_key', 'authorization'];\n\n    if (typeof data !== 'object' || data === null) return data;\n\n    const sanitized = Array.isArray(data) ? [...data] : { ...data };\n\n    for (const key in sanitized) {\n      if (sensitiveKeys.some(sk => key.toLowerCase().includes(sk.toLowerCase()))) {\n        sanitized[key] = '***REDACTED***';\n      } else if (typeof sanitized[key] === 'object' && sanitized[key] !== null) {\n        sanitized[key] = this.sanitize(sanitized[key]);\n      }\n    }\n\n    return sanitized;\n  }\n\n  /**\n   * Cria uma entrada de log\n   */\n  private createLogEntry(\n    level: LogLevel,\n    message: string,\n    context?: Record<string, any>,\n    error?", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3809, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d256cd8f-1612-48c7-891f-dc22562f58ef": {"__data__": {"id_": "d256cd8f-1612-48c7-891f-dc22562f58ef", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\services\\logger.service.ts", "language": "typescript", "lines": 490, "filename": "logger.service.ts"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\services\\logger.service.ts", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\services\\logger.service.ts", "language": "typescript", "lines": 490, "filename": "logger.service.ts"}, "hash": "b98f75dd71052bb4ac94ae5f286b538a853948999d8158db31a31c66e1ee2538", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1a4c65f3-ace8-499d-b418-53d3870c350e", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\services\\logger.service.ts", "language": "typescript", "lines": 490, "filename": "logger.service.ts"}, "hash": "03f938e571147b8a3786cc23311b7906f8937452d7f015c77db00e89c34fe682", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "72df7fa9-124c-492b-a8a0-af9f07dbd3fa", "node_type": "1", "metadata": {}, "hash": "be447eaa9cb2342b80ac4a8a14ea6a4a8b23d756244e719a4e26f4c1ae9f6aaa", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": ": Record<string, any>,\n    error?: Error\n  ): LogEntry {\n    const entry: LogEntry = {\n      timestamp: new Date().toISOString(),\n      level,\n      levelName: LogLevel[level],\n      message,\n      context: context ? this.sanitize(context) : undefined,\n      browser: this.getBrowserInfo(),\n      page: this.getPageInfo(),\n      session: this.getSessionInfo(),\n    };\n\n    // Adiciona informa\u00e7\u00f5es de erro se dispon\u00edvel\n    if (error) {\n      entry.error = {\n        name: error.name,\n        message: error.message,\n        stack: this.config.includeStackTrace ? error.stack : undefined,\n      };\n    }\n\n    // Adiciona informa\u00e7\u00f5es do usu\u00e1rio se dispon\u00edvel\n    const user = this.getCurrentUser();\n    if (user) {\n      entry.user = user;\n    }\n\n    return entry;\n  }\n\n  /**\n   * Obt\u00e9m informa\u00e7\u00f5es do usu\u00e1rio atual (do localStorage ou store)\n   */\n  private getCurrentUser(): { id?: string; email?: string } | undefined {\n    if (typeof window === 'undefined') return undefined;\n\n    try {\n      const userStr = localStorage.getItem('user');\n      if (userStr) {\n        const user = JSON.parse(userStr);\n        return {\n          id: user.id,\n          email: user.email,\n        };\n      }\n    } catch {\n      // Ignora erros ao buscar usu\u00e1rio\n    }\n\n    return undefined;\n  }\n\n  /**\n   * Registra um log\n   */\n  private log(\n    level: LogLevel,\n    message: string,\n    context?: Record<string, any>,\n    error?: Error\n  ): void {\n    // Verifica se o n\u00edvel \u00e9 suficiente\n    if (level < this.config.minLevel) return;\n\n    const entry = this.createLogEntry(level, message, context, error);\n\n    // Log no console\n    if (this.config.enableConsole) {\n      this.logToConsole(entry);\n    }\n\n    // Adiciona ao buffer para envio remoto\n    if (this.config.enableRemote) {\n      this.buffer.push(entry);\n\n      // Se buffer est\u00e1 cheio, faz flush imediatamente\n      if (this.buffer.length >= this.config.maxBufferSize) {\n        this.flush();\n      }\n    }\n  }\n\n  /**\n   * Escreve log no console do browser\n   */\n  private logToConsole(entry: LogEntry): void {\n    const styles = {\n      [LogLevel.DEBUG]: 'color: #888; font-weight: normal',\n      [LogLevel.INFO]: 'color: #2563eb; font-weight: normal',\n      [LogLevel.WARN]: 'color: #d97706; font-weight: bold',\n      [LogLevel.ERROR]: 'color: #dc2626; font-weight: bold',\n      [LogLevel.CRITICAL]: 'color: #991b1b; font-weight: bold; font-size: 14px',\n    };\n\n    const prefix = `[${entry.levelName}] ${entry.timestamp}`;\n    const style = styles[entry.level];\n\n    const consoleMethod =\n      entry.level >= LogLevel.ERROR ? console.error :\n      entry.level === LogLevel.WARN ? console.warn :\n      entry.level === LogLevel.INFO ?", "mimetype": "text/plain", "start_char_idx": 3776, "end_char_idx": 6461, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "72df7fa9-124c-492b-a8a0-af9f07dbd3fa": {"__data__": {"id_": "72df7fa9-124c-492b-a8a0-af9f07dbd3fa", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\services\\logger.service.ts", "language": "typescript", "lines": 490, "filename": "logger.service.ts"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\services\\logger.service.ts", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\services\\logger.service.ts", "language": "typescript", "lines": 490, "filename": "logger.service.ts"}, "hash": "b98f75dd71052bb4ac94ae5f286b538a853948999d8158db31a31c66e1ee2538", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d256cd8f-1612-48c7-891f-dc22562f58ef", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\services\\logger.service.ts", "language": "typescript", "lines": 490, "filename": "logger.service.ts"}, "hash": "9e2bce9a8cabf02dc3bb6c0af41eb22a7b1a6c0dc54987390b9c880c3c3d498c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1e3eabea-2b0b-4c07-9b75-83c40ff7619c", "node_type": "1", "metadata": {}, "hash": "c7169f78c7119ea5e6332d0041ed09d5e1efbb9f5e08e24423574ff47e2ee487", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "console.warn :\n      entry.level === LogLevel.INFO ? console.info :\n      console.debug;\n\n    consoleMethod(\n      `%c${prefix}`,\n      style,\n      entry.message,\n      entry.context || '',\n      entry.error || ''\n    );\n  }\n\n  /**\n   * Inicia o timer de flush autom\u00e1tico\n   */\n  private startFlushTimer(): void {\n    if (typeof window === 'undefined') return;\n\n    this.flushTimer = window.setInterval(() => {\n      if (this.buffer.length > 0) {\n        this.flush();\n      }\n    }, this.config.flushInterval);\n  }\n\n  /**\n   * Para o timer de flush\n   */\n  private stopFlushTimer(): void {\n    if (this.flushTimer !== null) {\n      clearInterval(this.flushTimer);\n      this.flushTimer = null;\n    }\n  }\n\n  /**\n   * Envia logs para o backend\n   */\n  public async flush(): Promise<void> {\n    if (this.buffer.length === 0 || !this.config.enableRemote) return;\n\n    const logsToSend = [...this.buffer];\n    this.buffer = [];\n\n    try {\n      const response = await fetch(this.config.remoteEndpoint!, {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json',\n        },\n        body: JSON.stringify({ logs: logsToSend }),\n        // N\u00e3o espera resposta em beforeunload\n        keepalive: true,\n      });\n\n      if (!response.ok) {\n        // Se falhar, recoloca no buffer\n        console.warn('Failed to send logs to backend:', response.statusText);\n        this.buffer.unshift(...logsToSend);\n      }\n    } catch (error) {\n      // Se falhar, recoloca no buffer\n      console.warn('Error sending logs to backend:', error);\n      this.buffer.unshift(...logsToSend);\n    }\n  }\n\n  /**\n   * Configura handlers para erros globais\n   */\n  private setupGlobalErrorHandlers(): void {\n    if (typeof window === 'undefined') return;\n\n    // Captura erros n\u00e3o tratados\n    window.addEventListener('error', (event) => {\n      this.error('Uncaught error', {\n        filename: event.filename,\n        lineno: event.lineno,\n        colno: event.colno,\n      }, event.error);\n    });\n\n    // Captura promises rejeitadas n\u00e3o tratadas\n    window.addEventListener('unhandledrejection', (event) => {\n      this.error('Unhandled promise rejection', {\n        reason: event.reason,\n      });\n    });\n  }\n\n  // M\u00e9todos p\u00fablicos para cada n\u00edvel de log\n\n  public debug(message: string, context?: Record<string, any>): void {\n    this.log(LogLevel.DEBUG, message, context);\n  }\n\n  public info(message: string, context?: Record<string, any>): void {\n    this.log(LogLevel.INFO, message, context);\n  }\n\n  public warn(message: string, context?: Record<string, any>): void {\n    this.log(LogLevel.WARN, message, context);\n  }\n\n  public error(message: string, context?: Record<string, any>, error?: Error): void {\n    this.log(LogLevel.ERROR, message, context, error);\n  }\n\n  public critical(message: string, context?: Record<string, any>, error?: Error): void {\n    this.log(LogLevel.CRITICAL, message, context, error);\n  }\n\n  /**\n   * M\u00e9todos para logging de eventos espec\u00edficos\n   */\n\n  public logPageView(pageName: string, metadata?: Record<string, any>): void {\n    this.info(`Page view: ${pageName}`, {\n      type: 'page_view',\n      page: pageName,\n      ...metadata,\n    });\n  }\n\n  public logUserAction(action: string, metadata?: Record<string, any>): void {\n    this.info(`User action: ${action}`, {\n      type: 'user_action',\n      action,\n      ...metadata,\n    });\n  }\n\n  public logApiCall(\n    method: string,\n    endpoint: string,\n    status: number,\n    duration: number,\n    error?: Error\n  ): void {\n    const level = status >= 500 ? LogLevel.ERROR : status >= 400 ? LogLevel.WARN : LogLevel.INFO;\n\n    this.log(\n      level,\n      `API ${method} ${endpoint} - ${status}`,\n      {\n        type: 'api_call',\n        method,\n        endpoint,\n        status,\n        duration,\n      },\n      error\n    );\n  }\n\n  public logPerformance(metric: string, value: number, metadata?", "mimetype": "text/plain", "start_char_idx": 6409, "end_char_idx": 10300, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1e3eabea-2b0b-4c07-9b75-83c40ff7619c": {"__data__": {"id_": "1e3eabea-2b0b-4c07-9b75-83c40ff7619c", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\services\\logger.service.ts", "language": "typescript", "lines": 490, "filename": "logger.service.ts"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\services\\logger.service.ts", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\services\\logger.service.ts", "language": "typescript", "lines": 490, "filename": "logger.service.ts"}, "hash": "b98f75dd71052bb4ac94ae5f286b538a853948999d8158db31a31c66e1ee2538", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "72df7fa9-124c-492b-a8a0-af9f07dbd3fa", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\services\\logger.service.ts", "language": "typescript", "lines": 490, "filename": "logger.service.ts"}, "hash": "9b589f49489adcad56b6a19c38e38c2dd47f43b3cc0f3ba32d04b0050ab31c07", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": ": Record<string, any>): void {\n    this.info(`Performance: ${metric}`, {\n      type: 'performance',\n      metric,\n      value,\n      ...metadata,\n    });\n  }\n\n  /**\n   * Limpa o logger e para os timers\n   */\n  public destroy(): void {\n    this.flush();\n    this.stopFlushTimer();\n  }\n}\n\n// Singleton instance\nlet loggerInstance: Logger | null = null;\n\n/**\n * Obt\u00e9m a inst\u00e2ncia singleton do logger\n */\nexport function getLogger(config?: Partial<LoggerConfig>): Logger {\n  if (!loggerInstance) {\n    loggerInstance = new Logger(config);\n  } else if (config) {\n    loggerInstance.configure(config);\n  }\n  return loggerInstance;\n}\n\n/**\n * Exporta uma inst\u00e2ncia padr\u00e3o\n */\nexport const logger = getLogger();\n\n/**\n * Exporta m\u00e9todos convenientes\n */\nexport const log = {\n  debug: (message: string, context?: Record<string, any>) => logger.debug(message, context),\n  info: (message: string, context?: Record<string, any>) => logger.info(message, context),\n  warn: (message: string, context?: Record<string, any>) => logger.warn(message, context),\n  error: (message: string, context?: Record<string, any>, error?: Error) => logger.error(message, context, error),\n  critical: (message: string, context?: Record<string, any>, error?: Error) => logger.critical(message, context, error),\n  pageView: (pageName: string, metadata?: Record<string, any>) => logger.logPageView(pageName, metadata),\n  userAction: (action: string, metadata?: Record<string, any>) => logger.logUserAction(action, metadata),\n  apiCall: (method: string, endpoint: string, status: number, duration: number, error?: Error) =>\n    logger.logApiCall(method, endpoint, status, duration, error),\n  performance: (metric: string, value: number, metadata?: Record<string, any>) =>\n    logger.logPerformance(metric, value, metadata),\n};\n\nexport default logger;", "mimetype": "text/plain", "start_char_idx": 10300, "end_char_idx": 12112, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "159c2bba-be84-4209-a1bc-f8d2ba9f9e28": {"__data__": {"id_": "159c2bba-be84-4209-a1bc-f8d2ba9f9e28", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\services\\reports.service.ts", "language": "typescript", "lines": 65, "filename": "reports.service.ts"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\services\\reports.service.ts", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\services\\reports.service.ts", "language": "typescript", "lines": 65, "filename": "reports.service.ts"}, "hash": "7c0e34edddb37adc9d26b42bc963a0ccfff373f8b3c407671eb705ca40b1344d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import { apiClient } from '@/lib/api/client';\nimport type {\n  Report,\n  ReportTemplate,\n  CreateReportDTO,\n  UpdateReportDTO,\n  ReportSchedule,\n} from '@/types/reports';\n\nexport const reportsService = {\n  async getAll(): Promise<Report[]> {\n    // Connect to FastAPI backend: GET /api/v1/reports\n    return apiClient.get<Report[]>('/api/v1/reports');\n  },\n\n  async getById(id: string): Promise<Report> {\n    // Connect to FastAPI backend: GET /api/v1/reports/{id}\n    return apiClient.get<Report>(`/api/v1/reports/${id}`);\n  },\n\n  async create(report: CreateReportDTO): Promise<Report> {\n    // Connect to FastAPI backend: POST /api/v1/reports\n    return apiClient.post<Report>('/api/v1/reports', report);\n  },\n\n  async update(id: string, report: UpdateReportDTO): Promise<Report> {\n    // Connect to FastAPI backend: PUT /api/v1/reports/{id}\n    return apiClient.put<Report>(`/api/v1/reports/${id}`, report);\n  },\n\n  async delete(id: string): Promise<void> {\n    // Connect to FastAPI backend: DELETE /api/v1/reports/{id}\n    return apiClient.delete(`/api/v1/reports/${id}`);\n  },\n\n  async getTemplates(): Promise<ReportTemplate[]> {\n    // Connect to FastAPI backend: GET /api/v1/reports/templates\n    // TODO: Backend endpoint not implemented yet\n    return apiClient.get<ReportTemplate[]>('/api/v1/reports/templates');\n  },\n\n  async generatePDF(id: string): Promise<Blob> {\n    // Connect to FastAPI backend: POST /api/v1/reports/{id}/generate-pdf\n    const response = await fetch(\n      `${process.env.NEXT_PUBLIC_API_URL}/api/v1/reports/${id}/generate-pdf`,\n      {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json',\n        },\n      }\n    );\n    return response.blob();\n  },\n\n  async schedule(\n    id: string,\n    schedule: Omit<ReportSchedule, 'id' | 'reportId'>\n  ): Promise<ReportSchedule> {\n    // Connect to FastAPI backend: POST /api/v1/reports/{id}/schedule\n    // TODO: Backend endpoint not implemented yet\n    return apiClient.post<ReportSchedule>(`/api/v1/reports/${id}/schedule`, schedule);\n  },\n};", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2054, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b551d08e-9f20-4596-9f2a-61beaac5d7fa": {"__data__": {"id_": "b551d08e-9f20-4596-9f2a-61beaac5d7fa", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\store\\auth.ts", "language": "typescript", "lines": 149, "filename": "auth.ts"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\store\\auth.ts", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\store\\auth.ts", "language": "typescript", "lines": 149, "filename": "auth.ts"}, "hash": "e3bff71ac5805e3ef8e65255588249888b1e0ec383ac753a036d5058456ea042", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "280d9738-977a-46f6-962b-f0955985c6b1", "node_type": "1", "metadata": {}, "hash": "80e79468bbba76938dd075e01579705d8fb05a8b18c39a929ed8621bbc5794b9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import { createSignal, createRoot } from 'solid-js';\nimport api from '@/lib/api';\n\nexport interface User {\n  username: string;\n  role: string;\n  email: string;\n  allowed_segments: string[];\n}\n\nfunction createAuthStore() {\n  const [user, setUser] = createSignal<User | null>(null);\n  const [token, setToken] = createSignal<string | null>(null);\n  const [isAuthenticated, setIsAuthenticated] = createSignal<boolean>(false);\n  const [loading, setLoading] = createSignal<boolean>(false);\n  const [error, setError] = createSignal<string | null>(null);\n\n  // Fun\u00e7\u00e3o para validar e decodificar token\n  const validateAndDecodeToken = (tokenString: string): any | null => {\n    try {\n      // Verificar formato JWT (deve ter 3 partes separadas por .)\n      const parts = tokenString.split('.');\n      if (parts.length !== 3) {\n        console.error('\u274c Token inv\u00e1lido: formato incorreto');\n        return null;\n      }\n\n      // Decodificar payload\n      const payload = JSON.parse(atob(parts[1]));\n\n      // Verificar expira\u00e7\u00e3o\n      if (payload.exp) {\n        const now = Math.floor(Date.now() / 1000);\n        if (payload.exp < now) {\n          console.error('\u274c Token expirado');\n          return null;\n        }\n      }\n\n      return payload;\n    } catch (e) {\n      console.error('\u274c Erro ao validar token:', e);\n      return null;\n    }\n  };\n\n  // Restaurar user do token ao inicializar (com prote\u00e7\u00e3o para SSR)\n  const initializeAuth = () => {\n    try {\n      if (typeof window === 'undefined' || !window.localStorage) {\n        return;\n      }\n      \n      const initToken = localStorage.getItem('token');\n      if (initToken) {\n        const payload = validateAndDecodeToken(initToken);\n        \n        // Verifica\u00e7\u00e3o ESTRITA: Se o payload for nulo ou token expirado, limpar TUDO.\n        if (payload) {\n          const userData: User = {\n            username: payload.username || payload.sub || 'user',\n            role: payload.role || 'user',\n            email: payload.email || `${payload.username || payload.sub}@agentbi.com`,\n            allowed_segments: payload.allowed_segments || []\n          };\n          setUser(userData);\n          setToken(initToken);\n          setIsAuthenticated(true);\n          console.log('\ud83d\udd04 Sess\u00e3o restaurada com sucesso.');\n        } else {\n          // Token inv\u00e1lido, malformado ou expirado -> Logout for\u00e7ado imediato\n          console.warn('\u26a0\ufe0f Token inv\u00e1lido detectado na inicializa\u00e7\u00e3o - Limpando sess\u00e3o.');\n          localStorage.removeItem('token');\n          setIsAuthenticated(false);\n          setUser(null);\n          setToken(null);\n          // Opcional: Redirecionar se estiver numa rota protegida \u00e9 responsabilidade do Router,\n          // mas garantir o estado limpo previne o acesso visual indevido.\n        }\n      }\n    } catch (error) {\n      console.error('\u274c Erro cr\u00edtico ao inicializar autentica\u00e7\u00e3o:', error);\n      localStorage.removeItem('token');\n      setIsAuthenticated(false);\n    }\n  };\n\n  // Executar inicializa\u00e7\u00e3o\n  initializeAuth();\n\n  const login = async (username: string, password: string): Promise<boolean> => {\n    setLoading(true);\n    setError(null);\n    try {\n      // Endpoint correto do FastAPI (/auth/login -> recebe LoginRequest JSON)\n      const response = await api.post('/auth/login', { username, password });\n\n      const { access_token } = response.data;\n\n      if (access_token) {\n        // Validar token antes de salvar\n        const payload = validateAndDecodeToken(access_token);\n\n        if (!payload) {\n          setError(\"Token inv\u00e1lido recebido do servidor\");\n          return false;\n        }\n\n        localStorage.setItem('token', access_token);\n        setToken(access_token);\n        setIsAuthenticated(true);\n\n        // Definir dados do usu\u00e1rio baseado no payload do JWT\n        const userData: User = {\n          username: payload.username || payload.sub || username,\n          role: payload.role || 'user',\n          email: payload.email || `${payload.username || username}@agentbi.com`,\n          allowed_segments: payload.allowed_segments || []\n        };\n\n        console.log('\u2705 Login successful.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4098, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "280d9738-977a-46f6-962b-f0955985c6b1": {"__data__": {"id_": "280d9738-977a-46f6-962b-f0955985c6b1", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\store\\auth.ts", "language": "typescript", "lines": 149, "filename": "auth.ts"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\store\\auth.ts", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\store\\auth.ts", "language": "typescript", "lines": 149, "filename": "auth.ts"}, "hash": "e3bff71ac5805e3ef8e65255588249888b1e0ec383ac753a036d5058456ea042", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b551d08e-9f20-4596-9f2a-61beaac5d7fa", "node_type": "1", "metadata": {"file_path": "frontend-solid\\src\\store\\auth.ts", "language": "typescript", "lines": 149, "filename": "auth.ts"}, "hash": "f3c13d9fe648288fd2c135886ffb11946edfa7d83d5267309c59bbfc23d971a1", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "User:', userData);\n        setUser(userData);\n\n        return true;\n      }\n      return false;\n    } catch (err: any) {\n      console.error(\"\u274c Login error:\", err);\n      const errorMsg = err.response?.data?.detail || \"Erro ao realizar login\";\n      setError(errorMsg);\n      return false;\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  const logout = () => {\n    localStorage.removeItem('token');\n    setToken(null);\n    setUser(null);\n    setIsAuthenticated(false);\n    window.location.href = '/login';\n  };\n\n  return { user, token, isAuthenticated, login, logout, loading, error };\n}\n\nexport default createRoot(createAuthStore);", "mimetype": "text/plain", "start_char_idx": 4099, "end_char_idx": 4738, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c71cffb6-87e6-4b4f-9dd6-329d0b602386": {"__data__": {"id_": "c71cffb6-87e6-4b4f-9dd6-329d0b602386", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\store\\dashboard.ts", "language": "typescript", "lines": 85, "filename": "dashboard.ts"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\store\\dashboard.ts", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\store\\dashboard.ts", "language": "typescript", "lines": 85, "filename": "dashboard.ts"}, "hash": "3055d552e0f65a8e9a395c85f531562b884f536387d3589aeb15808434c00a2a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import { createRoot, batch, createEffect } from 'solid-js';\nimport { createStore } from 'solid-js/store';\nimport { analyticsApi, KpiMetrics, TopQueryItem } from '@/lib/api';\n\ninterface DashboardState {\n  // Grid Data\n  data: TopQueryItem[]; // Now uses TopQueryItem\n  \n  // KPI Data\n  summary: KpiMetrics | null; // Now uses KpiMetrics\n  \n  // System State\n  isLoading: boolean;\n  error: string | null;\n  lastUpdate: Date | null;\n  isLive: boolean; // Controle do polling\n}\n\nfunction createDashboardStore() {\n  const [state, setState] = createStore<DashboardState>({\n    data: [],\n    summary: null,\n    isLoading: false,\n    error: null,\n    lastUpdate: null,\n    isLive: true\n  });\n\n  let intervalId: number;\n\n  const fetchData = async () => {\n    if (!state.data.length) setState('isLoading', true); // S\u00f3 mostra loading no primeiro load\n    \n    try {\n      // Buscar dados em paralelo dos novos endpoints\n      const [kpisRes, topQueriesRes] = await Promise.all([\n        analyticsApi.getKpis(),\n        analyticsApi.getTopQueries(7, 10) // Top 10 queries dos \u00faltimos 7 dias para a grid\n      ]);\n\n      batch(() => {\n        setState('summary', kpisRes.data); // KpiMetrics\n        setState('data', topQueriesRes.data); // TopQueryItem[]\n        setState('lastUpdate', new Date());\n        setState('error', null);\n        setState('isLoading', false);\n      });\n    } catch (err) {\n      console.error(\"Dashboard fetch error:\", err);\n      setState('error', \"Falha ao atualizar dados.\");\n      setState('isLoading', false);\n      // Se falhar, para o polling para n\u00e3o floodar erros\n      stopPolling(); \n    }\n  };\n\n  const startPolling = () => {\n    fetchData(); // Busca imediata\n    if (intervalId) clearInterval(intervalId);\n    intervalId = setInterval(fetchData, 5000); // Atualiza a cada 5s\n    setState('isLive', true);\n  };\n\n  const stopPolling = () => {\n    clearInterval(intervalId);\n    setState('isLive', false);\n  };\n\n  const togglePolling = () => {\n    if (state.isLive) stopPolling();\n    else startPolling();\n  };\n\n  // Iniciar polling automaticamente apenas se estiver logado (verifica\u00e7\u00e3o feita na view)\n  createEffect(() => {\n    const token = localStorage.getItem('token');\n    if (token && !state.isLive) {\n        startPolling();\n    }\n  });\n  \n  return { state, startPolling, stopPolling, togglePolling, fetchData };\n}\n\nexport default createRoot(createDashboardStore);", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2398, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7432f979-1fa6-43ce-89a5-8e1f649657c4": {"__data__": {"id_": "7432f979-1fa6-43ce-89a5-8e1f649657c4", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\__tests__\\App.test.tsx", "language": "typescript", "lines": 29, "filename": "App.test.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\__tests__\\App.test.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\__tests__\\App.test.tsx", "language": "typescript", "lines": 29, "filename": "App.test.tsx"}, "hash": "c57ce749fe3f44a745828b4d5a08f4ba040b9ef6c8bd26412ff3e68d98e64a41", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import { render, screen } from '@solidjs/testing-library';\nimport { describe, it, expect, beforeEach } from 'vitest';\nimport { Router, Route } from '@solidjs/router';\nimport Login from '../pages/Login';\nimport Dashboard from '../pages/Dashboard';\nimport Chat from '../pages/Chat';\n\ndescribe('App Component Tests', () => {\n  beforeEach(() => {\n    // Limpar localStorage antes de cada teste\n    localStorage.clear();\n  });\n\n  it('should render Login page', () => {\n    const { container } = render(() => (\n      <Router>\n        <Route path=\"/login\" component={Login} />\n      </Router>\n    ));\n\n    expect(container).toBeDefined();\n  });\n\n  it('should have root element in HTML', () => {\n    const root = document.getElementById('root');\n    expect(root).toBeDefined();\n  });\n});", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 779, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2c89f047-49ae-46a9-af99-88795c2208a0": {"__data__": {"id_": "2c89f047-49ae-46a9-af99-88795c2208a0", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\__tests__\\ErrorBoundary.test.tsx", "language": "typescript", "lines": 30, "filename": "ErrorBoundary.test.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\__tests__\\ErrorBoundary.test.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\__tests__\\ErrorBoundary.test.tsx", "language": "typescript", "lines": 30, "filename": "ErrorBoundary.test.tsx"}, "hash": "0a6582ddda2a4f114b582e1f74644179c8a47430046d240b04573e6b4abcaf28", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import { render } from '@solidjs/testing-library';\nimport { describe, it, expect } from 'vitest';\nimport { ErrorBoundary } from '../components/ErrorBoundary';\n\ndescribe('ErrorBoundary Component', () => {\n  it('should render children when no error', () => {\n    const { container } = render(() => (\n      <ErrorBoundary>\n        <div>Test Content</div>\n      </ErrorBoundary>\n    ));\n\n    expect(container.textContent).toContain('Test Content');\n  });\n\n  it('should render error message when error occurs', () => {\n    const ThrowError = () => {\n      throw new Error('Test error');\n    };\n\n    const { container } = render(() => (\n      <ErrorBoundary>\n        <ThrowError />\n      </ErrorBoundary>\n    ));\n\n    expect(container.textContent).toContain('Ops! Algo deu errado');\n  });\n});", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 786, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "dc9ae1a7-24a9-4db2-a52c-ac1320fbd083": {"__data__": {"id_": "dc9ae1a7-24a9-4db2-a52c-ac1320fbd083", "embedding": null, "metadata": {"file_path": "frontend-solid\\src\\__tests__\\Layout.test.tsx", "language": "typescript", "lines": 36, "filename": "Layout.test.tsx"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "frontend-solid\\src\\__tests__\\Layout.test.tsx", "node_type": "4", "metadata": {"file_path": "frontend-solid\\src\\__tests__\\Layout.test.tsx", "language": "typescript", "lines": 36, "filename": "Layout.test.tsx"}, "hash": "95085520cc5069d4836c7d9ac4e97b66dad523c71c55a6b1cae70aa4d372cf2e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import { render } from '@solidjs/testing-library';\nimport { describe, it, expect, beforeEach } from 'vitest';\nimport { Router } from '@solidjs/router';\nimport Layout from '../Layout';\n\ndescribe('Layout Component', () => {\n  beforeEach(() => {\n    localStorage.clear();\n  });\n\n  it('should render Layout component', () => {\n    const { container } = render(() => (\n      <Router>\n        <Layout>\n          <div>Test Content</div>\n        </Layout>\n      </Router>\n    ));\n\n    expect(container).toBeDefined();\n  });\n\n  it('should display Agent BI branding', () => {\n    const { container } = render(() => (\n      <Router>\n        <Layout>\n          <div>Test Content</div>\n        </Layout>\n      </Router>\n    ));\n\n    const text = container.textContent;\n    expect(text).toContain('Agent BI');\n  });\n});", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 805, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}}}