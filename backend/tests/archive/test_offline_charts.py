import asyncio
import sys
import os
import json
from langchain_core.messages import HumanMessage
from app.config.settings import settings

# Force 'mock' just in case
settings.LLM_PROVIDER = "mock"

from app.orchestration.graph import build_bi_agent_graph

async def verify_offline_charts():
    print(f"üîß CONFIG ATUAL: LLM_PROVIDER={settings.LLM_PROVIDER}")
    print("üöÄ Construindo Grafo...")
    app = build_bi_agent_graph()
    
    # Test case: Chart
    query = "gr√°fico de vendas por grupo"
    print(f"\nüìù Query: {query}")
    
    try:
        inputs = {"messages": [HumanMessage(content=query)]}
        result = await app.ainvoke(inputs)
        
        last_msg = result["messages"][-1]
        content = last_msg.content
        
        print(f"üìÑ Resposta Final (Length: {len(content)}):")
        print(content[:500] + "..." if len(content) > 500 else content)
        
        # Verify if JSON block is present
        if "```json" in content and "chart_spec" in content:
            print("\n‚úÖ SUCESSO! JSON de gr√°fico detectado na resposta.")
        else:
            print("\n‚ùå FALHA: Resposta n√£o cont√©m bloco JSON de gr√°fico esperado.")
            
    except Exception as e:
        print(f"‚ùå ERRO: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(verify_offline_charts())
